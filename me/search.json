[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Managerial Economics",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-the-notes",
    "href": "index.html#about-the-notes",
    "title": "Managerial Economics",
    "section": "About the notes",
    "text": "About the notes\n\n\n\n\n\n\nNotable changes\n\n\n\nOctober 22: I added 10  Under constraints and Appendix A — Microeconomic preliminaries. Moreover, I added exercises in 4  Certainty, 5  Uncertainty, and 8  Games.\nNovember 20: I changed the appearance of 9.3 A note on growth rates and the logarithm a bit to make things a bit clearer, I fixed some issues with the cross-referencing and the PDF, and I added 12  Efficiency and effectiveness, 13  Perfect, 14  Monopoly, and 15  Regional (preliminary).\n\n\n\n\n\n\n\n\nA PDF version of these notes is available here.\n\n\n\nPlease note that while the PDF contains the same content, it has not been optimized for PDF format. Therefore, some parts may not appear as intended.\n\n\n\nThese notes aims to support my lecture at the HS Fresenius but are incomplete and no substitute for taking actively part in class.\nI appreciate you reading it, and I appreciate any comments.\nThis is work in progress so please check for updates regularly.\nFor making an appointment, you can use the online tool that you find on my private homepage: https://hubchev.github.io/",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "Managerial Economics",
    "section": "About the author",
    "text": "About the author\n\n\n\nFigure 1: Prof. Dr. Stephan Huber\n\n\n\n\n\n\nI am a Professor of International Economics and Data Science at HS Fresenius, holding a Diploma in Economics from the University of Regensburg and a Doctoral Degree (summa cum laude) from the University of Trier. I completed postgraduate studies at the Interdisciplinary Graduate Center of Excellence at the Institute for Labor Law and Industrial Relations in the European Union (IAAEU) in Trier. Prior to my current position, I worked as a research assistant to Prof. Dr. Dr. h.c. Joachim Möller at the University of Regensburg, a post-doc at the Leibniz Institute for East and Southeast European Studies (IOS) in Regensburg, and a freelancer at Charles University in Prague.\nThroughout my career, I have also worked as a lecturer at various institutions, including the TU Munich, the University of Regensburg, Saarland University, and the Universities of Applied Sciences in Frankfurt and Augsburg. Additionally, I have had the opportunity to teach abroad for the University of Cordoba in Spain, the University of Perugia in Italy, and the Petra Christian University in Surabaya, Indonesia. My published work can be found in international journals such as the Canadian Journal of Economics and the Stata Journal. For more information on my work, please visit my private homepage at hubchev.github.io.\n\n\n\n\n\n\nContact:\n\n\n\n\n\nProf. Dr. Stephan Huber\nHochschule Fresenius für Wirtschaft & Medien GmbH\nIm MediaPark 4c\n50670 Cologne\nOffice: 4e OG-3\nTelefon: +49 221 973199-523\nMail: stephan.huber@hs-fresenius.de\nPrivate homepage: www.hubchev.github.io\nGithub: https://github.com/hubchev",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "Managerial Economics",
    "section": "About this course",
    "text": "About this course\nWorkload: 125 h = 42 h (in-class) + 21 h (guided private study hours) - 62 h (private self-study).\nAssessment Students complete this module with a written exam of 90 minutes. A passing grade in this module is achieved when the overall grade is greater than or equal to 4.0.\nLearning outcomes: After successful completion of the module, students are able to:\n\ndescribe how tools of standard price theory, location theory, production theory, and the theory of investment decision can be employed to formulate a decision problem,\nevaluate alternative courses of action and choose among alternatives,\napply economic concepts and techniques in evaluating strategic business decisions taken by firms,\napply the knowledge of the mechanics of supply and demand to explain the functioning of markets.\n\nHow to prepare for the exam: I am convinced that reading the lecture notes, preparing for class, taking actively part in class, and trying to solve the exercises without going straight to the solutions is the best method for students to\n\nmaximize leisure time and minimize the time needed to prepare for the exam, respectively,\ngetting long-term benefits out of the course,\nimprove grades, and\nhave more fun during lecture hours.\n\nLiterature: Bazerman & Moore (2012), Hoover & Giarratani (2020), Parkin et al. (2017), Wilkinson (2022), Bonanno (2017)\n\nBazerman, M. H., & Moore, D. A. (2012). Judgement in managerial decision making. In Inc. Hoboken, NJ, USA (8th ed.). John Wiley & Sons.\n\nHoover, E. M., & Giarratani, F. (2020). An introduction to regional economics (S. Loveridge & R. Jackson, Eds.; 4th ed.). reprint, edited by Scott Loveridge; Randall Jackson, Regional Research Institute, West Virginia University.\n\nParkin, M., Powell, M., & Matthews, K. (2017). Economics: European edition (10th ed.). Pearson Education Limited.\n\nWilkinson, N. (2022). Managerial economics problem-solving in a digital world (2nd ed.). Cambridge University Press.\n\nBonanno, G. (2017). Decision making. Accessed March 21, 2023. https://faculty.econ.ucdavis.edu/faculty/bonanno/DM_Book.html\nContent:\n\nPrice theory\n\nthe market price of an efficient competitive market and sources of inefficiency\nthe impact of supply and demand on the market price\nthe output and price decision of a profit maximizing monopolist\nregional market power and price setting\n\n\n\nProduction and cost theory\n\noutput and costs of firms in the short and long run\noptimization under constraints (Lagrangian multiplier)\ncost-volume-profit analysis\n\n\n\nLocation theory\n\nHotelling’s location model\nThünen’s model of agricultural land use\nlocation fundamentals and agglomeration forces (sharing, matching, learning)\n\n\n\nStrategic behaviour of firms\n\nnature, scope, and elements of game theory\nstatic games\nlimitations\n\n\n\nInvestment decisions\n\nnet present value\ninternal rate of return\ndecision-making under risk\ndecision-making under uncertainty\ncommon pitfalls in investment decisions",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-prepare-for-the-exam",
    "href": "index.html#how-to-prepare-for-the-exam",
    "title": "Managerial Economics",
    "section": "How to prepare for the exam",
    "text": "How to prepare for the exam\n\n\n\nFigure 2: Richard P. Feynman’s Los Alamos ID badge\n\n\n\nSource: https://en.wikipedia.org/wiki/File:Richard_Feynman_Los_Alamos_ID_badge.jpg\n\n\n\nRichard P. Feynman (1918-1988) was a team leader at the Manhatten Project (see Figure 2) and won the Nobel Prize in 1965 in physics. He once said:\n\n“I don’t know what’s the matter with people: they don’t learn by understanding; they learn by some other way – by rote, or something. Their knowledge is so fragile!” (Feynman, 1985)\n\nFeynman, R. P. (1985). Surely you’re joking, Mr. Feynman!: Adventures of a curious character. W.W. Norton.\n\nOf course, the key to learning is understanding. However, I believe that there is no understanding without practice, that is, solving problems and exercises by yourself with a pencil and a blank sheet of paper without knowing the solution in advance. Thus, I recommend the following:\n\nAttend lectures and and take the opportunity to ask questions and actively participate in class.\nStudy the lecture notes and work on the exercises.\nReview the material regularly each week. Learning in small increments is more effective than last-minute cramming.\nTest yourself with past exams that you find in the appendix.\nIf you have the opportunity to form a study group, make use of it. It is great to help each other, and it is very motivating to see that everyone has problems sometimes.\nIf you have difficulties with some exercises and the solutions shown do not solve your problem, ask a classmate or contact me.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "whatisme.html",
    "href": "whatisme.html",
    "title": "1  What is managerial economics?",
    "section": "",
    "text": "1.1 What is managerial economics for Wikipedia?\nAs a student, you might wonder what managerial economics really is. Well, there isn’t a single well-accepted definition. However, there are certain ideas that many people agree on.\nIn simple terms, managerial economics is about applying economic theories to make better decisions in business and management. It’s about using tools from economics to solve real-world problems that companies face every day. That means, any sort of method, information, and knowledge from economic research that can help managers in making good decisions.\nIf you’re curious about what most people mean by managerial economics, sources like Wikipedia can give you a good starting point. While I wouldn’t suggest citing Wikipedia in academic papers1 or using ChatGPT to generate text, it can provide helpful, widely accepted definitions and give you an overview of the topic.\nRead https://en.wikipedia.org/wiki/Managerial_economics",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is managerial economics?</span>"
    ]
  },
  {
    "objectID": "whatisme.html#what-is-managerial-economics-for-chatgpt",
    "href": "whatisme.html#what-is-managerial-economics-for-chatgpt",
    "title": "1  What is managerial economics?",
    "section": "1.2 What is managerial economics for ChatGPT?",
    "text": "1.2 What is managerial economics for ChatGPT?\nMe: Define managerial economics\n\n\n\n\n\n\nChatGPT (4.0):\n\n\n\nManagerial economics is a discipline that combines economic theory with managerial practice. It helps in analyzing business situations and decision-making processes within an organization. By applying microeconomic principles and tools, managerial economics aids managers in planning, optimizing resource use, forecasting future conditions, and making strategic decisions that enhance the organization’s performance. It encompasses various aspects of both economics and business, such as demand analysis, production and cost functions, pricing strategies, risk analysis, and capital budgeting.\nKey areas of focus in managerial economics include:\nDemand Analysis and Forecasting: Understanding consumer behavior and predicting future market trends to make informed decisions.\nProduction and Cost Analysis: Evaluating the production process and cost functions to optimize efficiency and reduce expenses.\nPricing Decisions: Developing pricing strategies that maximize profits while remaining competitive in the market.\nProfit Management: Analyzing profit margins and identifying ways to increase overall profitability.\nRisk and Uncertainty Analysis: Assessing and managing risks associated with business decisions.\nCapital Budgeting: Making decisions about long-term investments and capital expenditures.\nOverall, managerial economics provides a framework for systematically thinking about business decisions and executing strategies to achieve organizational objectives.\n\n\nMe: What distinguishes managerial economics from Microeconomics and Macroeconomics?\n\n\n\n\n\n\nChatGPT (4.0):\n\n\n\nManagerial economics, microeconomics, and macroeconomics are all subfields of economics, but they differ in their focus, scope, and application. Here’s how they are distinguished from one another:\nManagerial Economics\nScope and Focus:\nOrganizational Level: Primarily focuses on the firm or organization, aiming to solve specific managerial and business problems.\nDecision-Making: Applies economic theories and principles to managerial decision-making processes, such as pricing, production, costs, and resource allocation.\nPractical Application: Designed to be directly applicable by managers for optimizing business operations and strategic planning.\nMicroeconomics\nScope and Focus:\nIndividual and Firm Level: Concentrates on the behaviors of individuals, households, and firms.\nMarket Mechanisms: Studies how these entities interact within markets, how prices are determined, and how resources are allocated.\nTheoretical Framework: Provides the underlying theories that explain demand and supply, elasticity, consumer behavior, production, and costs.\nMacroeconomics\nScope and Focus:\nEconomy-Wide Perspective: Looks at the entire economy rather than individual units.\nAggregate Indicators: Studies large-scale economic factors such as national income, unemployment rates, inflation, GDP, and overall economic growth.\nPolicy Implications: Often deals with government policies, monetary and fiscal policy, and their impact on the economy as a whole.\nKey Differences\nScale:\nManagerial Economics: Focuses on optimizing decisions within individual firms or organizations.\nMicroeconomics: Explores the behavior of individual agents such as consumers and firms.\nMacroeconomics: Examines aggregate economic variables and economy-wide phenomena.\nApplication:\nManagerial Economics: Directly used by managers to make practical business decisions.\nMicroeconomics: Provides foundational theories that inform both managerial economics and broader economic policies.\nMacroeconomics: Used by policymakers to shape economic policy and understand economic fluctuations on a national or global scale.\nObjective:\nManagerial Economics: Goal-oriented towards improving organizational efficiency and profitability.\nMicroeconomics: Aims to understand the fundamental aspects of supply and demand and market mechanisms.\nMacroeconomics: Seeks to explain economic trends and issues that affect the economy as a whole.\nIn essence, while managerial economics draws heavily from microeconomic theories, it is distinct in its focus on practical application within firms. Macroeconomics, on the other hand, operates at a higher level of abstraction, dealing with broad economic indicators and policies.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is managerial economics?</span>"
    ]
  },
  {
    "objectID": "whatisme.html#what-is-economics",
    "href": "whatisme.html#what-is-economics",
    "title": "1  What is managerial economics?",
    "section": "1.3 What is economics?",
    "text": "1.3 What is economics?\nAll economic questions arise because we want more than we can get. Our inability to satisfy all our wants is called scarcity and because of scarcity, we must make choices that depend on the incentives we face. An incentive is a reward that encourages or a penalty that discourages an action.\nEconomics is a social science, and as in all social sciences, many of the terms used in it are poorly defined. The following quotes can demonstrate that:\n\nJohn Maynard Keynes (1883-1946): “The theory of economics does not furnish a body of settled conclusions immediately applicable to policy. It is a method rather than a doctrine, an apparatus of the mind, a technique of thinking, which helps it possessors to draw correct conclusions.” Keynes (1921)\n\nKeynes, J. M. (1921). Money. In D. H. Robertson, Money (Cambridge Economic Handbooks). Cambridge Economic Handbooks.\n\n\nAlfred Marshall (1842-1924): “Economics is a study of mankind in the ordinary business of life; it examines that part of individual and social action which is most closely connected with the attainment and with the use of the material requisites of wellbeing.” Marshall (2009, p. 1)\n\nMarshall, A. (2009). Principles of economics: Unabridged eighth edition. Cosimo, Inc.\n\n\nGary S. Becker (1930-2014): “Economics is all about how people make choices. Sociology is about why there isn’t any choice to be made.” Becker (1960, p. 233)\n\nBecker, G. S. (1960). An economic analysis of fertility. In G. S. Becker (Ed.), Demographic and economic change in developed countries. Princeton University Press.\n\n\nColander (2006, p. 4): “Economics is the study of how human beings coordinate their wants and desires, given the decision-making mechanisms, social customs, and political realities of the society.”\n\nColander, D. C. (2006). Economics (6th ed.). McGraw-Hill Irvin.\n\n\nParkin (2012, p. 2): “Economics is the social science that studies the choices that individuals, businesses, governments, and entire societies make as they cope with scarcity and the incentives that influence and reconcile those choices.”\n\n\nGwartney et al. (2006, p. 5.): “[E]conomics is the study of human behavior, with a particular focus on human decision making.”\n\nGwartney, J. D., Stroup, R. L., Sobel, R. S., & MacPherson, D. A. (2006). Microeconomics: Private and public choice. Mason.\n\n\nBackhouse & Medema (2009, p. 222): “[E]conomics is apparently the study of the economy, the study of the coordination process, the study of the effects of scarcity, the science of choice, and the study of human behavior.”\n\n\nGreenlaw & Shapiro (2022, ch. 1): Economics seeks to solve the problem of scarcity, which is when human wants for goods and services exceed the available supply. A modern economy displays a division of labor, in which people earn income by specializing in what they produce and then use that income to purchase the products they need or want. The division of labor allows individuals and firms to specialize and to produce more for several reasons: a) It allows the agents to focus on areas of advantage due to natural factors and skill levels; b) It encourages the agents to learn and invent; c) It allows agents to take advantage of economies of scale. Division and specialization of labor only work when individuals can purchase what they do not produce in markets. Learning about economics helps you understand the major problems facing the world today, prepares you to be a good citizen, and helps you become a well-rounded thinker.\n\nGreenlaw, S. A., & Shapiro, D. (2022). Principles of economics (2nd ed.). Accessed March 11, 2023; OpenStax. https://openstax.org/details/books/principles-economics-2e\n\n\nBackhouse & Medema (2009, p. 222): “Perhaps the definition of economics is best viewed as a tool for the first day of principles classes but otherwise of little concern to practicing economists.”\n\n\nJacob Viner (1892-1970): “Economics is what economists do.” Backhouse & Medema (2009, p. 222)\n\n\nParkin (2012, p. 2): “Microeconomics is the study of the choices that individuals and businesses make, the way these choices interact in markets, and the influence of governments. […] Macroeconomics is the study of the performance of the national economy and the global economy.”\n\nParkin, M. (2012). Economics (10th ed.). Addison-Wesley.\n\nAlthough many textbook definitions are quite similar in many ways, the lack of agreement on a clear-cut definition of economics does not really matter and does not necessarily pose a problem as\n\n“[E]conomists are generally guided by pragmatic considerations of what works or by methodological views emanating from various sources, not by formal definitions.” Backhouse & Medema (2009, p. 231)\n\nBackhouse, R. E., & Medema, S. G. (2009). Retrospectives: On the definition of economics. Journal of Economic Perspectives, 23(1), 221–233.\n\nThe important questions of economics: How do choices end up determining what, where, how, and for whom goods and services get produced? And: When do choices made in the pursuit of self-interest also promote the social interest?\n\n\n\n\n\n\n\nExercise 1.1 Brain\n\n\n\nFigure 1.1: From data to decision\n\n\n\nSource: https://pixabay.com/images/id-6671455\n\n\n\nI am the author of the Managerial Economics course and I am currently looking for a cover image for my book. I have reached out to several art and marketing companies for suggestions. Now imagine you are a sales representative from one of these companies and you have designed the cover shown in the image Figure 1.1. You have three minutes to make a compelling sales pitch that convinces me to choose your design. What would you say in those three minutes?",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is managerial economics?</span>"
    ]
  },
  {
    "objectID": "dmbasics.html",
    "href": "dmbasics.html",
    "title": "2  Decision making basics",
    "section": "",
    "text": "2.1 Definition: Decision\nThe statement of Eilon (1969) still holds true:\nThe word decision stems from the latin verb decidere which can have different meanings including\nWikipedia (2024) defines decision making as follows:\nLet’s agree on the following working definition that is symbolized in Figure 2.1:",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision making basics</span>"
    ]
  },
  {
    "objectID": "dmbasics.html#definition-decision",
    "href": "dmbasics.html#definition-decision",
    "title": "2  Decision making basics",
    "section": "",
    "text": "Eilon, S. (1969). What is a decision? Management Science, 16(4), B172–B189.\n\n“An examination of the literature reveals the somewhat perplexing fact that most books on management and decision theory do not contain a specific definition of what is meant by a decision. One can find detailed descriptions of decision trees, discussions of game theory and analyses of various statistical treatments of payoffs matrices under conditions of uncertainty, but the definition of the decision activity itself is often taken for granted and is associated with making a choice between alternative courses of action.”\n\n\n\nmake explicit,\nput an end to,\nbring to conclusion,\nsettle/decide/agree (on),\ndie,\nend up,\nfail,\nfall in ruin,\nfall/drop/hang/flow down/off/over,\nsink/drop,\ncut/notch/carve to delineate,\ndetach,\ncut off/out/down,\nfell.\n\n\n\nWikipedia. (2024). Decision-making — Wikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=Decision-making&oldid=1244138603\n\n“In psychology, decision-making […] is regarded as the cognitive process resulting in the selection of a belief or a course of action among several alternative possibilities. Decision-making is the process of identifying and choosing alternatives based on the values, preferences and beliefs of the decision-maker. Every decision-making process produces a final choice, which may or may not prompt action. […] Decision-making can be regarded as a problem-solving activity yielding a solution deemed to be optimal, or at least satisfactory. It is therefore a process which can be more or less rational or irrational…”\n\n\n\nFitzgerald (2002, p. 8): “A decision is the point at which a choice is made between alternative—and usually competing—options. As such, it may be seen as a stepping-off point—the moment at which a commitment is made to one course of action to the exclusion of others.”\n\n\n\n\nFigure 2.1: Decision-making\n\n\n\nSource: Picture is taken from https://pixabay.com/de/illustrations/entscheidung-auswahl-pfad-stra%C3%9Fe-1697537\n\n\n\n\n\n\n\n\n\n\nExercise 2.1 Why are you studying here?\nThere are probably many personal reasons why you have chosen your study program. Take a moment to think about the decisions that led you to choose this program. Think back to the moment you signed the contract - was it a difficult decision? What factors influenced your choice? Perhaps you had several options; why did you ultimately choose this degree program? Think about your decision-making process and write a short summary of how you came to this decision.\n\n\n\n\n\n\n\n\n\n\n\nExercise 2.2 Solve the puzzles\n\nThe nine dots problem Connect the dots shown in figure Figure 2.2 with no more than 4 straight lines without lifting your hand from the paper.\n\n\n\n\nFigure 2.2: The nine dots problem\n\n\n\n\n\n\n\nThe tasty cake puzzle In figure Figure 2.3 you see a tasty cake with the nine dots representing strawberries. Cut this cake up with exactly four straight cuts so that each portion of the cake contains just one strawberry on the top.\nReflect on how you tried to solve the puzzles. Did you have a problem solving strategy? How did you come to the right decision? Think of restrictions you imposed on yourself which was not inherent to the problem.\n\n\n\n\nFigure 2.3: The tasty cake puzzle\n\n\n\n\n\n\n\nThe house of Santa Claus The house of Santa Claus is an old German drawing game. It goes like this: You have to draw a house in one line where you\n\nmust start at bottom left (point 1),\nyou are not allowed to lift your pencil while drawing and\nit is forbidden to repeat a line.\n\nDuring drawing you say: “Das ist das Haus des Nikolaus”. What do you think is the success-rate of kids who play this game for the first time?\n\n\n\n\nFigure 2.4: The house of Santa Claus\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere are 44 solutions (see Figure 2.5) and only 10 different ways to fail (see Figure 2.6). Thus, the probability to fail is about 18.5% and hence the probability to succeed is about 81.5%.\n\n\n\nFigure 2.5: Forty-four ways to solve the puzzle\n\n\n\nTaken from wikipedia.org.\n\n\n\n\n\n\nFigure 2.6: Ten ways to fail in the puzzle\n\n\n\nTaken from wikipedia.org.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision making basics</span>"
    ]
  },
  {
    "objectID": "dmbasics.html#how-to-characterize-decisions",
    "href": "dmbasics.html#how-to-characterize-decisions",
    "title": "2  Decision making basics",
    "section": "2.2 How to characterize decisions",
    "text": "2.2 How to characterize decisions\nDecision making is a process of investing time and effort to make a decision that leads to a results. Before we talk about the results, let’s discuss some (stereo) types of decisions that can help to design an appropriate decision making process. Using stereotypes and categorizations can be beneficial as they simplify complexities and provide guidance. For example, we often employ stereotypes to appropriately engage with others. When encountering a person dressed formally, it is generally advisable to approach them in a professional manner, even when uncertain of their preferences. In this case, our prior experiences help guide our behavior based on stereotypes.\nAccording to Fitzgerald (2002, p. 9f) decisions can be roughly divided into two generic types:\n\nRoutine decisions: Decisions that must be made at regular intervals.\nNon-routine: Unique, random, non-recurring decision situations.\n\nAnother common method of dividing decisions into two categories is as follows:\n\nOperative decisions: This type of decision usually involves day-to-day business operations. There is a lot of overlap with the routine category here. Examples of this type of decision include\n\nsetting production levels,\ndetermining employee work shifts for the upcoming week to ensure adequate coverage,\ncoordinating daily delivery routes for distributing products to customers,\ndeciding to stop production or fix a problem if quality standards are not met during routine inspections, or, when it comes to decisions in our daily lives,\nwhere, what, when, and what to eat for lunch.\n\nStrategic decisions: These decisions typically concern long-term company policies and direction. Examples include\n\nentering a new market or exiting an industry,\nchoosing a corporate design, or\nacquiring a competitor.\nIn our personal lives, a strategic decision might be choosing between renting an apartment near the university or commuting from our parents’ home.\n\n\nPeople often distinguish between decisions at work and private decisions. Private decisions affect fewer people on average, but usually the people involved are closer to you personally. However, both types of decisions involve the same things such as people (human resources), money (budgeting), buying and selling (marketing), how we do something (operations) or how we want to do it in the future (strategy and planning).\nSome decisions are more important than others because the potential impact of a decision varies, that is, the scope of a decision. For example, decisions can affect one person or millions, one pound/dollar or millions, one product/service or an entire market, one day or ten years, etc.\nHowever, it is not entirely clear how to validate the scope. It depends heavily on the perspective of the decision-maker. For a small company, for example, an investment of 10,000 euros may be a big decision, while for a multinational cooperation it is a drop in the ocean. So the scope for decisions is relative, not absolute. It depends entirely on the context in which the decision is made and on the characteristics of the person(s) making it.\n\n\n\nFigure 2.7: Conditions of decision making\n\n\n\nSource: CEOpedia (2021)\n\nCEOpedia. (2021). Rational decision making. Accessed March 11, 2023. https://ceopedia.org/index.php/Rational_decision_making\n\n\n\nThere are three general conditions (see Figure 2.7) that determine the design of the optimal decision making process:\n\nCertainty: A condition under which taking a decision involves reasonable degree of certainty about its result, what are the opportunities and what conditions accompany this decision.\nRisk: A condition under which taking a decision involves reasonable degree of certainty about its result, what are the opportunities and what conditions accompany this decision.\nUncertainty: A condition in which decision maker does not know all the choices, as well as risks associated with each of them and possible consequences.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision making basics</span>"
    ]
  },
  {
    "objectID": "dmbasics.html#rationality",
    "href": "dmbasics.html#rationality",
    "title": "2  Decision making basics",
    "section": "2.3 Rationality",
    "text": "2.3 Rationality\n\n2.3.1 The rational model\nA choice can be considered as a rational one when a individual decides for the best alternative courses of action. That is, the alternative with the greatest benefit over cost for the individual making the choice. Whatever the benefits and the costs maybe, a decision maker has to consider all and make a decision. Of course, in reality it is often difficult if not impossible to sum up benefits and costs as the nature of both may be totally different. That is what makes decision often so difficult.\nThe nature of costs and benefits is manifold and emotions in general are hard to quantify and take as a basis for a decision. To deal with that economists use a theoretical concept that measures everything in utility. That is a general and abstract measure to model worth or value. Its usage has evolved significantly over time. The term was introduced initially as a measure of pleasure or happiness within the theory of utilitarianism. For example, it represents the satisfaction or pleasure that people receive for consuming a bundle of goods and services.\n\n\n\n\n\n\nDefinition: Rational decision\n\n\n\nA rational decision is the result of a logical and systematic process in which the decision-maker evaluates\n\nall relevant and available information about\nall possible courses of action (a.k.a., alternatives) and\nall their potential outcomes,\n\naiming to choose the option that maximizes utility, where utility increases with benefits and decreases with costs.\n\n\nThe rational model assumes that actors always act in a way that maximizes their utility (as consumers) and profit (as producers) and that they are capable of arbitrarily complex considerations. This means that they consider all possible outcomes and choose the course of action that leads to the best result. In economics, this is known as the homo economicus assumption, which is a paraphrase of the assumption of perfect rationality. Of course, this assumption is highly idealized, and it is doubtful that any serious economist has ever believed it to be completely true in reality. It is important to understand the limitations of this assumption in order to make good decisions. Therefore, we will discuss the limitations in detail later. All in all, it is a useful assumption that is indispensable in theoretical research and simplifies many things in practical analysis. It makes it possible to make predictions and explain behavior to a certain extent.\nHere is an example of a logical and systematic sequence of steps for making a decision, as outlined similarly by Fitzgerald (2002, p. 13):\n\nClearly identify the problem. A problem is defined as the perceived gap between the current situation and the desired outcome.\nGenerate potential solutions. For routine decisions, various alternatives can be easily identified using established decision rules. However, non-routine decisions require a creative process to discover new alternatives.\nSelect a solution. Using appropriate analytical approaches, choose the alternative with the highest expected value. In decision theory, this is referred to as maximizing the expected utility of the outcomes.\nImplement the solution. Successful implementation requires ensuring that those responsible understand and accept their roles, and have the necessary motivation and resources for success.\nEvaluate and improve. Assess the effectiveness of the decision and refine the process for future improvements.\n\n\n\n\n\n\n\n\nExercise 2.3 Poor and irrational decisions\nPeople make poor decisions all the time. They smoke, take drugs, and harm themself in various ways, make seemingly stupid things that they regret instantaneously. Do all these people act irrational? And, what is a poor decision? What is a stupid thing? The more you think about all that the more challenging it becomes to stay within a logically consistent framework where the meaning of words doesn’t change.\nDiscuss whether taking drugs can be considered a rational choice.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTaking drugs are usually considered to be a “stupid” idea because drugs (if not taken for medical purpose) usually don’t solve problems and causes addiction and bad side effects. However they may give some sort of relieve for some short period of time. Thus, taking drugs can be considered as a rational choice for people that have strong time preferences (i.e., people that can’t take the (emotional) pain now and want to postpone it), don’t fear side effects, and have little or no hope that things will get better later or that taking any other alternative would help them solving their problem. For those people it is, at least from their perspective, a rational choice.\nOverall, I would tend to argue that taking drugs can be a rational choice if these individuals consider all (!) alternative and all (!) information available and if they analyze all (!) relevant aspects without a bias.\nIf all that hold, we can disagree and we can try our best to convince these individuals that there are better alternative courses of action. Of course, we can and I believe, we should support those human beings not taking drugs. For example, we can teach them to be more optimistic and hence weight the chances that problems can be solved better. However, we cannot claim that their decision is irrational given the conditions mentioned above hold.\nOften the conditions to not hold as desperate people are not capable to use all the information without a bias. This gives bystanders such as relatives, friends, and other authorities the legitimate to interfere. For example, doctors and national authorities can send people that are not capable to act rational to a psychological institute until they have the ability to rationally make a decision.\n\n\n\n\n\n\n\n\n\n2.3.2 Irrationality\nWhile the rational model is useful, it can also be criticized in a number of ways. One key misconception is that managers always optimize their decisions through rationality, consciously selecting and implementing the best alternatives. However, this belief rests on several questionable assumptions, as outlined by Fitzgerald (2002, p. 13):\n\nFitzgerald, S. P. (2002). Decision making. Capstone Publishing.\n\nIt is rarely possible to know in advance all possible alternative solutions and predict their specific outcomes.\nThe assumption that there is always an optimal solution among the identified alternatives may not hold true.\nAccurately and numerically weighting the alternatives, their outcome probabilities, and the relative desirability of these outcomes is often impractical.\nDecision-makers are not always purely rational; emotions, biases, and organizational politics frequently influence the process.\nBusiness decisions are not exclusively driven by the desire to maximize profits.\n\nThe rational model is considered normative because it prescribes a strict, logical sequence of steps to follow in any decision-making process. It is based on the assumption that human behavior is logical and therefore predictable in certain conditions. However, this doesn’t always reflect real-world decision-making. For example, findings from behavioral economics reveal that the concept of homo economicus, while useful, is flawed in several key aspects.\nAfter all, what would happen if economics adopted the opposite extreme, assuming individuals act irrationally? If actors behaved randomly and unpredictably, we would struggle to make any predictions, and the future would resemble a random walk. Science itself would become meaningless and unnecessary.\nClearly, the extreme of irrationality isn’t a viable alternative. So, what can we do? We can identify, explain, and account for the limitations of the homo economicus assumption in both theory and empirical analysis. Economists, and anyone applying or studying economic theories, should be aware of the pitfalls in human decision-making and recognize that our ability to act rationally is often limited.\n\n\n2.3.3 Bounded rationality\n\n\n\nFigure 2.8: Herbert A. Simon\n\n\n\nSource: Picture is taken from Nobel Foundation archive.\n\n\n\nHerbert A. Simon (1916-2001) shown in figure Figure 2.8 received the Nobel Memorial Prize in Economic Sciences in 1978 and the Turing Award1 in 1975. According to NobelPrize.org (2021), he\n1 The Turing Award is an annual prize given by the Association for Computing Machinery (ACM) for contributions of lasting and major technical importance to the computer field. It is generally recognized as the highest distinction in computer science and is known as or often referred to as `Nobel Prize of Computing’.\nNobelPrize.org. (2021). Herbert A. Simon: facts [{Nobel Prize Outreach AB} 2021.]. Accessed March 11, 2023. https://www.nobelprize.org/prizes/economic-sciences/1978/simon/facts\n\n“combined different scientific disciplines and considered new factors in economic theories. Established economic theories held that enterprises and entrepreneurs all acted in completely rational ways, with the maximization of their own profit as their only goal. In contrast, Simon held that when making choices all people deviate from the strictly rational, and described companies as adaptable systems, with physical, personal, and social components. Through these perspectives, he was able to write about decision-making processes in modern society in an entirely new way”.\n\nIn particular, he proposed bounded rationality as an alternative basis for the mathematical and neoclassical economic modelling of decision-making, as used in economics, political science, and related disciplines.\n\n\n\nFigure 2.9: Bounded rationality\n\n\n\nSource: https://thedecisionlab.com/wp-content/uploads/2019/08/Bounded-Rationality.jpg.\n\n\n\nBounded rationality proposes that decision making is constrained by managers’ ability to process information, i.e., the rationally is bounded (see figure Figure 2.9). Managers use shortcuts and rules of thumb which are based on their prior experience with similar problems and scenarios. Given the constraints of managers in their position, they do not actually optimize their choice given the available information. It is more like finding a satisfactory solution, not necessarily the best or the optimal solution.\n\n\n\n\n\n\n\nExercise 2.4 Optimal vs. satisfactory solution\nUsing the images @ref(fig:picA) to @ref(fig:picD), explain the idea of bounded rationality in the context of decision making.\n\n\n\nFigure 2.10: The idea of bounded rationality\n\n\n\n\n\n\nPicture A\n\n\n\n\n\n\n\nPicture B\n\n\n\n\n\n\n\n\n\nPicture C\n\n\n\n\n\n\n\nPicture D\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCollecting and analyzing the available information about a product is costly. It is also difficult to analyze the importance of product features for the intended purpose.\nIndividuals often use rules of thumb to make a satisfactory decision.\nIt is difficult to understand complex situations such as the market for financial products. For some people, it is simply not possible to find the best product in these complex markets.\nConsumers are often confronted with many variants of a product. The differences are negligible and therefore it is not worthwhile for consumers to analyze the situation in detail. Thus, they make a decision that may not be optimal, but they are satisfied with it.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2.5 Are we irrational?\nDiscuss the following statement:\n\nSince the rationality of individuals is bounded and it is obvious that individuals do not make optimal decisions, we can say that individuals act irrationally.\n\n\n\n\n\n\n\n\n2.3.4 Heuristics\nIn real life, we frequently rely on heuristics to solve problems and make decisions. A heuristic is any approach to solving a problem that uses a practical method that is not guaranteed to be optimal, perfect, or rational. However, a heuristic should–at best–be sufficient to achieve an immediate, short-term goal or approximation. Overall, people use heuristics because they either cannot act completely rationally or want to act rationally but do not have the time it would take to compute the perfect solution. Moreover, the effort is probably not worth it or simply not possible given the time constraints under which the problem must be solved. A heuristic is a mental shortcut or rule of thumb to make decisions and solve problems quickly and efficiently. It helps individuals to arrive at a solution without extensive analysis or evaluation of all available information. Heuristics are usefull when time, resources, or information are limited.\nWhile heuristics can be helpful in many situations, they can also lead to errors and biases, particularly when they are overused or misapplied. We will discuss some of these biases in Chapter 11 in greater detail.\n\n\n2.3.5 System 1 and System 2 Thinking\n\n\n\nFigure 2.11: Kahneman and his bestseller\n\n\n\n\n\n\nIn fact, many studies have proven that people often do not act as predicted by theories that assume a home economicus. These behavioral economic research studies the effects of psychological, cognitive, emotional, cultural and social factors on the decisions of individuals and institutions and how those decisions vary from those implied by classical economic theory. While we will discover some more details about it in Chapter 11, I recommend watching the following video about the work of Tversky and Kahneman’s work \nThe Nobel prize winner Daniel Kahneman (1934 - 2024) is probably the most well-known figure of behavioral economics (see Figure 2.11). One reason is his best-selling book Thinking Fast and Slow where he summarizes his work for a broader audience and introduced the modes of System 1 and System 2 thinking. These two modes are easy to understand and often helpful. Here is a video where he describes these two modes in his own words. \nSystem 1 thinking refers to our intuitive system, which is typically fast, automatic, effortless, implicit, and emotional. We make most decisions in life using this mode of thinking. For instance, we usually decide how to interpret verbal language or visual information automatically and unconsciously.\nBy contrast, System 2 refers to reasoning that is slower, conscious, effortful, explicit, and logical. In most situations, our System 1 thinking is quite sufficient; it would be impractical, for example, to logically reason through every choice we make while shopping for products in our daily life. But System 2 logic should preferably influence our most important decisions. The busier and more rushed people are, the more they have on their minds, and the more likely they are to rely on System 1 thinking. In fact, the pace of managerial life suggests that executives often rely on System 1 thinking. Although a complete System 2 process is not required for every managerial decision, a key goal for managers should be to identify situations in which they should move from the intuitively compelling System 1 thinking to the more logical System 2.\n\n\n\n\n\n\n\nExercise 2.6 Kahneman’s examples\nKahneman describes the two different ways the brain forms thoughts in the first section of his book as follows:\n\nSystem 1: Fast, automatic, frequent, emotional, stereotypic, unconscious.\nSystem 2: Slow, effortful, infrequent, logical, calculating, conscious.\n\nBelow is a list of things that System 1 and System 2 can do. How do you perform these tasks? Do you use more of System 1 or System 2 thinking? Mark each number with a 1 or a 2 accordingly.\n\nDetermine that an object is at a greater distance than another\nLocalize the source of a specific sound\nComplete the phrase “war and …”\nDisplay disgust when seeing a gruesome image\nSolve 2+2=?\nRead text on a billboard\nDrive a car on an empty road\nCome up with a good chess move (if you’re a chess master)\nUnderstand simple sentences\nConnect the description ‘quiet and structured person with an eye for details’ to a specific job\nBrace yourself before the start of a sprint\nDirect your attention toward the clowns at the circus\nDirect your attention toward someone at a loud party\nLook out for the woman with the gray hair\nDig into your memory to recognize a sound\nSustain a higher than normal walking rate\nDetermine the appropriateness of a particular behavior in a social setting\nCount the number of A’s in a certain text\nGive someone your phone number\nPark in a tight parking space\nDetermine the price/quality ratio of two washing machines\nDetermine the validity of complex logical reasoning\nSolve 17 x 24",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision making basics</span>"
    ]
  },
  {
    "objectID": "dmbasics.html#decision-making-strategies",
    "href": "dmbasics.html#decision-making-strategies",
    "title": "2  Decision making basics",
    "section": "2.4 Decision making strategies",
    "text": "2.4 Decision making strategies\n\n\n\n\n\n\n\nExercise 2.7 Different schemes of a decision making process\n\nGoogle for “decision making strategies” and look at the images that Google suggests you.\nRead Indeed Editorial Team (2023) and discuss the twelve decision making strategies. The article can be found here.\nCompare these strategies to the scheme shown in Figure 2.12.\n\n\n\n\nFigure 2.12: Source: https://pixabay.com/de/illustrations/entscheidung-auswahl-pfad-stra%C3%9Fe-1697537/\n\n\nDecision-making\n\n\n\n\n\nChoose a problem of your choice and try to solve the problem using the two illustrations above by making a good decision.\nDiscuss in class whether the diagram or the strategies in Indeed Editorial Team (2023) are helpful in making a wise decision or solving a problem.\nWatch https://youtu.be/pPIhAm_WGbQ and answer the following questions: How is the nature of decisions discussed here? Does it contain a rational model of problem solving? Reflect on which ways to solve a problem and come to a decision, respectively, have been addressed.\n\n\n\n\n\n\n\n\nIndeed Editorial Team. (2023). 12 decision-making strategies. Accessed March 11, 2023. https://www.indeed.com/career-advice/career-development/decision-making-strategies?utm_campaign=earnedsocial%3Acareerguide%3Ashareemail%3AUS&utm_content=12%20Decision-Making%20Strategies&utm_medium=social&utm_source=directshare\n\n\n\n\n\n\n\nExercise 2.8 The businessman and the fisherman\nA classic tale that exist in different version^[This one stems from thestorytellers.com. A famous version stems from Paulo Coelho^[See https://paulocoelhoblog.com and it goes like this:\n\nOne day a fisherman was lying on a beautiful beach, with his fishing pole propped up in the sand and his solitary line cast out into the sparkling blue surf. He was enjoying the warmth of the afternoon sun and the prospect of catching a fish.\nAbout that time, a businessman came walking down the beach, trying to relieve some of the stress of his workday. He noticed the fisherman sitting on the beach and decided to find out why this fisherman was fishing instead of working harder to make a living for himself and his family. “You aren’t going to catch many fish that way”, said the businessman to the fisherman.\n“You should be working rather than lying on the beach!” The fisherman looked up at the businessman, smiled and replied, “And what will my reward be?” “Well, you can get bigger nets and catch more fish!” was the businessman’s answer. “And then what will my reward be?” asked the fisherman, still smiling. The businessman replied, “You will make money and you’ll be able to buy a boat, which will then result in larger catches of fish!” “And then what will my reward be?”” asked the fisherman again.\nThe businessman was beginning to get a little irritated with the fisherman’s questions. “You can buy a bigger boat, and hire some people to work for you!” he said. “And then what will my reward be?” repeated the fisherman. The businessman was getting angry. “Don’t you understand? You can build up a fleet of fishing boats, sail all over the world, and let all your employees catch fish for you!”\nOnce again the fisherman asked, “And then what will my reward be?” The businessman was red with rage and shouted at the fisherman, “Don’t you understand that you can become so rich that you will never have to work for your living again! You can spend all the rest of your days sitting on this beach, looking at the sunset. You won’t have a care in the world!”\nThe fisherman, still smiling, looked up and said, “And what do you think I’m doing right now?”\n\nDefine the cost and benefits of both persons. Who do you think has a better life overall. Who is acting rationally here? In other words, who is maximizing utility here? The fishermen or the businessmen? Both? None?\n\n\n\n\n\n\n\n\n\n\nReview\n\n\n\n\nDecision analysis is about using information in order to come to a decision.\nA structured and rational process can help improve the chances of receiving good decision outcomes.\nAs decision problems are often (too) complex to fully capture or solve rationally. Thus, a good decision analysis should try to use the available information and the existing understanding of the problem as transparent, consistent, and logical as possible.\nA complex decision problem should be simplified and hence decomposed into its basic and most important components.\nThere are hundred of different schemes or strategies how to make decisions in certain circumstances. Many heuristics exist how to think, behave, and calculate to come to a wise decision.\nMostly decisions are based on subjective expectations. These expectations are difficult to validate.\nArticulating exact expectation and preferences is a difficult task and the information that stems from these articulation is full of biases. Decision analytic tools need to take that into consideration.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision making basics</span>"
    ]
  },
  {
    "objectID": "dmtheory.html",
    "href": "dmtheory.html",
    "title": "3  Payoff table",
    "section": "",
    "text": "Learning outcomes of Chapter 3 to Chapter 7\n\n\n\n\nDistinguish different theories of decision making.\nCalculate the optimal decision under certainty, uncertainty, and under risk.\nDescribe and use various criteria of decision making.\nSimplify complex decision making situations and use formal approaches of decision making to guide the decision making behavior of managers.  \n\n\n\n\n\n\n\n\n\nReadings\n\n\n\nRequired: Finne (1998)\nRecommended: Bonanno (2017, sec. 3)\n\n\n\nBonanno, G. (2017). Decision making. Accessed March 21, 2023. https://faculty.econ.ucdavis.edu/faculty/bonanno/DM_Book.html\n\nFinne, T. (1998). The three categories of decision-making and information security. Computers & Security, 17(5), 397–405.\nEvery decision has consequences. While these consequences can be complex, economists often simplify decision analysis using the concept of utility. In this framework, anything positive is regarded as utility, and anything negative is viewed as disutility. Ultimately, these outcomes can be represented by a single value, which we will refer to as the “payoff.”\nIn this sense, decision-making becomes straightforward: we simply choose the alternative that provides the highest payoff. For example, if you know the weather will be sunny, you might choose to wear a T-shirt and shorts. On a cold day, however, you would opt for warmer clothing. But since the state of nature (the weather) is not completely certain, your decision involves some degree of risk, assuming you have some idea of the likelihood of sunshine or cold weather. If you have no information about the weather at all, your decision is made under uncertainty.\nIn the following, I introduce the payoff table as a tool to stylize a situation in which a decision must be made. Specifically, I will describe three modes of decision-making: under certainty, under uncertainty, and under risk.\nA payoff table, also known as a decision matrix, can be a helpful tool for decision making, as shown in the table below. It presents the available alternatives denoted by \\(A_i\\), along with the possible future states of nature denoted by \\(N_j\\). A state of nature (or simply “state”) refers to the set of external factors (he has no direct power in it) that are relevant to the decision maker.\nThe payoff or outcome depends on both the chosen alternative and the future state of nature that occurs. For instance, if alternative \\(A_i\\) is chosen and state of nature \\(N_j\\) occurs, the resulting payoff is \\(O_{ij}\\). Our goal is to choose the alternative \\(A_i\\) that yields the most favorable outcome \\(O_{ij}\\).\nThe payoff is a numerical value that represents either profit, cost, or more generally, utility (benefit) or disutility (loss).\n\n\n\nTable 3.1: Payoff matrix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState of nature (\\(N_j\\))\n\\(N_1\\)\n\\(N_2\\)\n\\(\\cdots\\)\n\\(N_j\\)\n\\(\\cdots\\)\n\\(N_n\\)\n\n\nProbability (p)\n\\(p_1\\)\n\\(p_2\\)\n\\(\\cdots\\)\n\\(p_j\\)\n\\(\\cdots\\)\n\\(p_n\\)\n\n\nAlternative (\\(A_i\\))\n\n\n\n\n\n\n\n\n\\(A_1\\)\n\\(O_{11}\\)\n\\(O_{12}\\)\n\\(\\cdots\\)\n\\(O_{1j}\\)\n\\(\\cdots\\)\n\\(O_{1n}\\)\n\n\n\\(A_2\\)\n\\(O_{21}\\)\n\\(O_{22}\\)\n\\(\\cdots\\)\n\\(O_{2j}\\)\n\\(\\cdots\\)\n\\(O_{2n}\\)\n\n\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\n\n\\(A_i\\)\n\\(O_{i1}\\)\n\\(O_{i2}\\)\n\\(\\cdots\\)\n\\(O_{ij}\\)\n\\(\\cdots\\)\n\\(O_{in}\\)\n\n\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\n\n\\(A_m\\)\n\\(O_{m1}\\)\n\\(O_{m2}\\)\n\\(\\cdots\\)\n\\(O_{mj}\\)\n\\(\\cdots\\)\n\\(O_{mn}\\)\n\n\n\n\n\n\nIf we assume that all states are independent from each other and that we are certain about the state of nature, the decision is straightforward: just go for the alternative with the best outcome for each state of nature. However, most real-world scenarios are not that simple because most states of nature are more complex and needs further to be considered.\nDecision making under uncertainty assumes that we are fully unaware of the future state of nature.\nIf a decision should be made under risks, then we have some information about the probability that certain states appear. A decision under uncertainty simple means we have no information, that is, no probabilities.\n\n\n\n\n\n\nWarning\n\n\n\nUnless stated otherwise, the outputs in a payoff table represent utility (or profits), where a higher number indicates a better outcome. However, the outputs could also represent something negative, such as disutility (or deficits). In such cases, the interpretation—and the decision-making process—changes significantly. Please keep this in mind.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Payoff table</span>"
    ]
  },
  {
    "objectID": "certainty.html",
    "href": "certainty.html",
    "title": "4  Certainty",
    "section": "",
    "text": "Domination\nWhen a decision must be made under certainty, the state of nature is fully known, and the optimal choice is to select the alternative with the highest payoff. However, determining this payoff can be complex, as it may be the result of a sophisticated function involving multiple variables.\nFor example, imagine you need to choose between four different restaurants (\\(a_1\\), \\(a_2\\), \\(a_3\\), \\(a_4\\)). Each restaurant offers a unique combination of characteristics, such as the quality of the food (\\(k_1\\)), the quality of the music played (\\(k_2\\)), the price (\\(k_3\\)), the quality of the service (\\(k_4\\)), and the overall environment (\\(k_5\\)). The corresponding payoff Table 4.1 assigns a numerical value to each characteristic, with higher numbers indicating better quality.\nIn this scenario, \\(a_i\\) represents the different restaurant options, \\(k_i\\) refers to specific characteristics of each restaurant, and the numbers in the table indicate the payoffs associated with each characteristic.\nPlease note that the characteristics \\(k_j\\) of the scheme in Table 4.1 do not represent different states of nature but represent characteristics and its corresponding utility (whatever that number may mean in particular) of one particular characteristics if we choose a respective alternative.\nTo arrive at an overall outcome for each alternative and make an informed decision, the first step is to determine whether any alternatives are dominated by others. An alternative is considered dominated if it is not superior in any characteristic compared to at least one other alternative.\nDominated alternatives can be excluded from consideration. For example, in Table 4.2, we can see that alternative 2 outperforms alternative 3. This makes it unnecessary to consider alternative 3 in the decision-making process.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Certainty</span>"
    ]
  },
  {
    "objectID": "certainty.html#domination",
    "href": "certainty.html#domination",
    "title": "4  Certainty",
    "section": "",
    "text": "Table 4.2: Alternative 3 is dominated by alternative 2\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\n\n\n\n\n\\(a_1\\)\n3\n0\n7\n1\n4\n\n\n\\(a_2\\)\n4\n1\n4\n2\n1\n\n\n\\(a_3\\)\n4\n0\n3\n2\n1\n\n\n\\(a_4\\)\n5\n1\n2\n3\n1",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Certainty</span>"
    ]
  },
  {
    "objectID": "certainty.html#weighting",
    "href": "certainty.html#weighting",
    "title": "4  Certainty",
    "section": "Weighting",
    "text": "Weighting\n\nNo preferences\nStill, we have three alternative left. How to decide? Well, we need to become clear what characteristics matter (most). Suppose you don’t have any preferences than you would go for restaurant \\(a_1\\) because it offers the best average value, see Table 4.3.\n\n\n\nTable 4.3: Alternative 1 is the best on average\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\nOverall\n\n\n\n\n\\(a_1\\)\n3\n0\n7\n1\n4\n14/5\n\n\n\\(a_2\\)\n4\n1\n4\n2\n1\n12/5\n\n\n\\(a_4\\)\n5\n1\n2\n3\n1\n12/5\n\n\n\n\n\n\n\n\nClear preferences\nSuppose you have a preference for the first three characteristics, that are quality of the food (\\(k_1\\)), the quality of the music played (\\(k_2\\)), and the price (\\(k_3\\)). Specifically, suppose that your preference scheme is as follows:\n\\[\ng_1 : g_2 : g_3 : g_4 : g_5 = 3 : 4 : 3 : 1 : 1\n\\]\nThis means, for example, that you value music (\\(k_2\\)) four times more than the quality of the service (\\(k_4\\)) and the overall environment (\\(k_5\\)). The weights assigned to each characteristic are:\n\\[\nw_1=3/12; w_2=4/12; w_3=3/12; w_4 = w_5 =1/12.\n\\]\nTo determine the best decision, you can calculate the aggregated expected utility for each alternative as follows:\n\\[\n\\Phi(a_i)=\\sum_{c}w_p\\cdot u_{ic} \\rightarrow max,\n\\]\nwhere \\(u_{ic}\\) represents the utility (or value) of alternative \\(i\\) for a given characteristic \\(c\\). The results of this calculation are shown in Table 4.4.\n\n\n\nTable 4.4: Results with preferences given\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\n\\(\\Phi(a_i)\\)\n\n\n\n\n\\(a_1\\)\n3\n0\n7\n1\n4\n35/12\n\n\n\\(a_2\\)\n4\n1\n4\n2\n1\n31/12\n\n\n\\(a_4\\)\n5\n1\n2\n3\n1\n29/12\n\n\n\n\n\n\nThus, alternative \\(a_1\\) offers the best value given the preference scheme outlined above. In summary, we express the choice as follows: \\[a_1\\succ a_2 \\succ a_4 \\succ a_3,\\] where \\(\\succ\\) represents the preference relation (that is, “is preferred to”). If two alternatives offer the same value and we are indifferent between them, we can use the symbol \\(\\sim\\) to represent this indifference.\n\n\nMaximax (go for cup)\nIf you like to go for cup, that is, you search for a great experience in at least one characteristic, then, you can choose the alternative that gives the maximum possible output in any characteristic. The choice would in our example be (see Table 4.5): \\[a_1\\succ a_4 \\succ a_2 \\sim a_3,\\]\n\n\n\nTable 4.5: Results with maximax\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\nOverall\n\n\n\n\n\\(a_1\\)\n3\n0\n7\n1\n4\n7\n\n\n\\(a_2\\)\n4\n1\n4\n2\n1\n4\n\n\n\\(a_3\\)\n4\n0\n3\n2\n1\n4\n\n\n\\(a_4\\)\n5\n1\n2\n3\n1\n5\n\n\n\n\n\n\n\n\nMinimax (best of the worst)\nThe Minimax (or maximin) criterion is a conservative criterion because it is based on making the best out of the worst possible conditions. The choice would in our example be (see Table 4.6): \\[a_2\\sim a_4 \\succ a_1 \\sim a_3,\\]\n\n\n\nTable 4.6: Results with maximax\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\nOverall\n\n\n\n\n\\(a_1\\)\n3\n0\n7\n1\n4\n0\n\n\n\\(a_2\\)\n4\n1\n4\n2\n1\n1\n\n\n\\(a_3\\)\n4\n0\n3\n2\n1\n0\n\n\n\\(a_4\\)\n5\n1\n2\n3\n1\n1\n\n\n\n\n\n\n\n\nKörth’s Maximin-Rule\nAccording to this rule, we compare alternatives by the worst possible outcome under each alternative, and we should choose the one which maximizes the utility of the worst outcome. More concrete, the procedure consists of 4 steps:\n\nCalculate the utility maximum for each column \\(c\\) of the payoff matrix (see Table 4.7): \\[\\overline{O}_c=\\max_{i=1,\\dots,m}{O_{ic}}\\qquad \\forall c.\\]\n\n\n\n\nTable 4.7: Best utility per alternative\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\n\n\n\n\n\\(a_1\\)\n3\n0\n7\n1\n4\n\n\n\\(a_2\\)\n4\n1\n4\n2\n1\n\n\n\\(a_3\\)\n4\n0\n3\n2\n1\n\n\n\\(a_4\\)\n5\n1\n2\n3\n1\n\n\n\\(\\overline{O}_c\\)\n5\n1\n7\n3\n4\n\n\n\n\n\n\n\nCalculate for each cell the relative utility (see Table 4.8), \\[\\frac{O_{ij}}{\\overline{O}_j}.\\]\n\n\n\n\nTable 4.8: Best relative utility\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\n\n\n\n\n\\(a_1\\)\n3/5\n0/1\n7/7\n1/3\n4/4\n\n\n\\(a_2\\)\n4/5\n1/1\n4/7\n2/3\n1/4\n\n\n\\(a_3\\)\n4/5\n0/1\n3/7\n2/3\n1/4\n\n\n\\(a_4\\)\n5/5\n1/1\n2/7\n3/3\n1/4\n\n\n\n\n\n\n\nCalculate for each row \\(i\\) the minimum (see Table 4.9): \\[\\Phi(a_i)=\\min_{j=1,\\dots,p}\\left(\\frac{O_{ij}}{\\overline{O}_j}\\right) \\qquad \\forall i.\\]\n\n\n\n\nTable 4.9: Relative minimum for each alternative\n\n\n\n\n\n\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\n\\(\\Phi(a_i)\\)\n\n\n\n\n\\(a_1\\)\n3/5\n0/1\n7/7\n1/3\n4/4\n0\n\n\n\\(a_2\\)\n4/5\n1/1\n4/7\n2/3\n1/4\n1/4\n\n\n\\(a_3\\)\n4/5\n0/1\n3/7\n2/3\n1/4\n0\n\n\n\\(a_4\\)\n5/5\n1/1\n2/7\n3/3\n1/4\n1/4\n\n\n\n\n\n\n\nSet preferences by maximizing \\(\\Phi(a_i)\\): \\[a_2\\sim a_4 \\succ a_1 \\sim a_3,\\]\n\n\n\n\n\n\n\n\nExercise 4.1 Körth\nFor the following payoff-matrix, calculate the order of preferences based on Körth’s Maximin-Rule.\n\n\n\n\\(O_{ij}\\)\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\n\n\n\n\n\\(a_1\\)\n3\n0\n7\n1\n4\n\n\n\\(a_2\\)\n4\n0\n4\n2\n1\n\n\n\\(a_3\\)\n4\n-1\n3\n2\n1\n\n\n\\(a_4\\)\n5\n1\n3\n3\n1\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(\\overline{O}_1=5; \\overline{O}_2=1; \\overline{O}_3=7; \\overline{O}_4=3; \\overline{O}_5=4\\)\n\n\n\n\\(O_{ij}\\)\n\\(k_1\\)\n\\(k_2\\)\n\\(k_3\\)\n\\(k_4\\)\n\\(k_5\\)\n\\(\\Phi(a_i)\\)\n\n\n\n\n\\(a_1\\)\n3/5\n0\n1\n1/3\n1\n0\n\n\n\\(a_2\\)\n4/5\n0\n4/7\n2/3\n1/4\n0\n\n\n\\(a_3\\)\n4/5\n-1\n3/7\n2/3\n1/4\n-1\n\n\n\\(a_4\\)\n1\n1\n3/7\n1\n1/4\n1/4\n\n\n\n\\(a_4\\succ a_1 \\sim a_2 \\succ a_3\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 4.2 Given the following payoff table Table 4.10 where high numbers indicate high utility, ranging from \\(0\\) (no utility) to \\(10\\) (high utility).\n\n\n\nTable 4.10: Payoff table\n\n\n\n\n\n\nz1\nz2\nz3\nz4\nz5\n\n\n\n\na1\n1\n2\n3\n4\n3\n\n\na2\n4\n3\n2\n1\n4\n\n\na3\n4\n5\n0\n5\n6\n\n\na4\n1\n5\n1\n5\n6\n\n\na5\n2\n2\n2\n1\n3\n\n\na6\n3\n4\n0\n5\n3\n\n\n\n\n\n\n\nState which alternatives can be excluded because they are dominated by other alternatives.\n\nSuppose your preference scheme is as follows: \\[g_1 = \\frac{1}{2}; \\quad g_2= 1; \\quad  g_3= 2;\\quad  g_4=1;\\quad  g_5=1.\\] Find the order of preference based on the aggregated expected utility.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Certainty</span>"
    ]
  },
  {
    "objectID": "uncertainty.html",
    "href": "uncertainty.html",
    "title": "5  Uncertainty",
    "section": "",
    "text": "Laplace criterion\nWhen a decision must be made under uncertainty, the state of nature is fully unknown. That is, different possible states of nature exist but no information on their probability of occurrences are given. The optimal rational choice can’t be made without a criterion that reflect preferences such as risk aversion. In the following, I discuss some popular criteria.\nThe Laplace criterion assigns equal probabilities to all possible payoffs for each alternative, then selects the alternative with the highest expected payoff. An example can be found in Finne (1998). In Table 5.1 are the data for another example. According to the expected average utility, the decision should be \\[a_2\\succ a_1 \\succ a_3.\\]",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uncertainty</span>"
    ]
  },
  {
    "objectID": "uncertainty.html#laplace-criterion",
    "href": "uncertainty.html#laplace-criterion",
    "title": "5  Uncertainty",
    "section": "",
    "text": "Table 5.1: Example data for uncertainty\n\n\n\n\n\nAlternatives\n\\(N_1\\)\n\\(N_2\\)\n\\(N_3\\)\nLaplace\nMaximax\nMinimax\n\n\n\n\n\\(a_1\\)\n30\n40\n50\n120/3\n50\n30\n\n\n\\(a_2\\)\n25\n70\n30\n125/3\n70\n25\n\n\n\\(a_3\\)\n10\n20\n80\n110/3\n80\n10",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uncertainty</span>"
    ]
  },
  {
    "objectID": "uncertainty.html#maximax-criterion-go-for-cup",
    "href": "uncertainty.html#maximax-criterion-go-for-cup",
    "title": "5  Uncertainty",
    "section": "Maximax criterion (go for cup)",
    "text": "Maximax criterion (go for cup)\nIf you’re aiming for the best possible outcome without regard for the potential worst-case scenario, you would choose the alternative with the highest possible payoff. This “go for cup” approach focuses on maximizing the best-case outcome.\nIn the example of Table 5.1, the decision applying the Maximax strategy is \\[a_3\\succ a_2 \\succ a_1.\\]",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uncertainty</span>"
    ]
  },
  {
    "objectID": "uncertainty.html#minimax-criterion-best-of-the-worst",
    "href": "uncertainty.html#minimax-criterion-best-of-the-worst",
    "title": "5  Uncertainty",
    "section": "Minimax criterion (best of the worst)",
    "text": "Minimax criterion (best of the worst)\nThe Minimax (or Maximin) criterion is a conservative approach, aimed at securing the best outcome under the worst possible conditions. This approach is often used by risk-averse decision-makers. For examples on how to apply this criterion, see Finne (1998).\nIn the example of Table 5.1, the decision applying the Maximax strategy is \\[a_1\\succ a_2 \\succ a_3.\\]",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uncertainty</span>"
    ]
  },
  {
    "objectID": "uncertainty.html#savage-minimax-criterion",
    "href": "uncertainty.html#savage-minimax-criterion",
    "title": "5  Uncertainty",
    "section": "Savage Minimax criterion",
    "text": "Savage Minimax criterion\nThe Savage Minimax criterion minimizes the worst-case regret by selecting the option that performs as closely as possible to the optimal decision. Unlike the traditional minimax, this approach applies the minimax principle to the regret (that is, the difference or ratio of payoffs), making it less pessimistic. For more details, see Finne (1998).\nUsing the example data of Table 5.1, the regret table is constructed by subtracting the maximum payoff in each state from the payoffs in that state, see Table 5.2.\n\n\n\nTable 5.2: Savage regret table\n\n\n\n\n\n\n\n\n\n\n\n\nAlternatives\nRegret for \\(N_1\\)\nRegret for \\(N_2\\)\nRegret for \\(N_3\\)\nMaximum Regret\n\n\n\n\n\\(a_1\\)\n\\(30-30 = 0\\)\n\\(70-40 = 30\\)\n\\(80-50 = 30\\)\n30\n\n\n\\(a_2\\)\n\\(30-25 = 5\\)\n\\(70-70 = 0\\)\n\\(80-30 = 50\\)\n50\n\n\n\\(a_3\\)\n\\(30-10 = 20\\)\n\\(70-20 = 50\\)\n\\(80-80 = 0\\)\n50\n\n\n\n\n\n\nBased on the Savage Minimax criterion, the alternative with the smallest maximum regret should be chosen and the decision is \\[a_1\\succ a_2 \\sim a_3.\\]",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uncertainty</span>"
    ]
  },
  {
    "objectID": "uncertainty.html#hurwicz-criterion",
    "href": "uncertainty.html#hurwicz-criterion",
    "title": "5  Uncertainty",
    "section": "Hurwicz criterion",
    "text": "Hurwicz criterion\nThe Hurwicz criterion allows the decision-maker to calculate a weighted average between the best and worst possible payoff for each alternative. The alternative with the highest weighted average is then chosen.\nFor each decision alternative, the weight \\(\\alpha\\) is used to compute Hurwicz the value: \\[\nH_i=\\alpha \\cdot \\overline{O}_i + (1-\\alpha)\\cdot \\underline{O}_i\n\\] where \\[\\overline{O}_i=\\max_{j=1,\\dots,p}{O_{ij}}\\quad \\forall i\\] and\n\\[\\underline{O}_i=\\min_{j=1,\\dots,p}{O_{ij}}\\qquad \\forall i,\\] that is, the respective maximum and minimum output for each alternative, \\(i\\).\nThis formula allows for flexibility in decision-making by adjusting the value of \\(\\alpha\\), which reflects the decision-maker’s optimism (with \\(\\alpha=1\\) representing complete optimism and \\(\\alpha=0\\) representing complete pessimism).\nThe Hurwicz criterion calculates a weighted average between the best and worst payoffs for each alternative. Using the data of Table 5.1 once again, we need to assume an optimism index. Let’s say we are slightly optimistic and willing to take some risks by setting \\(\\alpha = 0.6\\).\nIn \\(a_1\\), the maximum payoff is 50 and the minimum payoff is 30. \\[ H_1 = 0.6 \\cdot 50 + (1 - 0.6) \\cdot 30 = 30 + 12 = 42 \\]\nIn \\(a_2\\), the maximum payoff is 70 and the minimum payoff is 25. \\[ H_2 = 0.6 \\cdot 70 + (1 - 0.6) \\cdot 25 = 42 + 10 = 52 \\]\nIn \\(a_3\\), the maximum payoff is 80 and the minimum payoff is 10. \\[ H_3 = 0.6 \\cdot 80 + (1 - 0.6) \\cdot 10 = 48 + 4 = 52 \\]\nThus, the decision is \\[a_2\\sim a_3 \\succ a_1.\\]\n\n\n\n\n\n\n\nExercise 5.1 Use the data of Table 5.1 to make a decision for a complete pessimist (\\(\\alpha = 0\\)) and an optimist (\\(\\alpha = 1\\))\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhen \\(\\alpha = 0\\):\n\n\\(a_1\\): ( H_1 = 30 )\n\\(a_2\\): ( H_2 = 25 )\n\\(a_3\\): ( H_3 = 10 )\n\nThus, the decision is \\[a_1\\succ a_2 \\succ a_3.\\]\nWhen \\(\\alpha = 1\\):\n\n\\(a_1\\): ( H_1 = 50 )\n\\(a_2\\): ( H_2 = 70 )\n\\(a_3\\): ( H_3 = 80 )\n\nThus, the decision is \\[a_3\\succ a_2 \\succ a_1.\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nError in Finne (1998)\n\n\n\nThe example that is shown in Figure 7 of Finne (1998, p. 401) contains some errors. Here is the correct table including the Hurwicz-values (we assume a \\(\\alpha=.5\\)):\n\n\n\n\\(O_{ij}\\)\n\\(min(\\theta_1)\\)\n\\(max(\\theta_2)\\)\n\\(H_i\\)\n\n\n\n\n\\(a_1\\)\n36\n110\n73\n\n\n\\(a_2\\)\n40\n100\n70\n\n\n\\(a_3\\)\n58\n74\n66\n\n\n\\(a_4\\)\n61\n66\n63.5\n\n\n\nThus, the order of preference is \\(a_4\\succ a_3 \\succ a_1 \\succ a_2\\).\n\n\n\n\n\n\n\n\n\nExercise 5.2 Three categories\nRead Finne (1998) and answer the following questions:\n\nExplain the three categories of decision making.\nGive examples of the three categories of decision making.\nExplain the four criteria for decision making under uncertainty.\n\n\n\n\n\n\nFinne, T. (1998). The three categories of decision-making and information security. Computers & Security, 17(5), 397–405.\n\n\n\n\n\n\n\nExercise 5.3  \n\n\n\nTable 5.3: Payoff table\n\n\n\n\n\n\nz1\nz2\nz3\n\n\n\n\na1\n0\n9\n8\n\n\na2\n8\n5\n9\n\n\na3\n1\n10\n1\n\n\na4\n4\n5\n2\n\n\na5\n9\n10\n10\n\n\n\n\n\n\nIn Table 5.3 you see a payoff table where high numbers indicate high disutility, ranging from \\(0\\) (no disutility) to \\(10\\) (high disutility).\n\nUsing this payoff table, indicate which alternatives can be excluded because they are dominated by other alternatives. (Hint: Exclude dominated alternatives in the calculations of the following questions).\n\nUsing the , calculate the complete order of preferred alternative(s), \\(a_i\\).\nUsing the , calculate the complete order of preferred alternative(s), \\(a_i\\).\nUsing the , calculate the complete order of preferred alternative(s), \\(a_i\\).",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uncertainty</span>"
    ]
  },
  {
    "objectID": "risk.html",
    "href": "risk.html",
    "title": "6  Risk",
    "section": "",
    "text": "Infinite St. Petersburg lotteries\nWhen some information is given about the probability of occurrence of states of nature, we speak of decision-making under risk. The most straight forward technique to make a decision here is to maximize the expected outcome for each alternative given the probability of occurrence, \\(p_j\\).\nHowever, the expected utility hypothesis states that the subjective value associated with an individual’s gamble is the statistical expectation of that individual’s valuations of the outcomes of that gamble, where these valuations may differ from the Euro value of those outcomes. Thus, you should better look on the utility of a respective outcome rather than on the outcome itself because the utility and outcome do not have to be linked in a linear way. The St. Petersburg Paradox by Daniel Bernoulli in 1738 is considered the beginnings of the hypothesis.\nSuppose a casino offers a game of chance for a single player, where a fair coin is tossed at each stage. The first time head appears the player gets $1. From then onwards, every time a head appears, the stake is doubled. The game continues until the first tails appears, at which point the player receives \\(\\$ 2^{k-1}\\), where k is the number of tosses (number of heads) plus one (for the final tails). For instance, if tails appears on the first toss, the player wins $0. If tails appears on the second toss, the player wins $2. If tails appears on the third toss, the player wins $4, and so on. The extensive form of the game is given in Figure 6.1.\nGiven the rules of the game, what would be a fair price for the player to pay the casino in order to enter the game?\nTo answer this question, one needs to consider the expected payout: The player has a 1/2 probability of winning $1, a 1/4 probability of winning $2, a 1/8 probability of winning $4, and so on. Thus, the overall expected value can be calculated as follows: \\[ E = \\frac{1}{2} \\cdot 1 + \\frac{1}{4} \\cdot 2 + \\frac{1}{8} \\cdot 4+ \\frac{1}{16} \\cdot 8 + \\dots \\] This can be simplified as: \\[\nE = \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\dots = + \\infty.\n\\] That means the expected win for playing this game is an infinite amount of money. Based on the expected value, a risk-neutral individual should be willing to play the game at any price if given the opportunity. The willingness to pay of most people who have given the opportunity to play the game deviates dramatically from the objectively calculable expected payout of the lottery. This describes the apparent paradox.\nIn the context of the St. Petersburg Paradox, it becomes evident that relying solely on expected values is inadequate for certain games and for making well-informed decisions. Expected utility, on the other hand, has been the prevailing concept used to reconcile actual behavior with the notion of rationality thus far.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Risk</span>"
    ]
  },
  {
    "objectID": "risk.html#infinite-st.-petersburg-lotteries",
    "href": "risk.html#infinite-st.-petersburg-lotteries",
    "title": "6  Risk",
    "section": "",
    "text": "Figure 6.1: Extensive form of the St. Petersburg paradox",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Risk</span>"
    ]
  },
  {
    "objectID": "risk.html#finite-st.-petersburg-lotteries",
    "href": "risk.html#finite-st.-petersburg-lotteries",
    "title": "6  Risk",
    "section": "Finite St. Petersburg lotteries",
    "text": "Finite St. Petersburg lotteries\nLet us assume that at the beginning, the casino and the player agrees upon how many times the coin will be tossed. So we have a finite number I of lotteries with \\(1 \\leq I \\leq \\infty\\).\nTo calculate the expected value of the game, the probability \\(p(i)\\) of throwing any number \\(i\\) of consecutive head is crucial. This probability is given by \\[\np(i)=\\underbrace{\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\cdots \\frac{1}{2}}_{i \\text { factors}}=\\frac{1}{2^{i}}\n\\] The payoff \\(W(I)\\) is, if head appears \\(I\\)-times in a row by \\[\nW(I)=2^{I-1}\n\\] The expected payoff \\(E(W(I))\\) if the coin is flipped \\(I\\) times is then given by \\[\nE(W(I))=\\sum_{i=1}^{I} p(i) \\cdot W(i)=\\sum_{i=1}^{I} \\frac{1}{2^{i}} \\cdot 2^{i-1}=\\sum_{i=1}^{I} \\frac{1}{2}=\\frac{I}{2}\n\\]\nThus, the expected payoff grows proportionally with the maximum number of rolls. This is because at any point in the game, the option to keep playing has a positive value no matter how many times head has appeared before. Thus, the expected value of the game is infinitely high for an unlimited number of tosses but not so for a limited number of tosses. Even with a very limited maximum number of tosses of, for example, \\(I = 100\\), only a few players would be willing to pay $50 for participation. The relatively high probability to leave the game with no or very low winnings leads in general to a subjective rather low evaluation that is below the expected value.\nIn the real world, we understand that money is limited and the casino offering this game also operates within a limited budget. Let’s assume, for example, that the casino’s maximum budget is $20,000,000. As a result, the game must conclude after 25 coin tosses because \\(2^{25} = 33,554,432\\) would exceed the casino’s financial capacity. Consequently, the expected value of the game in this scenario would be significantly reduced to just $12.50. Interestingly, if you were to ask people, most would still be willing to pay less than $12.50 to participate. How can we explain this? Well, it is not the expected outcome that matters but the utility that stems from the outcome.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Risk</span>"
    ]
  },
  {
    "objectID": "risk.html#the-impact-of-output-on-utility-matters",
    "href": "risk.html#the-impact-of-output-on-utility-matters",
    "title": "6  Risk",
    "section": "The impact of output on utility matters",
    "text": "The impact of output on utility matters\nDaniel Bernoulli (1700 - 1782) worked on the paradox while being a professor in St. Petersburg. His solution builds on the conceptual separation of the expected payoff and its utility. He describes the basis of the paradox as follows:\n\n``Until now scientists have usually rested their hypothesis on the assumption that all gains must be evaluated exclusively in terms of themselves, i.e., on the basis of their intrinsic qualities, and that these gains will always produce a utility directly proportionate to the gain.’’ (Bernoulli, 1954, p. 27)\n\nBernoulli, D. (1954). Exposition of a new theory on the measurement. Econometrica, 22(1), 23–36.\n\nThe relationship between gain and utility, however, is not simply directly proportional but rather more complex. Therefore, it is important to evaluate the game based on expected utility rather than just the expected payoff. \\[\nE(u(W(I)))=\\sum_{i=1}^{I} p(i) \\cdot u(W(i))=\\sum_{i=1}^{I} \\frac{1}{2^{i}} \\cdot u\\left(2^{i-1}\\right)\n\\] Daniel Bernoulli himself proposed the following logarithmic utility function: \\[\nu(W)=a \\cdot \\ln (W),\n\\] where \\(a\\) is a positive constant. Using this function in the expected utility, we get \\[\nE(u(W(I)))=\\sum_{i=1}^{I} \\frac{1}{2^{i}} \\cdot a \\cdot \\ln \\left(2^{i-1}\\right)=a \\cdot \\sum_{i=1}^{I} \\frac{i-1}{2^{i}} \\ln 2=a \\cdot \\ln 2 \\cdot \\sum_{i=1}^{I} \\frac{i-1}{2^{i}}.\n\\] The infinite series, \\(\\sum_{i=1}^{I} \\frac{i-1}{2^{i}}\\), converges to 1 (\\(\\lim _{I \\rightarrow \\infty} \\sum_{i=1}^{I} \\frac{i-1}{2^{i}}=1\\)). Thus, given an ex ante unbounded number of throws, the expected utility of the game is given by \\[\nE(u(W(\\infty)))=a \\cdot \\ln 2 .\n\\]\nIn experiments in which people were offered this game, their willingness to pay was roughly between 2 and 3 Euro. Thus, the suggests logarithmic utility function seems to be a pretty realistic specification. The main reason is mathematically that the increasing expected payoff has decreasing marginal utility and hence the utility function reflects the risk aversion of many people.\n\n\n\n\n\n\n\nExercise 6.1 Rationality and risk\nThere are 90 balls in an box. It is known that 30 of them are red, the remaining 60 are blue or green. An individual can choose between the following lotteries:\n\n\n\n\n\n\n\n\n\nPayoff\nprobability\n\n\n\n\nLottery 1\n100 Euro if a red ball is drawn 0 Euro else\n\\(p=\\frac{1}{3}\\)\n\n\nLottery 2\n100 Euro if a blue ball is drawn 0 Euro else\n\\(0 \\leq p \\leq \\frac{2}{3}\\)\n\n\n\nIn a second variant it has the choice between the following lotteries:\n\n\n\n\n\n\n\n\n\nPayoff\nprobability\n\n\n\n\nLottery 3\n100 Euro if a red or green ball is drawn or 0 Euro else\n\\(\\frac{1}{3} \\leq p \\leq 1\\)\n\n\nLottery 4\n100 Euro if a blue or green ball is drawn or 0 Euro else\n\\(p=\\frac{2}{3}\\)\n\n\n\n\nWhich of the lotteries does the individual choose on the basis of expected values (risk neutral)?\nWhich of the lotteries does the individual choose on the basis of expected utility if the utility of a payoff of \\(x\\) is given by \\(u(x) = x^2\\)?\nEmpirical studies, e.g. , show, however, that most individuals will usually choose lotteries 1 and 4. will. Discuss: Is this consistent with rational behavior?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRead the Wikipedia entry about the Ellsberg paradox (2024):\n\n“In decision theory, the Ellsberg paradox (or Ellsberg’s paradox) is a paradox in which people’s decisions are inconsistent with subjective expected utility theory. John Maynard Keynes published a version of the paradox in 1921. Daniel Ellsberg popularized the paradox in his 1961 paper,”Risk, Ambiguity, and the Savage Axioms”. It is generally taken to be evidence of ambiguity aversion, in which a person tends to prefer choices with quantifiable risks over those with unknown, incalculable risks.\nEllsberg’s findings indicate that choices with an underlying level of risk are favored in instances where the likelihood of risk is clear, rather than instances in which the likelihood of risk is unknown. A decision-maker will overwhelmingly favor a choice with a transparent likelihood of risk, even in instances where the unknown alternative will likely produce greater utility. When offered choices with varying risk, people prefer choices with calculable risk, even when those choices have less utility.”\n\n\n\n\n\nEllsberg paradox. (2024). Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/wiki/Ellsberg_paradox",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Risk</span>"
    ]
  },
  {
    "objectID": "dmbayes.html",
    "href": "dmbayes.html",
    "title": "7  Conditional events",
    "section": "",
    "text": "7.1 Terminology: \\(P(A)\\), \\(P(A|B)\\), \\(\\Omega\\), \\(\\cap\\), \\(\\neg\\), …\nWhen dealing with probabilities, especially conditional probabilities, relying on intuition and gut feeling often leads to poor decision-making. Our judgments are biased, and the choices we make are usually less rational than we may believe. Exercise 7.1 provides some evidence for my claim. Before I discuss how conditional probabilities can be considered in a rational decision making process, I repeat the essential basics of stochastics in Section 7.1",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional events</span>"
    ]
  },
  {
    "objectID": "dmbayes.html#sec-baybas",
    "href": "dmbayes.html#sec-baybas",
    "title": "7  Conditional events",
    "section": "",
    "text": "Exercise 7.2  \n\n\n\nFigure 7.1: Set theory visualized\n\n\n\n\n\n\n\n(a) Intersection: \\(A \\cap B\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) Union: \\(A \\cup B\\)\n\n\n\n\n\n\n\n\n\n\n\n(c) Relative complement: \\(\\neg A \\cup B\\)\n\n\n\n\n\n\n\n\n\n\n\nThe next chapter will deal with stochastics, probabilities, and set theory. I guess you are somehow familiar with graphical visualization like shown in Figure 7.1. In Germany and most other countries, that is taught in school. When I moved to Cologne in 2020, I found the page shown in Figure 7.2 that I had received back then from my high school math teacher. It was September 1993 and I was a struggling fifth grader in my fourth week. Perhaps you’d like to share your experiences with stochastics?\n\n\n\nFigure 7.2: Relative complement: \\(\\neg A \\cup B\\)\n\n\n\n\n\n\n\n\n\n\n\n7.1.1 Sample space\nA result of an experiment is called an outcome. An experiment is a planned operation carried out under controlled conditions. Flipping a fair coin twice is an example of an experiment. The sample space of an experiment is the set of all possible outcomes. The Greek letter \\(\\Omega\\) is often used to denote the sample space. For example, if you flip a fair coin, \\(\\Omega = \\{H, T\\}\\) where the outcomes heads and tails are denoted with \\(H\\) and \\(T\\), respectively.\n\n\n\n\n\n\n\nExercise 7.3 Sample space\nFind the sample space for the following experiments:\n\nOne coin is tossed.\nTwo coins are tossed once.\nTwo dices are tossed once.\nPicking two marbles, one at a time, from a bag that contains many blue, \\(B\\), and red marbles, \\(R\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\(\\Omega = \\{head, tail\\}\\)\n\\(\\Omega = \\{(head, head), (tail, tail),(head, tail),(tail, head)\\}\\)\nOverall, 36 different outcomes: \\(\\{\n     (1,1),(1,2),(1,3),(1,4),(1,5),(1,6),(2,1),(2,2),\\dots,(6,6)\n     \\}\\)\n\\(\\Omega = \\{(B,B), (B,R), (R,B), (R,R)\\}\\).\n\n\n\n\n\n\n\n\nOverall, there are three ways to represent a sample space:\n\nto list the possible outcomes (see Exercise 7.3),\nto create a tree diagram (see Figure 7.3), or\nto create a Venn diagram (see Figure 7.4).\n\n\n\n\nFigure 7.3: Tree diagramm\n\n\n\n\n\n\n\n\n\nFigure 7.4: Venn diagramm\n\n\n\n\n\n\n\n\n7.1.2 Probability\nProbability is a measure that is associated with how certain we are of outcomes of a particular experiment or activity. The probability of an event \\(A\\), written \\(P(A)\\), is defined as \\[\nP(A)=\\frac{\\text{Number of outcomes favorable to the occurrence of } A}{\\text{Total number of equally likely outcomes}}=\\frac{n(A)}{n(\\Omega)}\n\\]\nFor example, A dice has 6 sides with 6 different numbers on it. In particular, the set of elements of a dice is \\(M=\\{1,2,3,4,5,6\\}\\). Thus, the probability to receive a 6 is 1/6 because we look for one wanted outcome in six possible outcomes.\n\n\n\n\n\n\n\nExercise 7.4 Probability\nWhen a fair dice is thrown, what is the probability of getting\n\nthe number 5,\na number that is a multiple of 3,\na number that is greater than 6,\na positive number that is less than 7.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA fair dice is an unbiased dice where each of the six numbers is equally likely to turn up. The sample space is \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\).\n\nLet A be the event of getting the number 5, \\(A=\\{5\\}\\). Then, \\(P(A)=\\frac{1}{6}\\).\nLet \\(B\\) be the event of getting a multiple of 3, \\(B=\\{3, 6\\}\\). Then, \\(P(B)=\\frac{1}{3}\\).\nLet \\(C\\) be the event of getting a number greater than 6, \\(C=7,8,\\dots\\). Then, \\(P(C)=0\\) as there is no number greater than 6 in the sample space \\(\\Omega=\\{1,2,3,4,5,6\\}\\). A probability of 0 means the event will never occur.\nLet D be the event of getting a number less than 7, \\(D=\\{1,2,3,4,5,6\\}\\). Then, \\(P=1\\) as the event will always occur.\n\n\n\n\n\n\n\n\n\n7.1.2.1 The complement of an event (\\(\\neg-Event\\))\nThe complement of event \\(A\\) is denoted with a \\(\\neg A\\) or sometimes with a superscript `c’ like \\(A^c\\). It consists of all outcomes that are not in \\(A\\). Thus, it should be clear that \\(P(A) + P(\\neg A) = 1\\). For example, let the sample space be \\[\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\] and let \\[A = \\{1, 2, 3, 4\\}.\\] Then, \\[\\neg A = \\{5, 6\\};\\] \\[P(A) = \\frac{4}{6};\\] \\[P(\\neg A) = \\frac{2}{6};\\] and \\[P(A) + P(\\neg A) = \\frac{4}{6}+\\frac{2}{6} = 1.\\]\n\n\n7.1.2.2 Independent events (AND-events)\nTwo events are independent when the outcome of the first event does not influence the outcome of the second event. For example, if you throw a dice and a coin, the number on the dice does not affect whether the result you get on the coin. More formally, two events are independent if the following are true: \\[\\begin{align*}\n    P(A|B) &= P(A)\\\\\n    P(B|A) &= P(B)\\\\\n    P(A \\cap B) &= P(A)P(B)\n\\end{align*}\\]\nTo calculate the probability of two independent events (\\(X\\) and \\(Y\\)) happen, the probability of the first event, \\(P(X)\\), has to be multiplied with the probability of the second event, \\(P(Y)\\): \\[ P(X \\text{ and } Y)=P(X \\cap Y)=P(X)\\cdot P(Y),\\] where \\(\\cap\\) stands for “and”.\nFor example, let \\(A\\) and \\(B\\) be \\(\\{1, 2, 3, 4, 5\\}\\) and \\(\\{4, 5, 6, 7, 8\\}\\), respectively. Then \\(A \\cap B = \\{4, 5\\}\\).\n\n\n\n\n\n\n\nExercise 7.5 Three dices\nSuppose you have three dice. Calculate the probability of getting three times a 4.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe probability of getting a \\(4\\) on one dice is 1/6. The probability of getting three \\(4\\) is: \\[\nP(4 \\cap 4 \\cap 4) = \\frac{1}{6}\\cdot \\frac{1}{6}\\cdot \\frac{1}{6}= \\frac{1}{216}\n\\]\n\n\n\n\n\n\n\n\n\n7.1.2.3 Dependent events (\\(|\\)-Events)\nEvents are dependent when one event affects the outcome of the other. If \\(A\\) and \\(B\\) are dependent events then the probability of both occurring is the product of the probability of \\(A\\) and the probability of \\(A\\) after \\(B\\) has occurred: \\[\nP(A \\cap B)=P(A)\\cdot P(B|A)\n\\] where \\(|A\\) stands for “after A has occurred”, or “given A has occurred”. In other words, \\(P(B|A)\\) is the probability of \\(B\\) given \\(A\\).\nOf course, the equation above can also be written as \\[  \\Leftrightarrow P(B|A)=\\frac{P(A \\cap B)}{P(A)}\\cdot.\n\\] \nFor example, suppose we toss a fair, six-sided die. The sample space is \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\). Let \\(A\\) be 2 and 3 and let \\(B\\) be even (2, 4, 6). To calculate \\(P(A|B)\\), we count the number of outcomes 2 or 3 in the sample space \\(B = \\{2, 4, 6\\}\\). Then we divide that by the number of outcomes \\(B\\) (rather than \\(\\Omega\\)).\nWe get the same result by using the formula. Remember that \\(\\Omega\\) has six outcomes. \\[P(A\\mid B)=\\frac{P(B\\cap A)}{P(B)} = \\frac{\\frac{\\text{number of outcomes that are 2 or 3 AND even}}{6}}{\\frac{\\text{number of outcomes that are even}}{6}}=\\frac{\\frac{1}{6}}{\\frac{3}{6}}=\\frac{1}{3} \\]\n\n\n\n\n\n\n\nExercise 7.6 Purse\nA purse contains four € 5 bills, five € 10 bills and three € 20 bills. Two bills are selected randomly without the first selection being replaced. Find the probability that two € 5 bills are selected.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere are four € 5 bills. There are a total of twelve bills. The probability to select at first a € 5 bill then is \\(P(\\text{€} 5) = \\frac{4}{12}\\). As the the result of the first draw affects the probability of the second draw, we have to consider that there are only three € 5 bills left and there are a total of eleven bills left. Thus, \\[\nP(\\text{€} 5 | \\text{€} 5)=\\frac{3}{11}\n\\] and \\[\nP(\\text{€} 5 \\cap \\text{€} 5) = P(\\text{€} 5) \\cdot P(\\text{€} 5 | \\text{€} 5) = \\frac{4}{12} \\cdot \\frac{3}{11}=\\frac{1}{11}.\n\\] The probability of drawing a € 5 bill and then another € 5 bill is \\(\\frac{1}{11}\\).",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional events</span>"
    ]
  },
  {
    "objectID": "dmbayes.html#bayes-theorem",
    "href": "dmbayes.html#bayes-theorem",
    "title": "7  Conditional events",
    "section": "7.2 Bayes’ Theorem",
    "text": "7.2 Bayes’ Theorem\nThe conditional probability of A given B is written \\(P(A|B)\\). \\(P(A|B)\\) is the probability that event A will occur given that the event B has already occurred. A conditional reduces the sample space. We calculate the probability of A from the reduced sample space B. The formula to calculate \\(P(A|B)\\) is \\[ P(A|B) = \\frac{P\\left(A\\cap B\\right)}{P\\left(B\\right)}\\] where \\(P(B)\\) is greater than zero. This formula is also known as Bayes’ Theorem, which is a simple mathematical formula used for calculating conditional probabilities, states that \\[\nP(A)P(B|A)=P(B)P(A|B)\n\\] This is true since \\(P(A \\cap B)=P(B \\cap A)\\) and due to the fact that \\(P(A\\cap B)=P(B\\mid A)P(A)\\), we can write Bayes’ Theorem as \\[P(A\\mid B)={\\frac {P(B\\mid A)P(A)}{P(B)}}.\\] The box below summarizes the important facts w.r.t. Bayes’ Theorem.\n\n\n\n\n\n\nBayes’ Theorem\n\n\n\n\n\nThe theorem states that \\[P(A\\mid B)={\\frac {P(B\\mid A)P(A)}{P(B)}} \\] if \\(P(B)\\neq 0\\) and \\(A\\) and \\(B\\) are events. It simply uses the following logical facts: \\[P(B\\cap A)=P(A\\cap B),\\] \\[P(A\\mid B)=\\frac {P(A\\cap B)}{P(B)},  \\text{ and}\\] \\[P(B\\mid A)=\\frac {P(A\\cap B)}{P(A)},\\] or, to put it in one line: \\[  P(A\\cap B)= P(B\\cap A)=P(A\\mid B)P(B)=P(B\\mid A)P(A).   \\] Sometimes, it is helpful to re-write the Theorem as follows: \\[P(A)=P(A|B)P(B)+P(A|\\neg B)P(\\neg B),  \\text{ and}\\] \\[P(B)=P(B|A)P(A)+P(B|\\neg A)P(\\neg A),\\]\n\n\n\nFor a deeper understanding of Bayes theorem, I recommend watching the following videos:\n\nBayes theorem and \nThe quick proof of Bayes’ theorem \n\nMoreover, this interactive tool can be helpful.\n\n\n\n\n\n\n\nExercise 7.7 To be vaccinated or not to be\n\n\n\nFigure 7.5: Tree diagramm (Exercise 7.7)\n\n\n\n\n\n\nThe tree diagram in Figure 7.5 shows probabilities of people to have a vaccine for some disease. Moreover, it shows the conditional probabilities of people to die given the fact they were vaccinated or not. \\(D\\) denotes the event of die and \\(\\neg D\\) denotes not die, i.e., survive; \\(V\\) denotes the event of vaccinated and \\(\\neg V\\) not vaccinated.\n\nCalculate the overall probability to die, \\(P(D)\\)\nCalculate the probability that a person that has died was vaccinated, \\(P(V|D)\\).\n\n\nDisclaimer: The case presented here is fictitious. The data given here are purely fictitious and serve only to practice the method.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\[\\begin{align*}\n          P(D)&=P(V)\\cdot P(D|V)+(P(\\neg V)\\cdot P(D|\\neg V))\\\\\n          &= .96\\cdot .05 + .04 \\cdot .09\\\\\n          &= 0.048 + 0.036 \\\\&= 0.084\n\\end{align*}\\]\n\\[\\begin{align*}\nP(V \\mid D)={\\frac {P(D\\mid V)P(V)}{P(D)}}= \\frac{.05\\cdot .96}{.084}\\approx .5714285\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 7.8 To die or not to die\nYou read on Facebook that in the year 2021 about over 80% of people that died were vaccinated. You are shocked by this high probability that a dead person was vaccinated, \\(P(V|D)\\). You decide to check this fact. Reading the study to which the Facebook post is referring, you find out that the study only refers to people above the age of 90. Moreover, you find the following Tree Diargram. It allows checking the fact as it describes the vaccination rates and the conditional probabilities of people to die given the fact they were vaccinated or not. In particular, \\(D\\) denotes the event of die and \\(\\neg D\\) denotes not die, i.e., survive; \\(V\\) denotes the event of vaccinated and \\(\\neg V\\) not vaccinated.\n\n\n\nFigure 7.6: Tree diagramm (Exercise 7.8)\n\n\n\n\n\n\n\nCalculate the overall probability to die, \\(P(D)\\)\nCalculate the probability that a person that has died was vaccinated, \\(P(V|D)\\).\nYour calculations shows that the fact used in the statement on Facebook is indeed true. Discuss whether this number should have an impact to get vaccinated or not.\n\n\nDisclaimer: The case presented here is fictitious. The data given here are purely fictitious and serve only to practice the method.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\[P(D) = 0.9\\cdot0.2+0.1\\cdot0.4=0.22\\]\n\\[P(V\\mid D)=\\frac P(D\\mid V)P(V)P(D)=\\frac0.2\\cdot 0.90.22=\\frac0.0360.22\\approx0.8181\\] % \\[P(\\neg V\\mid D)=\\frac P(D\\mid \\neg V)P(\\neg V)P(D)=\\frac0.4\\cdot 0.40.028=\\frac0.020.028\\approx0.71428\\]\n…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 7.9 Corona false positive\nSuppose that Corona infects one out of every 1000 people in a population and that the test for it comes back positive in 99% of all cases if a person has Corona. Moreover, the test also produces some false positive, that is about 2% of uninfected patients also tested positive.\nNow, assume you are tested positive and you want to know the chances of having the disease. Then, we have two events to work with:\nA: you have Corona\nB: your test indicates that you have Corona\nand we know that \\[\\begin{align*}\n    P(A)&=.001  \\qquad \\rightarrow \\text{one out of 1000 has Corona}\\\\\n    P(B|A)&=.99 \\qquad \\rightarrow \\text{probability of a positive test, given infection}\\\\\n    P(B|\\neg A)&=.02 \\qquad \\rightarrow \\text{probability of a false positive, given no infection}\n\\end{align*}\\]\nAs you don’t like to go into quarantine, you are interested in the probability of having the disease given a positive test, that is \\(P(A|B)\\)?\n\nDisclaimer: The case presented here is fictitious. The data given here are purely fictitious and serve only to practice the method.\n\n\n\n\n\n\n\n\n\n\n\nSolution to Exercise 7.9\n\n\n\n\n\nIn order to come to an answer, lets draw a table of the probabilities that may be of interest:\n\n\n\n\n\n\n\n\n\n\nA\n\\(\\neg A\\)\n\\(\\sum\\)\n\n\n\n\nB\n\\(P(A\\cap  B)\\)\n\\(P(\\neg A \\cap B)\\)\n\\(P(B)\\)\n\n\n\\(\\neg B\\)\n\\(P(A \\cap \\neg B)\\)\n\\(P(\\neg A \\cap \\neg B)\\)\n\\(P(\\neg B)\\)\n\n\n\n\\(P(A)\\)\n\\(P(\\neg A)\\)\n1\n\n\n\nPlease note, the symbol \\(\\neg\\) simply abbreviates “NOT” and the symbol \\(\\cap\\) stands for “AND”. The probability of you having both the disease and a positive test, \\(P(A \\cap B)\\), is easy to calculate: \\[\\underbrace{P(A \\cap B)= P(B|A)P(A)}_{\\text{a.k.a. multiplication rule}}=.99\\cdot .001=.00099\\] Also, it is straight forward to calculate the probability of having both, no infection and a positive test: \\[\nP(\\neg A \\cap B)= P(B|\\neg A)P(\\neg A)=.02\\cdot .999 = .01998\n\\] Knowing that, it is clear that the overall probability of being diagnosed with Corona is \\[P(B)=.00099+.0199=.02097\\] That means, out of 1000 people about 21 are on average diagnosed with Corona while only one person actually is infected with Corona. Thus, your probability of having Corona once your test came out to be positive, \\(P(A|B)\\), is approximately \\[P(A|B) \\approx \\frac{1}{21}=0,047619048\\] and more precisely \\[\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{.00099}{.02097}=0,0472103.\n\\]\nIn other words, with a probability of more than 95%, you may go into quarantine without infection: \\[\nP(\\neg A|B)=\\frac{P(\\neg A\\cap B)}{P(B)}=\\frac{.01998}{.02097}=0,9527897\\quad (=1-P(A|B))\n\\]\nGiven the accuracy of the test, this number appears to be rather high to many people. The high test accuracy of 99% and the rather low number of 2% false positives, however, is misleading. This is sometimes called the . The source of the fact that many people think \\(P(A|B)\\) is much lower is that they don’t consider the impact of the low probability of having the disease, \\(P(A)\\), on \\(P(A|B)\\), \\(P(B|A)\\), and \\(P(B|\\neg A)\\) respectively (also, see the ). Moreover, many people don’t understand the false positive rate correctly.\nTo summarize, we know\n\n\n\n\nA\n¬A\n\\(\\sum\\)\n\n\n\n\nB\n.00099\n.01998\n.02097\n\n\n¬B\nP(A ¬B)\nP(¬A ¬B)\nP(¬B)\n\n\n—\n.001\nP(¬A)\n1\n\n\n\nThe four remaining unknowns can be calculated by subtracting in the columns and adding across the crows, so that the final table is:\n\n\n\n\nA\n¬A\n\\(\\sum\\)\n\n\n\n\nB\n.00099\n.01998\n.02097\n\n\n¬B\n.00001\n.97902\n.97903\n\n\n—\n.001\n.999\n1",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional events</span>"
    ]
  },
  {
    "objectID": "game.html",
    "href": "game.html",
    "title": "8  Games",
    "section": "",
    "text": "8.1 Structure of games\nGame theory is the study of mathematical models that describe strategic interactions among rational decision-makers. Specifically, it analyzes how two or more players make decisions in situations where their choices affect one another’s outcomes. In these scenarios, each player’s actions influence the payoffs of others, and vice versa, creating interdependence. As in the models discussed earlier, game theory assumes that players act rationally, seeking to maximize their own benefits. This framework allows for economic research through laboratory experiments or real-world field studies.\nGame theory is not just an academic exercise; it has practical applications in real market situations and various human interactions. It is used across all fields of science including social science and computer science. In the 21st century, game theory has expanded to cover a wide range of behavioral relationships and is now an umbrella term for the study of logical decision-making in humans, animals, and machines.\nModern game theory began with the idea of mixed-strategy equilibria in two-person zero-sum games and its proof by John von Neumann. His work and in particular his jointly written with Oskar Morgenstern from 1944 Theory of Games and Economic Behavior (see Figure 8.1) which considered cooperative games of several players was the beginning of modern game theory. The second edition of this book provided an axiomatic theory of expected utility, which allowed mathematical statisticians and economists to treat decision-making under uncertainty.\nGame theory has been widely recognized as an important tool in many fields. As of 2014, with the Nobel Memorial Prize in Economic Sciences going to game theorist Jean Tirole, eleven game theorists have won the economics Nobel Prize including Reinhard Selten from Germany together with John Harsanyi and John Nash in 1994, see Figure 8.2.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Games</span>"
    ]
  },
  {
    "objectID": "game.html#structure-of-games",
    "href": "game.html#structure-of-games",
    "title": "8  Games",
    "section": "",
    "text": "8.1.1 Elements\nThe elements of a game include several key components that define its structure and dynamics. First, there is the number of players, which indicates how many individuals or entities are involved in the game. Each player has a specific set of strategies and alternative actions available to them, which can significantly influence the game’s outcome.\nAdditionally, the payoff functions determine the rewards or penalties that players receive based on the actions taken, reflecting their preferences and objectives. The state of information is also crucial, as it outlines what each player knows about the game, including the actions of other players. Lastly, the timing of actions and information plays a vital role, as it affects the decisions made by players and the overall flow of the game. Understanding these elements is essential for analyzing strategic interactions effectively.\n\n\n8.1.2 Classes\nGames can be categorized into various classes based on their characteristics:\n\nCooperative vs. Non-cooperative: Cooperative games allow players to form binding commitments, while non-cooperative games do not.\nStatic vs. Dynamic: Static games are played in a single time period, whereas dynamic games unfold over multiple periods, with players potentially adapting their strategies over time.\nOne-shot vs. Repeated: One-shot games are played once, while repeated games involve the same players playing multiple rounds, allowing for strategy adjustments based on previous outcomes.\nNon-zero-sum vs. Zero-sum: In zero-sum games, one player’s gain is another’s loss, while non-zero-sum games allow for outcomes where all players can benefit or suffer together.\nPerfect Information vs. Non-perfect Information: Perfect information games allow players to know all previous actions, whereas non-perfect information games involve some level of uncertainty about other players’ actions.\nSymmetric Information vs. Asymmetric Information: In symmetric information games, all players have access to the same information, while asymmetric information games involve players having different information.\nDeterministic vs. Non-deterministic Payoffs (Random): Deterministic payoffs yield consistent outcomes for given strategies, while non-deterministic payoffs involve randomness and variability in outcomes.\n\n\n\n\n\n\n\n\nExercise 8.2 Tic Tac Toe\nTic Tac Toe is a simple yet classic game that can be analyzed through various game theory classifications. Discuss the classes of the game Tic Tac Toe (see Figure 8.4).\n\n\n\nFigure 8.4: Tic Tac Toe\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHere’s how it fits into the categories mentioned:\nCooperative vs. Non-cooperative:\nNon-cooperative: Tic Tac Toe is a non-cooperative game because players cannot form binding agreements or commitments. Each player independently decides their move without collaboration.\nStatic vs. Dynamic:\nDynamic: The game is dynamic because it occurs in various rounds, with players taking turns one after another and they have the chance to respond on the moves made by the opponent.\nOne-shot vs. Repeated:\nOne-shot: A typical game of Tic Tac Toe is a one-shot game, meaning it is played once with no subsequent rounds. However, players may play multiple games in sequence, which can lead to a repeated game scenario, but each individual game remains one-shot.\nNon-zero-sum vs. Zero-sum:\nZero-sum: Tic Tac Toe is a zero-sum game because one player’s gain (winning the game) results in an equal loss for the other player.\nPerfect Information vs. Non-perfect Information:\nPerfect Information: The game has perfect information as both players are fully aware of all previous moves made by their opponent. There is no hidden information; each player can see the entire game board and all actions taken.\nSymmetric Information vs. Asymmetric Information:\nSymmetric Information: The game exhibits symmetric information, where both players have access to the same information regarding the game’s state. They both see the same board and the same moves, and neither player has an informational advantage over the other.\nDeterministic vs. Non-deterministic Payoffs:\nDeterministic: The payoffs in Tic Tac Toe are deterministic, as the outcome (win, loss, or draw) is solely determined by the players’ moves without any random elements involved. Each strategic decision directly influences the final result.\n\n\n\n\n\n\n\n\n\n8.1.3 Representations\n\n8.1.3.1 Normal form\nThe normal form of a game is a matrix representation that captures the strategic interactions between players who choose their strategies simultaneously. It lists each player’s possible strategies and the resulting payoffs for each combination of strategies. This format helps identify dominant strategies and Nash equilibria, making it useful for analyzing static games.\nThe matrix provided in Table 8.1 is a normal-form representation of a game in which players move simultaneously (or at least do not observe the other player’s move before making their own) and receive the payoffs as specified for the combinations of actions played.\n\n\n\nTable 8.1: Example of a normal-form representation\n\n\n\n\n\n\n\nPerson B - work\nPerson B - shirk\n\n\n\n\nPerson A - work\n10 ; 10\n5 ; 11\n\n\n\nPerson A - shirk\n11 ; 5\n6 ; 6\n\n\n\n\n\n\n\nIn the example of Table 8.1, two workers, A and B, have to make the choice to shirk or to work hard. In the following, I describe how to solve the decision for each person. The trick is to find the best answer of each person in whatever the other one is doing.\nTo solve the game represented in the normal-form table, follow these steps:\n\nIdentify strategies: Each player (Person A and Person B) has two strategies: “work” or “shirk.”\nPayoff matrix: The matrix shows the payoffs for both players based on their chosen strategies:\n\nIf both work, the payoffs are (10, 10).\nIf A works and B shirks, the payoffs are (5, 11).\nIf A shirks and B works, the payoffs are (11, 5).\nIf both shirk, the payoffs are (6, 6).\n\nDetermine dominant strategies: A dominant strategy is one that yields a higher payoff regardless of the other player’s action.\n\nFor Person A:\n\nIf B works, A gets 10 by working and 11 by shirking (so shirking is better).\nIf B shirks, A gets 5 by working and 6 by shirking (so again, shirking is better).\nThus, A’s dominant strategy is to shirk.\n\nFor Person B:\n\nIf A works, B gets 10 by working and 11 by shirking (so shirking is better).\nIf A shirks, B gets 5 by working and 6 by shirking (so again, shirking is better).\nThus, B’s dominant strategy is to shirk.\n\n\nNash Equilibrium: The Nash equilibrium occurs when both players choose their dominant strategies. In this case, both will choose to shirk: Payoffs at this equilibrium are (6, 6).\nConclusion: Both players have a strong incentive to shirk, leading to a Nash equilibrium with both receiving a payoff of 6.\n\nThis analysis shows how rational decision-making can lead to outcomes that may not be optimal for either player collectively, highlighting the potential for suboptimal outcomes in strategic interactions.\n\n\n\n\n\n\n\nExercise 8.3 Matching pennies (random and simultaneous version)\nWrite down the following game in the normal form:\nMatching pennies (random and simultaneous version) is a game with two players (1, 2). Both players flip a penny simultaneously. Each penny falls down and shows either heads up or tails up. If the two pennies match (either both heads up or both tails up), player 2 wins and player 1 must pay him a Euro. If the two pennies do not match, player 1 wins and player 2 must pay him a Euro.\nAdditionally, describe the elements of the game and the class of this game.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe normal form of the game is shown in Table 8.2.\n\n\n\nTable 8.2: Normal form of the random and simultaneous version\n\n\n\n\n\n\n\nPerson 2 - Head\nPerson 2 - Tail\n\n\n\n\nPerson 1 - Head\n-1 ; 1\n1 ; -1\n\n\n\nPerson 1 - Tail\n1 ; -1\n-1 ; 1\n\n\n\n\n\n\n\nIt is a game that belongs to the following classes:\n\nnon-cooperative\nstatic\none-shot\nzero-sum\nperfect information\nsymmetric information\nnon-deterministic payoffs\n\nElements of the game:\n\nNumber of players: 2\nNumber of strategies: No strategies as whether heads or tails shows up is random\nPayoff functions: \\[ \\text{Player 1} =\n  \\begin{cases}\n      1, & \\text{if } (T,T) \\text{ or } (H,H) \\\\\n      -1, & \\text{otherwise}\n  \\end{cases}\n  \\]\n\n\\[ \\text{Player 2 = }\n    \\begin{cases}\n        1, & \\text{if } (H,T) \\text{ or } (T,H) \\\\\n        -1, & \\text{otherwise}\n    \\end{cases}\n    \\]\n\nState of information: Everybody knows the rules and is perfectly informed\nTiming of actions and information: both throw the coin at the same time and see the result at the same time\n\n\n\n\n\n\n\n\n\n\n8.1.4 Extensive form\nThe extensive form in game theory is a way to represent games that captures the sequence of moves by players, their available choices at each point, and the information they have when making decisions. Unlike the normal form, which shows all strategies and payoffs in a matrix, the extensive form uses a tree diagram to show how a game unfolds over time. Each branch represents a possible action, and the endpoints show the payoffs for different outcomes. This format also accounts for chance events and imperfect information, making it useful for analyzing dynamic, sequential decision-making scenarios.\n\n\n\n\n\n\n\nExercise 8.4 Matching pennies (random version)\nWrite down the following game in the extensive form:\nMatching pennies (random version) is a game with two players (1, 2). Player 1 starts by flipping a fair penny high, catches it, and then turns it over into the other hand so that the result is hidden from the other player. Then, player 2 flips the coin. If the two pennies match (either both heads up or both tails up), player 2 wins and player 1 must pay him a Euro. If the two pennies do not match, player 1 wins and player 2 must pay him a Euro.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs player 2 has no idea what player 1 has chosen, he cannot come up with any strategy that increases his winning rate. The extensive\n\n\n\nFigure 8.5: Extensive form of the random version\n\n\n\n\n\n\nThe dashed circled line indicates that player 2 is not informed about whether P1 decided head or tail. As we have now introduced how to graphically show that some players have a restricted information set, we can draw the extensive form also for the random and simultaneous version of the matching pennies game. Please note that the dashed circle around player 1 is redundant and hence it is a convention not to draw it sometimes.\n\n\n\nFigure 8.6: Extensive form of the random and simultaneous version\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 8.5 Matching pennies (strategic version)\nWrite down the following game in the extensive form and discuss the strategies of both:\nMatching pennies (strategic version) is a game with two players (1, 2). Player 1 starts and decides whether to put a coin with either heads up or tails up onto a table. Player 2 can see the decision of player 1. Then, player 2 decides whether to put a coin with heads or tails on the table. If the two pennies match (either both heads up or both tails up), player 2 wins and player 1 must pay him a Euro. If the two pennies do not match, player 1 wins and player 2 must pay him a Euro.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs player 2 has complete information about the decision of player 1, he can always come up with the choice that makes him win. That is, if player 1 chooses head(/tail) player one will also choose head(/tail).\n\n\n\nFigure 8.7: Extensive form of the strategic version",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Games</span>"
    ]
  },
  {
    "objectID": "game.html#nash-equilibrium",
    "href": "game.html#nash-equilibrium",
    "title": "8  Games",
    "section": "8.2 Nash equilibrium",
    "text": "8.2 Nash equilibrium\n\n8.2.1 John Forbes Nash Jr. (1928-2015)\nJohn Forbes Nash Jr. (1928-2015) had an extraordinary life which ended tragically in a car accident after having received the Abel Prize. In Figure 8.8 you see the real John Nash as well as actor Russel Crowe who plays him in the movie A Beautiful Mind. To get known to John Nash and his contributions, read his Wikipedia entry, watch the following videos, and read the Nobel prize award ceremony speech below.\nNash Equilibrium (taken from A Beautiful Mind) \nDr. John Nash on his life before and after the Nobel Prize \n\n\n\nFigure 8.8: John Nash and The Beautiful Mind movie\n\n\n\n\n\n\nThe real John Nash\n\n\n\n\n\n\n\nThe movie: A Beautiful Mind\n\n\n\n\n\n\n\nExcerpt: “Adam Smith needs revision”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNobel Prize Award ceremony speech of 1994\n\n\n\nPresentation Speech by Professor Karl-Göran Mäler of the Royal Swedish Academy of Sciences taken from Nobel Prize Speech):\n\nMany situations in society, from everyday life to high-level politics, are characterized by what economists call strategic interactions. When there is strategic interaction, the outcome for one agent depends not only on what that agent does, but also very largely on how other agents act or react. A firm that decreases its price to attract more customers will not succeed in this strategy if the other major firms in the market use the same strategy. Whether a political party will be successful in attracting more votes by proposing lower taxes or increased spending will depend on the proposals from other parties. The success of’ a central bank which is trying to fight inflation by maintaining a fixed exchange rate depends – as we know – on decisions on fiscal policy, and also on reactions in markets for labor and commodities.\nA simple economic example of strategic interaction is where two firms are competing with identical products on the same market. If one firm increases its production, this will make the market price fall and therefore reduce profits for the other firm. The other firm will obviously try to counteract this, for example by increasing its production and so maintaining its market share but at the cost of further reduction in market price. The first company must therefore anticipate this countermove and possible further countermoves when it makes its decision to increase production. Can we predict how the parties will choose their strategies in situations like this?\nAs early as the 1830s the French economist Auguste Cournot had studied the probable outcome when two firms compete in the same market. Many economists and social scientists subsequently tried to analyze the outcome in other specific forms of strategic interaction. However, prior to the birth of game theory, there was no toolbox that gave scholars access to a general but rigorous method of analyzing different forms of strategic interaction. The situation is totally different now. Scientific journals and advanced textbooks are filled with analyses that build on game theory, as it has been developed by this year’s Laureates in economics, John Nash, John Harsanyi and Reinhard Selten.\nNon-cooperative game theory deals with situations where the parties cannot make binding agreements. Even in very complicated games, with many parties and many available strategies, it will be possible to describe the outcome in terms of a so-called Nash equilibrium – so named after one of the Laureates. John Nash has shown that there is at least one stable outcome, that is an outcome such that no player can improve his own outcome by choosing a different strategy when all players have correct expectations of each other’s strategy. Even if each party acts in an individually rational way, the Nash equilibrium shows that strategic interaction can quite often cause collective irrationality: trade wars or excessive emission of pollutants that threaten the global environment are examples in the international sphere. One should also add that the Nash equilibrium has been important within evolutionary ecology – to describe natural selection as a strategic interaction within and between species.\nIn many games, the players lack complete information about each other’`s objective. If the government, for example, wants to deregulate a firm but does not know the cost situation in the firm, while the firm’s management has this knowledge, we have a game with incomplete information. In three articles published toward the end of the 1960s, John Harsanyi showed how equilibrium analysis could be extended to handle this difficulty, which game theorists up to that time had regarded as insurmountable. Harsanyi’s approach has laid an analytical basis for several lively research areas including information economics which starts from the fact that different decision makers, in a market or within an organization, often have access to different information. These areas cover a broad range of issues, from contracts between shareholders and a company’s management to institutions in developing countries.\nOne problem connected with the concept of Nash equilibrium is that there may be several equilibria in non-cooperative games. It may thus be difficult – both for the players and an outside analyst – to predict the outcome. Reinhard Selten has, through his ``perfection’’ concepts, laid the foundations for the research program that has tried to exclude improbable or unreasonable equilibria. Certain Nash equilibria can, in fact, be such that they are based on threats or promises intended to make other players choose certain strategies. These threats and promises are often empty because it is not in the player’s interest to carry them out if a situation arises in which he has threatened to carry them out. By excluding such empty threats and promises Selten could make stronger predictions about the outcome in the form of socalled perfect equilibria.\nSelten’s contributions have had great importance for analysis of the dynamics of strategic interaction, for example between firms trying to reach dominant positions on the market, or between private agents and a government that tries to implement a particular economic policy.\nProfessor John Harsanyi, the analysis of games with incomplete information is due to you, and it has been of great importance for the economics of information.\nDr John Nash, your analysis of equilibria in non-cooperative games, and all your other contributions to game theory, have had a profound effect on the way economic theory has developed in the last two decades. Professor Reinhard Selten, your notion of perfection in the equilibrium analysis has substantially extended the use of non-cooperative game theory.\nIt is an honour and a privilege for me to convey to all of you, on behalf of the Royal Swedish Academy of Sciences, our warmest congratulations. I now ask you to receive your prizes from the hands of his Majesty the King.\n\n\n\n\n\n8.2.2 Nash equilibrium\nTo find a Nash equilibrium in a normal form game as shown in Table 8.3, we can look for the best responses for both players in a game. We do so by putting a star next to the payoff attained by the best response of a player for all the strategies of the other player. For example, we put a star next to the 4 because S1 is the best response by Player B to the action S1 of Player A.\nNotice that the bottom right corner box has a particular feature: it shows that the strategies played by all the (two) players and resulting in that outcome are best responses to the others’ players best responses. That defines a Nash equilibrium.\n\n\n\nTable 8.3: An example for a game with a Nash equilibrium\n\n\n\n\n\n\n\nPerson B\n\n\n\n\n\n\n\n\nS1\nS2\nS3\n\n\nPerson A\nS1\n0 ; 4*\n4* ; 0\n5 ; 3\n\n\n\nS2\n4* ; 0\n0 ; 4*\n5 ; 3\n\n\n\nS3\n3 ; 5\n3 ; 5\n6* ; 6*\n\n\n\n\n\n\n\n\n\n\n\n\nNash equilibrium\n\n\n\nThe Nash equilibrium is a concept of game theory where the optimal outcome of a game is one where no player has an incentive to deviate from their chosen strategy after considering the opponent’s choice.\nPlease watch the video: What is Nash Equilibrium? \n\n\n\n\n8.2.3 The prisoner’s dilemma\nThe prisoner’s dilemma is the most well-known example of game theory. It shows why two completely rational individuals might not cooperate, even if it appears that it is in their best interests to do so.\nConsider the example of two criminals arrested for a crime. Prosecutors have no hard evidence to convict them. However, to gain a confession, officials remove the prisoners from their solitary cells and question each one in separate chambers. Neither prisoner has the means to communicate with each other. The criminals are now confronted by the officials with four possible scenarios:\n\nIf both confess, they will each receive an eight-year prison sentence.\nIf Prisoner 1 confesses, but Prisoner 2 does not (he aims to cooperate with Prisoner 1), Prisoner 1 will go free and Prisoner 2 will get twenty years.\nIf Prisoner 2 confesses, but Prisoner 1 does not (he aims to cooperate with Prisoner 1), Prisoner 1 will get twenty years, and Prisoner 2 will go free.\nIf neither confesses, each will serve two years in prison.\n\nThe corresponding normal form of the game is shown in Table 8.4.\n\n\n\nTable 8.4: Example for a prisoner’s dilemma\n\n\n\n\n\n\n\nPerson B\n\n\n\n\n\n\n\nConfess\nCooperate\n\n\nPerson A\nConfess\n8 years ; 8 years\n0 years ; 20 years\n\n\n\nCooperate\n20 years ; 0 years\n2 years ; 2 years\n\n\n\n\n\n\nThe scenario is also explained in this video \nLet us now look at how individuals would rationally decide what to do:\n\nIf A assumes that B confesses, A would also confess.\nIf A assumes that B cooperates, A would still confess.\n\nSince the same logic applies for B, we can conclude that the strategy of choice is to confess, even though the most favorable strategy for both would be to cooperate. The game-theoretical equilibrium (both confess) in this game can be called a Nash equilibrium because it suggests that both players will make the move that is best for them individually, even if it is worse for them collectively.\n\n\n\n\n\n\n\nExercise 8.6  \n\nDefine briefly what is meant by a Nash equilibrium.\nAnalyze whether the normal form of the given game has a Nash equilibrium. Please notice that high numbers indicate high utility, ranging from \\(0\\) (no utility) to \\(10\\) (high utility).\n\n\n\n\nTable 8.5: Normal form of a game\n\n\n\n\n\n\n\nPlayer 2\n\n\n\n\n\n\n\nP\nV\n\n\nPlayer 1\nP\n2, 4\n2, 6\n\n\n\nV\n7, 1\n3, 3\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe Nash equilibrium is a concept of game theory where the optimal outcome of a game is one where no player has an incentive to deviate from his chosen strategy after considering an opponent’s choice.\nIn the game above the point where both play with (3,3) is a Nash-Equilibrium Nash equilibrium.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Games</span>"
    ]
  },
  {
    "objectID": "finance.html",
    "href": "finance.html",
    "title": "9  Finance",
    "section": "",
    "text": "9.1 Simple financial mathematics\nYou are financially literate if you understand and manage personal finances effectively. It involves having a basic understanding of financial concepts, such as budgeting, saving, investing, and managing debt. Financial literacy also includes knowledge of financial products and services, such as bank accounts, credit cards, loans, and insurance. Being financially literate means having the skills and knowledge to make informed financial decisions, and being able to assess risks and opportunities when it comes to managing money. It is an important life skill that can help individuals achieve their financial goals, build wealth, and avoid financial pitfalls.\nBeing better-educated was always associated with having more financial knowledge (Figure 1) across the countries we examined,3 yet we also found that education is not enough. That is, even well-educated people are not necessarily savvy about money.\nUnfortunately, financial illiteracy is widespread. While being better-educated is associated with making better financial decisions on average, “even well-educated people are not necessarily savvy about money” (Mitchell & Lusardi, 2015, p. 3).\nThere are various attempts to assess the levels of financial literacy. See https://www.oecd.org/finance/financial-education/measuringfinancialliteracy.htm for example.\nI discuss financial mathematics in the following chapter just briefly. If you want to gather a deeper understanding, I recommend the open textbook of Dahlquist et al. (2022) or the respective chapters of Wilkinson (2022).",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Finance</span>"
    ]
  },
  {
    "objectID": "finance.html#simple-financial-mathematics",
    "href": "finance.html#simple-financial-mathematics",
    "title": "9  Finance",
    "section": "",
    "text": "Dahlquist, J., Knight, R., Adams, A. S., Bacon, C. J., Cooper, S. T., Griffin, M. P., Higgins, K. C., & Musolino, L. (2022). Principles of finance. OpenStax. https://biz.libretexts.org/Bookshelves/Finance/Principles_of_Finance_(OpenStax)\n\nWilkinson, N. (2022). Managerial economics problem-solving in a digital world (2nd ed.). Cambridge University Press.\n\n9.1.1 Simple Interest\nSuppose \\(r\\) denotes annual interest rates, \\(P\\) denotes the initial deposit which earns the interest, \\(A\\) denotes the value of the deposit at the end of an investment. Then, the relationship of these for a single year is\n\\[\nA=P+Pr=P(1+r)\n\\]\nand for many years, \\(t\\), it is\n\\[\nA=P(1+rt)\n\\]\nwhich is the simple interest formula. It gives the amount due when the annual interests does not become part of the deposit \\(P\\).\n\n\n9.1.2 Compound interest\nIf the annual interest, \\(P(1+r)\\), is added to \\(P\\), we need a formula that takes this into account, and for two periods this is\n\\[\nA=P\\cdot  [(1+r)\\cdot(1+r)]=P(1+r)^2\n\\]\nand for t periods\n\\[\nA=P(1+r)^t.\n\\]\nCompound interest is the addition of interest to the principal sum of a loan or deposit, or in other words, interest on principal plus interest. It is the result of reinvesting interest, or adding it to the loaned capital rather than paying it out, or requiring payment from borrower, so that interest in the next period is then earned on the principal sum plus previously accumulated interest.\n\\[\nA=P\\left(1+\\frac{r}{n}\\right)^{nt}\n\\]\n\nExample\nSuppose a principal amount of $1,500 is deposited in a bank paying an annual interest rate of 4.3%, compounded quarterly. Then the balance after 6 years is found by using the formula above, with \\(P = 1500\\), \\(r = 0.043\\) (4.3%), \\(n = 4\\), and \\(t = 6\\):\n\\[\nA=1500\\times\\left(1+\\frac{0.043}{4}\\right)^{4\\times 6}\\approx 1938.84\n\\]\nSo the amount \\(A\\) after 6 years is approximately $1,938.84.\nSubtracting the original principal from this amount gives the amount of interest received: \\(1938.84-1500=438.84\\)\n\n\n\n9.1.3 Continuously compounded interest\nAs \\(n\\), the number of compounding periods per year, increases without limit, the case is known as continuous compounding, in which case the effective annual rate approaches an upper limit of \\(e^r- 1\\), where \\(e\\) is a mathematical constant that is the base of the natural logarithm.\nContinuous compounding can be thought of as making the compounding period infinitesimally small, achieved by taking the limit as \\(n\\) goes to infinity. The amount after \\(t\\) periods of continuous compounding can be expressed in terms of the initial amount \\(P\\) as\n\\[\nA=Pe^{rt}\n\\]\n\n\n9.1.4 Present value\nThe present is the value of an expected income stream determined as of the date of valuation. The present value is usually less than the future value because money has interest-earning potential, a characteristic referred to as the time value of money, except during times of zero- or negative interest rates, when the present value will be equal or more than the future value. Time value can be described with the simplified phrase, ``A dollar today is worth more than a dollar tomorrow’‘. Here, ’worth more’ means that its value is greater than tomorrow. A dollar today is worth more than a dollar tomorrow because the dollar can be invested and earn a day’s worth of interest, making the total accumulate to a value more than a dollar by tomorrow.\n\\[\nP=Ae^{-rt}\n\\]",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Finance</span>"
    ]
  },
  {
    "objectID": "finance.html#net-present-value-and-internal-rate-of-return",
    "href": "finance.html#net-present-value-and-internal-rate-of-return",
    "title": "9  Finance",
    "section": "9.2 Net present value and internal rate of return",
    "text": "9.2 Net present value and internal rate of return\nWhen making decisions about financial products such as investments or loans, it is important to consider their long-term impact on your finances. Net Present Value (NPV) and Internal Rate of Return (IRR) are two key indicators that can help guide decision making and determine whether a financial product is a good investment.\nNet Present Value (NPV) is the difference between the present value of all cash inflows and the present value of all cash outflows over a given time period. The formula to calculate NPV is:\n\\[ NPV = \\sum_{n=1}^{N} \\frac{C_n}{(1+r)^n} - C_0 \\]\nwhere \\(C_n\\) denotes net cash inflow during the period \\(n\\), \\(r\\) the discount rate, or the cost of capital, \\(n\\) the number of periods, and \\(C_0\\) the initial investment.\nIn other words, NPV helps determine the current value of future cash flows, adjusted for the time value of money. A positive NPV indicates that an investment is expected to generate a return greater than the cost of capital, while a negative NPV suggests that the investment is likely to result in a loss.\nInternal Rate of Return (IRR), on the other hand, is the discount rate that makes the NPV of all cash inflows equal to the NPV of all cash outflows. The formula to calculate IRR is:\n\\[ 0 = \\sum_{n=0}^{N} \\frac{C_n}{(1+IRR)^n}  \\]\nwhere \\(C_n\\) denotes the net cash inflow during the period \\(n\\), \\(IRR\\) the internal rate of return, \\(n\\) the number of periods, and \\(C_0\\) the initial investment.\nIRR can be thought of as the rate of return an investment generates over time, taking into account the time value of money. When comparing different investment opportunities, a higher IRR generally indicates a more profitable investment.\nBoth NPV and IRR are important tools to help individuals make informed decisions about financial products. By comparing the NPV and IRR of different investment options, individuals can determine which investments are likely to generate the greatest returns over time, and which products may not be worth the initial investment.\nIt is worth noting that while NPV and IRR are useful indicators for decision making, they are not the only factors to consider. Individuals should also consider other important factors such as risk, liquidity, and diversification when evaluating different financial products. By taking a holistic approach and considering all relevant factors, individuals can make informed decisions that are best suited to their financial goals and circumstances.\n\n\n\n\n\n\n\nExercise 9.3 Investment case\nYou deposit 1,000 euros today into a savings account with an annual interest rate of 5% for 2 years. What is the balance after 2 years with annual, semi-annual (4 interest payments per year), and continuous compounding?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nAnnual compounding:\n\n\\[1,000 \\text{€} \\cdot (1 + 0.05) ^ 2 = 1,102.50 \\text{€}\\]\n\nSemi-annual compounding:\n\n\\[ 1,000 \\text{€} \\cdot \\left( 1 +  \\frac{0.05}{4} \\right)^{2 \\cdot 4} = 1,104.49 \\text{€}\\] - Continuous compounding:\n\\[1,000 \\text{€} \\cdot e^{0.05 \\cdot 2} = 1,105.17 \\text{€}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.4 Present value\nYou want to have 100,000 in 10 years, and you can save money with an interest rate of 5% p.a. How much do you need to invest today for annual, semi-annual (4 interest periods), and continuous compounding to achieve your goal?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nAnnual compounding:\n\nThe formula for the future value of a present amount with annual compounding is: \\[\nV_{\\text{future}} = V_{\\text{present}} \\cdot (1 + i)^t\n\\]\nTo calculate the present value, we need to rearrange the above formula for Present Value: \\[\nV_{\\text{present}} = \\frac{V_{\\text{future}}}{(1 + i)^t}\n\\] \\[\nV_{\\text{present}} = \\frac{100,000}{(1 + 0.05)^{10}} \\approx 61,391\n\\]\n\nSemi-annual compounding (4 interest periods per year):\n\nThe formula for the future value of a present amount with semi-annual compounding is: \\[\nV_{\\text{future}} = V_{\\text{present}} \\cdot \\left(1 + \\frac{i}{p}\\right)^{p\\cdot t}.\n\\] To calculate the present value, we need to rearrange the above formula for Present Value: \\[\nV_{\\text{present}} = \\frac{V_{\\text{present}}}{\\left(1 +\\frac{i}{p}\\right)^{p\\cdot t}}\n\\] \\[\n\\frac{100,000}{\\left(1 + \\frac{0.05}{4}\\right)^{4\\cdot 10}} \\approx 60,841\n\\]\n\nContinuous compounding:\n\nThe formula for the future value of a present amount with continuous compounding is: \\[\nV_{\\text{future}} = V_{\\text{present}} \\cdot e^{i \\cdot t}\n\\] To calculate the present value, we need to rearrange the above formula for present value: \\[\nV_{\\text{present}}  = \\frac{V_{\\text{future}}}{e^{i\\cdot t}}\n\\] \\[\nV_{\\text{present}} = \\frac{100,000}{e^{0.05 \\cdot 10}} \\approx 60,653\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.5 Invest in A or B\nYou are considering investing in project A or B.\nProject A: It costs 50,000 today and is expected to generate cash flows of 20,000 per year for the next 5 years. You have a required rate of return of 8%.\nProject B: It costs 50,000 today and you get 100,000 back in 5 years.\nCalculate the value of your invest after five years. Which investment is the better one?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\nV_{A}^{t=5}\\approx 117,332\n\\] \\[\nV_{B}^{t=5}= 100,000\n\\]\nThus, we should prefer project A.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.6 Net present value\nYou are considering investing in project A or B.\nProject A: It costs 50,000 today and is expected to generate cash flows of 20,000 per year for the next 5 years. You have a required rate of return of 8%.\nProject B: It costs 50,000 today and you get 100,000 back in 5 years.\nCalculate the net present value of both projects and decide where to invest.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAssuming that the cash flows occur at the end of each year, we can use the following formula to calculate the NPV of the project:\n\\[\nNPV = \\sum_{n=1}^{N} \\frac{C_n}{(1+r)^n} - C_0\n\\]\n\\[\nNPV_A = -50,000 + \\frac{20,000}{(1 + 0.08)^1} +\n    \\frac{20,000 }{ (1 + 0.08)^2} +\n        \\frac{20,000 }{ (1 + 0.08)^3} +\n            \\frac{20,000 }{ (1 + 0.08)^4} +\n                \\frac{20,000 }{ (1 + 0.08)^5}\n\\]\n\\[\nNPV_A = -50,000 + 18,518.52 + 17,146.77 + 15,876.64 + 14,700.59 + 13,611.66 \\approx 29,854\n\\]\n\\[\nNPV_B = -50,000 + \\frac{100,000 }{ (1 + 0.08)^5} = -50,000+68058,31\\approx 18058\n\\] Since the \\(NPV_A&gt;NPV_B\\), we should invest in project A.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.7 Internal rate of return\nYou are considering investing in project A or B.\nProject A: It costs 50,000 today and is expected to generate cash flows of 20,000 per year for the next 5 years. You have a required rate of return of 8%.\nProject B: It costs 50,000 today and you get 100,000 back in 5 years.\nCalculate the internal rate of return of both projects with the help of a software package such as Excel or Libre Calc and decide where to invest.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAssuming that the cash flows occur at the end of each year, we can use the following formula to calculate the IRR of the project: \\[ 0 = \\sum_{n=0}^{N} \\frac{C_n}{(1+IRR)^n}  \\] \\[\n0 = -50,000 +\n\\frac{20,000}{(1 + IRR)^1}\n+ \\frac{20,000 }{ (1 + IRR)^2 }\n+ \\frac{20,000 }{ (1 + IRR)^3 }\n+ \\frac{20,000 }{ (1 + IRR)^4 }\n+ \\frac{20,000 }{ (1 + IRR)^5 }\n\\]\nSolving for \\(IRR\\) is not that easy. Using a spreadsheet program, we get \\(IRR_A\\approx 28.68%\\) and \\(IRR_B\\approx 14.87%\\). Thus, project A seems to be better.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.8 Rule of 70\nThe Rule of 70 is often used to approximate the time required for a growing series to double. To understand this rule calculate how many periods it takes to double your money when it growth at a constant rate of 1% each period.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhat is the time required for a growing variable to double?\nLet \\(X\\) be the initial value of a growing variable, and \\(Y\\) denote the terminal value at time \\(t + n\\). The relationship between the two is given by\n\\[Y = X(1+g)^n\\]\nwhere \\(g\\) is the annual growth rate. As we are interested in the time span required for \\(X\\) to double, \\(Y = 2\\), and\n\\[2 = (1+g)^n\\]\nTaking natural logarithms (logarithm to the base of \\(e\\)), we get\n\\[\\ln 2 = n \\ln (1+g)\\]\nand hence\n\\[n = \\frac{\\ln 2}{\\ln (1+g)} \\quad (*).\\]\nThis is the exact number of time periods required for a growing variable to double its size.\nOne can approximate \\(n\\) using the definition of \\(e^x\\):\n\\[e^x = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots + \\frac{x^n}{n!} + R_n\\]\nwhere the remainder term \\(R_n \\rightarrow 0\\) as \\(n \\rightarrow \\infty\\). Ignoring high-order terms, for small \\(x\\), it may be approximated by\n\\[e^x \\approx 1 + x\\]\nTaking logarithms of both sides, we get\n\\[x \\approx \\ln (1 + x) \\quad (**).\\]\nUsing (**), equation (*) may be approximated as\n\\[n \\approx \\frac{\\ln 2}{g} = \\frac{0.693147}{g} \\approx \\frac{70}{g\\%}\\]\nThis is the origin of the Rule of 70.\nUsing the number \\(e\\) right away is simpler:\n\\[\\begin{align*}\n(e^r)^t &= 2 \\\\\n\\ln e^{rt} &= \\ln 2 \\\\\nrt &= \\ln 2 \\\\\nt &= \\frac{\\ln 2}{r} \\\\\nt &\\approx \\frac{0.693147}{r}\n\\end{align*}\\]",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Finance</span>"
    ]
  },
  {
    "objectID": "finance.html#sec-noteloggrow",
    "href": "finance.html#sec-noteloggrow",
    "title": "9  Finance",
    "section": "9.3 A note on growth rates and the logarithm",
    "text": "9.3 A note on growth rates and the logarithm\n\n9.3.1 Log approximation of growth rates\nMost data are recorded for discrete periods of time (e.g., quarters, years). Consequently, it is often useful to model economic dynamics in discrete periods of time. A good linear approximation to a growth rate from time \\(t=0\\) to \\(t=1\\) in \\(x\\) is \\(\\ln x_0 - \\ln x_1\\):\n\\[\ng=\\frac{x_1 - x_0}{x_0} \\approx \\ln x_1 - \\ln x_0\n\\]\nLet us prove that with the a small change from 1000 to 1002. The exact calculation would be: \\[\n\\frac{1002-1000}{1000}=0.002.\n\\] The approximate calculation is\n\\[\ng\\approx\\ln(1002)-\\ln(1000)=0.00199800266267314.\n\\]\nThe approximation is close because the change is small.\nLet us consider now changes considering some numbers of per capita real GDP for the US and Japan in 1950 and 1989 given in Table 9.1.\n\n\n\nTable 9.1: GDP over time\n\n\n\n\n\nYear\nUS\nJapan\n\n\n\n\n1950\n8611\n1563\n\n\n1989\n18317\n15101\n\n\n\n\n\n\nFor these large changes the said approximation does not give us close results. The exact calculation for the US would be: \\[\ng=\\frac{18317-8611}{8611}=1.1271629311346.\n\\] The approximate calculation is\n\\[\ng\\approx \\ln(18317)-\\ln(8611)=0.754789134664051.\n\\]\n\n\n9.3.2 Annual average growth rates\nWhat are the annual average growth rates over this period for the US and Japan? Here is one way to answer this question:\n\\[\\begin{align}\nY_{1989} &= (1 + g)^{39} \\cdot Y_{1950}\\\\\n\\Leftrightarrow \\frac{Y_{1989}}{Y_{1950}} &= (1 + g)^{39}\\\\\n\\Leftrightarrow g &= \\left(\\frac{Y_{1989}}{Y_{1950}}\\right)^{\\frac{1}{39}}-1.\n\\end{align}\\]\nYielding \\(g = 0.019542\\) for the US and \\(g = 0.0598822\\) for Japan. The US grew at an average growth rate of about 2% annually over the period, while Japan grew at about 6% annually.  \nLet us now do the calculation using the natural log of both sides of:\n\\[\n\\frac{Y_{1989}}{Y_{1950}} = (1 + g)^{39}\n\\]\nto get:\n\\[\n\\ln (Y_{1989}) - \\ln (Y_{1950}) = 39 \\cdot \\ln (1 + g)\n\\]\nwhich rearranges to:\n\\[\n\\ln (1 + g) = \\frac{\\ln (Y_{1989}) - \\ln (Y_{1950})}{39}.\n\\] Calculating that now for the US and China, we get \\(g \\approx 0.0195420\\) for the US and \\(g \\approx 0.05988224\\) for Japan. \n\n\n\n\n\n\n9.3.3 Plotting growth using the logarithm\nRecall that, with a constant growth rate \\(g\\) and starting from time 0, output in time \\(t\\) is:\n\\[Y_t = (1 + g)^t \\cdot Y_0\\]\nTaking natural logs of both sides, we have:\n\\[\\ln Y_t = \\ln Y_0 + t \\cdot \\ln (1 + g)\\]\nWe see that log output is linear in time. Thus, if the growth rate is constant, a plot of log output against time will yield a straight line. Consequently, plotting log output against time is a quick way to eyeball whether growth rates have changed over time.\n\n\n\nFigure 9.1: Log plot\n\n\n\n\n\n\nIn Figure 9.1 and Figure 9.2 you see a semi-logarithmic plot that has one axis on a logarithmic scale and the other on a linear scale. It is useful for data with exponential relationships, where one variable covers a large range of values, or to zoom in and visualize that what seems to be a straight line in the beginning is, in fact, the slow start of a logarithmic curve that is about to spike, and changes are much bigger than thought initially.\n\n\n\nFigure 9.2: Log-Lin scale\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.9 Investments over time\nDescribe the formulas to describe the growth process of an investment over time when time is discrete and when time is continuous.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe formula under discrete time is: \\[\nY_t=Y_0\\cdot (1+g)^t\n\\] The formula under continuous time is: \\[\nY_t=Y_0\\cdot e^{gt}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.10 Exponential growth\nSketch a timeline for each of the following series:\n\n\\(a_t=a_{t-1}+g\\)\n\\(\\ln(a_t)\\)\n\\(b_t=b_{t-1}\\cdot (1+g)\\)\n\\(\\ln b_t\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFigure Figure 9.3 provides the solution.\n\n\n\nFigure 9.3: Various growth functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.11 COVID and how to plot it\nI downloaded the complete Our World in Data COVID-19 dataset from ourworldindata.org. I created some graphs which I will show you below in Figure 9.4 to Figure 9.9. Can you discuss the scaling and how to interpret them? What is your opinion on these graphs? Are some of them a bit misleading (at least if you don’t look twice)?\n\n\n\nFigure 9.4: Total cases\n\n\n\n\n\n\n\n\n\nFigure 9.5: Total cases 2\n\n\n\n\n\n\n\n\n\nFigure 9.6: Total cases 3\n\n\n\n\n\n\n\n\n\nFigure 9.7: New cases\n\n\n\n\n\n\n\n\n\nFigure 9.8: New cases 2\n\n\n\n\n\n\n\n\n\nFigure 9.9: New cases 3",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Finance</span>"
    ]
  },
  {
    "objectID": "constraints.html",
    "href": "constraints.html",
    "title": "10  Under constraints",
    "section": "",
    "text": "10.1 Consumption and production choices\nSubjects such as consumers and producers often face decisions with specific goals while dealing with various constraints. This process is referred to as decision-making and optimization under constraints. Specifically, we encounter problems related to maximization or minimization within these constraints.\nFor example, consumers may have a fixed budget to allocate among various items, or consumers have identified a specific basket of items they wish to purchase and now they seek to minimize the costs for that basket. The first is represents a maximization problem and the latter a minimization problem. Similarly, producers typically aim to maximize their profits given a limited amount of production factors, or they seek to minimize costs for a certain level of production.\nThis section will explore how to approach these optimization problems rationally. We will revisit the concept of utility before discussing two mathematical techniques that can provide solutions: the Lagrangian Multiplier method and Linear Programming.\nIn microeconomics, utility maximization (in its simplest form when having just two goods) involves selecting a combination of two goods that satisfies two essential conditions, see Figure 10.1:\nThese conditions ensure that the consumer selects the optimal bundle of goods that maximizes their utility while taking into account the constraints imposed by production capabilities or budget limitations.\nBy analyzing production possibilities and individual preferences, economists gain insights into how consumers make choices, allocate resources, and achieve utility maximization. Understanding these concepts helps economists explore the trade-offs and decision-making processes that influence consumer behavior and shape market dynamics.\nIf you are not familiar with the basic principles of the production possibility frontier curve, indifference curves, and budget constraints, I recommend referring to Appendix A for a comprehensive overview. This section provides a detailed explanation and exploration of these concepts.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Under constraints</span>"
    ]
  },
  {
    "objectID": "constraints.html#consumption-and-production-choices",
    "href": "constraints.html#consumption-and-production-choices",
    "title": "10  Under constraints",
    "section": "",
    "text": "The chosen point of utility maximization must fall within the attainable region defined by the Production Possibility Frontier (PPF) or be affordable within the constraints of a given budget.\nThe selected point of utility maximization must lie on the highest indifference curve that is consistent with the first condition.\n\n\n\n\nFigure 10.1: Optimal consumption\n\n\n\n\n\n\n\n\n\n\n10.1.1 The role of income and budget\nIf income increases the budget constraint curve shifts outwards (to the right) as shown in Figure 10.2.\n\n\n\nFigure 10.2: Impact of income change on consumption\n\n\n\n\n\n\nThe utility-maximizing choice on the original budget constraint is M. The dashed horizontal and vertical lines extending through point M allow you to see at a glance whether the quantity consumed of goods on the new budget constraint is higher or lower than on the original budget constraint. On the new budget constraint, a choice like N will be made if both goods are normal goods. If good \\(x\\) is an inferior good, a choice like P will be made. If good \\(y\\) is an inferior good, a choice like Q will be made.\n\n\n10.1.2 The role of prices\nIf price of one good increases then the budget constraint curve. When the price rises, the budget constraint shifts in to the left for that good.\n\n\n\nFigure 10.3: Impact of price change on consumption\n\n\n\n\n\n\nThe dashed lines make it possible to see at a glance whether the new consumption choice involves less of both goods, or less of one good and more of the other. The new possible choices would be good \\(x\\)’s and more good \\(y\\)’s, like point H, or less of both goods, as at point J. Choice K would mean that the higher price of good \\(x\\) led to exactly the same quantity of good \\(x\\) being consumed, but fewer of good \\(y\\). Choices like L are theoretically possible (if good \\(x\\) are giffen goods) but highly unlikely in the real world, because they would mean that a higher price for goods \\(x\\) means a greater quantity consumed of good \\(x\\).\n\n\n10.1.3 Substitution and income effect\nWhen prices increase, individuals typically respond by reducing their consumption of the product with the higher price. This reaction is driven by two factors, both of which can occur simultaneously.\n\n\n\nFigure 10.4: Impact of income change on consumption\n\n\n\n\n\n\nThe substitution effect occurs when a price change incentivizes consumers to consume less of a good with a relatively higher price and more of a good with a relatively lower price.\nThe income effect stems from the fact that a higher price effectively reduces the purchasing power of income (even if actual income remains the same). This reduction in purchasing power leads to a decrease in the consumption of the good, particularly when the good is considered normal.\nFigure 10.4 illustrates the Hicksian decomposition for a price reduction of good \\(A\\), which affects the consumption of goods \\(A\\) and \\(B\\), shifting the consumption point from \\(C\\) to \\(D\\). The point \\(C'\\) represents the hypothetical consumption point resulting from a rotated budget constraint that reflects the new price relationship.\n\n\n\n\n\n\n\nExercise 10.1 The graphical foundations of demand curves\nA shift in the budget constraint means that when individuals are seeking their highest utility, the quantity that is demanded of that good will change. In this way, the logical foundations of demand curves—which show a connection between prices and quantity demanded—are based on the underlying idea of individuals seeking utility.\nIn Figure 10.5, two points of consumption are displayed, illustrating the optimal choices made by customers when faced with prices \\(p_x^1&gt;p_x^2\\). The objective of this exercise is to graphically derive the demand function for good \\(x\\). To accomplish this, please provide a second two-dimensional plot below the existing graph, with the price of good \\(x\\), \\(p_x\\), represented on the y-axis.\n\n\n\n\n\n\n\nFigure 10.5: Graphical derivation of the demand function\n\n\n\n\n\n\n\n\n10.1.4 Consumption, production, and terms of trade\nMarket prices in a closed economy: The price relation of two goods, the so-called terms of trade, is determined by the slope of the Production Possibility Frontier (PPF) at the point where it is tangent to the indifference curve. This relationship highlights the trade-off between the two goods and their relative scarcity within a closed economy.\nUtility maximizing production: The production point that maximizes utility is where the PPF is tangent to the price relation, that is, the terms of trade. This principle applies not only in a closed economy (autarky) but also under free trade (open economy). It implies that producers should allocate resources in a way that balances the trade-off between producing more of one good at the expense of another, while considering consumer preferences. Figure 10.1 depicts this.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Under constraints</span>"
    ]
  },
  {
    "objectID": "constraints.html#linear-programming",
    "href": "constraints.html#linear-programming",
    "title": "10  Under constraints",
    "section": "10.2 Linear programming",
    "text": "10.2 Linear programming\nLinear Programming is a common technique for decision making under certainty. It allows to express a desired benefit (such as profit) as a mathematical function of several variables. The solution is the set of values for the independent variables (decision variables) that serves to maximize the benefit or to minimize the negative outcome under consideration of certain limits, a.k.a. constraints. The method usually follows a four step procedure:\n\nstate the problem;\nstate the decision variables;\nset up an objective function;\nclarify the constraints.\n\nExample: Consider a factory producing two products, product X and product Y. The problem is this: If you can realize $10.00 profit per unit of product X and $14.00 per unit of product Y, what is the production level of x units of product X and y units of product Y that maximizes the profit P each day? Your production, and therefore your profit, is subject to resource limitations, or constraints. Assume in this example that you employ five workers—three machinists and two assemblers—and that each works only 40 hours a week.1\n1 The example is taken from Morse et al. (2014, p. 134f).\nMorse, L. C., Babcock, D. L., & Murthy, M. (2014). Managing engineering and technology (Sixth Edition). Pearson.\n\nProduct X requires three hours of machining and one hour of assembly per unit.\nProduct Y requires two hours of machining and two hours of assembly per unit.\n\n\nState the problem: How many of product X and product Y to produce to maximize profit?\nDecision variables: Suppose x denotes the number of product X to produce per day and y denotes number of product Y to produce per day\nObjective function: Maximize \\[P = 10x + 14y\\]\nConstraints:\n\n\nmachine time=120h\nassembling time=80h\nhours needed for production of one good:\n\nmachine time: \\(x\\rightarrow 3h\\) and \\(y \\rightarrow 2h\\)\nassembling time: \\(x\\rightarrow 1h\\) and \\(y \\rightarrow 2h\\)\nThus, we get: \\[3x + 2y \\leq 120 \\quad \\Leftrightarrow y\\leq 60-\\frac{3}{2}x \\quad \\text{(hours of machining time)}\\] \\[x + 2y \\leq 80 \\quad \\Leftrightarrow y \\leq 40-\\frac{1}{2}x \\quad \\text{(hours of assembly time)}\\] Since there are only two products, these limitations can be shown on a two-dimensional graph Figure 10.6. Since all relationships are linear, the solution to our problem will fall at one of the corners.\n\n\n\nFigure 10.6: Linear program example: Constraints and solution\n\n\n\n\n\n\nTo draw the isoprofit function in a plot with the good \\(y\\) on the y-axis and good \\(x\\) on the x-axis, we can re-arrange the objective function to get \\[y=\\frac{1}{14}P-\\frac{10}{14}x\\] To illustrate the function let us consider some arbitrarily chosen levels of profit in Figure 10.7:\n\n$350 by selling 35 units of X or 25 units of Y\n$700 by selling 70 units of X or 50 units of Y\n$620 by selling 62 units of X or 44.3 units of Y.\n\n\n\n\nFigure 10.7: Linear program example: Isoprofit lines\n\n\n\n\n\n\nTo find the solution, begin at some feasible solution (satisfying the given constraints) such as \\((x,y) = (0,0)\\), and proceed in the direction of steepest ascent of the profit function (in this case, by increasing production of Y at $14.00 profit per unit) until some constraint is reached. Since assembly hours are limited to 80, no more than 80/2, or 40, units of Y can be made, earning \\(40 \\cdot \\$14.00\\), or $560 profit. Then proceed along the steepest allowable ascent from there (along the assembly constraint line) until another constraint (machining hours) is reached. At that point, (x,y) = (20,30) and profit P = (20 * +10.00) + (30 * +14.00), or $620. Since there is no remaining edge along which profit increases, this is the optimum solution.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Under constraints</span>"
    ]
  },
  {
    "objectID": "constraints.html#lagrange-multiplier-method",
    "href": "constraints.html#lagrange-multiplier-method",
    "title": "10  Under constraints",
    "section": "10.3 Lagrange multiplier method",
    "text": "10.3 Lagrange multiplier method\nThe method outlined below requires an understanding of how to take derivatives of functions and solve systems of equations. If readers feel they need a refresher on these topics, I recommend consulting the lecture notes Calculus and Linear Algebra from Huber (2023).\n\nHuber, S. (2023). Mathematics and statistics I: Calculus and linear algebra (lecture notes). online. https://raw.githubusercontent.com/hubchev/courses/main/pdfs/cla_A4.pdf\n\n\n\nFigure 10.8: Joseph-Louis Lagrange (1736-1813)2\n\n2 Picture is taken from http://www-history.mcs.st-and.ac.uk/history/PictDisplay/Lagrange.html\n\n\n\n\nThe decision-making process of consumers and producers lies at the core of microeconomic research and is of significant importance for managers. I will not go into detail here, but I will show some examples of how to come to a decision when certain information is given.\nFor a deeper understanding of the microeconomic preliminaries related to this topic, please read section Appendix A of the appendix.\n\n\n\nFigure 10.9: Contours of the function and the constraint in red\n\n\n\n\n\n\nThe Lagrange multiplier method, named after Joseph-Louis Lagrange (see Figure 10.8), is a strategy for finding the local maxima and minima of a function subject to constraints. The red curve in Figure 10.9 represents the constraint \\(g(x, y) = c\\), while the blue curves depict contours of \\(f(x, y)\\). The point where the red constraint tangentially intersects a blue contour represents the maximum of \\(f(x, y)\\) along the constraint, as \\(d1 &gt; d2\\).\nFor a detailed visual explanation of the method, you can watch Dr. Trefor Bazett’s YouTube video on Lagrange Multipliers | Geometric Meaning & Full Example, see Figure 10.10.\n\n\n\nFigure 10.10: Lagrange Multiplier graphically explained3\n\n3 This is a snapshot of a YouTube clip, see: https://youtu.be/8mjcnxGMwFo\n\n\n\n\nThe Lagrange multiplier method, named after Joseph-Louis Lagrange, is a powerful technique for solving optimization problems with constraints. It allows us to find the local maxima and minima of a function subject to certain conditions. The method involves four key steps:\nStep 1: Formulate the Problem\nDefine the problem you want to solve in mathematical terms. This includes specifying the objective function to be maximized or minimized and the constraints that need to be satisfied.\nThe problem that we want to solve can be written in the following way, \\[\n\\begin{array}{ll}\n    \\max _{x, y} & F(x, y) \\\\\n    \\text{ s.t. } & g(x, y)=0\n\\end{array}\n\\] where \\(F(x, y)\\) is the function to be maximized and \\(g(x, y)=0\\) is the constraint to be respected. Notice that \\(\\max _{x, y}\\) means that we must solve (maximize) with respect to \\(x\\) and \\(y\\).\nStep 2: Construct the Lagrangian\nCreate a new function called the Lagrangian by combining the objective function and the constraints using Lagrange multipliers. The Lagrangian introduces new variables, known as Lagrange multipliers, to account for the constraints. The Lagrangian, \\(\\mathcal{L}\\), is a combination of the functions that explain the problem: The \\(\\lambda\\) is called the Lagrange Multiplier. \\[\n\\mathcal{L}(x, y, \\lambda)=F(x, y)-\\lambda g(x, y)\n\\]\nStep 3: Determine the First-Order Conditions\nDifferentiate the Lagrangian with respect to the variables of the problem (e.g., x and y) and the Lagrange multipliers. Set the partial derivatives equal to zero to obtain the first-order conditions. These conditions represent the necessary conditions for optimality.\nDifferentiate \\(\\mathcal{L}\\) w.r.t. \\(x, y,\\) and \\(\\lambda\\) and equate the partial derivatives to 0: \\[\\begin{align*}\n    \\frac{\\partial \\mathcal{L}(x, y, \\lambda)}{\\partial x}=0 & \\Leftrightarrow \\frac{\\partial F(x, y)}{\\partial x}-\\lambda \\frac{\\partial g(x, y)}{\\partial x}=0 \\\\\n    \\frac{\\partial \\mathcal{L}(x, y, \\lambda)}{\\partial y}=0 & \\Leftrightarrow \\frac{\\partial F(x, y)}{\\partial y}-\\lambda \\frac{\\partial g(x, y)}{\\partial y}=0 \\\\\n    \\frac{\\partial \\mathcal{L}(x, y, \\lambda)}{\\partial \\lambda}=0 & \\Leftrightarrow g(x, y)=0\n\\end{align*}\\]\nStep 4: Solve the System of Equations\nSolve the system of equations obtained from the first-order conditions to find the values of the variables and Lagrange multipliers that satisfy the optimality conditions. The solutions represent the optimal quantities that maximize or minimize the objective function subject to the given constraints.\nBy following these four steps, you can effectively apply the Lagrange multiplier method to various optimization problems with constraints. It provides a systematic approach to finding the optimal solutions while incorporating the necessary trade-offs imposed by the constraints.",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Under constraints</span>"
    ]
  },
  {
    "objectID": "constraints.html#exercises",
    "href": "constraints.html#exercises",
    "title": "10  Under constraints",
    "section": "10.4 Exercises",
    "text": "10.4 Exercises\n\n\n\n\n\n\n\nExercise 10.2 Burgers and drinks\nSuppose you are in a fast food restaurant and you want to buy burgers and some drinks. You have €12 to spend, a burger costs €3 and a drink costs €2.\n\nAssume that you want to spend all your money and that you can only buy complete units of each products. What are the possible choices of consumption?\nGiven your utility function \\(U(x,y)=B^{0.6}D^{0.4}\\) calculate for each possible consumption point your overall utility. How will you decide?\nAssume that you want to spend all your money and that both products can be bought on a metric scale where one burger weights 200 grams and a drink is 200 ml. How much of both goods would you consume now? Hint: Use the Lagrangian multiplier method.4\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn Figure 10.11, I marked all 19 possible bundles of burger and drinks of consumption. The budget constraint is shown by the solid line.\n\n\n\nFigure 10.11: Possible consumption choices\n\n\n\n\n\n\n\nWe now should calculate the utility of all 19 points, but only the red dots denote choices that may yield an optimal utility. The best utility is achieved when we buy 2 burgers and 3 drinks:\n\n\\[U=2^{0.6}3^{0.4}=2.35\\]\n\nSolve:\n\n\\[\n\\mathcal{L}=B^{0.6}D^{0.4}+\\lambda(3B+2D-12)\n\\]\nFOC: \\[\\begin{align*}\n3B+2D-12&=0\\\\\n0.6B^{-0.4}D^{0.4}+3\\lambda&=0\\\\\n0.4B^{0.6}D^{-0.6}+2\\lambda&=0\n\\end{align*}\\]\nSolving the second and third FOC for \\(\\lambda\\) and substituting \\(\\lambda\\) gives:\n\\[B=D\\]\nwhich we can plug into the first FOC to obtain:\n\\[B^*=2.4 \\quad \\text{and} \\quad D^*=2.4\\]\n\n\n\n\n\n\n4 Also see: http://www.sfu.ca/~wainwrig/5701/notes-lagrange.pdf\n\n\n\n\n\n\nExercise 10.3 Labor and machines\nSuppose you rent a factory for a month to produce as many masks as possible. After you have paid the rent, you need to decide how many machines to buy and how many workers to hire for the given month.\nWhat is the optimal amount of workers and machines to employ for the given month, if you assume the following:\n\n\\(L\\) denotes the number of workers\n\\(K\\) denotes the number of machines\n\\(Q\\) denotes the number of masks produced\n\\(p_L\\) denotes the price of a worker for a month\n\\(p_K\\) denotes the price of a machine for a month\n\\(B\\) denotes the money you can invest in the production of masks for the next month\n\\(B = 216\\)\nThe production of masks can be explained by the following Cobb-Douglas production function: \\(Q = K^{0.4}L^{0.6}\\)\n\\(p_L = 2\\)\n\\(p_K = 8\\)\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSet up Lagrangian: \\[\\mathcal{L} = K^{0.4}L^{0.6} - 216\\lambda + 2\\lambda L + 8\\lambda K\\]\n\nFOC: \\[\\begin{align*}\n   0 &= 0.4K^{-0.6}L^{0.6} - 8\\lambda \\quad (*) \\\\\n   0 &= 0.6K^{0.4}L^{-0.4} - 2\\lambda \\quad (**) \\\\\n   0 &= 216 - 2L - 8K \\quad (***) \\\\\n\\end{align*}\\]\nSolving (*) and (**) for \\(\\lambda\\) and substituting \\(\\lambda\\) gives us: \\[\\frac{1}{6}L = K \\quad (****)\\]\nPlugging (****) into (***) yields: \\[0 = 216 - 2L - 8\\cdot\\left(\\frac{1}{6}L\\right) \\Rightarrow L = 64\\frac{4}{5}\\]\nUsing that result in (***) again, we get: \\[216 - 2\\cdot 64\\frac{4}{5} + 8K \\Rightarrow K = 10\\frac{4}{5}\\]\n\nThus, the optimal combination of inputs is \\(L = 64\\frac{4}{5}\\) and \\(K = 10\\frac{4}{5}\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.4 Consumption choice\nSuppose you want to spend your complete budget of €30, \\[I=30,\\] on the consumption of two goods, \\(A\\) and \\(B\\). Further assume good \\(A\\) costs €6, \\[p_A=6,\\] and good \\(B\\) costs €4, \\[p_B=4\\] and that you want to maximize your utility that stems from consuming the two goods. Calculate how much of both goods to buy and consume, respectively, when your utility function is given as \\[U(A,B)=A^{0.8}B^{0.2}\\]\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\begin{align*}\n\\mathcal{L}&=A^{0.8}B^{0.2}+\\lambda(6A+4B-30)\\\\\nFOC: \\frac{\\partial \\mathcal{L}}{\\partial \\lambda}&=6A+4B-30=0 \\qquad (*)\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial A}&=0.8A^{-0.2}B^{0.2}+6\\lambda=0 \\qquad (**)\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial B}&=0.2A^{0.8}B^{-0.8}+4\\lambda=0 \\qquad (***)\n\\end{align*}\\] System of 3 equation with 3 unknowns can be solved in various ways. The easiest way is to solve () and (*) for \\(\\lambda\\) and substitute it out:\n\nsolve for \\(\\lambda\\) \\[\\begin{align*}\n  -\\frac{2}{15} A^{-0.2}B^{0.2}&=\\lambda \\qquad (**')\\\\\n      -\\frac{1}{20} A^{0.8}B^{-0.8}&=\\lambda \\qquad (***')\\\\\n\\end{align*}\\]\nset both equations equal by substituting \\(\\lambda\\) and solve for \\(B\\) \\[\\begin{align*}\n  \\frac{2}{15} A^{-0.2}B^{0.2}&=  \\frac{1}{20} A^{0.8}B^{-0.8}\\\\\n  B&=0.375A \\qquad (****) %\\\\\n\\end{align*}\\]\nNow, plug in \\((****)\\) into \\((*)\\) to get a number for \\(A\\) \\[\\begin{align*}\n  30&=6A+4\\cdot 0.375 A\\\\\n  \\Leftrightarrow 30&=7.5A\\\\\n  \\Leftrightarrow A&=4\n\\end{align*}\\]\nUse \\(A=4\\) in \\((*)\\) to get a number for \\(B\\) \\[\\begin{align*}\n  30&=6\\cdot 4+4 B\\\\\n  \\Leftrightarrow 6&=4B\\\\\n  B&=\\frac{6}{4}=1.5\n\\end{align*}\\]\n\nThus, we’d consume 4 units of good A and 1.5 of good B.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.5 Cost-minimizing combination of factors\nUsing two input factors \\(r_1\\) and \\(r_2\\), a firm wants to produces a fixed quantity of a product, that is \\(x=20\\). Given the production function \\[\n    x=\\frac{5}{4} r_1^{\\frac{1}{2}} r_2^{\\frac{1}{2}}\n    \\] and the factor prices \\[\n    p_{r_1}=1 \\quad \\text{ and } p_{r_2}=4.\n    \\] calculate the cost-minimizing combination of factors (\\(r_1, r_2\\)).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\n\\mathcal{L}=r_1+4r_2+\\lambda\\left(\\frac{5}{4}r_1^{\\frac{1}{2}}r_2^{\\frac{1}{2}}-20\\right)\n\\] Taking the FOC we get \\[r_1=4r_2\\] using that in the constraint, we get \\(r_1=32\\) and \\(r_2=8\\).\nAlso see which uses this tool: \n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.6 Lagrange with n-constraints\nWrite down the Lagrangian multiplier for the following minimization problem:\nMinimize \\(f(\\mathbf{x})\\) subject to: \\[\\begin{aligned}\n    g_1(\\mathbf{x})&=0 \\\\\n    g_2(\\mathbf{x})&=0\\\\\n    &\\vdots\\\\\n    g_n(\\mathbf{x})&=0,\\end{aligned}\\] where \\(n\\) denotes the number of constraints.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\n\\mathcal{L}(x_1, \\dots, x_m, \\lambda_i, \\dots, \\lambda_n)=f(\\mathbf{x})+\\lambda_1 g_1(\\mathbf{x})+\\lambda_2 g_2(\\mathbf{x})+\\ldots+\\lambda_n g_n(\\mathbf{x})\n\\] The points of local minimum would be the solution of the following equations: \\[\\begin{align*}\n    \\frac{\\partial \\mathcal{L}}{\\partial x_{j}} &=0 \\quad \\forall j=1 \\dots m \\\\\n    g_i(\\mathbf{x}) &=0 \\quad \\forall i=1\\dots n\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.7 Derivation of demand function using the Lagranian multiplier\nA representative consumer has on average the following utility function: \\(U=x y,\\) and faces a budget constraint of \\(B=P_{x} x+P_{y} y,\\) where \\(B, P_{x}\\) and \\(P_{y}\\) are the budget and prices, which are given. Solve the following choice problem:\nMaximize \\(U=x y\\) s.t. \\(B=P_{x} x+P_{y} y\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe Lagrangian for this problem is \\[\n  Z=x y+\\lambda\\left(P_{x} x+P_{y} y-B\\right)\n\\] The first order conditions are \\[\n\\begin{array}{l}\nZ_{x}=y+\\lambda P_{x}=0 \\\\\nZ_{y}=x+\\lambda P_{y}=0 \\\\\nZ_{\\lambda}=-B+P_{x} x+P_{y} y=0\n\\end{array}\n\\]\nSolving the first order conditions yield the following solutions\n\\[\n  x^{M}=\\frac{B}{2 P_{x}} \\quad y^{M}=\\frac{B}{2 P_{y}} \\quad \\lambda=\\frac{B}{2 P_{x} P_{y}}\n\\] where \\(x^{M}\\) and \\(y^{M}\\) are the consumer’s demand functions.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.8 Cobb-Douglas and demand\nA consumer who has a Cobb-Douglas utility function \\(u(x, y)=A x^{\\alpha} y^{\\beta}\\) faces the budget constraint \\(p x+q y=I\\), where \\(A, \\alpha, \\beta, p,\\) and \\(q\\) are positive constants. Solve the problem:\n\\[\n\\begin{array}{lll}\n\\max A x^{\\alpha} y^{\\beta} & \\text { subject to } & p x+q y=I\n\\end{array}\n\\]\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe Lagrangian is \\[\n\\mathcal{L}(x, y)=A x^{\\alpha} y^{\\beta}+\\lambda(p x+q y-I)\n\\]\nTherefore, the first-order conditions are \\[\n    \\begin{aligned}\n        \\mathcal{L}_{x}^{\\prime}(x, y)=A \\alpha x^{\\alpha-1} y^{\\beta}+\\lambda p &=0 \\qquad (*)\\\\\n        \\mathcal{L}_{y}^{\\prime}(x, y)=A x^{\\alpha} \\beta y^{\\beta-1}+\\lambda q &=0  \\qquad (**)\\\\\n        p x+q y-I &=0  \\qquad (***)\n    \\end{aligned}\n\\]\nSolving \\((*)\\) and \\((**)\\) for \\(\\lambda\\) yields \\[\n\\lambda=\\frac{A \\alpha x^{\\alpha-1} y^{\\beta-1} y}{p}=\\frac{A x^{\\alpha-1} x \\beta y^{\\beta-1}}{q}\n\\] Canceling the common factor \\(A x^{\\alpha-1} y^{\\beta-1}\\) from the last two fractions gives \\[\n    \\frac{\\alpha y}{p}=\\frac{x \\beta}{q}\n\\] and therefore \\[\nq y=p x \\frac{\\beta}{\\alpha}\n\\] Inserting this result in \\((***)\\) yields \\[\np x+p x \\frac{\\beta}{\\alpha}=I\n\\] Rearranging gives \\[\np x\\left(\\frac{\\alpha+\\beta}{\\alpha}\\right)=I\n\\] Solving for \\(x\\) yields the following demand function \\[\nx=\\frac{\\alpha}{\\alpha+\\beta} \\frac{I}{p}\n\\] Inserting \\[\np x=q y \\frac{\\alpha}{\\beta}\n\\] in \\((***)\\) gives \\[\nq y \\frac{\\partial}{\\beta}+q y=I\n\\] and therefore the _demand function} \\[\ny=\\frac{\\beta}{\\alpha+\\beta}  \\frac{I}{q}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.9 Understanding indifference curves and budget constraints\n\nWhich indifference curve in the figure on the right represents the highest utility level? Explain your decision.\nSuppose two goods are perfect substitutes. Two goods are substitutes if they can be used for the same purpose or provide the same utility to the consumer. Draw the indifference curves for perfect substitutes.\nSuppose two goods are perfect complements. Two goods are complements if they go well together and the demand for one good is related to the demand for another good. A perfect complement is a good that must be consumed together with another good. Draw the indifference curves for perfect complements.\nSuppose you have a fixed income \\(I=10\\) that you can spend on consuming two goods \\(x, y\\) at certain prices \\(p_x=1, p_y=1\\). Draw the budget line consisting of all possible combinations of two goods that a consumer can buy at certain market prices by allocating his income. Using indifference curves, sketch what each consumer should consume to maximize utility.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\\(IC_3\\) represents the highest level of utility. \\(IC_1\\) represents the lowest level of utility.\n\nTask solved in class.\nTask solved in class.\nThe budget line can be sketched into a y-x plot by solving \\(p_xx+p_yy=I\\) for y: \\[y=\\frac{I}{p_y}-\\frac{p_x}{p_y}x\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.10 Utility maximization\n\n\n\nFigure 10.12: Utility maximization\n\n\n\nSource: This graph is taken from Emerson (2019, ch. 4)\n\n\n\nFigure 10.12 stems from Emerson (2019, ch. 4). Use the following sentences to describe the respective points in the figure.\n\nOptimal bundle.\nCan do better by trading some B for some A.\nCan do better by trading some B for some A.\nUnaffordable.\n\nPlease find solutions to the exercise in Emerson (2019, ch. 4).\n\n\n\n\n\n\n\nEmerson, P. M. (2019). Intermediate microeconomics (O. S. University, Ed.; 1st edition). Open Educational Resources. https://open.oregonstate.education/intermediatemicroeconomics",
    "crumbs": [
      "Decision making theory",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Under constraints</span>"
    ]
  },
  {
    "objectID": "cognitive.html",
    "href": "cognitive.html",
    "title": "11  Cognitive biases",
    "section": "",
    "text": "11.1 Availability heuristic\nIn section Section 2.3.3, we discussed how human beings have limited cognitive abilities to arrive at optimal solutions. Behavioral economics, pioneered by Amos Tversky (1937-1996) and 2002 Nobel Prize winner Daniel Kahnemann (*1934), has identified several biases that explain why and when people fail to act perfectly rationally. In the following sections, we will explore some of the most prominent biases that arise from humans relying on heuristics in decision-making. Specifically, we will describe biases result from the use of availability, representative, and confirmation heuristics and can lead to flawed decision-making and negative outcomes for individuals and organizations. By recognizing and accounting for these biases, we can make better decisions.\nThe availability heuristic refers to our tendency to make judgments or decisions based on information that is easily retrievable from memory. For example, if someone hears a lot of news about a particular stock or investment, they may be more likely to invest in it, even if there are other better investment options available. This bias can also lead individuals to overestimate the frequency of certain events, such as the likelihood of a market crash, based on recent media coverage.",
    "crumbs": [
      "Decision making practice",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cognitive biases</span>"
    ]
  },
  {
    "objectID": "cognitive.html#representative-heuristic",
    "href": "cognitive.html#representative-heuristic",
    "title": "11  Cognitive biases",
    "section": "11.2 Representative heuristic",
    "text": "11.2 Representative heuristic\nThe representative heuristic refers to our tendency to make judgments based on how similar something is to a stereotype or preconceived notion. For example, an investor might assume that a company with a flashy website and marketing materials is more successful than a company with a more low-key image, even if the latter is actually more profitable. This bias can also lead to assumptions about the performance of certain investment strategies based on their resemblance to other successful strategies.",
    "crumbs": [
      "Decision making practice",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cognitive biases</span>"
    ]
  },
  {
    "objectID": "cognitive.html#confirmation-heuristic",
    "href": "cognitive.html#confirmation-heuristic",
    "title": "11  Cognitive biases",
    "section": "11.3 Confirmation heuristic",
    "text": "11.3 Confirmation heuristic\nThe confirmation heuristic refers to our tendency to seek out information that confirms our existing beliefs and ignore information that contradicts them. For example, an investor who strongly believes in the potential of a particular investment might only read news and analysis that supports their belief and ignore any information that suggests otherwise. This can lead to a failure to consider potential risks and downsides of an investment.",
    "crumbs": [
      "Decision making practice",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cognitive biases</span>"
    ]
  },
  {
    "objectID": "cognitive.html#investment-mistakes",
    "href": "cognitive.html#investment-mistakes",
    "title": "11  Cognitive biases",
    "section": "11.4 Investment mistakes",
    "text": "11.4 Investment mistakes\nInvesting can be a daunting task, but avoiding some common investment mistakes can help set you on the right path to financial success. The following list list shows according to Stammers (2016) the Top 20 common investment mistakes without the explanations provided in the paper:\n\nStammers, R. (2016). Tips for avoiding the top 20 common investment mistakes (Version 1.0). CFA Institute; Accessed April 24, 2023. https://www.cfainstitute.org/-/media/documents/support/future-finance/avoiding-common-investor-mistakes.pdf\n\nExpecting too much or using someone else’s expectations: Nobody can tell you what a reasonable rate of return is without having an understanding of you, your goals, and your current asset allocation.\nNot having clear investment goals: Too many investors focus on the latest investment fad or on maximizing short-term investment return instead of designing an investment portfolio that has a high probability of achieving their long-term investment objectives.\nFailing to diversify enough: The best course of action is to find a balance. Seek the advice of a professional adviser.\nFocusing on the wrong kind of performance: If you find yourself looking short term, refocus.\nBuying high and selling low: Instead of rational decision making, many investment decisions are motivated by fear or greed.\nTrading too much and too often: You should always be sure you are on track. Use the impulse to reconfigure your investment portfolio as a prompt to learn more about the assets you hold instead of as a push to trade.\nPaying too much in fees and commissions: Look for funds that have fees that make sense and make sure you are receiving value for the advisory fees you are paying.\nFocusing too much on taxes: It is important that the impetus to buy or sell a security is driven by its merits, not its tax consequences.\nNot reviewing investments regularly: Check in regularly to make sure that your investments still make sense for your situation and that your portfolio doesn’t need rebalancing.\nTaking too much, too little, or the wrong risk: Make sure that you know your financial and emotional ability to take risks and recognize the investment risks you are taking.\nNot knowing the true performance of your investments: Many investors do not know how their investments have performed in the context of their portfolio. You must relate the performance of your overall portfolio to your plan to see if you are on track after accounting for costs and inflation.\nReacting to the media: Using the news channels as the sole source of investment analysis is a common investor mistake. Successful investors gather information from several independent sources and conduct their own proprietary research and analysis.\nChasing yield: High-yielding assets can be seductive, but the highest yields carry the highest risks. Past returns are no indication of future performance. Focus on the whole picture and don’t get distracted while disregarding risk management.\nTrying to be a market timing genius: Market timing is very difficult and attempting to make a well-timed call can be an investor’s undoing. Consistently contributing to your investment portfolio is often better than trying to trade in and out in an attempt to time the market.\nNot doing due diligence: Check the training, experience, and ethical standing of the people managing your money. Ask for references and check their work on the investments they recommend. Taking the time to do due diligence can help avoid fraudulent schemes and provide peace of mind.\nWorking with the wrong adviser: An investment adviser should share a similar philosophy about investing and life in general. The benefits of taking extra time to find the right adviser far outweigh the comfort of making a quick decision.\nLetting emotions get in the way: Investing can bring up significant emotional issues that can impede decision-making. A good adviser can help construct a plan that works no matter what the answers to important financial questions are.\nForgetting about inflation: It’s important to focus on real returns after accounting for fees and inflation. Even if the economy is not in a massive inflationary period, some costs will still rise, so it’s important to focus on what you can buy with your assets, rather than their value in dollar terms.\nNeglecting to start or continue: Investment management requires continual effort and analysis to be successful. It’s important to start investing and continue to invest over time, even if you lack basic knowledge or have experienced investment losses.\nNot controlling what you can: While you can’t control what the market will bear, you can control how much money you save. Continually investing capital over time can have as much influence on wealth accumulation as the return on investment and increase the probability of reaching your financial goals.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 11.2 Heuristics can fail\nRespond to the following problems which are taken from Bazerman & Moore (2012, p. 15f). In class, we will discuss your answers and how they match with the mathematically correct solutions to these problems.\nProblem 1: Please rank the following causes of death in the United States between 1990 and 2000. Place a 1 next to the most common cause, 2 next to the second, and so on. - Tobacco - Poor diet and physical inactivity - Motor vehicle accidents - Firearms (guns) - Illicit drug use\nNow, estimate the number of deaths caused by each of these five causes between 1990 and 2000.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAccording to Mokdad et al. (2004, p. 1240), the answer is the following order:\n\nTobacco\nPoor diet and physical inactivity\nMotor vehicle accidents\nFirearms (guns)\nIllicit drug use\n\n\n\n\nProblem 2: Estimate the percentage of words in the English language that begin with the letter “a.”\nProblem 3: Estimate the percentage of words in the English language that have the letter “a” as their third letter.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMost people estimate that there are more words beginning with “a” than words in which “a” is the third letter. In fact, the latter are more numerous than the former. Words beginning with “a” constitute roughly 6 percent of English words, whereas words with “a” as the third letter make up more than 9 percent of English words.\n\n\n\nProblem 4: Lisa is thirty-three and pregnant for the first time. She is worried about birth defects like Down syndrome. Her doctor tells her there is only a 1 in 1,000 chance that a woman of her age will have a baby with Down syndrome. However, Lisa remains anxious and decides to get a test called the Triple Screen, which detects Down syndrome. The test is moderately accurate: when a baby has Down syndrome, the test gives a positive result 86% of the time. However, 5% of babies who don’t have Down syndrome also get a false positive. Lisa takes the test and gets a positive result. What are the chances that her baby has Down syndrome?\n\n0-20%\n\n21-40%\n\n41-60%\n\n61-80%\n\n81-100%\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMost people think that Lisa has a substantial chance of having a baby with Down syndrome. The test gets it right 86 percent of the time, right? That sounds rather reliable, doesn’t it? Well, it does, but we should not rely on our feelings here. It’s better to do the math, because the correct result would show that there is just a 1.7 percent chance of the baby having Down syndrome. Here is the proof for that small number:\nLet \\(A\\) be the event of the baby having Down syndrome and \\(B\\) the event of a positive test result. Then,\n\\[\\begin{align*}\nP(A) &= 0.001 \\\\\nP(B \\mid A) &= 0.86 \\\\\nP(B \\mid \\neg A) &= 0.05 \\\\\nP(B) &= \\frac{999 \\cdot 0.05}{1000} + \\frac{1 \\cdot 0.86}{1000} = \\frac{50.81}{1000} = 0.05081 \\\\\nP(A \\mid B) &= \\frac{P(B \\mid A) P(A)}{P(B)} = \\frac{0.86 \\cdot 0.001}{0.05081} = 0.01693\n\\end{align*}\\]\n\n\n\nProblem 5: A town is served by two hospitals. In the larger hospital, about 45 babies are born each day. In the smaller hospital, about 15 babies are born daily. About 50% of all babies are boys. For a year, each hospital recorded days when more than 60% of the babies born were boys. Which hospital recorded more such days?\n\nThe larger hospital\n\nThe smaller hospital\n\nAbout the same (within 5%)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMost individuals choose C, expecting the two hospitals to record a similar number of days on which 60 percent or more of the babies born are boys. However, statistics tell us that we are much more likely to observe 60 percent of male babies in a smaller sample than in a larger sample. Think about which is more likely: getting more than 60 percent heads in 3 flips of a coin or in 3,000 flips of a coin? Half of the time, 3 flips will produce more than 60 percent heads. But with 3,000 flips, it happens about 0.0001 percent of the time. Most people ignore sample size when judging probabilities.\n\n\n\nProblem 6: You and your spouse have had three daughters. Now expecting a fourth child, you wonder about the odds of having a boy. What is the best estimate of your chances of having another girl?\n\n6.25% (1 in 16), because the odds of getting four girls in a row is 1 in 16\n\n50% (1 in 2), because there is an equal chance of getting each gender\n\nSomewhere between 6.25% and 50%\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMany assume that after having three girls, the probability of having another girl must be lower. However, the gender determination of each baby is independent; the chance remains 50 percent for each child, regardless of previous children.\n\n\n\nProblem 7: You manage a Major League Baseball team, and the 2005 season has just ended. Your job is to predict future player performance. You must estimate 2006 batting averages for nine players. Fill in your guesses in the right column:\n\n\n\nPlayer\n2005 Batting Average\nEstimated 2006 Batting Average\n\n\n\n\n1\n.215\n\n\n\n2\n.242\n\n\n\n3\n.244\n\n\n\n4\n.258\n\n\n\n5\n.261\n\n\n\n6\n.274\n\n\n\n7\n.276\n\n\n\n8\n.283\n\n\n\n9\n.305\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMost people predict that a player’s 2006 performance will be almost identical to their 2005 performance. However, statistics show the correlation between Major League Baseball players’ batting averages from one year to the next is only 0.4. This tendency is known as “regression to the mean”—the worst performers tend to improve, and the best tend to decline.\n\n\n\nProblem 8: Linda is 31, single, outspoken, and very smart. She majored in philosophy and was deeply concerned with issues of discrimination and social justice. Rank the following descriptions in order of how likely they are to describe Linda:\n\nLinda is a teacher in an elementary school.\n\nLinda works in a bookstore and takes yoga classes.\n\nLinda is active in the feminist movement.\n\nLinda is a psychiatric social worker.\n\nLinda is a member of the League of Women Voters.\n\nLinda is a bank teller.\n\nLinda is an insurance salesperson.\n\nLinda is a bank teller who is active in the feminist movement.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nExamine your rank orderings of descriptions C, F, and H. Most people rank C as more likely than H, and H as more likely than F. However, a conjunction (being both a bank teller and a feminist) cannot be more probable than being a bank teller alone. This is a fundamental law of probability, but it’s commonly misunderstood due to representativeness bias.\n\n\n\nProblem 9: Take the last three digits of your phone number. Add a “1” to the front to form a four-digit number. Now, estimate whether the Taj Mahal was completed before or after this year.\n___ Before ___ After\nNow, make your best estimate of the actual year in which the Taj Mahal was completed: ___\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMost people are influenced by irrelevant information, such as their phone number. If your phone number resulted in a year like 1978 or 1040, your estimate might change. In reality, the Taj Mahal was completed in 1648, but people with high phone numbers tend to give more recent estimates.\n\n\n\nProblem 10: Which of the following instances seems most likely? Which is the second most likely?\n\nDrawing a red marble from a bag containing 50% red marbles and 50% white marbles.\n\nDrawing a red marble seven times in succession (with replacement) from a bag containing 90% red marbles and 10% white marbles.\n\nDrawing at least one red marble in seven tries (with replacement) from a bag containing 10% red marbles and 90% white marbles.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe most common order of likelihood chosen is \\(B &gt; A &gt; C\\). However, the correct order is C (52 percent), A (50 percent), and B (48 percent). This illustrates a bias where people overestimate the probability of conjunctive events (where multiple events must happen together) and underestimate disjunctive events (where only one of many events needs to happen).\n\n\n\nProblem 11: Ten uncertain quantities are listed below. For each, write down your best estimate. Then, put a lower and upper bound around your estimate so you’re 98% confident the range includes the actual value.\n\n\n\nEstimate\nLower Bound\nUpper Bound\n\n\n\n\na. Wal-Mart’s 2006 revenue\n\n\n\n\nb. Microsoft’s 2006 revenue\n\n\n\n\nc. World population (July 2007)\n\n\n\n\nd. Market cap of Best Buy (July 2007)\n\n\n\n\ne. Market cap of Heinz (July 2007)\n\n\n\n\nf. McDonald’s rank in 2006 Fortune 500\n\n\n\n\ng. Nike’s rank in 2006 Fortune 500\n\n\n\n\nh. US motor vehicle fatalities (2005)\n\n\n\n\ni. US national debt (July 2007)\n\n\n\n\nj. US federal budget (FY 2008)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe correct answers are:\n(a) $351 billion,\n(b) $44 billion,\n(c) 6.6 billion people,\n(d) $23 billion,\n(e) $15 billion,\n(f) 108,\n(g) 158,\n(h) 43,443,\n(i) $8.8 trillion,\n(j) $2.9 trillion.\nMost people are overconfident, estimating too narrow a range for these quantities. Despite claiming a 98 percent confidence, many fail to surround more than 30–70 percent of the actual values.\n\n\n\nProblem 12: Which best describes the relationship between a baseball player’s batting average in one season and the next?\n\nZero correlation\n\nWeak correlation (about .4)\n\nStrong correlation (about .7)\n\nPerfect correlation (1.0)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe correct answer is a correlation of about 0.4 between batting averages from one season to the next.\n\n\n\nAfter answering the 12 questions, please watch this video: https://youtu.be/wEwGBIr_RIw\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 11.3 Twelve cognitive biases\nIn the textbook of Bazerman & Moore (2012) twelve cognitive biases that are described. Read chapter 2 of the book and summarize the twelve biases in a sentence.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nEase of Recall: Individuals tend to consider events that are more easily remembered to be more frequent, regardless of their actual frequency.\nRetrievability: Individuals’ assessments of event frequency are influenced by how easily information can be retrieved from memory.\nInsensitivity to Base Rates: Individuals tend to ignore the frequency of events in the general population and focus instead on specific characteristics of the events.\nInsensitivity to Sample Size: Individuals often fail to take sample size into account when assessing the reliability of sample information.\nMisconceptions of Chance: Individuals expect random processes to produce results that look “random” even when the sample size is too small for statistical validity.\nRegression to the Mean: Individuals fail to recognize that extreme events tend to regress to the mean over time.\nConjunction Fallacy: Individuals often judge that the occurrence of two events together is more likely than the occurrence of either event alone.\nConfirmation Trap: Individuals tend to seek out information that confirms their existing beliefs and ignore information that contradicts them.\nAnchoring: Individuals often make estimates based on initial values, and fail to make sufficient adjustments from those values.\nConjunctive- and Disjunctive-Events Bias: Individuals tend to overestimate the likelihood of conjunctive events (two events occurring together) and underestimate the likelihood of disjunctive events (either of two events occurring).\nOverconfidence: Individuals tend to be overconfident in the accuracy of their judgments, particularly when answering difficult questions.\nHindsight and the Curse of Knowledge: After learning the outcome of an event, individuals tend to overestimate their ability to have predicted that outcome. Additionally, individuals often fail to consider the perspective of others when making predictions.\n\n\n\n\n\n\n\n\n\n\n\nBazerman, M. H., & Moore, D. A. (2012). Judgement in managerial decision making. In Inc. Hoboken, NJ, USA (8th ed.). John Wiley & Sons.",
    "crumbs": [
      "Decision making practice",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cognitive biases</span>"
    ]
  },
  {
    "objectID": "efficiency.html",
    "href": "efficiency.html",
    "title": "12  Efficiency and effectiveness",
    "section": "",
    "text": "Economics and successful management revolves around two key concepts: Efficiency and Effectiveness.\nEfficiency refers to the ability to achieve an intended result while minimizing waste in terms of time, effort, and resources. It emphasizes performing tasks in the most optimal manner, such as achieving results quickly or at the lowest cost. However, it’s important to note that efficiency can sometimes be applied to the wrong activities, meaning that while the task may be done optimally, the outcome may not be the desired one.\nEffectiveness, on the other hand, is the capacity to produce better results that deliver greater value or achieve more favorable outcomes. It focuses on ensuring that the right tasks are carried out, completing activities successfully, and ultimately reaching one’s goals.\nSuccessful managers should do the right things and make the right decisions. Moreover, they should do the things right and take the decisions into action properly.\n\n\n\n\n\n\n\nExercise 12.1 Wisdom of the Dakota indians\nA well-known piece of wisdom from the Dakota Indians states: “If you realize that you are riding a dead horse, get off!”\nDiscuss what could that mean in a management context.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhen managers are not doing the right thing they sometimes refuse to accept that they have the wrong business idea or the wrong strategy or product. Instead, they often tend to pursue the chosen strategy trying to do things more efficiency. To stay in the metapher:\n\nThey procure a stronger whip.\nThey change the rider.\nThey argue, “That’s how we’ve always ridden this horse!”\nThey form a working group to analyze the dead horse.\nThey visit other places to see how they handle dead horses there.\nThey raise the quality standards for riding dead horses.\nThey create a task force to revive the dead horse.\nThey schedule a training session to learn how to ride better.\nThey make comparisons between different dead horses.\nThey change the criteria that determine whether a horse is dead.\nThey hire external experts to ride the dead horse.\nThey yoke several dead horses together to make them faster.\nThey assert, “No horse can be so dead that it can’t be beaten!”\nThey allocate additional resources to improve the horse’s performance.\nThey commission a study to find out if there are cheaper consultants.\nThey purchase something that claims to teach dead horses to run faster.\nThey declare that our horse is better, faster, and cheaper when dead.\nThey form a quality circle to find a use for dead horses.\nThey revise the performance criteria for dead horses.\nThey establish an independent cost center for dead horses.\nThey have the horses certified as quickly as possible.\nThey freeze the horses and wait for a new technology that will allow them to ride dead horses.\nThey form a prayer group to pray for the horse’s health.\nThey place the horse in someone else’s stable and claim it as theirs.\nThey note that others are also riding dead horses and declare this the norm.\nThey change the requirements for riding and movement and issue a new development mandate.\nThey outsource the horse.\nThey bet that the horse is just pretending to be dead.\nIf you can’t ride a dead horse, it can at least pull a cart.",
    "crumbs": [
      "Decision making practice",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Efficiency and effectiveness</span>"
    ]
  },
  {
    "objectID": "perfect.html",
    "href": "perfect.html",
    "title": "13  Perfect",
    "section": "",
    "text": "Perfect markets with perfect competition and perfect information are hard to spot in reality. However, it is a useful theoretical model that serves as a reference point for analyzing real-world markets. It provides valuable insights into market functioning and informs policymakers on how to address instances of market failure, where at least one assumption of perfect markets is not met.\nThe assumptions of perfect markets and perfect competition, respectively, are:\n\nMany buyers and sellers: In a perfectly competitive market, there are numerous buyers and sellers, none of whom have a significant influence over market price. Each participant is a price taker, meaning they have no control over the price at which goods or services are exchanged.\nHomogeneous products: The products offered by all firms in a perfectly competitive market are identical or homogeneous. Consumers perceive no differences between the goods or services provided by different sellers. As a result, buyers base their purchase decisions solely on price.\nPerfect information: All buyers and sellers in a perfectly competitive market have complete and accurate information about prices, quality, availability, and other relevant factors. This assumption ensures that market participants can make rational decisions and respond efficiently to changes in market conditions.\nFree entry and exit: Firms can freely enter or exit the market in response to profits or losses. There are no barriers to entry or exit, such as legal restrictions or substantial costs, that prevent new firms from entering the market or existing firms from leaving it.\nPerfect mobility of factors of production: The resources used in production, such as labor and capital, can move freely between different firms and industries. There are no constraints on the mobility of factors of production, allowing firms to allocate resources efficiently.\nProfit maximization: All firms in a perfectly competitive market are profit maximizers. They aim to maximize their profits by adjusting their output levels based on prevailing market conditions. If firms can increase their profits, they will expand production, and if they incur losses, they will reduce output or exit the market.\nNo externatlities: There are assumed to be no externalities, that is no external costs or benefits to third parties not involved in the transaction.\n\nThese assumptions collectively define perfect competition and form the foundation of its analysis. If all conditions are fulfilled, there is no need for government regulation. Welfare is maximized and no pareto-improvement can be achieved.\nTheory would predict that if firms in an industry would make some profits, new firms will enter the market or existing firms would produce more which both yields an increase in supply. That, in turn, will drive down market prices until all firms earn zero profits and no more firms would have an incentive to enter the market. In the equilibrium, total revenue equals total cost. Thus, firms do not make profits. Firms can only make profits if they have some sort of competitive advantage and hence are not price takers which would be against assumption 1. The most extreme form of competitive advantage is a monopoly. It describes that one firm is the only provider of a certain good or service. This firm can set prices and the supply of the good and service completely. We will discuss that extreme case in the next section.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Perfect</span>"
    ]
  },
  {
    "objectID": "monopoly.html",
    "href": "monopoly.html",
    "title": "14  Monopoly",
    "section": "",
    "text": "14.1 Revenue function\nA monopolist is a firm that is the only provider of a good or service. There is no close substitute to it. The ability of a monopolist to raise its price above the competitive level by reducing output is known as market power. This implies a loss of total welfare. In contrast with a perfectly competitive firm which faces a perfectly elastic demand (taking price as given), a monopolist faces the market demand. As a consequence, a monopolist has the power to set the market price. While we can consider a competitive firm as a price taker, a monopolist is price decision-maker or price setter. Firms that have to face fierce competition are more like price takers as they cannot set the price above the market price. If firms in perfect competition would set the price higher, all consumers would simply stop buying from that particular firm. That is not the case for a firm with market power, that is, a firm that has a product with unique features no other competitor has to offer.\nThere are two types of constraints that restrict the behavior of a monopolist (and any other firm):\nThus, we can write the revenue (or profit) function of the monopolist in two alternative ways:\nThe demand, \\(x(p)\\), and the inverse demand, \\(p(x)\\), represent the same relationship between price and demanded quantity from different points of view. The demand function is a complete description of the demanded quantity at each price, whereas the inverse demand gives us the maximum price at which a given output \\(x\\) may be sold in the market.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#revenue-function",
    "href": "monopoly.html#revenue-function",
    "title": "14  Monopoly",
    "section": "",
    "text": "Technological constraints summarized in the cost function \\(C(x)\\).\nDemand constraints: \\(x(p)\\).\n\n\n\nEither by using the demand function: \\[\n\\pi(p) = px(p) - C(x(p))\n\\]\nOr by using the inverse demand function: \\[\n\\pi(x) = p(x)x - C(x)\n\\]",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#revenue-and-price-relationship",
    "href": "monopoly.html#revenue-and-price-relationship",
    "title": "14  Monopoly",
    "section": "14.2 Revenue and price relationship",
    "text": "14.2 Revenue and price relationship\nThus, an increase in production by a monopolist has two opposing effects on revenue:\n\nA quantity effect: one more unit is sold, increasing total revenue by the price at which the unit is sold.\nA price effect: in order to sell the last unit, the monopolist must cut the market price on all units sold. This decreases total revenue.\n\n\n\n\nFigure 14.1: Price Effects and Revenue1\n\n1 Graph is taken from Emerson (2019).\nEmerson, P. M. (2019). Intermediate microeconomics (O. S. University, Ed.; 1st edition). Open Educational Resources. https://open.oregonstate.education/intermediatemicroeconomics\n\n\n\n\n\nThe two effects are shown in figure Figure 14.1: At price \\(p_1\\), the total revenue is \\(p_1 \\cdot Q_1\\), which is represented by the areas A+B. At price \\(p_2\\), the total revenue is \\(p_2 \\cdot Q_2\\), which is represented by the areas A+C. Area A is the same for both, so the marginal revenue is the difference between B and C or C-B. Note that area C is the price, \\(p_2\\), times the change in quantity, \\(Q_2 - Q_1\\), or \\(p \\Delta Q\\); and area B is the quantity, \\(Q_1\\), times the change in price, \\(p_2 - p_1\\), or \\(\\Delta p \\cdot Q\\). Since \\(p_2 - p_1\\) is negative, the change in total revenue is C-B or: \\(\\Delta TR = p \\Delta Q + \\Delta p \\cdot Q\\). Dividing both sides by \\(\\Delta Q\\) gives us an expression for marginal revenue:\n\\[\nMR = \\frac{\\Delta TR}{\\Delta Q} = \\underbrace{p}_{\\text{quantity effect}} + \\underbrace{Q \\frac{\\Delta p}{\\Delta Q}}_{\\text{price effect}}\n\\]",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#profit-maximizing-level-of-output",
    "href": "monopoly.html#profit-maximizing-level-of-output",
    "title": "14  Monopoly",
    "section": "14.3 Profit-maximizing level of output",
    "text": "14.3 Profit-maximizing level of output\nTo find the profit-maximizing price and quantity, respectively, we should look at the first-order conditions:\n\\[\\begin{align*}\n\\max_{p} \\pi (p) \\equiv& \\max_{p} \\quad px(p) - C(x(p))\\\\\n\\frac{\\partial \\pi (p)}{\\partial p} =& \\pi ' (p) = x(p) + px'(p) - C'(x(p))x'(p) \\overset{!}{=} 0\n\\end{align*}\\]\nor\n\\[\\begin{align*}\n\\max_{p} \\pi (x) \\equiv& \\max_{x} \\quad p(x)x - C(x)\\\\\n\\frac{\\partial \\pi (x)}{\\partial x} =& \\pi ' (p) = \\underbrace{p(x)}_{\\text{quantity effect}} + \\underbrace{xp'(x)}_{\\text{price effect}} - C'(x) \\overset{!}{=}& 0\\\\\n\\Rightarrow \\underbrace{p(x) + xp'(x)}_{\\text{marginal revenue}} =& \\underbrace{C'(x)}_{\\text{marginal costs}}\\\\\n\\Rightarrow MR =& MC\n\\end{align*}\\]\nAt the profit-maximizing level of output, marginal revenue equals marginal cost, that is, an infinitesimal change in the level of output changes revenue and cost equally. In other words, an infinitesimal increase in the level of output increases revenue and cost by the same amount, and an infinitesimal decrease in the level of output reduces revenue and cost by the same amount.\nThus, we can determine a monopoly firm’s profit-maximizing price and output by following three steps:\n\nDetermine the demand, marginal revenue, and marginal cost curves.\nSelect the output level at which the marginal revenue and marginal cost curves intersect.\nDetermine from the demand curve the price at which that output can be sold.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#price-effect-of-a-monopoly",
    "href": "monopoly.html#price-effect-of-a-monopoly",
    "title": "14  Monopoly",
    "section": "14.4 Price effect of a monopoly",
    "text": "14.4 Price effect of a monopoly\nDue to the price effect of an increase in output, the marginal revenue curve of a firm with market power always lies below its demand curve. So, a profit-maximizing monopolist chooses the output level at which marginal cost is equal to marginal revenue—not equal to price. As a result, the monopolist produces less and sells its output at a higher price than a perfectly competitive industry would. It earns a profit in the short run and the long run.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#welfare",
    "href": "monopoly.html#welfare",
    "title": "14  Monopoly",
    "section": "14.5 Welfare",
    "text": "14.5 Welfare\nAs illustrated in Figure Figure 14.2, the price-setting behavior of a monopolist typically leads to a reduction in overall welfare: The shaded green area represents the monopoly profit, and the blue area denotes the consumer surplus, the sum of both constitute the total welfare. The yellow triangle represents the deadweight loss, indicating the welfare that is lost due to the monopolist producing fewer goods at a higher price than in a competitive market. The horizontal line at \\(p=100\\) represents the marginal costs (MC).\n\n\n\nFigure 14.2: Price setting of a monopolist",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#price-elasticity-and-market-power",
    "href": "monopoly.html#price-elasticity-and-market-power",
    "title": "14  Monopoly",
    "section": "14.6 Price elasticity and market power",
    "text": "14.6 Price elasticity and market power\nWe know that the demand elasticity of price can be measured with:\n\\[ \\frac{\\triangle p/\\bar{p}}{\\triangle x / \\bar{x}}. \\]\nUsing differential calculus, the point-price elasticity of demand (PPD) can be written as:\n\\[ PPD = \\frac{\\partial p(x)}{\\partial x} \\cdot \\frac{x}{p(x)} \\]\nThis can also be expressed as:\n\\[ PPD = p'(x) \\frac{x}{p(x)} = x \\frac{p'(x)}{p(x)} \\]\nThus, if \\(PPD = 0\\), the price does not change if a single firm increases its quantity sold on the market. That means the firms are price takers, and their quantity sold has no impact on the price. If firms, however, have market power, \\(PPD &lt; 0\\), which means that if a firm increases the quantity on the market, the price must fall. The PPD can hence be interpreted as an indicator of the market power of firms.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#marginal-revenue-and-price-elasticity",
    "href": "monopoly.html#marginal-revenue-and-price-elasticity",
    "title": "14  Monopoly",
    "section": "14.7 Marginal revenue and price elasticity",
    "text": "14.7 Marginal revenue and price elasticity\nNow, plugging the PPD into the MR function, we can show that MR is equal to zero when we have a unit demand elasticity, PPD, of \\(-1\\):\n\\[ MR = p(x) + xp'(x) = p(x)\\left(1 + x\\frac{p'(x)}{p(x)}\\right) = p(x)\\left(1 + PPD\\right) \\]\nAlso see figure Figure 14.3. In the monopoly output, marginal revenue and marginal cost are equal:\n\\[ MC = p(x) \\cdot \\left(1 + PPD\\right) \\]\n\n\n\nFigure 14.3: Price setting of a monopolist2\n\n2 Graph stems from Anon (2020, p. 344)\nAnon. (2020). Principles of economics. University of Minnesota Libraries Publishing. https://open.lib.umn.edu/principleseconomics",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#lerner-index",
    "href": "monopoly.html#lerner-index",
    "title": "14  Monopoly",
    "section": "14.8 Lerner index",
    "text": "14.8 Lerner index\nThe Lerner index is a measure of monopoly power, which equals the markup over marginal cost as a percentage of price. To obtain the Lerner index of monopoly power (or market power), let us rearrange \\(MC = p(x) \\cdot \\left(1 + PPD\\right)\\) as follows:\n\\[ \\frac{MC - p(x)}{p(x)} = PPD = \\text{Lerner Index} \\]\nIf a firm does not have market power (\\(PPD = 0\\)), its price equals the marginal cost. When a firm’s market power is high (up to \\(|PPD| = \\infty\\)), the higher the markup that a firm sets. In perfect competition, since \\(p\\) and MC are equal, the Lerner Index is 0. A pure monopolist, on the other hand, can theoretically charge an infinite markup, which leads us to a Lerner index of 1.\n\n\n\n\n\n\n\nExercise 14.1 Marginal revenue and total revenue\nShow the relationship between a linear demand curve and the marginal revenue curve in one panel and the relationship of the quantity sold and the total revenue in another panel. What characterizes the price of a profit maximizing monopolist?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSee: chapter 15.2 Profit Maximization for Monopolists of Emerson (2019), see: here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 14.2 How to maximize profits\nA company sold a quantity of 750 goods ((Q_{t=1}=750)) in January ((t=1)), at a price of 45 € ((P_{t=1}=45)). In February ((t=2)), they reduced the price to 40 Euro ((P_{t=2}=40)) and sold 800 goods ((Q_{t=2}=800)). Now answer the following questions knowing that the total costs had been 26,500 € in January and 28,000 € in February.\n\nCalculate the price elasticity of demand at the current prices.\nDerive the demand function.\nDerive the cost function.\nDerive the revenue function.\nDerive the marginal revenue function.\nDerive the marginal cost function.\nCalculate the profit-maximizing price and output.\nCalculate the amount of profit in January, February, and what the company can expect by setting the prices profit-maximizing.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe price elasticity of demand (PED) is given by: \\[PED=\\frac{17}{31} \\approx 0.5483\\]\nThe demand function can be derived using the point-slope formula and one sales point: \\[P - 40 = -\\frac{1}{10}(Q - 800) \\Rightarrow P = 120 - \\frac{1}{10}Q \\Rightarrow Q = 1200 - 10P\\]\nTotal costs (TC) are given by: \\[TC = FC + VC = FC + MC \\cdot Q.\\] Solving the system of equations: \\[26500 = FC + 750 \\cdot MC\\] \\[28000 = FC + 800 \\cdot MC\\] we find that (MC = 30) and (FC = 4000). The cost function is: \\[TC = 4000 + 30 \\cdot Q.\\]\nThe revenue function is given by: \\[TR = P \\cdot Q(P).\\] Plugging the demand function in gives: \\[TR(Q) = 120Q - \\frac{1}{10}Q^2.\\]\nThe marginal revenue function is: \\[\\frac{\\partial TR(Q)}{\\partial Q} = 120 - \\frac{2}{10}Q.\\]\nThe marginal cost function is: \\[MC = 30\\] (as found in step 3).\nSetting (MC = MR), we find the optimal quantity: \\[30 = 120 - \\frac{2}{10}Q \\Rightarrow Q^* = 450.\\] Plugging (Q^) into the demand function, we find the optimal price: \\[P^ = 120 - \\frac{1}{10} \\cdot 450 = 75.\\]\nProfit (\\(\\pi\\)) is given by \\(\\pi = TR - TC\\): \\[\\pi_{t=1} = 1200 \\cdot 75 - 10 \\cdot 75^2 - 4000 - 30 \\cdot 750 = 7250\\] \\[\\pi_{t=2} = 1200 \\cdot 75 - 10 \\cdot 75^2 - 4000 + 30 \\cdot 800 = 4000\\] \\[\\pi_{t=3} = 12\\]",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "monopoly.html#monopoly-and-price-discrimination",
    "href": "monopoly.html#monopoly-and-price-discrimination",
    "title": "14  Monopoly",
    "section": "14.9 Monopoly and price discrimination",
    "text": "14.9 Monopoly and price discrimination\nDiscrimination is the practice of treating people differently based on some (irrelevant) characteristic, such as race or gender. It is important to actively fight discrimination whenever it is observed. However, the concept of discrimination takes a different form when it comes to price discrimination, which is a business practice involving the sale of the same goods at different prices to different buyers. This practice can be commonly seen in special offers tailored for students or retired individuals.\nOne of the key factors utilized in price discrimination is the willingness to pay (WTP) of individuals. By charging a higher price to buyers with a higher WTP, a firm can maximize its profit. Moreover, and that is kind of surprising, it also comes with a increase in social welfare as is shown in figure Figure 14.5 and figure Figure 14.5. In Figure 14.5, the monopolist charges the same price (PM) to all buyers. A deadweight loss results. In Figure 14.5, however, the monopolist produces the competitive quantity but charges each buyer his or her WTP. This is called perfect price discrimination. The monopolist captures all consumer surplus as profit. But there is no deadweight loss.\n\n\n\nFigure 14.4: Monopoly without price discrimination and welfare\n\n\n\n\n\n\n\n\n\nFigure 14.5: Monopoly with price discrimination and welfare\n\n\n\n\n\n\nIn the real world, price discrimination is a common phenomenon, but achieving perfect price discrimination is highly challenging. This is primarily because no firm possesses complete knowledge of every buyer’s willingness to pay (WTP), and buyers typically do not disclose this information to sellers. Consequently, firms often divide customers into groups based on observables that are likely correlated with their WTP.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Monopoly</span>"
    ]
  },
  {
    "objectID": "regional.html",
    "href": "regional.html",
    "title": "15  Regional (preliminary)",
    "section": "",
    "text": "15.1 Von Thünen model of land use\nThe classical model of spatial organization of the economy stems Heinrich von Thünen (1783-1850). The model focuses on agriculture as this was the dominant use of land at the time. However, the fundamental ideas of the model can be applied to various industries. The model can be described as follows: Assume a focal point of demand for agricultural goods (e.g., the marketplace of a large city). Differences in soil quality in the agricultural periphery of the considered city are neglected. The demand is differentiated. That means, various goods such as grains, dairy products, meat, timber, vegetables are required to satisfy the needs of the people. The goods differ in terms of\nAll mentioned variables are exogenously given. In particular, the model is based on the following assumptions:\nTo analyze the model, let us start by considering the restriction to a single land use. The key idea is that the rent price for a unit of land arises from the net yield that this unit of land enables under that particular land use. However, since both production costs and distance-dependent transport costs need to be subtracted from the gross yield to determine the net yield, it follows that land rent is determined by the distance from the center. Under a given land use, the value of an agricultural area is significantly influenced by its distance from the marketplace.\nFormally, the land rent for land use for production of good \\(i\\), depending on the distance \\(x\\) from the marketplace, is given by:\n\\[\nr_i(x) = q_i(p_i - c_i - \\theta_i \\cdot x)\n\\]\nThe land rent increases with the quantity demanded \\((q)\\) and the price of the good, and it decreases with the marginal production costs \\((c)\\), the specific transportation costs \\((\\theta)\\), and the distance \\((x)\\) from the marketplace. The typical shape of a rent curve, with \\(r\\) on the y-axis and \\(x\\) on the x-axis, is a linearly decreasing curve. Its slope is determined by the expression \\(-q_i  \\theta_i\\). Therefore, the steeper the specific transportation costs, the steeper the curve.\nSuppose, different land uses are allowed. By varying the price, revenue, and cost parameters in the equation above, different rent curves with varying locations and slopes emerge for different land uses. The interesting question now is: How high will the market rent be?\nThünen provides a clear answer to this question: Competition among land tenants will ensure that in a specific distance zone around the center, the production method with the highest net yield in that zone will prevail. In other words, the market rent curve (or bid rent curve) is the upper envelope of all rent curves for specific production methods. The situation is illustrated in figure @ref(fig:thuenen) and @ref(fig:thuenen2) for three different production methods. The intersections of the market rent curves determine the shifts in production zones.\nThis model is also known as the Bid rent theory. A short but nice explanation of the model can be found on Wikipedia, see here.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regional (preliminary)</span>"
    ]
  },
  {
    "objectID": "regional.html#von-thünen-model-of-land-use",
    "href": "regional.html#von-thünen-model-of-land-use",
    "title": "15  Regional (preliminary)",
    "section": "",
    "text": "the market price they can achieve,\nthe assumed constant marginal production costs \\((c_i)\\),\nthe revenue per unit of land, and\nin terms of their transportability, that is, each good has different specific transport costs \\((\\theta_i)\\).\n\n\n\nPoint-centered demand for all goods \\(i\\).\nDifferent production methods possible, each with constant (marginal) production costs \\(c_i\\).\nHomogeneous Space: The agricultural land surrounding the central marketplace is assumed to be uniform and homogeneous in terms of soil fertility, climate, and other relevant factors.\nGiven market prices for the individual products \\(p_i\\)\nProducers supply the market and have linear product-specific transportation costs \\((\\theta_i)\\).\nPerfect competition: The model assumes perfect competition among farmers for the available land (free market access). That implies that they have full knowledge of market conditions and make rational decisions.\n\n\n\n\n\n\n\n\n\n(#fig:thuenen) Thünen’s rings of land use\n\n\n\n\n\n(#fig:thuenen2) Bid rent curve1\n1 The graph stems from https://en.wikipedia.org/wiki/File:Bid_rent1.png\n\n\n\n\n\n\n\n\n\n\nExercise 15.1 Agricultural land use\nIn the vicinity of an agglomeration center, four different agricultural land use forms are possible. We have information about the specific yield per unit of land (q_i), the (constant) marginal costs (c_i), the specific transportation costs (_i), and the price (p_i) that can be achieved for a unit of the respective product in the center.\nWhere do we see which land use form?\n\n\n\n\n\n\n\n\n\n\n\nProduction Form\nProduction Form\nProduction Form\nProduction Form\n\n\n\n\n(i)\n1\n2\n3\n4\n\n\n(q_i)\n10\n5\n30\n20\n\n\n(p_i)\n5\n5\n2\n6\n\n\n(c_i)\n1\n2\n1\n5\n\n\n(_i)\n0.4\n0.1\n0.15\n0.05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 15.2 Business location model\nThe Thünenian approach is intended to be applied to a business location model. The customer frequency, depending on the distance \\(x\\) from the center, can be approximated by the following function:\n[ f(x)i = A{0} e^{-a x} ]\nThe probability of sale per square meter for business type \\(i\\) is denoted by \\(\\lambda_i\\). The business types also differ in terms of profit margin and fixed costs. Describe the market rent curve and show which business type will dominate in each location. What effects does an increase in the parameter \\(a\\) have? What about an increase in \\(A_0\\)? Interpret the changes in parameters and the results from an economic perspective.",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regional (preliminary)</span>"
    ]
  },
  {
    "objectID": "regional.html#launhardthotelling-location-model",
    "href": "regional.html#launhardthotelling-location-model",
    "title": "15  Regional (preliminary)",
    "section": "15.2 Launhardt/Hotelling location model",
    "text": "15.2 Launhardt/Hotelling location model\nConsider a scenario where two firms, i.e., \\(i={F1;F2}\\), have the option to establish their locations along a linear market, such as a street or a beach. These firms can relocate without incurring any costs and sell an identical product at the same price. Consequently, the only means of competition available to them is by strategically selecting their respective locations. Moreover, assume that customers are uniformly distributed throughout the market, and each customer is willing to purchase one unit of the product up to a certain price, denoted as \\(\\bar{p}\\). The cost of transportation is the same for both firms and is proportional to the distance between the firm and the customer.\nIf we assume that the transportation costs are equal for both firms and that the market has a finite size, the firms will eventually position themselves at the center of the market with no empty space between them. The rationale and dynamics behind this behavior are clearly explained in the YouTube clip of TED-Ed Why do competitors open their stores next to one another? - Jac de Haan, see figure @ref(fig:hotelling). I highly recommend watching the clip.\n\n\n(#fig:hotelling) YouTube clip of TED-Ed and Jac de Haan2\n2 Taken from https://youtu.be/jILgxeNBK_8\n\n\nIf we assume that the transportation costs can vary between the two firms, things became a bit more complicated. Let us define transportation costs for a firm as \\(\\theta_i=a_i d(x)\\), where \\(d(x)\\) represents the distance between the company and the respective costumer and \\(a_i\\) is firm-specific costs of transportation. Let us further assume competition and loosen the assumption of fixed prices: Firms can set prices but they need to charge the price of the good, \\(p\\), plus their costs of transporting the good to the costumer. Thus, the price of a good a firm needs to charge in order not to make deficits is \\[\np^{min}(x)=c+\\theta_i=c+a_i d(x)\n\\]\nIf we assume that the transport costs are the same for both firms and that the market is limited in size, the firms will end up at the center of the market with no space inbetween them. However, there is always an incentive to deviate from that minimum of spatial differentiation. However, the dynamic is kind of strange as we can show in the following four figures.\n\n\n(#fig:lau1) Scenario 1\n\n\n\n\n\n(#fig:lau2) Scenario 2\n\n\n\n\n\n(#fig:lau3) Scenario 3\n\n\n\n\n\n(#fig:lau4) Scenario 4",
    "crumbs": [
      "Markets",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regional (preliminary)</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anon. (2020). Principles of economics. University of Minnesota\nLibraries Publishing. https://open.lib.umn.edu/principleseconomics\n\n\nBackhouse, R. E., & Medema, S. G. (2009). Retrospectives: On the\ndefinition of economics. Journal of Economic Perspectives,\n23(1), 221–233.\n\n\nBazerman, M. H., & Moore, D. A. (2012). Judgement in managerial\ndecision making. In Inc. Hoboken, NJ, USA (8th ed.). John Wiley\n& Sons.\n\n\nBecker, G. S. (1960). An economic analysis of fertility. In G. S. Becker\n(Ed.), Demographic and economic change in developed countries.\nPrinceton University Press.\n\n\nBernoulli, D. (1954). Exposition of a new theory on the measurement.\nEconometrica, 22(1), 23–36.\n\n\nBonanno, G. (2017). Decision making. Accessed March 21, 2023.\nhttps://faculty.econ.ucdavis.edu/faculty/bonanno/DM_Book.html\n\n\nCEOpedia. (2021). Rational decision making. Accessed March 11,\n2023. https://ceopedia.org/index.php/Rational_decision_making\n\n\nColander, D. C. (2006). Economics (6th ed.). McGraw-Hill Irvin.\n\n\nDahlquist, J., Knight, R., Adams, A. S., Bacon, C. J., Cooper, S. T.,\nGriffin, M. P., Higgins, K. C., & Musolino, L. (2022).\nPrinciples of finance. OpenStax. https://biz.libretexts.org/Bookshelves/Finance/Principles_of_Finance_(OpenStax)\n\n\nEilon, S. (1969). What is a decision? Management Science,\n16(4), B172–B189.\n\n\nEllsberg paradox. (2024). Wikipedia, The Free\nEncyclopedia. https://en.wikipedia.org/wiki/Ellsberg_paradox\n\n\nEmerson, P. M. (2019). Intermediate microeconomics (O. S.\nUniversity, Ed.; 1st edition). Open Educational Resources. https://open.oregonstate.education/intermediatemicroeconomics\n\n\nFeynman, R. P. (1985). Surely you’re joking, Mr.\nFeynman!: Adventures of a curious character. W.W.\nNorton.\n\n\nFinne, T. (1998). The three categories of decision-making and\ninformation security. Computers & Security, 17(5),\n397–405.\n\n\nFitzgerald, S. P. (2002). Decision making. Capstone Publishing.\n\n\nGreenlaw, S. A., & Shapiro, D. (2022). Principles of\neconomics (2nd ed.). Accessed March 11, 2023; OpenStax. https://openstax.org/details/books/principles-economics-2e\n\n\nGwartney, J. D., Stroup, R. L., Sobel, R. S., & MacPherson, D. A.\n(2006). Microeconomics: Private and public choice. Mason.\n\n\nHoover, E. M., & Giarratani, F. (2020). An introduction to\nregional economics (S. Loveridge & R. Jackson, Eds.; 4th ed.).\nreprint, edited by Scott Loveridge; Randall Jackson, Regional Research\nInstitute, West Virginia University.\n\n\nHuber, S. (2023). Mathematics and statistics I:\nCalculus and linear algebra (lecture notes). online. https://raw.githubusercontent.com/hubchev/courses/main/pdfs/cla_A4.pdf\n\n\nIndeed Editorial Team. (2023). 12 decision-making strategies.\nAccessed March 11, 2023. https://www.indeed.com/career-advice/career-development/decision-making-strategies?utm_campaign=earnedsocial%3Acareerguide%3Ashareemail%3AUS&utm_content=12%20Decision-Making%20Strategies&utm_medium=social&utm_source=directshare\n\n\nKahneman, D., & Tversky, A. (1972). Subjective probability: A\njudgment of representativeness. Cognitive Psychology,\n3(3), 430–454.\n\n\nKeynes, J. M. (1921). Money. In D. H. Robertson, Money\n(Cambridge Economic Handbooks). Cambridge Economic Handbooks.\n\n\nKlapper, L., & Lusardi, A. (2020). Financial literacy and financial\nresilience: Evidence from around the world. Financial\nManagement, 49(3), 589–614. https://onlinelibrary.wiley.com/doi/full/10.1111/fima.12283\n\n\nLusardi, A., & Mitchell, O. S. (2014). The economic importance of\nfinancial literacy: Theory and evidence. Journal of Economic\nLiterature, 52(1), 5–44.\n\n\nMarshall, A. (2009). Principles of economics: Unabridged eighth\nedition. Cosimo, Inc.\n\n\nMitchell, O. S., & Lusardi, A. (2015). Financial literacy and\neconomic outcomes: Evidence and policy implications. The Journal of\nRetirement, 3, 1, 107–114.\n\n\nMorse, L. C., Babcock, D. L., & Murthy, M. (2014). Managing\nengineering and technology (Sixth Edition). Pearson.\n\n\nNash, J. F. (1950). Non-cooperative games [PhD thesis].\nPrinceton University Princeton.\n\n\nNobelPrize.org. (2021). Herbert A. Simon: facts\n[{Nobel Prize Outreach AB} 2021.]. Accessed March 11, 2023. https://www.nobelprize.org/prizes/economic-sciences/1978/simon/facts\n\n\nParkin, M. (2012). Economics (10th ed.). Addison-Wesley.\n\n\nParkin, M., Powell, M., & Matthews, K. (2017). Economics:\nEuropean edition (10th ed.). Pearson Education Limited.\n\n\nSaylor Academy. (2002). Principles of management (1.1 ed.). https://saylordotorg.github.io/text_principles-of-management-v1.1/\n\n\nStammers, R. (2016). Tips for avoiding the top 20 common investment\nmistakes (Version 1.0). CFA Institute; Accessed April 24, 2023. https://www.cfainstitute.org/-/media/documents/support/future-finance/avoiding-common-investor-mistakes.pdf\n\n\nVon Neumann, J., & Morgenstern, O. (1947). Theory of games and\neconomic behavior. Princeton University Press.\n\n\nWikipedia. (2024). Decision-making —\nWikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=Decision-making&oldid=1244138603\n\n\nWilkinson, N. (2022). Managerial economics problem-solving in a\ndigital world (2nd ed.). Cambridge University Press.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "micro_prelim.html",
    "href": "micro_prelim.html",
    "title": "Appendix A — Microeconomic preliminaries",
    "section": "",
    "text": "A.1 Production functions\nBefore starting discussing production and consumption, we should first define what (micro)economist mean when they speak of firms and consumers.\nA firm is a productive unit. In particular, it is an organization that produces goods and services, called the output. To do so, it uses inputs called factors of production: labor, capital, land, skills, etc. The relationship between the inputs and the output is the production function. The goal of the firm is to achieve whatever goal its owner(s) decide to achieve. Usually, it is (and in Germany, for example, it has to be the case by law) to generate profits, that is, total revenue minus total cost for the level of production. Determining the optimal level of production for a firm is a multifaceted decision that encompasses various strategic aspects and is heavily influenced by the market situation of firms. This includes factors such as market power, demand function, production function, cost function, and revenue function.\nA consumer is an individual that purchases goods or services to satisfy their needs. They make decisions regarding what to buy, how much to buy in order to maximize their utility. Microeconomists study consumer behavior and factors that influence it, such as prices, income, preferences, and market conditions, to understand the choices consumers make and their impact on markets and the overall economy.\nA firm or a company is a productive unit. In particular, it is an organization that produces goods and services. In short, it can be called output. To do so, it uses inputs called factors of production, that is, labor, capital, land, skills, etc. The relationship between the inputs and the output is the production function. The goal of the firm is to achieve whatever goal its owner(s) decide to achieve through the firm. Usually, it is (and in Germany for example it has to be the case by law) to generate profits, that is, total revenue minus total cost for the level of production.\nA production function (PF) is a mathematical representation of the process that transforms inputs into output.\nThe returns to scale describes the increase in output when a firm multiples all of its inputs by some factor. Let \\(\\lambda&gt;1,\\) then, with two factors \\(\\mathrm{K}\\) and \\(L\\), we can define that for \\[\nf(c K, c L)= c^\\lambda f(K, L),\n\\]\nThe marginal product is the change in the total output when the input varies of one infinitesimal small unit. Graphically, the marginal product is the slope of the total product function at any point. The slope of the total product function, that is, the marginal product, is generally not constant. The marginal product to an input is assumed to decrease beyond some level of input. This is called the law of diminishing marginal returns. In particular, we can distinguish:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microeconomic preliminaries</span>"
    ]
  },
  {
    "objectID": "micro_prelim.html#production-functions",
    "href": "micro_prelim.html#production-functions",
    "title": "Appendix A — Microeconomic preliminaries",
    "section": "",
    "text": "When factors of production are perfect substitutes the PF can be written like this: \\[\nq=f(K,L)=L+K\n\\]\nWhen factors of production are perfect complements the PF can be written like this: \\[\nq=f(K,L)=\\min (L,K)\n\\]\nA special and often used function is the Cobb-Douglas PF: \\[\nq=f(K,L)=K^\\alpha L^{1-\\alpha} \\quad \\text{with} \\quad 0&lt;\\alpha&lt;1\n\\]\n\n\n\n\\(\\lambda&gt;1\\) the PF has increasing returns to scale,\n\\(\\lambda=1\\) the PF has constant returns to scale,\n\\(\\lambda&lt;1\\) the PF has decreasing returns to scale.\n\n\n\npositive marginal returns when \\(f'&gt;0\\) and\ndiminishing marginal returns when \\(f''&lt;0\\) and\nincreasing marginal returns when \\(f''&gt;0\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microeconomic preliminaries</span>"
    ]
  },
  {
    "objectID": "micro_prelim.html#production-possibility-frontier-curve",
    "href": "micro_prelim.html#production-possibility-frontier-curve",
    "title": "Appendix A — Microeconomic preliminaries",
    "section": "A.2 Production possibility frontier curve",
    "text": "A.2 Production possibility frontier curve\n\n\n\nFigure A.1: The production possibility frontier curve\n\n\n\n\n\n\nThe production possibilities frontier (PPF) curve shown in Figure A.1 provides a graphical representation of all possible production options for two products when all available resources and factors of production are fully and efficiently utilized within a given time period. The PPF serves as a boundary between combinations of goods and services that can be produced and those that cannot.\nThe PPF is an invaluable tool for illustrating the effects of scarcity as it provides insights into production efficiency, opportunity costs and the trade-offs between different choices. In general, the PPF exhibits concavity, as not all factors of production can be used equally productively in all activities.\nEconomic growth refers to the continuous expansion of production possibilities. An economy experiences growth through technological advances, improvements in the quality of labor or an increase in the factors of production (labor, capital). When the resources of an economy increase, the production possibilities also expand, shifting the PPF outwards. It is worth noting that PPF can be used to explain production in an economy or company.\nProduction efficiency occurs when it is impossible to produce more of one good or service without producing less of another. If production takes place directly on the PPF, this means efficiency. If, on the other hand, production takes place within the PPF (yellow shaded area of Figure A.1), it is possible to produce more goods without sacrificing existing goods, which indicates inefficiency. If production is on the PPF, there is a trade-off, as obtaining more of one good requires sacrificing a certain amount of another good. This trade-off is associated with costs called opportunity costs.\n\n\n\n\n\n\n\nExercise A.1 Understanding production (Solution A.1)\n\nFigure A.2 shows a PPF and five conceivable production points, \\(C_i\\), where \\(i\\in \\{1,\\dots,5\\}\\). Explain the figure using the following terms: _attainable point; available resources, unattainable, inefficient, efficient point.\n\n\n\n\nFigure A.2: Production and different consumption points\n\n\n\n\n\n\n\nWhat would happen to the PPF if the technology available in a country and needed for the production process became better?\nWhat would happen to the PPF if the resources available in a country and needed in the production process of both goods shrank?\nWhat would happen to the PPF if the resources (technology) available in a country that are needed in the production process…\n\n…for both goods increased (improved)?\n…for good A shrank (got worse)?\n…for good B increased (improved)?\n\nDoes the shape of the PPF tell us anything about economies of scale in the production process?\nFigure A.3 shows an extreme PPF. How can such a PPF be explained?\n\n\n\n\nFigure A.3: Extreme production possibility frontier curve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution A.1. Understanding production (Exercise A.1)\n\nAny point that lies either on the production possibilities curve or to the left of it is said to be an attainable point: it can be produced with currently available resources. Production points that lie in the yellow shaded area are said to be unattainable because they cannot be produced using currently available resources. These points represent an inefficient production, because existing resources would allow for production of more of at least one good without sacrificing the production of any other good. An efficient point is one that lies on the production possibilities curve. At any such point, more of one good can be produced only by producing less of the other.\nThe PPF would shift outwards.\nThe PPF would shift inwards.\nThe PPF would shift…\n\n…outwards for both goods.\n…inwards for good A, see Figure A.4.\n…outwards for good B.\n\nWith economies of scale, the PPF would curve inward, with the opportunity cost of one good falling as more of it is produced. A straight-line (linear) PPF reflects a situation where resources are not specialized and can be substituted for each other with no added cost. With constant returns to scale, there are two opportunities for a linear PPF: if there was only one factor of production to consider or if the factor intensity ratios in the two sectors were constant at all points on the production-possibilities curve.\nHere is one example: Suppose a country that is endowed with two factors of production and that one factor can only be used for producing good A and the other factor can only be used to produce good B.\n\n\n\n\nFigure A.4: Shrinking production possibilities in good A",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microeconomic preliminaries</span>"
    ]
  },
  {
    "objectID": "micro_prelim.html#indifference-curves-and-isoquants",
    "href": "micro_prelim.html#indifference-curves-and-isoquants",
    "title": "Appendix A — Microeconomic preliminaries",
    "section": "A.3 Indifference curves and isoquants",
    "text": "A.3 Indifference curves and isoquants\n\n\n\nFigure A.5: Indifference curve\n\n\n\n\n\n\nCombinations of two goods that yield the same level of utility for consumers are represented by indifference curves, see figure Figure A.5. These curves illustrate the various bundles of goods where consumers are equally satisfied. That means all points on an indifference curve represent the same level of utility. The shape of the indifference curve is determined by the underlying utility function, which captures the preferences of consumers for consuming different combinations of the two goods.\nThe slope of an indifference curve indicates the rate at which the two goods can be substituted while maintaining the same level of utility for the consumer. Technically, the slope represents the marginal rate of substitution, which is equal to the absolute value of the slope. It measures the maximum quantity of one good that a consumer is willing to give up in order to obtain an additional unit of the other good.\nIt is assumed that consumers aim to attain the highest possible indifference curve because a higher curve, located further to the right on a coordinate system, represents a higher level of utility. In Figure A.6, for example, \\((IC_1)\\) represents a lower level of utility than \\((IC_2)\\).\n\n\n\nFigure A.6: Indifference curve\n\n\n\n\n\n\nSimilar to the concept of indifference curves, an isoquant shows the combinations of factors of production that result in the same quantity of output.\n\n\n\nFigure A.7: Perfect complements or substitutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise A.2 Isoquants\n\nWhich of the two plots of Figure A.7 show isoquants when factors of production are perfect complements and perfect substitutes, respectively?\nDiscuss the features of a Cobb-Douglas PF with respect to returns to scale and marginal product of production for both inputs. Sketch the total output curve in an output-(K) and an output-(L) quadrant. Sketch the isoquants for different levels of production.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microeconomic preliminaries</span>"
    ]
  },
  {
    "objectID": "micro_prelim.html#budget-constraint",
    "href": "micro_prelim.html#budget-constraint",
    "title": "Appendix A — Microeconomic preliminaries",
    "section": "A.4 Budget constraint",
    "text": "A.4 Budget constraint\nIn microeconomics, the concept of a budget constraint plays a vital role in understanding consumer decision-making and helps to analyze consumer choices and trade-offs. The budget constraint represents the limitations faced by consumers in allocating their limited income across different goods and services. The budget constraint indicates that the total expenditure on goods and services, calculated by multiplying the prices of each item by its corresponding quantity, must be less than or equal to the consumer’s income. Mathematically, the budget constraint can be expressed as: \\[\nP_1 \\cdot Q_1 + P_2 \\cdot Q_2 + \\ldots + P_n \\cdot Q_n \\leq I\n\\] where (\\(P_n\\)) represent the prices of goods, (\\(Q_n\\)) denote the quantities of goods (\\(n\\)) consumed. (\\(I\\)) denotes the consumer’s income or their budget.\nConsumers strive to maximize their utility by selecting the optimal combination of goods and services within the constraints imposed by their limited income. This involves making decisions about how much of each good to consume while staying within the budgetary limits. The graphical representation of the ideal consumption point is depicted in Figure Figure A.8.\nBy studying the budget constraint, economists can gain insights into consumer behavior, price changes, and the impact of income fluctuations on consumption patterns.\n\n\n\nFigure A.8: Optimal consumption choice",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microeconomic preliminaries</span>"
    ]
  },
  {
    "objectID": "math_prelim.html",
    "href": "math_prelim.html",
    "title": "Appendix B — Mathematical preliminaries",
    "section": "",
    "text": "Please feel free to download and study my introduction for mathematics for economics here.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Mathematical preliminaries</span>"
    ]
  },
  {
    "objectID": "exams.html",
    "href": "exams.html",
    "title": "Appendix C — Past exams",
    "section": "",
    "text": "Please feel free to download a collection of past exams here.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Past exams</span>"
    ]
  }
]