[
  {
    "objectID": "80_exercises.html",
    "href": "80_exercises.html",
    "title": "9  Collection of exercises",
    "section": "",
    "text": "9.1 Import data with c()\nTable 9.1 shows COVID for three states in Germany:\nWrite down the code you would need to put into the R-console…",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exeimportdata",
    "href": "80_exercises.html#sec-exeimportdata",
    "title": "9  Collection of exercises",
    "section": "",
    "text": "Table 9.1: Covid cases and deaths till August 2022\n\n\n\n\n\n\n\n\n\n\n\nstate\nBavaria\nNorth Rhine-Westphalia\nBaden-Württemberg\n\n\n\n\ndeaths (in mio)\n4,92M\n5,32M\n3,69M\n\n\ncases\n24.111\n25.466\n16.145\n\n\n\n\n\n\n\n\n…to store each of variables state and deaths in a vector.\n…to store both vectors in a data frame with the name df_covid.\n…to store both vectors in a tibble with the name tbl_covid.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: c, data.frame, tibble.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Solution to excercise \"Import data\":\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tibble)\n\nstate &lt;- c(\"BY\", \"NRW\", \"BW\")\ndeaths &lt;- c(4.92, 5.32, 3.69)\ncases &lt;- c(24111, 25466, 16145)\ndf_covid &lt;- data.frame(state, deaths)\ntbl_covid &lt;- tibble(state, deaths)\n\ntbl_covid\n\nsuppressMessages(pacman::p_unload(tibble))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Solution to excercise \"Import data\":\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tibble)\n\nstate &lt;- c(\"BY\", \"NRW\", \"BW\")\ndeaths &lt;- c(4.92, 5.32, 3.69)\ncases &lt;- c(24111, 25466, 16145)\ndf_covid &lt;- data.frame(state, deaths)\ntbl_covid &lt;- tibble(state, deaths)\n\ntbl_covid\n\n# A tibble: 3 × 2\n  state deaths\n  &lt;chr&gt;  &lt;dbl&gt;\n1 BY      4.92\n2 NRW     5.32\n3 BW      3.69\n\nsuppressMessages(pacman::p_unload(tibble))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#filter-and-select-observations",
    "href": "80_exercises.html#filter-and-select-observations",
    "title": "9  Collection of exercises",
    "section": "9.2 Filter and select observations",
    "text": "9.2 Filter and select observations\nSet up R, RStudio, and R packages\nOpen this interactive tutorial and work through it.\n\n\n\n\n\n\nThe script uses among others the following functions: filter, is.na, select.",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-baseinoperator",
    "href": "80_exercises.html#sec-baseinoperator",
    "title": "9  Collection of exercises",
    "section": "9.3 Base R,%in% operator, and the pipe |>",
    "text": "9.3 Base R,%in% operator, and the pipe |&gt;\n\nUsing the mtcars dataset, write code to create a new dataframe that includes only the rows where the number of cylinders is either 4 or 6, and the weight (wt) is less than 3.5.\n\nDo this in two different ways using:\n\nThe %in% operator and the pipe |&gt; .\nBase R without the pipe |&gt;.\n\nCompare the resulting dataframes using the identical() function.\n\nUsing the mtcars dataset, generate a logical variable that indicates with TRUE all cars with either 4 or 6 cylinders that wt is less than 3.5 and add this variable to a new dataset.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: c, filter, identical, if_else, mutate, subset, transform, with.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Base R or pipe\n# exe_base_pipe.R\n# Stephan Huber; 2023-05-08\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list=ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\n# Using the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf1 &lt;- mtcars |&gt; \n  filter(cyl %in% c(4, 6) & wt &lt; 3.5)  \ndf1\n\n# Without the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf2 &lt;- subset(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\ndf2\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df1, df2)\n\n\n# b)\n# Using the pipe |&gt; and tidyverse (mutate)\ndf3 &lt;- mtcars |&gt; \n  mutate(cyl_4_or_6 = \n           if_else(cyl %in% c(4, 6) & wt &lt; 3.5, TRUE, FALSE))\ndf3\n\n# without pipe and with base R (transform)\ndf4 &lt;- mtcars\ndf4$cyl_4_or_6 &lt;- with(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\n\n# Alternatively in one line:\ndf5 &lt;- transform(mtcars, cyl_4_or_6 = cyl %in% c(4,6) & wt &lt; 3.5)\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df3, df4)\nidentical(df3, df5)\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Base R or pipe\n# exe_base_pipe.R\n# Stephan Huber; 2023-05-08\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list=ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\n# Using the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf1 &lt;- mtcars |&gt; \n  filter(cyl %in% c(4, 6) & wt &lt; 3.5)  \ndf1\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# Without the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf2 &lt;- subset(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\ndf2\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df1, df2)\n\n[1] TRUE\n\n# b)\n# Using the pipe |&gt; and tidyverse (mutate)\ndf3 &lt;- mtcars |&gt; \n  mutate(cyl_4_or_6 = \n           if_else(cyl %in% c(4, 6) & wt &lt; 3.5, TRUE, FALSE))\ndf3\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n                    cyl_4_or_6\nMazda RX4                 TRUE\nMazda RX4 Wag             TRUE\nDatsun 710                TRUE\nHornet 4 Drive            TRUE\nHornet Sportabout        FALSE\nValiant                   TRUE\nDuster 360               FALSE\nMerc 240D                 TRUE\nMerc 230                  TRUE\nMerc 280                  TRUE\nMerc 280C                 TRUE\nMerc 450SE               FALSE\nMerc 450SL               FALSE\nMerc 450SLC              FALSE\nCadillac Fleetwood       FALSE\nLincoln Continental      FALSE\nChrysler Imperial        FALSE\nFiat 128                  TRUE\nHonda Civic               TRUE\nToyota Corolla            TRUE\nToyota Corona             TRUE\nDodge Challenger         FALSE\nAMC Javelin              FALSE\nCamaro Z28               FALSE\nPontiac Firebird         FALSE\nFiat X1-9                 TRUE\nPorsche 914-2             TRUE\nLotus Europa              TRUE\nFord Pantera L           FALSE\nFerrari Dino              TRUE\nMaserati Bora            FALSE\nVolvo 142E                TRUE\n\n# without pipe and with base R (transform)\ndf4 &lt;- mtcars\ndf4$cyl_4_or_6 &lt;- with(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\n\n# Alternatively in one line:\ndf5 &lt;- transform(mtcars, cyl_4_or_6 = cyl %in% c(4,6) & wt &lt; 3.5)\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df3, df4)\n\n[1] TRUE\n\nidentical(df3, df5)\n\n[1] TRUE\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exe_genanddrop",
    "href": "80_exercises.html#sec-exe_genanddrop",
    "title": "9  Collection of exercises",
    "section": "9.4 Generate and drop variables",
    "text": "9.4 Generate and drop variables\nUse the mtcars dataset. It is part of the package datasets and can be called with\n\nmtcars\n\n\nCreate a new tibble called mtcars_new using the pipe operator |&gt;. Generate a new dummy variable called d_cyl_6to8 that takes the value 1 if the number of cylinders (cyl) is greater than 6, and 0 otherwise. Do all of this in a single pipe.\nGenerate a new dummy variable called posercar that takes a value of 1 if a car has more than 6 cylinders (cyl) and can drive less than 18 miles per gallon (mpg), and 0 otherwise. Add this variable to the tibble mtcars_new.\nRemove the variable d_cyl_6to8 from the data frame.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: as_tibble, if_else, mutate, rownames_to_column, select.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Generate and drop variables\n# exe_genanddrop.R\n# Stephan Huber; 2023-05-09\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\nmtcars_new &lt;- mtcars |&gt;\n  rownames_to_column(var = \"car\") |&gt;\n  as_tibble() |&gt;\n  mutate(d_cyl_6to8 = if_else(cyl &gt; 6, 1, 0))\nmtcars_new\n\n# b)\nmtcars_new &lt;- mtcars_new |&gt;\n  mutate(posercar = if_else(cyl &gt; 6 & mpg &lt; 18, 1, 0))\nmtcars_new\n\n# c)\nmtcars_new &lt;- mtcars_new |&gt;\n  select(-d_cyl_6to8)\nmtcars_new\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Generate and drop variables\n# exe_genanddrop.R\n# Stephan Huber; 2023-05-09\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\nmtcars_new &lt;- mtcars |&gt;\n  rownames_to_column(var = \"car\") |&gt;\n  as_tibble() |&gt;\n  mutate(d_cyl_6to8 = if_else(cyl &gt; 6, 1, 0))\nmtcars_new\n\n# A tibble: 32 × 13\n   car           mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n# ℹ 1 more variable: d_cyl_6to8 &lt;dbl&gt;\n\n# b)\nmtcars_new &lt;- mtcars_new |&gt;\n  mutate(posercar = if_else(cyl &gt; 6 & mpg &lt; 18, 1, 0))\nmtcars_new\n\n# A tibble: 32 × 14\n   car           mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n# ℹ 2 more variables: d_cyl_6to8 &lt;dbl&gt;, posercar &lt;dbl&gt;\n\n# c)\nmtcars_new &lt;- mtcars_new |&gt;\n  select(-d_cyl_6to8)\nmtcars_new\n\n# A tibble: 32 × 13\n   car           mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n# ℹ 1 more variable: posercar &lt;dbl&gt;\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exe_subset",
    "href": "80_exercises.html#sec-exe_subset",
    "title": "9  Collection of exercises",
    "section": "9.5 Subsetting",
    "text": "9.5 Subsetting\n\nCheck to see if you have the mtcars dataset by entering mtcars.\nSave the mtcars dataset in an object named cars.\nWhat class is cars?\nHow many observations (rows) and variables (columns) are in the mtcars dataset?\nRename mpg in cars to MPG. Use rename().\nConvert the column names of cars to all upper case. Use rename_all, and the toupper function.\nConvert the rownames of cars to a column called car using rownames_to_column.\nSubset the columns from cars that end in “p” and call it pvars using ends_with().\nCreate a subset cars that only contains the columns: wt, qsec, and hp and assign this object to carsSub. (Use select().)\nWhat are the dimensions of carsSub? (Use dim().)\nConvert the column names of carsSub to all upper case. Use rename_all(), and toupper() (or colnames()).\nSubset the rows of cars that get more than 20 miles per gallon (mpg) of fuel efficiency. How many are there? (Use filter().)\nSubset the rows that get less than 16 miles per gallon (mpg) of fuel efficiency and have more than 100 horsepower (hp). How many are there? (Use filter() and the pipe operator.)\nCreate a subset of the cars data that only contains the columns: wt, qsec, and hp for cars with 8 cylinders (cyl) and reassign this object to carsSub. What are the dimensions of this dataset? Do not use the pipe operator.\nCreate a subset of the cars data that only contains the columns: wt, qsec, and hp for cars with 8 cylinders (cyl) and reassign this object to carsSub2. Use the pipe operator.\nRe-order the rows of carsSub by weight (wt) in increasing order. (Use arrange().)\nCreate a new variable in carsSub called wt2, which is equal to wt\\(^2\\), using mutate() and piping |&gt;.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: arrange, class, dim, ends_with, filter, mutate, ncol, nrow, rename, rename_all, rownames_to_column, select.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Subsetting with \\R\n# exe_subset.R\n# Stephan Huber; 2022-06-07\n\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsda/work/\")\nrm(list = ls())\n\n# 0\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, dplyr, tibble)\n\n# 1\nmtcars\n\n# 2\ncars &lt;- mtcars\n\n# 3\nclass(cars)\n\n# 4\ndim(cars)\n\n# Alternative\nncol(cars)\nnrow(cars)\n\n# 5\ncars &lt;- rename(cars, MPG = mpg)\n\n# 6\ncars &lt;- rename_all(cars, toupper)\n# if you like lower cases:\n# cars &lt;- rename_all(cars, tolower)\n\n# 7\ncars &lt;- rownames_to_column(mtcars, var = \"car\")\n\n# 8\npvars &lt;- select(cars, car, ends_with(\"p\"))\n\n# 9\ncarsSub &lt;- select(cars, car, wt, qsec, hp)\n\n# 10\ndim(carsSub)\n\n# 11\ncarsSub &lt;- rename_all(carsSub, toupper)\n\n# 12\ncars_mpg &lt;- filter(cars, mpg &gt; 20)\ndim(cars_mpg)\n\n# 13\ncars_whattever &lt;- filter(cars, mpg &lt; 16 & hp &gt; 100)\n\n# 14\ncarsSub &lt;- filter(cars, cyl == 8)\ncarsSub &lt;- select(carsSub, wt, qsec, hp, car)\ndim(carsSub)\n\n# 15\n# Alternative with pipe operator:\ncarsSub &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car)\n\n# 16\ncarsSub &lt;- arrange(carsSub, wt)\n\n# 17\ncarsSub &lt;- carsSub |&gt;\n  mutate(wt2 = wt^2)\n\n# Alternatively you can put everything into one pipe:\ncarsSub2 &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car) |&gt;\n  arrange(carsSub, wt) |&gt;\n  mutate(wt2 = wt^2)\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, dplyr, tibble))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Subsetting with \\R\n# exe_subset.R\n# Stephan Huber; 2022-06-07\n\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsda/work/\")\nrm(list = ls())\n\n# 0\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, dplyr, tibble)\n\n# 1\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# 2\ncars &lt;- mtcars\n\n# 3\nclass(cars)\n\n[1] \"data.frame\"\n\n# 4\ndim(cars)\n\n[1] 32 11\n\n# Alternative\nncol(cars)\n\n[1] 11\n\nnrow(cars)\n\n[1] 32\n\n# 5\ncars &lt;- rename(cars, MPG = mpg)\n\n# 6\ncars &lt;- rename_all(cars, toupper)\n# if you like lower cases:\n# cars &lt;- rename_all(cars, tolower)\n\n# 7\ncars &lt;- rownames_to_column(mtcars, var = \"car\")\n\n# 8\npvars &lt;- select(cars, car, ends_with(\"p\"))\n\n# 9\ncarsSub &lt;- select(cars, car, wt, qsec, hp)\n\n# 10\ndim(carsSub)\n\n[1] 32  4\n\n# 11\ncarsSub &lt;- rename_all(carsSub, toupper)\n\n# 12\ncars_mpg &lt;- filter(cars, mpg &gt; 20)\ndim(cars_mpg)\n\n[1] 14 12\n\n# 13\ncars_whattever &lt;- filter(cars, mpg &lt; 16 & hp &gt; 100)\n\n# 14\ncarsSub &lt;- filter(cars, cyl == 8)\ncarsSub &lt;- select(carsSub, wt, qsec, hp, car)\ndim(carsSub)\n\n[1] 14  4\n\n# 15\n# Alternative with pipe operator:\ncarsSub &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car)\n\n# 16\ncarsSub &lt;- arrange(carsSub, wt)\n\n# 17\ncarsSub &lt;- carsSub |&gt;\n  mutate(wt2 = wt^2)\n\n# Alternatively you can put everything into one pipe:\ncarsSub2 &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car) |&gt;\n  arrange(carsSub, wt) |&gt;\n  mutate(wt2 = wt^2)\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, dplyr, tibble))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-weighdatareg",
    "href": "80_exercises.html#sec-weighdatareg",
    "title": "9  Collection of exercises",
    "section": "9.6 Weighting, data management and regression",
    "text": "9.6 Weighting, data management and regression\n\n\n\n\nTable 9.2: Data\n\n\n\n \n\n  \n    \n    \n    tinytable_g5pzizadtbwm53urti3d\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                v1\n                v2\n                v3\n                v4\n              \n        \n        \n        \n                \n                  1\n                  A \n                   NA\n                     \n                \n                \n                  2\n                  NA\n                  0.2\n                  0.4\n                \n                \n                   \n                  C \n                  0.3\n                  0.1\n                \n                \n                  4\n                  D \n                   NA\n                  3  \n                \n                \n                  5\n                  E \n                  0.5\n                  1.5\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nConsider the data of Table Table 9.2 and solve the following exercises:\n\nAdd variable misone that is 1 if there is a missing and 0 otherwise. (Hint: Use case_when and is.na().)\n\n\ndf &lt;- df |&gt; \n  mutate(misone = case_when(\n    v1 == \"\" | is.na(v1) ~ 1,\n    v2 == \"\" | is.na(v2) ~ 1,\n    v3 == \"\" | is.na(v3) ~ 1,\n    v4 == \"\" | is.na(v4) ~ 1,\n    TRUE ~ 0 \n  ))\n\ntt(df)\n\n \n\n  \n    \n    \n    tinytable_shxrrjla1we9lgu0walv\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                v1\n                v2\n                v3\n                v4\n                misone\n              \n        \n        \n        \n                \n                  1\n                  A \n                   NA\n                     \n                  1\n                \n                \n                  2\n                  NA\n                  0.2\n                  0.4\n                  1\n                \n                \n                   \n                  C \n                  0.3\n                  0.1\n                  1\n                \n                \n                  4\n                  D \n                   NA\n                  3  \n                  1\n                \n                \n                  5\n                  E \n                  0.5\n                  1.5\n                  0\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\nAdd variable miscount that counts how many observations are missing in each row. (Hint: Use mutate_all, rowSums, and pick(everything()))\n\n\ntest_df &lt;- df |&gt; \n  mutate_all(~ if_else(is.na(.) | . == \"\", 1, 0)) |&gt;\n  mutate(miscount = rowSums(pick(everything())))\n\ntest_df_miscount &lt;- test_df |&gt; \n  select(miscount) \n\ndf &lt;- bind_cols(df, test_df_miscount)\n\ntt(df)\n\n \n\n  \n    \n    \n    tinytable_5s9a1f7vsguoe4zxajat\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                v1\n                v2\n                v3\n                v4\n                misone\n                miscount\n              \n        \n        \n        \n                \n                  1\n                  A \n                   NA\n                     \n                  1\n                  2\n                \n                \n                  2\n                  NA\n                  0.2\n                  0.4\n                  1\n                  1\n                \n                \n                   \n                  C \n                  0.3\n                  0.1\n                  1\n                  1\n                \n                \n                  4\n                  D \n                   NA\n                  3  \n                  1\n                  1\n                \n                \n                  5\n                  E \n                  0.5\n                  1.5\n                  0\n                  0\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\nUse the function rowwise to calculate the NA and \"\" observations. (Hint: Use is.na and pick(everything()).)\n\n\ndf &lt;- df |&gt; \n  rowwise() |&gt; \n  mutate(countNA = sum(is.na(pick(everything())))) |&gt; \n  mutate(countOK = sum(pick(everything()) == \"\", na.rm = TRUE)) |&gt; \n  ungroup()\n\ntt(df)\n\n \n\n  \n    \n    \n    tinytable_tuk9flzq81llopvoioi2\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                v1\n                v2\n                v3\n                v4\n                misone\n                miscount\n                countNA\n                countOK\n              \n        \n        \n        \n                \n                  1\n                  A \n                   NA\n                     \n                  1\n                  2\n                  1\n                  1\n                \n                \n                  2\n                  NA\n                  0.2\n                  0.4\n                  1\n                  1\n                  1\n                  0\n                \n                \n                   \n                  C \n                  0.3\n                  0.1\n                  1\n                  1\n                  0\n                  1\n                \n                \n                  4\n                  D \n                   NA\n                  3  \n                  1\n                  1\n                  1\n                  0\n                \n                \n                  5\n                  E \n                  0.5\n                  1.5\n                  0\n                  0\n                  0\n                  0\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\nAdd variable mispercent that measures the percentage of missings and a variable mis30up that is 1 if the percentage is above 30%. (Hint: Use mutate, select, ifelse, and bind_cols.)\n\n\ntest_df_mis30up &lt;- test_df |&gt; \n  mutate(fraction = miscount / 4) |&gt; \n  mutate(mis30up = ifelse(fraction &gt; 0.3, 1, 0)) |&gt; \n  select(mis30up, fraction)\n\ndf &lt;- bind_cols(df, test_df_mis30up)\n\ntt(df)\n\n \n\n  \n    \n    \n    tinytable_9l6quh2in3u50mol3233\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                v1\n                v2\n                v3\n                v4\n                misone\n                miscount\n                countNA\n                countOK\n                mis30up\n                fraction\n              \n        \n        \n        \n                \n                  1\n                  A \n                   NA\n                     \n                  1\n                  2\n                  1\n                  1\n                  1\n                  0.50\n                \n                \n                  2\n                  NA\n                  0.2\n                  0.4\n                  1\n                  1\n                  1\n                  0\n                  0\n                  0.25\n                \n                \n                   \n                  C \n                  0.3\n                  0.1\n                  1\n                  1\n                  0\n                  1\n                  0\n                  0.25\n                \n                \n                  4\n                  D \n                   NA\n                  3  \n                  1\n                  1\n                  1\n                  0\n                  0\n                  0.25\n                \n                \n                  5\n                  E \n                  0.5\n                  1.5\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0.00\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\nCalculate the average of the numeric variables v1, v3, and v4. Name the variable average. (Hint: Use as.numeric, rowwise, and mean.)\n\n\ndf &lt;- df |&gt; \n  mutate(\n    v1 = as.numeric(v1),\n    v4 = as.numeric(v4)\n  )\ndf &lt;- df |&gt; \n  rowwise() |&gt; \n  mutate(average = mean(c(v1, v3, v4), na.rm = TRUE)) |&gt; \n  ungroup()\n\ntest_df &lt;- df |&gt; \n  select(v1, v3, v4, average)\n\ntt(test_df)\n\n \n\n  \n    \n    \n    tinytable_xv6h51soc9g19mwk47cs\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                v1\n                v3\n                v4\n                average\n              \n        \n        \n        \n                \n                   1\n                   NA\n                   NA\n                  1.0000000\n                \n                \n                   2\n                  0.2\n                  0.4\n                  0.8666667\n                \n                \n                  NA\n                  0.3\n                  0.1\n                  0.2000000\n                \n                \n                   4\n                   NA\n                  3.0\n                  3.5000000\n                \n                \n                   5\n                  0.5\n                  1.5\n                  2.3333333",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#consumer-prices-over-time",
    "href": "80_exercises.html#consumer-prices-over-time",
    "title": "9  Collection of exercises",
    "section": "9.7 Consumer prices over time",
    "text": "9.7 Consumer prices over time\n\nRead in the following data:\n\n\nhttps://raw.githubusercontent.com/hubchev/courses/main/dta/PCEPI.csv \n\nThe data stem from the Federal Reserve Bank of St. Louis (FRED).\n\n\n\n\n\n\nTip\n\n\n\nYou should always try to use most recent data and you should not work outside of R. Thus, it would be optimal to download the data directly from FRED and using a R package. If this would be serious research, I would not recommend to use the data that I have downloaded from FRED, I’d recommend to use the fredr package which allows to fetch the observation directly from FRED database using the function fredr.\n\n\nHere is an excerpt of the data:\n\n\n        DATE PCEPI_NBD20190101\n1 1965-01-01          15.92229\n2 1966-01-01          16.32477\n3 1967-01-01          16.73491\n4 1968-01-01          17.38977\n5 1969-01-01          18.17313\n6 1970-01-01          19.02267\n\n\n\nDivide the variable PCEPI_NBD20190101 by 100 and name the resulting variable pce. Additionally, generate a new variable year that contains the respective year. Save the modified dataframe as pce_cl.\nMake the following plot:\n\n\n\n\n\n\n\n\n\n\n\nMake the following plot:\n\n\n\n\n\n\n\n\n\n\n\nMake the following plot:\n\n\n\n\n\n\n\n\n\n\n\nMake a plot of inflation for all years except the 90s:\n\n\n\n\n\n\n\n\n\n\n\nCalculate the yearly inflation. Here is an excpert of how the data should look like:\n\n\n\n  year       pce inflation_rate\n1 1965 0.1592229             NA\n2 1966 0.1632477       2.527777\n3 1967 0.1673491       2.512378\n4 1968 0.1738977       3.913137\n5 1969 0.1817313       4.504717\n6 1970 0.1902267       4.674704\n\n\n\nPlot the yearly inflation rate:\n\n\n\n\n\n\n\n\n\n\n\nCalculate the average inflation rate over all years.\nCalculate the average inflation rate for each decade:\n\n\n\n# A tibble: 7 × 2\n  decade avg_inf\n  &lt;chr&gt;    &lt;dbl&gt;\n1 1960s     3.36\n2 1970s     6.43\n3 1980s     5.03\n4 1990s     2.32\n5 2000s     2.14\n6 2010s     1.57\n7 2020s     2.53\n\n\n\nMake the following plot:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, as.integer, case_when, filter, geom_bar, geom_line, geom_point, ggplot, group_by, lag, mean, mutate, read.csv, select, str_sub, summarize.\n\n\n\n\n\n\nR script\n\n\n\n\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, expss)\n# setwd(\"~/yourdirectory-of-choice\")\nrm(list = ls())\n\n\n# read in raw data\n# PCEPI &lt;- read.csv(\"PCEPI.csv\")\nPCEPI &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/PCEPI.csv\")\n\n# clean data\npce_cl &lt;- PCEPI |&gt;\n  mutate(pce = PCEPI_NBD20190101/100) |&gt;\n  mutate(year = str_sub(DATE, 1, 4)) |&gt;\n  mutate(year = as.integer(year)) |&gt;\n  select(pce, year) \n\n# make a plot\npce_cl |&gt;\n  ggplot( aes(x=year, y=pce))+\n  geom_line() +\n  geom_point()\n\n# make a barplot\npce_cl |&gt;\n  ggplot( aes(x=year, y=pce))+\n  geom_bar(stat=\"identity\")\n\n# make a plot for all years from 2000 onwards\npce_cl |&gt;\n  filter(year &gt; 2000 ) |&gt;\n  ggplot( aes(x=year, y=pce)) +\n  geom_bar(stat=\"identity\")\n\n# make a plot for all years except the 90s\npce_cl |&gt;\n  filter(year &gt; 2000 | year &lt;1990) |&gt;\n  ggplot( aes(x=year, y=pce)) +\n  geom_bar(stat=\"identity\")\n\n# calculate yearly inflation\npce_cl &lt;- pce_cl |&gt;\n  mutate(inflation_rate = (pce/lag(pce)-1)*100 )\n\n# plot the inflation rate\npce_cl |&gt;\n  ggplot( aes(x=year, y=inflation_rate))+\n  geom_bar(stat=\"identity\")\n\n# what is the avergage inflation rate\npce_cl |&gt;\n  summarize(avg_mpg = mean(inflation_rate, na.rm = TRUE))\n\n# make a variable that indicates the decades 1 for 60s, 2 for 70s, etc.\n\npce_cl &lt;- pce_cl |&gt;\n  mutate(decade = case_when(\n    year &lt; 1970  ~ \"1960s\",\n    (year &gt; 1969 & year &lt; 1980) ~ \"1970s\",\n    (year &gt; 1979 & year &lt; 1990) ~ \"1980s\",\n    (year &gt; 1989 & year &lt; 2000) ~ \"1990s\",\n    (year &gt; 1999 & year &lt; 2010) ~ \"2000s\",\n    (year &gt; 2009 & year &lt; 2020) ~ \"2010s\",\n    (year &gt; 2019 & year &lt; 2030) ~ \"2020s\",\n  )) \n\n\npce_decade &lt;- pce_cl |&gt;\n  group_by(decade) |&gt;\n  summarize(avg_inf = mean(inflation_rate, na.rm = TRUE)) \n\npce_decade\npce_decade |&gt;\n  ggplot( aes(x=decade, y=avg_inf))+\n  geom_bar(stat=\"identity\")\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, expss)\n# setwd(\"~/yourdirectory-of-choice\")\nrm(list = ls())\n\n\n# read in raw data\n# PCEPI &lt;- read.csv(\"PCEPI.csv\")\nPCEPI &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/PCEPI.csv\")\n\n# clean data\npce_cl &lt;- PCEPI |&gt;\n  mutate(pce = PCEPI_NBD20190101/100) |&gt;\n  mutate(year = str_sub(DATE, 1, 4)) |&gt;\n  mutate(year = as.integer(year)) |&gt;\n  select(pce, year) \n\n# make a plot\npce_cl |&gt;\n  ggplot( aes(x=year, y=pce))+\n  geom_line() +\n  geom_point()\n\n\n\n\n\n\n\n# make a barplot\npce_cl |&gt;\n  ggplot( aes(x=year, y=pce))+\n  geom_bar(stat=\"identity\")\n\n\n\n\n\n\n\n# make a plot for all years from 2000 onwards\npce_cl |&gt;\n  filter(year &gt; 2000 ) |&gt;\n  ggplot( aes(x=year, y=pce)) +\n  geom_bar(stat=\"identity\")\n\n\n\n\n\n\n\n# make a plot for all years except the 90s\npce_cl |&gt;\n  filter(year &gt; 2000 | year &lt;1990) |&gt;\n  ggplot( aes(x=year, y=pce)) +\n  geom_bar(stat=\"identity\")\n\n\n\n\n\n\n\n# calculate yearly inflation\npce_cl &lt;- pce_cl |&gt;\n  mutate(inflation_rate = (pce/lag(pce)-1)*100 )\n\n# plot the inflation rate\npce_cl |&gt;\n  ggplot( aes(x=year, y=inflation_rate))+\n  geom_bar(stat=\"identity\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n# what is the avergage inflation rate\npce_cl |&gt;\n  summarize(avg_mpg = mean(inflation_rate, na.rm = TRUE))\n\n   avg_mpg\n1 3.454529\n\n# make a variable that indicates the decades 1 for 60s, 2 for 70s, etc.\n\npce_cl &lt;- pce_cl |&gt;\n  mutate(decade = case_when(\n    year &lt; 1970  ~ \"1960s\",\n    (year &gt; 1969 & year &lt; 1980) ~ \"1970s\",\n    (year &gt; 1979 & year &lt; 1990) ~ \"1980s\",\n    (year &gt; 1989 & year &lt; 2000) ~ \"1990s\",\n    (year &gt; 1999 & year &lt; 2010) ~ \"2000s\",\n    (year &gt; 2009 & year &lt; 2020) ~ \"2010s\",\n    (year &gt; 2019 & year &lt; 2030) ~ \"2020s\",\n  )) \n\n\npce_decade &lt;- pce_cl |&gt;\n  group_by(decade) |&gt;\n  summarize(avg_inf = mean(inflation_rate, na.rm = TRUE)) \n\npce_decade\n\n# A tibble: 7 × 2\n  decade avg_inf\n  &lt;chr&gt;    &lt;dbl&gt;\n1 1960s     3.36\n2 1970s     6.43\n3 1980s     5.03\n4 1990s     2.32\n5 2000s     2.14\n6 2010s     1.57\n7 2020s     2.53\n\npce_decade |&gt;\n  ggplot( aes(x=decade, y=avg_inf))+\n  geom_bar(stat=\"identity\")",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#load-the-stata-dataset-auto-using-r",
    "href": "80_exercises.html#load-the-stata-dataset-auto-using-r",
    "title": "9  Collection of exercises",
    "section": "9.8 Load the Stata dataset “auto” using R",
    "text": "9.8 Load the Stata dataset “auto” using R\n\nCreate a scatter plot illustrating the relationship between the price and weight of a car. Provide a meaningful title for the graph and try to make it clear which car each observation corresponds to.\nSave this graph in the formats of .png and .pdf.\nCreate a variable lp100km that indicates the fuel consumption of an average car in liters per 100 kilometers. (Note: One gallon is approximately equal to 3.8 liters, and one mile is about 1.6 kilometers.)\nCreate a dummy variable larger6000 that is equal to 1 if the price of a car is above $6000.\nNow, search for the “most unreasonable poser car” that costs no more than $6000. A poser car is defined as one that is expensive, has a large turning radius, consumes a lot of fuel, and is often defective (rep78 is low). For this purpose, create a metric indicator for each corresponding variable that indicates a value of 1 for the car that is the most unreasonable in that variable and 0 for the most reasonable car. All other cars should fall between 0 and 1.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, arrange, desc, dir.create, dir.exists, filter, geom_point, geom_text_repel, ggplot, head, ifelse, max, min, min_max_norm, mutate, na.omit, read_dta, select, tail, theme_minimal, xlab, ylab.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Load the required libraries\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven, ggrepel)\n\n# setwd(\"~/Dropbox/hsf/23-ws/R_begin\")\n\nrm(list = ls())\n\n# Read the Stata dataset\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r8/auto.dta\")\n\n\n# Create a scatter plot of price vs. weight\nscatter_plot &lt;- ggplot(auto, aes(x = mpg, y = price, label = make)) +\n  geom_point() +\n  geom_text_repel() +\n  xlab(\"Miles per Gallon\") +\n  ylab(\"Price in Dollar\") +\n  theme_minimal()\n\nscatter_plot\n\n# Create \"fig\" directory if it doesn't already exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\n# Save the scatter plot in different formats\n# ggsave(\"fig/scatter_plot.png\", plot = scatter_plot, device = \"png\")\n# ggsave(\"fig/scatter_plot.pdf\", plot = scatter_plot, device = \"pdf\")\n\n# Create 'lp100km' variable for fuel consumption\nn_auto &lt;- auto |&gt;\n  mutate(lp100km = (1 / (mpg * 1.6 / 3.8)) * 100)\n\n# Create 'larger6000' dummy variable\nn_auto &lt;- n_auto |&gt;\n  mutate(larger6000 = ifelse(price &gt; 6000, 1, 0))\n\n\n\n# Normalize variables\n\n## Do it slowly\nn_auto &lt;- n_auto |&gt;\n  mutate(sprice = (price - min(auto$price)) / (max(auto$price) - min(auto$price)))\n\nn_auto &lt;- n_auto |&gt;\n  filter(larger6000 == 0)\n\n## Do it with a self-written function\nmin_max_norm &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = min_max_norm(mpg)) |&gt;\n  mutate(sturn = min_max_norm(turn)) |&gt;\n  mutate(slp100km = min_max_norm(lp100km)) |&gt;\n  mutate(sprice = min_max_norm(price)) |&gt;\n  mutate(srep78 = min_max_norm(rep78))\n\n## With a loop:\n\n# vars_to_normalize &lt;- c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")\n#\n# # Loop through the selected variables and apply min_max_norm\n# for (var in c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")) {\n#   auto &lt;- auto |&gt;\n#     mutate(!!paste0(\"s\", var) := min_max_norm(!!sym(var))) |&gt;\n#     select(make, starts_with(\"s\"))\n# }\n\n## mpg and rep78 need to be changed because a SMALL value is poser-like\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = 1 - smpg) |&gt;\n  mutate(srep78 = 1 - srep78)\n\n## create the poser (composite) indicator\nn_auto &lt;- n_auto |&gt;\n  mutate(poser = (sturn + smpg + sprice + srep78) / 4)\n\n## filter results\nn_auto |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  head(5)\n\ndf_poser &lt;- n_auto |&gt;\n  filter(larger6000 == 0) |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  na.omit()\n\n# Five top poser cars\nhead(df_poser, 15)\n\n# Five top non-poser cars\ntail(df_poser, 5)\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven, ggrepel))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Load the required libraries\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven, ggrepel)\n\n# setwd(\"~/Dropbox/hsf/23-ws/R_begin\")\n\nrm(list = ls())\n\n# Read the Stata dataset\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r8/auto.dta\")\n\n\n# Create a scatter plot of price vs. weight\nscatter_plot &lt;- ggplot(auto, aes(x = mpg, y = price, label = make)) +\n  geom_point() +\n  geom_text_repel() +\n  xlab(\"Miles per Gallon\") +\n  ylab(\"Price in Dollar\") +\n  theme_minimal()\n\nscatter_plot\n\nWarning: ggrepel: 43 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n# Create \"fig\" directory if it doesn't already exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\n# Save the scatter plot in different formats\n# ggsave(\"fig/scatter_plot.png\", plot = scatter_plot, device = \"png\")\n# ggsave(\"fig/scatter_plot.pdf\", plot = scatter_plot, device = \"pdf\")\n\n# Create 'lp100km' variable for fuel consumption\nn_auto &lt;- auto |&gt;\n  mutate(lp100km = (1 / (mpg * 1.6 / 3.8)) * 100)\n\n# Create 'larger6000' dummy variable\nn_auto &lt;- n_auto |&gt;\n  mutate(larger6000 = ifelse(price &gt; 6000, 1, 0))\n\n\n\n# Normalize variables\n\n## Do it slowly\nn_auto &lt;- n_auto |&gt;\n  mutate(sprice = (price - min(auto$price)) / (max(auto$price) - min(auto$price)))\n\nn_auto &lt;- n_auto |&gt;\n  filter(larger6000 == 0)\n\n## Do it with a self-written function\nmin_max_norm &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = min_max_norm(mpg)) |&gt;\n  mutate(sturn = min_max_norm(turn)) |&gt;\n  mutate(slp100km = min_max_norm(lp100km)) |&gt;\n  mutate(sprice = min_max_norm(price)) |&gt;\n  mutate(srep78 = min_max_norm(rep78))\n\n## With a loop:\n\n# vars_to_normalize &lt;- c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")\n#\n# # Loop through the selected variables and apply min_max_norm\n# for (var in c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")) {\n#   auto &lt;- auto |&gt;\n#     mutate(!!paste0(\"s\", var) := min_max_norm(!!sym(var))) |&gt;\n#     select(make, starts_with(\"s\"))\n# }\n\n## mpg and rep78 need to be changed because a SMALL value is poser-like\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = 1 - smpg) |&gt;\n  mutate(srep78 = 1 - srep78)\n\n## create the poser (composite) indicator\nn_auto &lt;- n_auto |&gt;\n  mutate(poser = (sturn + smpg + sprice + srep78) / 4)\n\n## filter results\nn_auto |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  make             poser\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Dodge Magnum     0.888\n2 Pont. Firebird   0.782\n3 Merc. Cougar     0.763\n4 Buick LeSabre    0.754\n5 Pont. Grand Prix 0.720\n\ndf_poser &lt;- n_auto |&gt;\n  filter(larger6000 == 0) |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  na.omit()\n\n# Five top poser cars\nhead(df_poser, 15)\n\n# A tibble: 15 × 2\n   make              poser\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Dodge Magnum      0.888\n 2 Pont. Firebird    0.782\n 3 Merc. Cougar      0.763\n 4 Buick LeSabre     0.754\n 5 Pont. Grand Prix  0.720\n 6 Chev. Impala      0.702\n 7 Dodge Diplomat    0.690\n 8 Chev. Monte Carlo 0.684\n 9 Pont. Catalina    0.678\n10 Olds Cutl Supr    0.671\n11 Plym. Volare      0.665\n12 Buick Regal       0.663\n13 Olds Cutlass      0.629\n14 Olds Starfire     0.626\n15 AMC Pacer         0.619\n\n# Five top non-poser cars\ntail(df_poser, 5)\n\n# A tibble: 5 × 2\n  make           poser\n  &lt;chr&gt;          &lt;dbl&gt;\n1 VW Diesel      0.261\n2 Dodge Colt     0.227\n3 Toyota Corolla 0.195\n4 Datsun 210     0.195\n5 Subaru         0.178\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven, ggrepel))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#datasaurus",
    "href": "80_exercises.html#datasaurus",
    "title": "9  Collection of exercises",
    "section": "9.9 DatasauRus",
    "text": "9.9 DatasauRus\n\n\n\nFigure 9.1: The logo of the DatasauRus package\n\n\n\nSource: https://github.com/jumpingrivers/datasauRus _\n\n\n\n\nLoad the packages datasauRus and tidyverse. If necessary, install these packages.\nThe packagedatasauRus comes with a dataset in two different formats: datasaurus_dozen and datasaurus_dozen_wide. Store them as ds and ds_wide.\nOpen and read the R vignette of the datasauRus package. Also open the R documentation of the dataset datasaurus_dozen.\nExplore the dataset: What are the dimensions of this dataset? Look at the descriptive statistics.\nHow many unique values does the variable dataset of the tibble ds have? Hint: The function unique() return the unique values of a variable and the function length() returns the length of a vector, such as the unique elements.\nCompute the mean values of the x and y variables for each entry in dataset. Hint: Use the group_by() function to group the data by the appropriate column and then the summarise() function to calculate the mean.\nCompute the standard deviation, the correlation, and the median in the same way. Round the numbers.\nWhat can you conclude?\nPlot all datasets of ds. Hide the legend. Hint: Use the facet_wrap() and the theme() function.\nCreate a loop that generates separate scatter plots for each unique datatset of the tibble ds. Export each graph as a png file.\nWatch the video Animating the Datasaurus Dozen Dataset in R from The Data Digest on YouTube.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, cor, dim, dir.create, dir.exists, facet_wrap, filter, geom_point, ggplot, ggsave, glimpse, group_by, head, labs, length, mean, median, paste, paste0, round, sd, select, summarise, summary, theme, theme_bw, unique, view.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/23-ws/ds_mim/\")\nrm(list = ls())\n\n# Load the packages datasauRus and tidyverse. If necessary, install these packages.\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasauRus, tidyverse)\n\n# The packagedatasauRus comes with a dataset in two different formats:\n#   datasaurus_dozen and datasaurus_dozen_wide. Store them as ds and ds_wide.\n\nds &lt;- datasaurus_dozen\nds_wide &lt;- datasaurus_dozen_wide\n\n# Open and read the R vignette of the datasauRus package.\n#   Also open the R documentation of the dataset datasaurus_dozen.\n\n??datasaurus\n\n# Explore the dataset: What are the dimensions of this dataset? Look at the descriptive statistics.\n\nds\ndim(ds)\nhead(ds)\nglimpse(ds)\nview(ds)\nsummary(ds)\n\n# How many unique values does the variable dataset of the tibble ds have?\n#   Hint: The function unique() return the unique values of a variable and the\n#   function length() returns the length of a vector, such as the unique elements.\n\nunique(ds$dataset)\n\nunique(ds$dataset) |&gt;\n  length()\n\n# Compute the mean values of the x and y variables for each entry in dataset.\n#   Hint: Use the group_by() function to group the data by the appropriate column and\n#   then the summarise() function to calculate the mean.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = mean(x),\n    mean_y = mean(y)\n  )\n\n# Compute the standard deviation, the correlation, and the median in the same way. Round the numbers.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = round(mean(x), 2),\n    mean_y = round(mean(y), 2),\n    sd_x = round(sd(x), 2),\n    sd_y = round(sd(y), 2),\n    med_x = round(median(x), 2),\n    med_y = round(median(y), 2),\n    cor = round(cor(x, y), digits = 4)\n  )\n\n# What can you conclude?\n#   --&gt; The standard deviation, the mean, and the correlation are basically the\n#   same for all datasets. The median is different.\n\n# Plot all datasets of ds. Hide the legend. Hint: Use the facet_wrap() and the theme() function.\n\nggplot(ds, aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\n# Create a loop that generates separate scatter plots for each unique datatset of the tibble ds.\n#   Export each graph as a png file.\n\n# Assuming uni_ds is a vector of unique values for the 'dataset' variable\nuni_ds &lt;- unique(ds$dataset)\n\n# Create the 'pic' folder if it doesn't exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\nfor (uni_v in uni_ds) {\n  # Select data for the current value\n  subset_ds &lt;- ds |&gt;\n    filter(dataset == uni_v) |&gt;\n    select(x, y)\n\n  # Make plot\n  graph &lt;- ggplot(subset_ds, aes(x = x, y = y)) +\n    geom_point() +\n    labs(\n      title = paste(\"Dataset:\", uni_v),\n      x = \"X\",\n      y = \"Y\"\n    ) +\n    theme_bw()\n\n  # Save the plot as a PNG file\n  filename &lt;- paste0(\"fig/\", \"plot_ds_\", uni_v, \".png\")\n  ggsave(filename, plot = graph)\n}\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasauRus, tidyverse))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/23-ws/ds_mim/\")\nrm(list = ls())\n\n# Load the packages datasauRus and tidyverse. If necessary, install these packages.\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasauRus, tidyverse)\n\n# The packagedatasauRus comes with a dataset in two different formats:\n#   datasaurus_dozen and datasaurus_dozen_wide. Store them as ds and ds_wide.\n\nds &lt;- datasaurus_dozen\nds_wide &lt;- datasaurus_dozen_wide\n\n# Open and read the R vignette of the datasauRus package.\n#   Also open the R documentation of the dataset datasaurus_dozen.\n\n??datasaurus\n\n# Explore the dataset: What are the dimensions of this dataset? Look at the descriptive statistics.\n\nds\n\n# A tibble: 1,846 × 3\n   dataset     x     y\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# ℹ 1,836 more rows\n\ndim(ds)\n\n[1] 1846    3\n\nhead(ds)\n\n# A tibble: 6 × 3\n  dataset     x     y\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 dino     55.4  97.2\n2 dino     51.5  96.0\n3 dino     46.2  94.5\n4 dino     42.8  91.4\n5 dino     40.8  88.3\n6 dino     38.7  84.9\n\nglimpse(ds)\n\nRows: 1,846\nColumns: 3\n$ dataset &lt;chr&gt; \"dino\", \"dino\", \"dino\", \"dino\", \"dino\", \"dino\", \"dino\", \"dino\"…\n$ x       &lt;dbl&gt; 55.3846, 51.5385, 46.1538, 42.8205, 40.7692, 38.7179, 35.6410,…\n$ y       &lt;dbl&gt; 97.1795, 96.0256, 94.4872, 91.4103, 88.3333, 84.8718, 79.8718,…\n\nview(ds)\nsummary(ds)\n\n   dataset                x               y           \n Length:1846        Min.   :15.56   Min.   : 0.01512  \n Class :character   1st Qu.:41.07   1st Qu.:22.56107  \n Mode  :character   Median :52.59   Median :47.59445  \n                    Mean   :54.27   Mean   :47.83510  \n                    3rd Qu.:67.28   3rd Qu.:71.81078  \n                    Max.   :98.29   Max.   :99.69468  \n\n# How many unique values does the variable dataset of the tibble ds have?\n#   Hint: The function unique() return the unique values of a variable and the\n#   function length() returns the length of a vector, such as the unique elements.\n\nunique(ds$dataset)\n\n [1] \"dino\"       \"away\"       \"h_lines\"    \"v_lines\"    \"x_shape\"   \n [6] \"star\"       \"high_lines\" \"dots\"       \"circle\"     \"bullseye\"  \n[11] \"slant_up\"   \"slant_down\" \"wide_lines\"\n\nunique(ds$dataset) |&gt;\n  length()\n\n[1] 13\n\n# Compute the mean values of the x and y variables for each entry in dataset.\n#   Hint: Use the group_by() function to group the data by the appropriate column and\n#   then the summarise() function to calculate the mean.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = mean(x),\n    mean_y = mean(y)\n  )\n\n# A tibble: 13 × 3\n   dataset    mean_x mean_y\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 away         54.3   47.8\n 2 bullseye     54.3   47.8\n 3 circle       54.3   47.8\n 4 dino         54.3   47.8\n 5 dots         54.3   47.8\n 6 h_lines      54.3   47.8\n 7 high_lines   54.3   47.8\n 8 slant_down   54.3   47.8\n 9 slant_up     54.3   47.8\n10 star         54.3   47.8\n11 v_lines      54.3   47.8\n12 wide_lines   54.3   47.8\n13 x_shape      54.3   47.8\n\n# Compute the standard deviation, the correlation, and the median in the same way. Round the numbers.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = round(mean(x), 2),\n    mean_y = round(mean(y), 2),\n    sd_x = round(sd(x), 2),\n    sd_y = round(sd(y), 2),\n    med_x = round(median(x), 2),\n    med_y = round(median(y), 2),\n    cor = round(cor(x, y), digits = 4)\n  )\n\n# A tibble: 13 × 8\n   dataset    mean_x mean_y  sd_x  sd_y med_x med_y     cor\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 away         54.3   47.8  16.8  26.9  53.3  47.5 -0.0641\n 2 bullseye     54.3   47.8  16.8  26.9  53.8  47.4 -0.0686\n 3 circle       54.3   47.8  16.8  26.9  54.0  51.0 -0.0683\n 4 dino         54.3   47.8  16.8  26.9  53.3  46.0 -0.0645\n 5 dots         54.3   47.8  16.8  26.9  51.0  51.3 -0.0603\n 6 h_lines      54.3   47.8  16.8  26.9  53.1  50.5 -0.0617\n 7 high_lines   54.3   47.8  16.8  26.9  54.2  32.5 -0.0685\n 8 slant_down   54.3   47.8  16.8  26.9  53.1  46.4 -0.069 \n 9 slant_up     54.3   47.8  16.8  26.9  54.3  45.3 -0.0686\n10 star         54.3   47.8  16.8  26.9  56.5  50.1 -0.063 \n11 v_lines      54.3   47.8  16.8  26.9  50.4  47.1 -0.0694\n12 wide_lines   54.3   47.8  16.8  26.9  64.6  46.3 -0.0666\n13 x_shape      54.3   47.8  16.8  26.9  47.1  39.9 -0.0656\n\n# What can you conclude?\n#   --&gt; The standard deviation, the mean, and the correlation are basically the\n#   same for all datasets. The median is different.\n\n# Plot all datasets of ds. Hide the legend. Hint: Use the facet_wrap() and the theme() function.\n\nggplot(ds, aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n# Create a loop that generates separate scatter plots for each unique datatset of the tibble ds.\n#   Export each graph as a png file.\n\n# Assuming uni_ds is a vector of unique values for the 'dataset' variable\nuni_ds &lt;- unique(ds$dataset)\n\n# Create the 'pic' folder if it doesn't exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\nfor (uni_v in uni_ds) {\n  # Select data for the current value\n  subset_ds &lt;- ds |&gt;\n    filter(dataset == uni_v) |&gt;\n    select(x, y)\n\n  # Make plot\n  graph &lt;- ggplot(subset_ds, aes(x = x, y = y)) +\n    geom_point() +\n    labs(\n      title = paste(\"Dataset:\", uni_v),\n      x = \"X\",\n      y = \"Y\"\n    ) +\n    theme_bw()\n\n  # Save the plot as a PNG file\n  filename &lt;- paste0(\"fig/\", \"plot_ds_\", uni_v, \".png\")\n  ggsave(filename, plot = graph)\n}\n\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasauRus, tidyverse))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#convergence",
    "href": "80_exercises.html#convergence",
    "title": "9  Collection of exercises",
    "section": "9.10 Convergence",
    "text": "9.10 Convergence\nThe dataset convergence.dta, see https://github.com/hubchev/courses/blob/main/dta/convergence.dta, contains the per capita GDP of 1960 (gdppc60) and the average growth rate of GDP per capita between 1960 and 1995 (growth) for different countries (country), as well as 3 dummy variables indicating the belonging of a country to the region Asia (asia), Western Europe (weurope) or Africa (africa).\n\nSome countries are not assigned to a certain country group. Name the countries which are assign to be part of Western Europe, Africa or Asia. If you find countries that are members of the EU, assign them a ‘1’ in the variable weurope.\nCreate a table that shows the average GDP per capita for all available points in time. Group by Western European, Asian, African, and the remaining countries.\nCreate the growth rate of GDP per capita from 1960 to 1995 and call it gdpgrowth. (Note: The log value X minus the log value X of the previous period is approximately equal to the growth rate).\nCalculate the unconditional convergence of all countries by constructing a graph in which a scatterplot shows the GDP per capita growth rate between 1960 and 1995 (gdpgrowth) on the y-axis and the 1960 GDP per capita (gdppc60) on the x-axis. Add to the same graph the estimated linear relationship. You do not need to label the graph further, just two things: title the graph world and label the individual observations with the country names.\nCreate three graphs describing the same relationship for the sample of Western European, African and Asian countries. Title the graph accordingly with weurope, africa and asia.\nCombine the four graphs into one image. Discuss how an upward or downward sloping regression line can be interpreted.\nEstimate the relationships illustrated in the 4 graphs using the least squares method. Present the 4 estimation results in a table, indicating the significance level with stars. In addition, the Akaike information criterion, and the number of observations should be displayed in the table. Interpret the four estimation results regarding their significance.\nPut the data set into the so-called long format and calculate the GDP per capita growth rates for the available time points in the countries.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, as.numeric, c, cor, describe, diff, filter, gather, geom_point, geom_text, ggarrange, ggplot, ggtitle, group_by, head, ifelse, lag, list, lm, log, mean, mutate, names, read_dta, select, set_label, starts_with, stat_smooth, stat.desc, str, subset, substr, summarise, summarise_all, summarise_at, summary, tab_model, tail, tbl_summary, vars, view.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Convergence\n\n# set working directory\n# setwd(\"/home/sthu/Dropbox/hsf/github/courses/\")\n\n# clear the environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot, psych\n)\n\n# import data\ndata &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/convergence.dta\")\n\n# inspect data\nnames(data)\nstr(data)\ndata\nhead(data)\ntail(data)\nsummary(data)\nview(data)\n\n# library(vtable)\n# vtable(data, missing=TRUE)\n\n# library(pastecs)\nstat.desc(data)\n\n# library(Hmisc)\ndescribe(data)\n\n# library(gtsummary)\ntbl_summary(data)\n\n# check the assignments of countries to continents\ndata |&gt;\n  select(country, africa, asia, weurope) |&gt;\n  view()\n\ndata &lt;- mutate(data, x_1 = africa + asia + weurope)\n\ndata |&gt;\n  filter(x_1 == 0) |&gt;\n  select(africa, asia, weurope, country) |&gt;\n  view()\n\n# correct the assignment manually\ndata$weurope[data$country == \"Austria\"] &lt;- 1\ndata$weurope[data$country == \"Greece\"] &lt;- 1\ndata$weurope[data$country == \"Cyprus\"] &lt;- 1\n\nfilter(data, data$weurope == 1) # check changes\n\n# In the following, I do the same with a loop\n# c_europe &lt;- c(\"Austria\",\"Greece\",\"Cyprus\")\n# sum(data$weurope)                       # check changes\n# for (i in c_europe){\n#   print(i)\n#   data$weurope[data$country == i] &lt;- 1\n#   }\n# sum(data$weurope)                       # check changes\n# data$weurope[data$country == \"Austria\"] # check changes\n\n# create a category for the remaining countries\n# use ifelse -- ifelse(condition, result if TRUE, result if FALSE)\ndata$rest &lt;- ifelse(data$africa == 0 & data$asia == 0 & data$weurope == 0, 1, 0)\ndata$rest &lt;- set_label(data$rest, label = \"=1 if not in Africa, W.Europe, or Asia\")\n\n# create table with means across country groups\ntable_gdp &lt;- data |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  summarise_at(vars(gdppc60:gdppc95), list(name = mean))\n\ndata |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  select(gdppc60:gdppc95) |&gt;\n  summarise_all(mean)\n\n# create growth rate\ndata$gr1 &lt;- (data$gdppc95 - data$gdppc60) / data$gdppc60\ndata$gr2 &lt;- log(data$gdppc95) - log(data$gdppc60)\ncor(data$gr1, data$gr2)\n\nggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0)\n\np1 &lt;- ggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"World\")\n\np2 &lt;- data |&gt;\n  filter(weurope == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Western Europe\")\n\np3 &lt;- data |&gt;\n  filter(asia == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Asia\")\n\np4 &lt;- data |&gt;\n  filter(africa == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  #  geom_text( hjust=0, vjust=0) +\n  ggtitle(\"Africa\")\n\nggarrange(p1, p2, p3, p4,\n  labels = c(\"A\", \"B\", \"C\", \"D\"),\n  ncol = 2, nrow = 2\n)\n\n# Regression analysis\nm1 &lt;- lm(growth ~ gdppc60, data = data)\nm2 &lt;- lm(growth ~ gdppc60, data = subset(data, weurope == 1))\nm3 &lt;- lm(growth ~ gdppc60, data = subset(data, asia == 1))\nm4 &lt;- lm(growth ~ gdppc60, data = subset(data, africa == 1))\n\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE,\n  show.aic = TRUE,\n  dv.labels = c(\"World\", \"W.Europe\", \"Asia\", \"Africa\")\n)\n\n# reshape data (see: https://stackoverflow.com/questions/2185252/reshaping-data-frame-from-wide-to-long-format)\ndata_long &lt;- gather(data, condition, measurement, gdppc60:gdppc95, factor_key = TRUE)\ndata_long$year &lt;- as.numeric(substr(data_long$condition, 6, 7))\n\ndata_long$gr_long &lt;- data_long |&gt;\n  select(country, measurement) |&gt;\n  group_by(country) |&gt;\n  mutate(gr = c(NA, diff(measurement)) / lag(measurement, 1))\n\n# erase all helping variables\ndata &lt;- select(data, -starts_with(\"h_\"))\n\n# generate and remove variables in a dataframe\ndata &lt;- mutate(data, Land = country)\ndata &lt;- select(data, -country)\n\ndata |&gt;\n  summarise(\n    y65 = mean(gdppc65, na.rm = TRUE),\n    y70 = mean(gdppc70, na.rm = TRUE),\n    y75 = mean(gdppc75, na.rm = TRUE),\n    y80 = mean(gdppc80, na.rm = TRUE),\n    y85 = mean(gdppc85, na.rm = TRUE),\n    y90 = mean(gdppc90, na.rm = TRUE),\n    y95 = mean(gdppc95, na.rm = TRUE)\n  )\n\nsuppressMessages(pacman::p_unload(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot\n))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Convergence\n\n# set working directory\n# setwd(\"/home/sthu/Dropbox/hsf/github/courses/\")\n\n# clear the environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot, psych\n)\n\n# import data\ndata &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/convergence.dta\")\n\n# inspect data\nnames(data)\n\n [1] \"country\" \"gdppc60\" \"gdppc65\" \"gdppc70\" \"gdppc75\" \"gdppc80\" \"gdppc85\"\n [8] \"gdppc90\" \"gdppc95\" \"africa\"  \"asia\"    \"weurope\" \"growth\" \n\nstr(data)\n\ntibble [107 × 13] (S3: tbl_df/tbl/data.frame)\n $ country: chr [1:107] \"Algeria\" \"Angola\" \"Argentina\" \"Australia\" ...\n  ..- attr(*, \"format.stata\")= chr \"%24s\"\n $ gdppc60: num [1:107] 2848 2642 7879 11436 7842 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1960\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc65: num [1:107] 3536 3072 8802 13192 9387 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1965\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc70: num [1:107] 3670 3558 9903 15842 11946 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1970\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc75: num [1:107] 3917 2230 10609 16716 14198 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1975\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc80: num [1:107] 5094 2059 11359 18300 16869 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1980\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc85: num [1:107] 5876 1988 9246 19669 17919 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1985\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc90: num [1:107] 5307 2081 7716 21446 21178 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1990\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc95: num [1:107] 4935 1339 10973 23827 22474 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1995\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ africa : num [1:107] 1 1 0 0 0 0 0 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"=1 if in Africa\"\n  ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n $ asia   : num [1:107] 0 0 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"=1 if in Asia\"\n  ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n $ weurope: num [1:107] 0 0 0 0 0 0 0 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"=1 if in Western Europe\"\n  ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n $ growth : num [1:107] 0.55 -0.68 0.331 0.734 1.053 ...\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n\ndata\n\n# A tibble: 107 × 13\n   country    gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95\n   &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Algeria      2848.   3536.   3670.   3917.   5094.   5876.   5307.   4935.\n 2 Angola       2642.   3072.   3558.   2230.   2059.   1988.   2081.   1339.\n 3 Argentina    7879.   8802.   9903.  10609.  11359.   9246.   7716.  10973.\n 4 Australia   11436.  13192.  15842.  16716.  18300.  19669.  21446.  23827.\n 5 Austria      7842.   9387.  11946.  14198.  16869.  17919.  21178.  22474.\n 6 Bangladesh   1130.   1164.   1181.   1030.   1040.   1245.   1366.   1568.\n 7 Barbados     3632.   4632.   6456.   8827.  10911.  11090.  14411.  14636.\n 8 Belgium      8314.  10454.  12980.  15024.  17451.  18109.  21246.  22356.\n 9 Benin        1140.   1188.   1170.   1048.   1069.   1252.   1069.   1139.\n10 Bolivia      2516.   2880.   2670.   3124.   3264.   2718.   2615.   2795.\n# ℹ 97 more rows\n# ℹ 4 more variables: africa &lt;dbl&gt;, asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;\n\nhead(data)\n\n# A tibble: 6 × 13\n  country gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95 africa\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Algeria   2848.   3536.   3670.   3917.   5094.   5876.   5307.   4935.      1\n2 Angola    2642.   3072.   3558.   2230.   2059.   1988.   2081.   1339.      1\n3 Argent…   7879.   8802.   9903.  10609.  11359.   9246.   7716.  10973.      0\n4 Austra…  11436.  13192.  15842.  16716.  18300.  19669.  21446.  23827.      0\n5 Austria   7842.   9387.  11946.  14198.  16869.  17919.  21178.  22474.      0\n6 Bangla…   1130.   1164.   1181.   1030.   1040.   1245.   1366.   1568.      0\n# ℹ 3 more variables: asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;\n\ntail(data)\n\n# A tibble: 6 × 13\n  country gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95 africa\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 United…  10341.  11633.  12917.  14072.  15302.  16878.  19585.  20963.      0\n2 United…  13118.  15697.  17478.  19284.  22806.  25251.  28281.  30366.      0\n3 Uruguay   6279.   5936.   6553.   6949.   8580.   6625.   7763.   9399.      0\n4 Venezu…   8381.  10618.  11253.   8815.   8516.   7274.   7431.   7582.      0\n5 Zambia    1290.   1564.   1427.   1446.   1324.   1167.   1091.    870.      1\n6 Zimbab…   1317.   1539.   2303.   2694.   2816.   2923.   3115.   2832.      1\n# ℹ 3 more variables: asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;\n\nsummary(data)\n\n   country             gdppc60           gdppc65           gdppc70       \n Length:107         Min.   :  407.8   Min.   :  513.6   Min.   :  354.5  \n Class :character   1st Qu.: 1153.2   1st Qu.: 1364.5   1st Qu.: 1488.0  \n Mode  :character   Median : 2484.7   Median : 2884.4   Median : 3072.2  \n                    Mean   : 3634.3   Mean   : 4367.5   Mean   : 5128.4  \n                    3rd Qu.: 4354.0   3rd Qu.: 5873.3   3rd Qu.: 6994.6  \n                    Max.   :16010.3   Max.   :18928.9   Max.   :22030.9  \n    gdppc75           gdppc80           gdppc85           gdppc90       \n Min.   :  617.9   Min.   :  473.6   Min.   :  542.3   Min.   :  527.7  \n 1st Qu.: 1480.7   1st Qu.: 1708.6   1st Qu.: 1598.8   1st Qu.: 1829.0  \n Median : 3741.7   Median : 4306.2   Median : 4200.7   Median : 4034.0  \n Mean   : 5759.1   Mean   : 6553.6   Mean   : 6900.3   Mean   : 7775.1  \n 3rd Qu.: 8355.8   3rd Qu.: 9968.6   3rd Qu.:10037.2   3rd Qu.:11716.2  \n Max.   :21808.9   Max.   :23860.1   Max.   :25251.4   Max.   :28744.1  \n    gdppc95            africa            asia           weurope      \n Min.   :  499.3   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.: 1673.7   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median : 4467.9   Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   : 8468.2   Mean   :0.3738   Mean   :0.1308   Mean   :0.1402  \n 3rd Qu.:13627.8   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000  \n Max.   :36741.1   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n     growth       \n Min.   :-0.6888  \n 1st Qu.: 0.2458  \n Median : 0.6587  \n Mean   : 0.6345  \n 3rd Qu.: 1.0505  \n Max.   : 2.3493  \n\nview(data)\n\n# library(vtable)\n# vtable(data, missing=TRUE)\n\n# library(pastecs)\nstat.desc(data)\n\n         country      gdppc60      gdppc65      gdppc70      gdppc75\nnbr.val       NA 1.070000e+02 1.070000e+02 1.070000e+02 1.070000e+02\nnbr.null      NA 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\nnbr.na        NA 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\nmin           NA 4.078180e+02 5.135667e+02 3.545075e+02 6.178639e+02\nmax           NA 1.601025e+04 1.892888e+04 2.203095e+04 2.180892e+04\nrange         NA 1.560243e+04 1.841531e+04 2.167644e+04 2.119105e+04\nsum           NA 3.888715e+05 4.673224e+05 5.487424e+05 6.162241e+05\nmedian        NA 2.484720e+03 2.884388e+03 3.072176e+03 3.741725e+03\nmean          NA 3.634313e+03 4.367500e+03 5.128433e+03 5.759103e+03\nSE.mean       NA 3.314566e+02 4.021934e+02 4.736475e+02 5.272377e+02\nCI.mean       NA 6.571449e+02 7.973875e+02 9.390523e+02 1.045300e+03\nvar           NA 1.175539e+07 1.730827e+07 2.400459e+07 2.974381e+07\nstd.dev       NA 3.428613e+03 4.160321e+03 4.899448e+03 5.453789e+03\ncoef.var      NA 9.434006e-01 9.525635e-01 9.553499e-01 9.469857e-01\n              gdppc80      gdppc85      gdppc90      gdppc95       africa\nnbr.val  1.070000e+02 1.070000e+02 1.070000e+02 1.070000e+02 107.00000000\nnbr.null 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00  67.00000000\nnbr.na   0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00   0.00000000\nmin      4.735793e+02 5.422725e+02 5.277151e+02 4.993415e+02   0.00000000\nmax      2.386009e+04 2.525136e+04 2.874414e+04 3.674105e+04   1.00000000\nrange    2.338651e+04 2.470909e+04 2.821642e+04 3.624171e+04   1.00000000\nsum      7.012400e+05 7.383373e+05 8.319308e+05 9.061030e+05  40.00000000\nmedian   4.306217e+03 4.200733e+03 4.034010e+03 4.467940e+03   0.00000000\nmean     6.553645e+03 6.900349e+03 7.775054e+03 8.468253e+03   0.37383178\nSE.mean  6.018749e+02 6.552251e+02 7.711596e+02 8.456513e+02   0.04699273\nCI.mean  1.193276e+03 1.299048e+03 1.528899e+03 1.676586e+03   0.09316766\nvar      3.876112e+07 4.593724e+07 6.363152e+07 7.651850e+07   0.23628990\nstd.dev  6.225843e+03 6.777701e+03 7.976937e+03 8.747486e+03   0.48609659\ncoef.var 9.499817e-01 9.822259e-01 1.025965e+00 1.032974e+00   1.30030838\n                 asia      weurope      growth\nnbr.val  107.00000000 107.00000000 107.0000000\nnbr.null  93.00000000  92.00000000   0.0000000\nnbr.na     0.00000000   0.00000000   0.0000000\nmin        0.00000000   0.00000000  -0.6887722\nmax        1.00000000   1.00000000   2.3493433\nrange      1.00000000   1.00000000   3.0381155\nsum       14.00000000  15.00000000  67.8899760\nmedian     0.00000000   0.00000000   0.6586871\nmean       0.13084112   0.14018692   0.6344858\nSE.mean    0.03275433   0.03372119   0.0601857\nCI.mean    0.06493865   0.06685553   0.1193240\nvar        0.11479457   0.12167166   0.3875881\nstd.dev    0.33881347   0.34881465   0.6225657\ncoef.var   2.58950297   2.48821120   0.9812131\n\n# library(Hmisc)\ndescribe(data)\n\n         vars   n    mean      sd  median trimmed     mad    min      max\ncountry*    1 107   54.00   31.03   54.00   54.00   40.03   1.00   107.00\ngdppc60     2 107 3634.31 3428.61 2484.72 3032.19 2027.76 407.82 16010.25\ngdppc65     3 107 4367.50 4160.32 2884.39 3673.42 2579.50 513.57 18928.88\ngdppc70     4 107 5128.43 4899.45 3072.18 4370.29 2854.11 354.51 22030.95\ngdppc75     5 107 5759.10 5453.79 3741.72 4977.54 3708.25 617.86 21808.92\ngdppc80     6 107 6553.64 6225.84 4306.22 5707.40 4476.29 473.58 23860.09\ngdppc85     7 107 6900.35 6777.70 4200.73 5929.46 4382.44 542.27 25251.36\ngdppc90     8 107 7775.05 7976.94 4034.01 6660.00 4258.37 527.72 28744.14\ngdppc95     9 107 8468.25 8747.49 4467.94 7235.12 4935.09 499.34 36741.05\nafrica     10 107    0.37    0.49    0.00    0.34    0.00   0.00     1.00\nasia       11 107    0.13    0.34    0.00    0.05    0.00   0.00     1.00\nweurope    12 107    0.14    0.35    0.00    0.06    0.00   0.00     1.00\ngrowth     13 107    0.63    0.62    0.66    0.63    0.59  -0.69     2.35\n            range skew kurtosis     se\ncountry*   106.00 0.00    -1.23   3.00\ngdppc60  15602.43 1.53     1.55 331.46\ngdppc65  18415.31 1.41     1.16 402.19\ngdppc70  21676.44 1.29     0.74 473.65\ngdppc75  21191.05 1.15     0.09 527.24\ngdppc80  23386.51 1.07    -0.11 601.87\ngdppc85  24709.09 1.14     0.01 655.23\ngdppc90  28216.42 1.13    -0.10 771.16\ngdppc95  36241.71 1.14     0.12 845.65\nafrica       1.00 0.51    -1.75   0.05\nasia         1.00 2.16     2.69   0.03\nweurope      1.00 2.04     2.20   0.03\ngrowth       3.04 0.15     0.07   0.06\n\n# library(gtsummary)\ntbl_summary(data)\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1071\n\n\n\n\ncountry\n\n\n\n\n    Algeria\n1 (0.9%)\n\n\n    Angola\n1 (0.9%)\n\n\n    Argentina\n1 (0.9%)\n\n\n    Australia\n1 (0.9%)\n\n\n    Austria\n1 (0.9%)\n\n\n    Bangladesh\n1 (0.9%)\n\n\n    Barbados\n1 (0.9%)\n\n\n    Belgium\n1 (0.9%)\n\n\n    Benin\n1 (0.9%)\n\n\n    Bolivia\n1 (0.9%)\n\n\n    Botswana\n1 (0.9%)\n\n\n    Brazil\n1 (0.9%)\n\n\n    Burkina Faso\n1 (0.9%)\n\n\n    Burundi\n1 (0.9%)\n\n\n    Cameroon\n1 (0.9%)\n\n\n    Canada\n1 (0.9%)\n\n\n    Cape Verde\n1 (0.9%)\n\n\n    Central African Republic\n1 (0.9%)\n\n\n    Chad\n1 (0.9%)\n\n\n    Chile\n1 (0.9%)\n\n\n    China\n1 (0.9%)\n\n\n    Colombia\n1 (0.9%)\n\n\n    Comoros\n1 (0.9%)\n\n\n    Congo, Republic of\n1 (0.9%)\n\n\n    Costa Rica\n1 (0.9%)\n\n\n    Cote d'lvoire\n1 (0.9%)\n\n\n    Cyprus\n1 (0.9%)\n\n\n    Denmark\n1 (0.9%)\n\n\n    Dominican Republic\n1 (0.9%)\n\n\n    Ecuador\n1 (0.9%)\n\n\n    Egypt\n1 (0.9%)\n\n\n    El Salvador\n1 (0.9%)\n\n\n    Ethiopia\n1 (0.9%)\n\n\n    Fiji\n1 (0.9%)\n\n\n    Finland\n1 (0.9%)\n\n\n    France\n1 (0.9%)\n\n\n    Gabon\n1 (0.9%)\n\n\n    Gambia, The\n1 (0.9%)\n\n\n    Ghana\n1 (0.9%)\n\n\n    Greece\n1 (0.9%)\n\n\n    Guatemala\n1 (0.9%)\n\n\n    Guinea\n1 (0.9%)\n\n\n    Guinea-Bissau\n1 (0.9%)\n\n\n    Guyana\n1 (0.9%)\n\n\n    Honduras\n1 (0.9%)\n\n\n    Hong Kong\n1 (0.9%)\n\n\n    Iceland\n1 (0.9%)\n\n\n    India\n1 (0.9%)\n\n\n    Indonesia\n1 (0.9%)\n\n\n    Iran\n1 (0.9%)\n\n\n    Ireland\n1 (0.9%)\n\n\n    Israel\n1 (0.9%)\n\n\n    Italy\n1 (0.9%)\n\n\n    Jamaica\n1 (0.9%)\n\n\n    Japan\n1 (0.9%)\n\n\n    Jordan\n1 (0.9%)\n\n\n    Kenya\n1 (0.9%)\n\n\n    Lesotho\n1 (0.9%)\n\n\n    Luxembourg\n1 (0.9%)\n\n\n    Madagascar\n1 (0.9%)\n\n\n    Malawi\n1 (0.9%)\n\n\n    Malaysia\n1 (0.9%)\n\n\n    Mali\n1 (0.9%)\n\n\n    Mauritania\n1 (0.9%)\n\n\n    Mauritius\n1 (0.9%)\n\n\n    Mexico\n1 (0.9%)\n\n\n    Morocco\n1 (0.9%)\n\n\n    Mozambique\n1 (0.9%)\n\n\n    Namibia\n1 (0.9%)\n\n\n    Nepal\n1 (0.9%)\n\n\n    Netherlands\n1 (0.9%)\n\n\n    New Zealand\n1 (0.9%)\n\n\n    Nicaragua\n1 (0.9%)\n\n\n    Niger\n1 (0.9%)\n\n\n    Nigeria\n1 (0.9%)\n\n\n    Norway\n1 (0.9%)\n\n\n    Pakistan\n1 (0.9%)\n\n\n    Panama\n1 (0.9%)\n\n\n    Papua New Guinea\n1 (0.9%)\n\n\n    Paraguay\n1 (0.9%)\n\n\n    Peru\n1 (0.9%)\n\n\n    Philippines\n1 (0.9%)\n\n\n    Portugal\n1 (0.9%)\n\n\n    Romania\n1 (0.9%)\n\n\n    Rwanda\n1 (0.9%)\n\n\n    Senegal\n1 (0.9%)\n\n\n    Seychelles\n1 (0.9%)\n\n\n    Singapore\n1 (0.9%)\n\n\n    South Africa\n1 (0.9%)\n\n\n    South Korea\n1 (0.9%)\n\n\n    Spain\n1 (0.9%)\n\n\n    Sri Lanka\n1 (0.9%)\n\n\n    Sweden\n1 (0.9%)\n\n\n    Switzerland\n1 (0.9%)\n\n\n    Syria\n1 (0.9%)\n\n\n    Tanzania\n1 (0.9%)\n\n\n    Thailand\n1 (0.9%)\n\n\n    Togo\n1 (0.9%)\n\n\n    Trinidad & Tobago\n1 (0.9%)\n\n\n    Turkey\n1 (0.9%)\n\n\n    Uganda\n1 (0.9%)\n\n\n    United Kingdom\n1 (0.9%)\n\n\n    United States of America\n1 (0.9%)\n\n\n    Uruguay\n1 (0.9%)\n\n\n    Venezuela\n1 (0.9%)\n\n\n    Zambia\n1 (0.9%)\n\n\n    Zimbabwe\n1 (0.9%)\n\n\nreal gdp per capita 1960\n2,485 (1,153, 4,354)\n\n\nreal gdp per capita 1965\n2,884 (1,365, 5,873)\n\n\nreal gdp per capita 1970\n3,072 (1,488, 6,995)\n\n\nreal gdp per capita 1975\n3,742 (1,481, 8,356)\n\n\nreal gdp per capita 1980\n4,306 (1,709, 9,969)\n\n\nreal gdp per capita 1985\n4,201 (1,599, 10,037)\n\n\nreal gdp per capita 1990\n4,034 (1,829, 11,716)\n\n\nreal gdp per capita 1995\n4,468 (1,674, 13,628)\n\n\n=1 if in Africa\n40 (37%)\n\n\n=1 if in Asia\n14 (13%)\n\n\n=1 if in Western Europe\n15 (14%)\n\n\ngrowth\n0.66 (0.25, 1.05)\n\n\n\n1 n (%); Median (IQR)\n\n\n\n\n\n\n\n\n# check the assignments of countries to continents\ndata |&gt;\n  select(country, africa, asia, weurope) |&gt;\n  view()\n\ndata &lt;- mutate(data, x_1 = africa + asia + weurope)\n\ndata |&gt;\n  filter(x_1 == 0) |&gt;\n  select(africa, asia, weurope, country) |&gt;\n  view()\n\n# correct the assignment manually\ndata$weurope[data$country == \"Austria\"] &lt;- 1\ndata$weurope[data$country == \"Greece\"] &lt;- 1\ndata$weurope[data$country == \"Cyprus\"] &lt;- 1\n\nfilter(data, data$weurope == 1) # check changes\n\n# A tibble: 18 × 14\n   country       gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Austria         7842.   9387.  11946.  14198.  16869.  17919.  21178.  22474.\n 2 Belgium         8314.  10454.  12980.  15024.  17451.  18109.  21246.  22356.\n 3 Cyprus          3178.   4261.   5638.   4827.   8302.  10228.  13798.  17169.\n 4 Denmark        11745.  14749.  17143.  17750.  19558.  21596.  23308.  25293.\n 5 Finland         8007.   9851.  12198.  14884.  16621.  18585.  21667.  20084.\n 6 France          8364.  10497.  13186.  14951.  17335.  18429.  21403.  21502.\n 7 Greece          4454.   6549.   9022.  11121.  12672.  12287.  12794.  13332.\n 8 Iceland         8786.  11403.  11678.  15235.  19440.  20414.  22502.  21901.\n 9 Ireland         5490.   6413.   7760.   9064.  10649.  11641.  15133.  18456.\n10 Italy           7364.   9097.  12072.  13386.  16286.  17518.  20638.  21691.\n11 Luxembourg     12510.  14019.  16163.  17384.  19089.  21414.  28744.  36741.\n12 Netherlands     9883.  11702.  14237.  15803.  17339.  17974.  20823.  22320.\n13 Norway          8808.  10478.  11959.  14873.  17977.  20630.  21855.  25538.\n14 Portugal        3665.   4866.   6730.   7951.   9667.   9847.  13155.  13924.\n15 Spain           4956.   7459.   9701.  11970.  12294.  12583.  15475.  17434.\n16 Sweden         10870.  13552.  15850.  17588.  18348.  20001.  22219.  22122.\n17 Switzerland    16010.  18929.  22031.  21809.  23860.  24844.  27931.  26227.\n18 United Kingd…  10341.  11633.  12917.  14072.  15302.  16878.  19585.  20963.\n# ℹ 5 more variables: africa &lt;dbl&gt;, asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;,\n#   x_1 &lt;dbl&gt;\n\n# In the following, I do the same with a loop\n# c_europe &lt;- c(\"Austria\",\"Greece\",\"Cyprus\")\n# sum(data$weurope)                       # check changes\n# for (i in c_europe){\n#   print(i)\n#   data$weurope[data$country == i] &lt;- 1\n#   }\n# sum(data$weurope)                       # check changes\n# data$weurope[data$country == \"Austria\"] # check changes\n\n# create a category for the remaining countries\n# use ifelse -- ifelse(condition, result if TRUE, result if FALSE)\ndata$rest &lt;- ifelse(data$africa == 0 & data$asia == 0 & data$weurope == 0, 1, 0)\ndata$rest &lt;- set_label(data$rest, label = \"=1 if not in Africa, W.Europe, or Asia\")\n\n# create table with means across country groups\ntable_gdp &lt;- data |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  summarise_at(vars(gdppc60:gdppc95), list(name = mean))\n\ndata |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  select(gdppc60:gdppc95) |&gt;\n  summarise_all(mean)\n\nAdding missing grouping variables: `africa`, `asia`, `weurope`\n\n\n# A tibble: 4 × 11\n# Groups:   africa, asia [3]\n  africa  asia weurope gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1      0     0       0   4288.   5034.   5727.   6411.   7042.   7185.   7457.\n2      0     0       1   8366.  10294.  12401.  13994.  16059.  17272.  20192.\n3      0     1       0   1739.   2247.   3090.   3760.   4905.   5761.   7501.\n4      1     0       0   1596.   1860.   2046.   2182.   2426.   2382.   2562.\n# ℹ 1 more variable: gdppc95 &lt;dbl&gt;\n\n# create growth rate\ndata$gr1 &lt;- (data$gdppc95 - data$gdppc60) / data$gdppc60\ndata$gr2 &lt;- log(data$gdppc95) - log(data$gdppc60)\ncor(data$gr1, data$gr2)\n\n[1] 0.9008887\n\nggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0)\n\n\n\n\n\n\n\np1 &lt;- ggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"World\")\n\np2 &lt;- data |&gt;\n  filter(weurope == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Western Europe\")\n\np3 &lt;- data |&gt;\n  filter(asia == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Asia\")\n\np4 &lt;- data |&gt;\n  filter(africa == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  #  geom_text( hjust=0, vjust=0) +\n  ggtitle(\"Africa\")\n\nggarrange(p1, p2, p3, p4,\n  labels = c(\"A\", \"B\", \"C\", \"D\"),\n  ncol = 2, nrow = 2\n)\n\nWarning: The following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n# Regression analysis\nm1 &lt;- lm(growth ~ gdppc60, data = data)\nm2 &lt;- lm(growth ~ gdppc60, data = subset(data, weurope == 1))\nm3 &lt;- lm(growth ~ gdppc60, data = subset(data, asia == 1))\nm4 &lt;- lm(growth ~ gdppc60, data = subset(data, africa == 1))\n\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE,\n  show.aic = TRUE,\n  dv.labels = c(\"World\", \"W.Europe\", \"Asia\", \"Africa\")\n)\n\n\n\n\n\n \nWorld\nW.Europe\nAsia\nAfrica\n\n\nPredictors\nEstimates\nEstimates\nEstimates\nEstimates\n\n\n(Intercept)\n0.54 ***\n1.59 ***\n0.91 ***\n0.20 \n\n\nreal gdp per capita 1960\n0.00 *\n-0.00 ***\n0.00 *\n0.00 \n\n\nObservations\n107\n18\n14\n40\n\n\nR2 / R2 adjusted\n0.021 / 0.012\n0.727 / 0.710\n0.158 / 0.088\n0.002 / -0.024\n\n\nAIC\n204.917\n-14.237\n31.220\n76.318\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n# reshape data (see: https://stackoverflow.com/questions/2185252/reshaping-data-frame-from-wide-to-long-format)\ndata_long &lt;- gather(data, condition, measurement, gdppc60:gdppc95, factor_key = TRUE)\n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\ndata_long$year &lt;- as.numeric(substr(data_long$condition, 6, 7))\n\ndata_long$gr_long &lt;- data_long |&gt;\n  select(country, measurement) |&gt;\n  group_by(country) |&gt;\n  mutate(gr = c(NA, diff(measurement)) / lag(measurement, 1))\n\n# erase all helping variables\ndata &lt;- select(data, -starts_with(\"h_\"))\n\n# generate and remove variables in a dataframe\ndata &lt;- mutate(data, Land = country)\ndata &lt;- select(data, -country)\n\ndata |&gt;\n  summarise(\n    y65 = mean(gdppc65, na.rm = TRUE),\n    y70 = mean(gdppc70, na.rm = TRUE),\n    y75 = mean(gdppc75, na.rm = TRUE),\n    y80 = mean(gdppc80, na.rm = TRUE),\n    y85 = mean(gdppc85, na.rm = TRUE),\n    y90 = mean(gdppc90, na.rm = TRUE),\n    y95 = mean(gdppc95, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 7\n    y65   y70   y75   y80   y85   y90   y95\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 4367. 5128. 5759. 6554. 6900. 7775. 8468.\n\nsuppressMessages(pacman::p_unload(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot\n))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#unemployment-and-gdp-in-germany-and-france",
    "href": "80_exercises.html#unemployment-and-gdp-in-germany-and-france",
    "title": "9  Collection of exercises",
    "section": "9.11 Unemployment and GDP in Germany and France",
    "text": "9.11 Unemployment and GDP in Germany and France\nThe following exercise was a former exam.\nPlease answer all (!) questions in an R script. Normal text should be written as comments, using the ‘#’ to comment out text. Make sure the script runs without errors before submitting it. Each task (starting with 1) is worth five points. You have a total of 120 minutes of editing time. Please do not forget to number your answers.\nWhen you are done with your work, save the R script, export the script to pdf format and upload the pdf file.\nSuppose you aim to empirically examine unemployment and GDP for Germany and France. The data set that we use in the following is ‘forest.Rdata’.\n\nWrite down your name, matriculation number, and date.\nSet your working directory.\n\n\nClear your global environment.\n\n\nInstall and load the following packages: ‘tidyverse’, ‘sjPlot’, and ‘ggpubr’\n\n\nDownload and load the data, respectively, with the following code:\n\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nIf that is not working, you can also download the data from ILIAS, save it in your working directory and load it from there with:\n\n# load(\"forest.Rdata\")\n\n\nShow the first eight observations of the dataset df.\nShow the last observation of the dataset df.\nWhich type of data do we have here (Panel, cross-section,time series, …)? Name the variable(s) that are necessary to identify the observations in the dataset.\nExplain what the assignment operator in R is and what it is good for.\nWrite down the R code to store the number of observations and the number of variables that are in the dataset df. Name the object in which you store these numbers ‘observations_df’.\nIn the dataset df, rename the variable ‘country.x’ to ‘nation’ and the variable ‘date’ to ‘year’.\nExplain what the pipe operator in R is and what it is good for.\nFor the upcoming analysis you are only interested the following variables that are part of the dataframe df: nation, year, gdp, pop, gdppc, and unemployment. Drop all other variables from the dataframe df.\nCreate a variable that indicates the GDP per capita (‘gdp’ divided by ‘pop’). Name the variable ‘gdp_pc’. (Hint: If you fail here, use the variable ‘gdppc’ which is already in the dataset as a replacement for ‘gdp_pc’ in the following tasks.)\nFor the upcoming analysis you are only interested the following countries that are part of the dataframe df: Germany and France. Drop all other countries from the dataframe df.\nCreate a table showing the average unemployment rate and GDP per capita for Germany and France in the given years. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\n\n\nCreate a table showing the unemployment rate and GDP per capita for Germany and France in the year 2020. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\n\n\nCreate a table showing the highest unemployment rate and the highest GDP per capita for Germany and France during the given period. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\n\n\nCalculate the standard deviation of the unemployment rate and GDP per capita for Germany and France in the given years. (Hint: See below for how your result should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\n\n\nIn statistics, the coefficient of variation (COV) is a standardized measure of dispersion. It is defined as the ratio of the standard deviation (\\(\\sigma\\)) to the mean (\\(\\mu\\)): \\(COV={\\frac {\\sigma }{\\mu }}\\). Write down the R code to calculate the coefficient of variation (COV) for the unemployment rate in Germany and France. (Hint: See below for what your result should should look like.)\n\n\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\n\n\nWrite down the R code to calculate the coefficient of variation (COV) for the GDP per capita in Germany and France. (Hint: See below for what your result should look like.)\n\n\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\n\n\nCreate a chart (bar chart, line chart, or scatter plot) that shows the unemployment rate of Germany over the available years. Label the chart ‘Germany’ with ‘ggtitle(“Germany”)’. Please note that you may choose any type of graphical representation. (Hint: Below you can see one of many |&gt; of what your result may look like).\n\n\n\n\n\n\n\n\n\n\n\nand 23. (This task is worth 10 points) The following chart shows the simultaneous development of the unemployment rate and GDP per capita over time for France.\n\n\n\n\n\n\n\n\n\n\nSuppose you want to visualize the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany as well.\nSuppose further that you have found the following lines of code that create the kind of chart you are looking for.\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\n\nUse these lines of code and customize them to create the co-movement visualization for Germany using the available df data. The result should look something like this:\n\n\n\n\n\n\n\n\n\n\nInterpret the two graphs above, which show the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany and France. What are your expectations regarding the correlation between the unemployment rate and GDP per capita variables? Can you see this expectation in the figures? Discuss.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, dim, filter, geom_line, ggplot, ggtitle, group_by, head, load, max, mean, mutate, plot, rename, sd, select, summarise, tail, text, title, url.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\ntail(df, 1)\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\ndf |&gt;\n  filter(nation == \"Germany\") |&gt;\n  ggplot(aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\n# rmarkdown::render(\"22-11_dsda_exam.Rmd\", \"all\")\n\n# knitr::purl(input = \"22-11_dsda_exam.Rmd\", output = \"22-11_dsda_solution.R\",documentation = 0)\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\n# A tibble: 8 × 11\n# Groups:   country.x [1]\n  country.x     date     gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 United Arab…  1992 1.26e11     -2.48          1.84 Middl… High …   3.63 2.05e6\n2 United Arab…  1993 1.27e11     -4.34          1.85 Middl… High …   3.72 2.17e6\n3 United Arab…  1994 1.36e11      1.25          1.81 Middl… High …   3.81 2.29e6\n4 United Arab…  1995 1.45e11      1.35          1.80 Middl… High …   3.90 2.42e6\n5 United Arab…  1996 1.54e11      0.631         1.90 Middl… High …   3.99 2.54e6\n6 United Arab…  1997 1.66e11      2.83          1.98 Middl… High …   4.08 2.67e6\n7 United Arab…  1998 1.67e11     -4.77          2.14 Middl… High …   4.18 2.81e6\n8 United Arab…  1999 1.72e11     -2.40          2.22 Middl… High …   4.27 2.97e6\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\ntail(df, 1)\n\n# A tibble: 1 × 11\n# Groups:   country.x [1]\n  country.x  date        gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Zimbabwe   2020    1.94e10      -7.62         5.35 Sub-S… Lower…   45.1 1.49e7\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\ndf |&gt;\n  filter(nation == \"Germany\") |&gt;\n  ggplot(aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\n\n\n\n\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n\n\n\n\n\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\n\n\n\n\n\n\n# rmarkdown::render(\"22-11_dsda_exam.Rmd\", \"all\")\n\n# knitr::purl(input = \"22-11_dsda_exam.Rmd\", output = \"22-11_dsda_solution.R\",documentation = 0)\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#import-data-and-write-a-report",
    "href": "80_exercises.html#import-data-and-write-a-report",
    "title": "9  Collection of exercises",
    "section": "9.12 Import data and write a report",
    "text": "9.12 Import data and write a report\nReproduce Figure 3 of Hortaçsu & Syverson (2015, p. 99) using R. Write a clear report about your work, i.e., document everything with a R script or a R Markdown file.\nHere are the required steps:\n\nGo to https://www.aeaweb.org/articles?id=10.1257/jep.29.4.89 and download the replication package from the OPENICPSR page. Please note, that you can download the replication package after you have registered for the platform.\nUnzip the replication package.\nIn the file diffusion_curves_figure.xlsx you find the required data. Import them to R.\nReproduce the plot using ggplot().\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, download.file, geom_line, ggplot, pivot_longer, read_excel, unzip.\n\n\n\n\n\n\nR script\n\n\n\n\n\n\n# setwd(\"~/Dropbox/hsf/courses/Rlang/hortacsu\")\n\nrm(list = ls())\n\n\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, readxl)\n\n\n# Define the URL of the ZIP file\nzip_f &lt;- \"https://github.com/hubchev/courses/raw/main/dta/113962-V1.zip\"\n\n# Download the ZIP file\ndownload.file(zip_f, destfile = \"113962-V1.zip\")\n\n# Unzip the contents\nunzip(\"113962-V1.zip\")\n\ndf_curves &lt;- read_excel(\"Hortacsu_Syverson_JEP_Retail/diffusion_curves_figure.xlsx\",\n  sheet = \"Data and Predictions\", range = \"N3:Y60\"\n)\n\ndf &lt;- df_curves |&gt;\n  pivot_longer(\n    cols = \"Music and Video\":\"Food and Beverages\",\n    names_to = \"industry\",\n    values_to = \"value\"\n  )\n\n# Plot\ndf |&gt;\n  ggplot(aes(x = Year, y = value, group = industry, color = industry)) +\n  geom_line()\n\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, readxl))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"~/Dropbox/hsf/courses/Rlang/hortacsu\")\n\nrm(list = ls())\n\n\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, readxl)\n\n\n# Define the URL of the ZIP file\nzip_f &lt;- \"https://github.com/hubchev/courses/raw/main/dta/113962-V1.zip\"\n\n# Download the ZIP file\ndownload.file(zip_f, destfile = \"113962-V1.zip\")\n\n# Unzip the contents\nunzip(\"113962-V1.zip\")\n\ndf_curves &lt;- read_excel(\"Hortacsu_Syverson_JEP_Retail/diffusion_curves_figure.xlsx\",\n  sheet = \"Data and Predictions\", range = \"N3:Y60\"\n)\n\ndf &lt;- df_curves |&gt;\n  pivot_longer(\n    cols = \"Music and Video\":\"Food and Beverages\",\n    names_to = \"industry\",\n    values_to = \"value\"\n  )\n\n# Plot\ndf |&gt;\n  ggplot(aes(x = Year, y = value, group = industry, color = industry)) +\n  geom_line()\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, readxl))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#explain-the-weight-of-students",
    "href": "80_exercises.html#explain-the-weight-of-students",
    "title": "9  Collection of exercises",
    "section": "9.13 Explain the weight of students",
    "text": "9.13 Explain the weight of students\nIn the statistic course of WS 2020, I asked 23 students about their weight, height, sex, and number of siblings. I wonder how good the height can explain the weight of students. Examine with corelations and a regression analysis the association. Load the data as follows:\n\nlibrary(\"haven\")\n\n\nAttaching package: 'haven'\n\n\nThe following objects are masked from 'package:expss':\n\n    is.labelled, read_spss\n\nclassdata &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/classdata.csv\")\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, coef, fitted, geom_abline, geom_point, ggplot, head, library, lm, plot, read.csv, residuals, show, stat_smooth, subset, summary, tab_model.\n\n\n\n\n\n\nR script\n\n\n\n\n\n## ---- echo = TRUE--------------------------------------------------\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\nclassdata &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/classdata.csv\")\n\nhead(classdata)\n\n## ---- echo = TRUE--------------------------------------------------\n\nsummary(classdata)\n\n## ----pressure, echo=TRUE-------------------------------------------\nlibrary(\"ggplot2\")\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point()\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1)\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline regression  model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\nshow(model)\ninterm &lt;- model$coefficients[1]\nslope &lt;- model$coefficients[2]\ninterw &lt;- model$coefficients[1] + model$coefficients[3]\n\n## ---- echo=TRUE----------------------------------------------------\nsummary(model)\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point() +\n  geom_abline(slope = slope, intercept = interw, linetype = 2, size = 1.5) +\n  geom_abline(slope = slope, intercept = interm, linetype = 2, size = 1.5) +\n  geom_abline(slope = coef(model)[[2]], intercept = coef(model)[[1]])\n\n\n## ---- echo=TRUE----------------------------------------------------\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x, method = \"lm\",\n    se = FALSE, colour = \"red\", linetype = 1\n  )\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = siblings))\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x,\n    method = \"lm\",\n    se = T,\n    colour = \"red\",\n    linetype = 1\n  )\n\n## ---- echo=TRUE, results='hide'------------------------------------\n\nm1 &lt;- lm(weight ~ height, data = classdata)\nm2 &lt;- lm(weight ~ height + sex, data = classdata)\nm3 &lt;- lm(weight ~ height + sex + height * sex, data = classdata)\nm4 &lt;- lm(weight ~ height + sex + height * sex + siblings, data = classdata)\nm5 &lt;- lm(weight ~ height + sex + height * sex, data = subset(classdata, siblings &lt; 4))\n\nlibrary(sjPlot)\ntab_model(m1, m2, m3, m4, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m3, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n## ---- echo=T-------------------------------------------------------\nplot(residuals(m3), fitted(m3))\nplot(residuals(m3), classdata$siblings)\n\n## ----eval=FALSE----------------------------------------------------\n#  rmarkdown::render(\"regress_lecture.Rmd\", \"all\")\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n## ---- echo = TRUE--------------------------------------------------\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\nclassdata &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/classdata.csv\")\n\nhead(classdata)\n\n  id sex weight height siblings row\n1  1   w     53    156        1   g\n2  2   w     73    170        1   g\n3  3   m     68    169        1   g\n4  4   w     67    166        1   g\n5  5   w     65    175        1   g\n6  6   w     48    161        0   g\n\n## ---- echo = TRUE--------------------------------------------------\n\nsummary(classdata)\n\n       id           sex                weight          height     \n Min.   : 1.0   Length:23          Min.   :48.00   Min.   :156.0  \n 1st Qu.: 6.5   Class :character   1st Qu.:64.50   1st Qu.:168.0  \n Median :12.0   Mode  :character   Median :70.00   Median :175.0  \n Mean   :12.0                      Mean   :70.61   Mean   :173.7  \n 3rd Qu.:17.5                      3rd Qu.:81.00   3rd Qu.:180.0  \n Max.   :23.0                      Max.   :90.00   Max.   :194.0  \n    siblings         row           \n Min.   :0.000   Length:23         \n 1st Qu.:1.000   Class :character  \n Median :1.000   Mode  :character  \n Mean   :1.391                     \n 3rd Qu.:2.000                     \n Max.   :4.000                     \n\n## ----pressure, echo=TRUE-------------------------------------------\nlibrary(\"ggplot2\")\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point()\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1)\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline regression  model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\nshow(model)\n\n\nCall:\nlm(formula = weight ~ height + sex, data = classdata)\n\nCoefficients:\n(Intercept)       height         sexw  \n   -29.5297       0.5923      -5.7894  \n\ninterm &lt;- model$coefficients[1]\nslope &lt;- model$coefficients[2]\ninterw &lt;- model$coefficients[1] + model$coefficients[3]\n\n## ---- echo=TRUE----------------------------------------------------\nsummary(model)\n\n\nCall:\nlm(formula = weight ~ height + sex, data = classdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.086  -3.730   2.850   7.245  12.914 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -29.5297    47.6606  -0.620   0.5425  \nheight        0.5923     0.2671   2.217   0.0383 *\nsexw         -5.7894     4.4773  -1.293   0.2107  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.942 on 20 degrees of freedom\nMultiple R-squared:  0.4124,    Adjusted R-squared:  0.3537 \nF-statistic: 7.019 on 2 and 20 DF,  p-value: 0.004904\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point() +\n  geom_abline(slope = slope, intercept = interw, linetype = 2, size = 1.5) +\n  geom_abline(slope = slope, intercept = interm, linetype = 2, size = 1.5) +\n  geom_abline(slope = coef(model)[[2]], intercept = coef(model)[[1]])\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x, method = \"lm\",\n    se = FALSE, colour = \"red\", linetype = 1\n  )\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = siblings))\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x,\n    method = \"lm\",\n    se = T,\n    colour = \"red\",\n    linetype = 1\n  )\n\n\n\n\n\n\n\n## ---- echo=TRUE, results='hide'------------------------------------\n\nm1 &lt;- lm(weight ~ height, data = classdata)\nm2 &lt;- lm(weight ~ height + sex, data = classdata)\nm3 &lt;- lm(weight ~ height + sex + height * sex, data = classdata)\nm4 &lt;- lm(weight ~ height + sex + height * sex + siblings, data = classdata)\nm5 &lt;- lm(weight ~ height + sex + height * sex, data = subset(classdata, siblings &lt; 4))\n\nlibrary(sjPlot)\n\nLearn more about sjPlot with 'browseVignettes(\"sjPlot\")'.\n\ntab_model(m1, m2, m3, m4, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n\n\n\n\n \nweight\nweight\nweight\nweight\nweight\n\n\nPredictors\nEstimates\nEstimates\nEstimates\nEstimates\nEstimates\n\n\n(Intercept)\n-65.44 *\n-29.53 \n47.14 \n50.27 \n27.69 \n\n\nheight\n0.78 ***\n0.59 ***\n0.16 \n0.16 \n0.28 \n\n\nsex [w]\n\n-5.79 \n-153.96 **\n-161.92 **\n-134.51 *\n\n\nheight × sex [w]\n\n\n0.85 *\n0.89 *\n0.74 *\n\n\nsiblings\n\n\n\n-1.16 \n\n\n\nObservations\n23\n23\n23\n23\n21\n\n\nR2 / R2 adjusted\n0.363 / 0.333\n0.412 / 0.354\n0.487 / 0.407\n0.496 / 0.385\n0.572 / 0.497\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n\n\n\n\n \nweight\nweight\nweight\nweight\n\n\nPredictors\nEstimates\nEstimates\nEstimates\nEstimates\n\n\n(Intercept)\n-65.44 *\n-29.53 \n47.14 \n50.27 \n\n\nheight\n0.78 ***\n0.59 ***\n0.16 \n0.16 \n\n\nsex [w]\n\n-5.79 \n-153.96 **\n-161.92 **\n\n\nheight × sex [w]\n\n\n0.85 *\n0.89 *\n\n\nsiblings\n\n\n\n-1.16 \n\n\nObservations\n23\n23\n23\n23\n\n\nR2 / R2 adjusted\n0.363 / 0.333\n0.412 / 0.354\n0.487 / 0.407\n0.496 / 0.385\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m3, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n\n\n\n\n \nweight\nweight\n\n\nPredictors\nEstimates\nEstimates\n\n\n(Intercept)\n47.14 \n27.69 \n\n\nheight\n0.16 \n0.28 \n\n\nsex [w]\n-153.96 **\n-134.51 *\n\n\nheight × sex [w]\n0.85 *\n0.74 *\n\n\nObservations\n23\n21\n\n\nR2 / R2 adjusted\n0.487 / 0.407\n0.572 / 0.497\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n## ---- echo=T-------------------------------------------------------\nplot(residuals(m3), fitted(m3))\n\n\n\n\n\n\n\nplot(residuals(m3), classdata$siblings)\n\n\n\n\n\n\n\n## ----eval=FALSE----------------------------------------------------\n#  rmarkdown::render(\"regress_lecture.Rmd\", \"all\")\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#calories-and-weight",
    "href": "80_exercises.html#calories-and-weight",
    "title": "9  Collection of exercises",
    "section": "9.14 Calories and weight",
    "text": "9.14 Calories and weight\n\nWrite down your name, your matriculation number, and the date.\nSet your working directory.\nClear your global environment.\nLoad the following package: tidyverse\n\nThe following table stems from a survey carried out at the Campus of the German Sport University of Cologne at Opening Day (first day of the new semester) between 8:00am and 8:20am. The survey consists of 6 individuals with the following information:\n\n\n\nid\nsex\nage\nweight\ncalories\nsport\n\n\n\n\n1\nf\n21\n48\n1700\n60\n\n\n2\nf\n19\n55\n1800\n120\n\n\n3\nf\n23\n50\n2300\n180\n\n\n4\nm\n18\n71\n2000\n60\n\n\n5\nm\n20\n77\n2800\n240\n\n\n6\nm\n61\n85\n2500\n30\n\n\n\nData Description:\n\nid: Variable with an anonymized identifier for each participant.\nsex: Gender, i.e., the participants replied to be either male (m) or female (f).\nage: The age in years of the participants at the time of the survey.\nweight: Number of kg the participants pretended to weight.\ncalories: Estimate of the participants on their average daily consumption of calories.\nsport: Estimate of the participants on their average daily time that they spend on doing sports (measured in minutes).\n\n\nWhich type of data do we have here? (Panel data, repeated cross-sectional data, cross-sectional data, time Series data)\nStore each of the five variables in a vector and put all five variables into a dataframe with the title df. If you fail here, read in the data using this line of code:\n\n\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/df-calories.csv\")\n\nRows: 6 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (4): age, weight, calories, sport\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nShow for all numerical variables the summary statistics including the mean, median, minimum, and the maximum.\nShow for all numerical variables the summary statistics including the mean and the standard deviation, separated by male and female. Use therefore the pipe operator.\nSuppose you want to analyze the general impact of average calories consumption per day on the weight. Discuss if the sample design is appropriate to draw conclusions on the population. What may cause some bias in the data? Discuss possibilities to improve the sampling and the survey, respectively.\nThe following plot visualizes the two variables weight and calories. Discuss what can be improved in the graphical visualization.\n\n\n\nWeight vs. Calories\n\n\n\n\nMake a scatterplot matrix containing all numerical variables.\nCalculate the Pearson Correlation Coefficient of the two variables\n\ncalories and sport\nweight and calories\n\nMake a scatterplot with weight in the y-axis and calories on the x-axis. Additionally, the plot should contain a linear fit and the points should be labeled with the sex just like in the figure shown above.\nEstimate the following regression specification using the OLS method: [weight_i=_0+_1 calories_i+ _i]\n\nShow a summary of the estimates that look like the following:\n\n\n\nCall:\nlm(formula = weight ~ calories, data = df)\n\nResiduals:\n     1      2      3      4      5      6 \n-5.490 -1.182 -6.640  9.435 -6.099  9.976 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  7.730275  20.197867   0.383   0.7214  \ncalories     0.026917   0.009107   2.956   0.0417 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.68 on 4 degrees of freedom\nMultiple R-squared:  0.6859,    Adjusted R-squared:  0.6074 \nF-statistic: 8.735 on 1 and 4 DF,  p-value: 0.04174\n\n\n\nInterpret the results. In particular, interpret how many kg the estimated weight increases—on average and ceteris paribus—if calories increase by 100 calories. Additionally, discuss the statistical properties of the estimated coefficient \\(\\hat{\\beta_1}\\) and the meaning of the Adjusted R-squared.\nOLS estimates can suffer from omitted variable bias. State the two conditions that need to be fulfilled for omitted bias to occur.\nDiscuss potential confounding variables that may cause omitted variable bias. Given the dataset above how can some of the confounding variables be controlled for?\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, cor, data.frame, geom_point, geom_text, ggplot, group_by, lm, mean, plot, read_csv, sd, stat_smooth, summarise, summary.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# 1\n# Stephan Huber, 000, 2020-May-30\n\n# 2\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsb_bac/work/\")\n\n# 3\nrm(list = ls())\n\n# 4\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\n# 5\n# cross-section\n\n# 6\nsex &lt;- c(\"f\", \"f\", \"f\", \"m\", \"m\", \"m\")\nage &lt;- c(21, 19, 23, 18, 20, 61)\nweight &lt;- c(48, 55, 63, 71, 77, 85)\ncalories &lt;- c(1700, 1800, 2300, 2000, 2800, 2500)\nsport &lt;- c(60, 120, 180, 60, 240, 30)\ndf &lt;- data.frame(sex, age, weight, calories, sport)\n\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/exams/21-04/stuff/df.csv\")\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/github/courses/dta/df-calories.csv\")\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/df-calories.csv\")\n\n# 7\nsummary(df)\n\n# 8\ndf |&gt;\n  group_by(sex) |&gt;\n  summarise(\n    mcal = mean(calories),\n    sdcal = sd(calories),\n    mweight = mean(weight),\n    sdweight = sd(weight)\n  )\n\n# 9\n# discussed in class\n\n# 10\n# Many things can be mentioned here such as the use of colors\n# (red/blue is not a good choice for color blind people),\n# the legend makes no sense as red and green both refer to \\textit{sport},\n# the label of `f' and `m' is not explained in the legend,\n# rotating the labels of the y-axis would increase readability, and\n# both axes do not start at zero which is hard to see.\n# Also, it is a common to draw the variable you want to explain\n# (here: calories) on the y-axis.\n\n# 11\nplot(df)\n\n# 12\ncor(df$calories, df$sport, method = c(\"pearson\"))\ncor(df$weight, df$calories, method = c(\"pearson\"))\n\n# 13\nggplot(df, aes(x = calories, y = weight, label = sex)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE)\n\n# 14\nreg_base &lt;- lm(weight ~ calories, data = df)\nsummary(reg_base)\n\n# 15\n# 1) An increase of 100 calories (taken on average on a daily basis) is associated\n# - on average and ceteris paribus - with 2.69 more of kg the participants are\n# pretended to weight.\n# 2) The estimated coefficient $beta_1$ is statistically significantly different to zero\n# on a significance level of 5%.\n# 3) About 60 % of the variation of the weight is explained by the\n# estimated coefficients of the empirical model.\n\n# 16\n# For omitted variable bias to occur, the omitted variable `Z` must satisfy\n# two conditions:\n#   1) The omitted variable is correlated with the included regressor\n#   2) The omitted variable is a determinant of the dependent variable\n\n# 17\n# discussed in class\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# 1\n# Stephan Huber, 000, 2020-May-30\n\n# 2\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsb_bac/work/\")\n\n# 3\nrm(list = ls())\n\n# 4\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\n# 5\n# cross-section\n\n# 6\nsex &lt;- c(\"f\", \"f\", \"f\", \"m\", \"m\", \"m\")\nage &lt;- c(21, 19, 23, 18, 20, 61)\nweight &lt;- c(48, 55, 63, 71, 77, 85)\ncalories &lt;- c(1700, 1800, 2300, 2000, 2800, 2500)\nsport &lt;- c(60, 120, 180, 60, 240, 30)\ndf &lt;- data.frame(sex, age, weight, calories, sport)\n\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/exams/21-04/stuff/df.csv\")\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/github/courses/dta/df-calories.csv\")\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/df-calories.csv\")\n\nRows: 6 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (4): age, weight, calories, sport\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# 7\nsummary(df)\n\n     sex                 age            weight        calories        sport    \n Length:6           Min.   :18.00   Min.   :48.0   Min.   :1700   Min.   : 30  \n Class :character   1st Qu.:19.25   1st Qu.:57.0   1st Qu.:1850   1st Qu.: 60  \n Mode  :character   Median :20.50   Median :67.0   Median :2150   Median : 90  \n                    Mean   :27.00   Mean   :66.5   Mean   :2183   Mean   :115  \n                    3rd Qu.:22.50   3rd Qu.:75.5   3rd Qu.:2450   3rd Qu.:165  \n                    Max.   :61.00   Max.   :85.0   Max.   :2800   Max.   :240  \n\n# 8\ndf |&gt;\n  group_by(sex) |&gt;\n  summarise(\n    mcal = mean(calories),\n    sdcal = sd(calories),\n    mweight = mean(weight),\n    sdweight = sd(weight)\n  )\n\n# A tibble: 2 × 5\n  sex    mcal sdcal mweight sdweight\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 f     1933.  321.    55.3     7.51\n2 m     2433.  404.    77.7     7.02\n\n# 9\n# discussed in class\n\n# 10\n# Many things can be mentioned here such as the use of colors\n# (red/blue is not a good choice for color blind people),\n# the legend makes no sense as red and green both refer to \\textit{sport},\n# the label of `f' and `m' is not explained in the legend,\n# rotating the labels of the y-axis would increase readability, and\n# both axes do not start at zero which is hard to see.\n# Also, it is a common to draw the variable you want to explain\n# (here: calories) on the y-axis.\n\n# 11\nplot(df)\n\n\n\n\n\n\n\n# 12\ncor(df$calories, df$sport, method = c(\"pearson\"))\n\n[1] 0.5330615\n\ncor(df$weight, df$calories, method = c(\"pearson\"))\n\n[1] 0.8281972\n\n# 13\nggplot(df, aes(x = calories, y = weight, label = sex)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE)\n\nWarning: The following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n# 14\nreg_base &lt;- lm(weight ~ calories, data = df)\nsummary(reg_base)\n\n\nCall:\nlm(formula = weight ~ calories, data = df)\n\nResiduals:\n     1      2      3      4      5      6 \n-5.490 -1.182 -6.640  9.435 -6.099  9.976 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  7.730275  20.197867   0.383   0.7214  \ncalories     0.026917   0.009107   2.956   0.0417 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.68 on 4 degrees of freedom\nMultiple R-squared:  0.6859,    Adjusted R-squared:  0.6074 \nF-statistic: 8.735 on 1 and 4 DF,  p-value: 0.04174\n\n# 15\n# 1) An increase of 100 calories (taken on average on a daily basis) is associated\n# - on average and ceteris paribus - with 2.69 more of kg the participants are\n# pretended to weight.\n# 2) The estimated coefficient $beta_1$ is statistically significantly different to zero\n# on a significance level of 5%.\n# 3) About 60 % of the variation of the weight is explained by the\n# estimated coefficients of the empirical model.\n\n# 16\n# For omitted variable bias to occur, the omitted variable `Z` must satisfy\n# two conditions:\n#   1) The omitted variable is correlated with the included regressor\n#   2) The omitted variable is a determinant of the dependent variable\n\n# 17\n# discussed in class\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#bundesliga",
    "href": "80_exercises.html#bundesliga",
    "title": "9  Collection of exercises",
    "section": "9.15 Bundesliga",
    "text": "9.15 Bundesliga\nOpen the script that you find here and work on the following tasks:\n\nSet your working directory.\nClear th environment.\nInstall and load the bundesligR and tidyverse.\nRead in the data bundesligR as a tibble.\nReplace “Bor. Moenchengladbach” with “Borussia Moenchengladbach.”\nCheck for the data class.\nView the data.\nGlimpse on the data.\nShow the first and last observations.\nShow summary statistics to all variables.\nHow many teams have played in the league over the years?\nWhich teams have played Bundesliga so far?\nHow many teams have played Bundesliga?\nHow often has each team played in the Bundesliga?\nShow summary statistics of variable Season only.\nShow summary statistics of all numeric variables (Team is a character).\nWhat is the highest number of points ever received by a team? Show only the name of the club with the highest number of points ever received.\nCreate a new tibble using liga removing the variable Pts_pre_95 from the data.\nCreate a new tibble using liga renaming W, D, and L to Win, Draw, and Loss. Additionally rename GF, GA, GD to Goals_shot, Goals_received, Goal_difference.\nCreate a new tibble using liga without the variable Pts_pre_95 and only observations before the year 1996.\nRemove the three tibbles just created from the environment.\nRename all variables of liga to lowercase and store it as dfb.\nShow the winner and the runner up after the year 2010. Additionally show the points received.\nCreate a variable that counts how often a team was ranked first.\nHow often has each team played in the Bundesliga?\nMake a ranking that shows which team has played the Bundesliga most often.\nAdd a variable to dfb that contains the number of appearances of a team in the league.\nCreate a number that indicates how often a team has played Bundesliga in a given year.\nMake a ranking with the number of titles of all teams that ever won the league.\nCreate a numeric identifying variable for each team.\nWhen a team is in the league, what is the probability that it wins the league?\nMake a scatterplot with points on the y-axis and position on the x-axis.\nMake a scatterplot with points on the y-axis and position on the x-axis. Additionally, only consider seasons with 18 teams and add lines that make clear how many points you needed to be placed in between rank 2 and 15.\nRemove all objects from the environment except dfb and liga.\nIn Figure Figure 9.2, the ranking history of 1. FC Kaiserslautern is shown. Replicate that plot.\n\n\n\n\nFigure 9.2: Ranking history: 1. FC Kaiserslautern\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Figure Figure 9.3, I made the graph a bit nicer. Can you spot all differences and can you guess what the dashed line and the triangles mean? How could the visualization be improved further? Replicate the plot.\n\n\n\n\nFigure 9.3: Ranking history: 1. FC Köln\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry to make the ranking history for each club ever played the league and export the graph as a png file.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, arrange, as_tibble, as.numeric, between, c, case_when, class, complete, desc, dir.create, dir.exists, element_blank, facet_wrap, factor, filter, geom_hline, geom_line, geom_point, geom_vline, ggplot, ggsave, glimpse, group_by, head, ifelse, is.na, labs, list, max, mutate, n_distinct, paste, print, rename, rename_all, row_number, scale_x_continuous, scale_y_continuous, scale_y_reverse, select, seq, setdiff, slice_head, subset, sum, summarise, summary, table, tail, theme, theme_classic, theme_minimal, unique, unlink, view, xlim.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# In dfb.R I analyze German soccer results\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/23-ws/dsda/scripts\")\n\n# clear environment\nrm(list = ls())\n\n# (Install and) load packagages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  bundesligR,\n  tidyverse\n)\n\n# Read in the data as tibble\nliga &lt;- as_tibble(bundesligR)\n\n# --------------------------------------\n# !!! ERRORS / ISSUES:\n# \"Borussia Moenchengladbach\" is also entitled \"Bor. Moenchengladbach\"!\n# Leverkusen is falsly entitled \"SV Bayer 04 Leverkusen\"\n# Uerdingen has changed its name several times\n# Stuttgarter Kickers are named differently\n\n# How often is \"Bor. Moenchengladbach\" in the data?\nsum(liga$Team == \"Bor. Moenchengladbach\")\n\n# show the entries\nliga |&gt;\n  filter(Team == \"Bor. Moenchengladbach\")\n\n# Replace \"Bor. Moenchengladbach\" with \"Borussia Moenchengladbach\"\nliga &lt;- liga |&gt;\n  mutate(Team = ifelse(Team == \"Bor. Moenchengladbach\",\n    \"Borussia Moenchengladbach\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Bayer 04 Leverkusen\",\n    \"TSV Bayer 04 Leverkusen\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"FC Bayer 05 Uerdingen\" |\n    Team == \"Bayer 05 Uerdingen\",\n  \"KFC Uerdingen 05\",\n  Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Stuttgarter Kickers\",\n    \"Stuttgarter Kickers\",\n    Team\n  ))\n\n# ------------------------------------\n\n# Check for the data class\nclass(liga)\n\n# view data\nview(liga)\n\n# Glimpse on the data\nglimpse(liga)\n\n# first and last observations\nhead(liga)\ntail(liga)\n\n# summary statistics\nsummary(liga)\n\n# How many teams have played in the league over the years?\ntable(liga$Season)\n\n# Which teams have played Bundesliga\nunique(liga$Team)\n\n# How many teams have played Bundesliga\nn_distinct(liga$Team)\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n# summary of variable Season only\nsummary(liga$Season)\n\n# summary of numeric of variables (Team is a character)\nliga |&gt;\n  select(Season, Position, Played, W, D, L, GF, GA, GD, Points, Pts_pre_95) |&gt;\n  summary()\n\n# shorter alternative\nliga |&gt;\n  select(Season, Position, Played:Pts_pre_95) |&gt;\n  summary()\n\n# shortest alternative\nliga |&gt;\n  select(-Team) |&gt;\n  filter(Season == 1999 | Season == 2010) |&gt;\n  summary()\n\n# Most points ever received by a team\nliga |&gt;\n  filter(Points == max(Points))\n\n# Show only the team name\nliga |&gt;\n  filter(Points == max(Points)) |&gt;\n  select(Team) |&gt;\n  print()\n\n# remove the variable `Pts_pre_95` from the data\nliga_post95 &lt;- liga |&gt;\n  select(-Pts_pre_95)\n\n# rename W, D, and L to Win, Draw, and Loss\n# additionally rename GF, GA, GD to Goals_shot, Goals_received, Goal_difference\nliga_longnames &lt;- liga |&gt;\n  rename(Win = W, Draw = D, Loss = L) |&gt;\n  rename(Goals_shot = GF, Goals_received = GA, Goal_difference = GD)\n\n# Remove the variable `Pts_pre_95` from `liga`\n# additionally remove all observations before the year 1996\nliga_no3point &lt;- liga |&gt;\n  select(-Pts_pre_95) |&gt;\n  filter(Season &gt;= 1996)\n\n# Remove the objects liga_post95, liga_longnames, and liga_no3point from the environment\nrm(liga_post95, liga_longnames, liga_no3point)\n\n# Rename all variables of `liga`to lower cases and store it as `dfb`\ndfb &lt;- liga |&gt;\n  rename_all(tolower)\n\n# Show the winner and the runner up after 2010\n# additionally show the points\ndfb |&gt;\n  filter(season &gt; 2010) |&gt;\n  group_by(season) |&gt;\n  arrange(desc(points)) |&gt;\n  slice_head(n = 2) |&gt;\n  select(team, points, position)\n\n# Create a variable that counts how often a team was ranked first\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(meister_count = sum(position == 1))\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n# Make a ranking\ndfb |&gt;\n  group_by(team) |&gt;\n  summarise(appearances = n_distinct(season)) |&gt;\n  arrange(desc(appearances)) |&gt;\n  print(n = Inf)\n\n# Add a variable to `dfb` that contains the number of appearances of a team in the league\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(appearances = n_distinct(season))\n\n# create a number that indicates how often a team has played Bundesliga in a given year\ndfb &lt;- dfb |&gt;\n  arrange(team, season) |&gt;\n  group_by(team) |&gt;\n  mutate(team_in_liga_count = row_number())\n\n# Make a ranking with the number of titles of all teams that ever won the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  filter(meister_count != 0) |&gt;\n  arrange(desc(meister_count)) |&gt;\n  select(meister_count, team)\n\n# Create a numeric identifying variable for each team\ndfb_teamid &lt;- dfb |&gt;\n  mutate(team_id = as.numeric(factor(team)))\n\n# When a team is in the league, what is the probability that it wins the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  mutate(prob_win = meister_count / appearances) |&gt;\n  filter(prob_win &gt; 0) |&gt;\n  arrange(desc(prob_win)) |&gt;\n  select(meister_count, prob_win, team)\n\n\n# make a scatterplot with points on the y-axis and position on the x-axis\nggplot(dfb, aes(x = position, y = points)) +\n  geom_point()\n\n# Make a scatterplot with points on the y-axis and position on the x-axis.\n# Additionally, only consider seasons with 18 teams and\n# add lines that make clear how many points you needed to be placed\n# in between rank 2 and 15.\ndfb_18 &lt;- dfb |&gt;\n  group_by(season) |&gt;\n  mutate(teams_in_league = n_distinct(team)) |&gt;\n  filter(teams_in_league == 18)\n\nh_1 &lt;- dfb_18 |&gt;\n  filter(position == 16) |&gt;\n  mutate(ma = max(points))\n\nmax_points_rank_16 &lt;- max(h_1$ma) + 1\n\nh_2 &lt;- dfb_18 |&gt;\n  filter(position == 2) |&gt;\n  mutate(mb = max(points))\n\nmin_points_rank_2 &lt;- max(h_2$mb) + 1\n\ndfb_18 &lt;- dfb_18 |&gt;\n  mutate(season_category = case_when(\n    season &lt; 1970 ~ 1,\n    between(season, 1970, 1979) ~ 2,\n    between(season, 1980, 1989) ~ 3,\n    between(season, 1990, 1999) ~ 4,\n    between(season, 2000, 2009) ~ 5,\n    between(season, 2010, 2019) ~ 6,\n    TRUE ~ 7 # Adjust this line based on the actual range of your data\n  ))\n\nggplot(dfb_18, aes(x = position, y = points)) +\n  geom_point() +\n  labs(\n    title = \"Scatterplot of Points and Position\",\n    x = \"Position\",\n    y = \"Points\"\n  ) +\n  geom_vline(xintercept = c(1.5, 15.5), linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = max_points_rank_16, linetype = \"dashed\", color = \"blue\") +\n  geom_hline(yintercept = min_points_rank_2, linetype = \"dashed\", color = \"blue\") +\n  scale_y_continuous(breaks = c(min_points_rank_2, max_points_rank_16, seq(0, max(dfb_18$points), by = 5))) +\n  scale_x_continuous(breaks = c(seq(0, max(dfb_18$points), by = 1))) +\n  theme_classic()\n\n\n# Remove all objects except liga and dfb\nrm(list = setdiff(ls(), c(\"liga\", \"dfb\")))\n\n# Rank \"1. FC Kaiserslautern\" over time\ndfb_bal &lt;- dfb |&gt;\n  select(season, team, position) |&gt;\n  as_tibble() |&gt;\n  complete(season, team)\n\ntable(dfb_bal$team)\n\ndfb_fck &lt;- dfb_bal |&gt;\n  filter(team == \"1. FC Kaiserslautern\")\n\nggplot(dfb_fck, aes(x = season, y = position)) +\n  geom_point() +\n  geom_line() +\n  scale_y_reverse(breaks = seq(1, 18, by = 1))\n\n\n\n\n# Make the plot nice\n\n# consider different rules for having to leave the league:\ndfb_fck &lt;- dfb_fck |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown))\n\n\nggplot(dfb_fck, aes(x = season)) +\n  geom_point(aes(y = position)) +\n  geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 18, by = 1)) +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"blue\")\n\n\n\ndfb_bal &lt;- dfb_bal |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown)) |&gt;\n  mutate(inliga = ifelse(is.na(position), 0, 1))\n\n\n\nrank_plot &lt;- ggplot(dfb_bal, aes(x = season)) +\n  geom_point(aes(y = position), shape = 1) +\n  # geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n  xlim(1963, 2015) +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n  geom_point(aes(y = position), shape = 1)\n\nrank_plot\n# !--&gt; in 1979 is a gap! Error?\n# No. Reason: two clubs shared the third place.\n\nrank_plot +\n  facet_wrap(~team)\n\n# Create \"test\" directory if it doesn't already exist\nif (!dir.exists(\"test\")) {\n  dir.create(\"test\")\n}\n\n\nplots &lt;- list()\nfor (club in unique(dfb_bal$team)) {\n  dfb_subset &lt;- subset(dfb_bal, team == club)\n\n  p &lt;- ggplot(dfb_subset, aes(x = season)) +\n    geom_point(aes(y = position), shape = 15) +\n    geom_line(aes(y = position)) +\n    geom_point(aes(y = godown), shape = 25) +\n    scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n    xlim(1963, 2015) +\n    theme(panel.grid.minor = element_blank()) +\n    geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n    geom_point(aes(y = position), shape = 1) +\n    labs(title = paste(\"Ranking History:\", club))\n  ggsave(filename = paste(\"test/r_\", club, \".png\", sep = \"\"))\n  plots[[club]] &lt;- p\n}\n\nprint(plots$`Meidericher SV`)\nprint(plots$`1. FC Koeln`)\n\n# unload packages\nsuppressMessages(pacman::p_unload(\n  bundesligR,\n  tidyverse\n))\n\n# Remove the \"test\" directory and its contents after saving all graphs\nunlink(\"test\", recursive = TRUE)\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# In dfb.R I analyze German soccer results\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/23-ws/dsda/scripts\")\n\n# clear environment\nrm(list = ls())\n\n# (Install and) load packagages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  bundesligR,\n  tidyverse\n)\n\n# Read in the data as tibble\nliga &lt;- as_tibble(bundesligR)\n\n# --------------------------------------\n# !!! ERRORS / ISSUES:\n# \"Borussia Moenchengladbach\" is also entitled \"Bor. Moenchengladbach\"!\n# Leverkusen is falsly entitled \"SV Bayer 04 Leverkusen\"\n# Uerdingen has changed its name several times\n# Stuttgarter Kickers are named differently\n\n# How often is \"Bor. Moenchengladbach\" in the data?\nsum(liga$Team == \"Bor. Moenchengladbach\")\n\n[1] 2\n\n# show the entries\nliga |&gt;\n  filter(Team == \"Bor. Moenchengladbach\")\n\n# A tibble: 2 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   1989       15 Bor. Moench…     34    11     8    15    37    45    -8     41\n2   1976        1 Bor. Moench…     34    17    10     7    58    34    24     61\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\n# Replace \"Bor. Moenchengladbach\" with \"Borussia Moenchengladbach\"\nliga &lt;- liga |&gt;\n  mutate(Team = ifelse(Team == \"Bor. Moenchengladbach\",\n    \"Borussia Moenchengladbach\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Bayer 04 Leverkusen\",\n    \"TSV Bayer 04 Leverkusen\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"FC Bayer 05 Uerdingen\" |\n    Team == \"Bayer 05 Uerdingen\",\n  \"KFC Uerdingen 05\",\n  Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Stuttgarter Kickers\",\n    \"Stuttgarter Kickers\",\n    Team\n  ))\n\n# ------------------------------------\n\n# Check for the data class\nclass(liga)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# view data\nview(liga)\n\n# Glimpse on the data\nglimpse(liga)\n\nRows: 952\nColumns: 12\n$ Season     &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,…\n$ Position   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ Team       &lt;chr&gt; \"FC Bayern Muenchen\", \"Borussia Dortmund\", \"Bayer 04 Leverk…\n$ Played     &lt;dbl&gt; 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,…\n$ W          &lt;dbl&gt; 28, 24, 18, 17, 15, 14, 14, 12, 10, 11, 10, 9, 10, 9, 9, 9,…\n$ D          &lt;dbl&gt; 4, 6, 6, 4, 7, 8, 8, 9, 13, 8, 10, 11, 8, 11, 10, 9, 6, 4, …\n$ L          &lt;dbl&gt; 2, 4, 10, 13, 12, 12, 12, 13, 11, 15, 14, 14, 16, 14, 15, 1…\n$ GF         &lt;dbl&gt; 80, 82, 56, 67, 51, 46, 42, 47, 38, 40, 33, 42, 50, 38, 39,…\n$ GA         &lt;dbl&gt; 17, 34, 40, 50, 49, 42, 42, 49, 42, 46, 42, 52, 65, 53, 54,…\n$ GD         &lt;dbl&gt; 63, 48, 16, 17, 2, 4, 0, -2, -4, -6, -9, -10, -15, -15, -15…\n$ Points     &lt;dbl&gt; 88, 78, 60, 55, 52, 50, 50, 45, 43, 41, 40, 38, 38, 38, 37,…\n$ Pts_pre_95 &lt;dbl&gt; 60, 54, 42, 38, 37, 36, 36, 33, 33, 30, 30, 29, 28, 29, 28,…\n\n# first and last observations\nhead(liga)\n\n# A tibble: 6 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   2015        1 FC Bayern M…     34    28     4     2    80    17    63     88\n2   2015        2 Borussia Do…     34    24     6     4    82    34    48     78\n3   2015        3 Bayer 04 Le…     34    18     6    10    56    40    16     60\n4   2015        4 Borussia Mo…     34    17     4    13    67    50    17     55\n5   2015        5 FC Schalke …     34    15     7    12    51    49     2     52\n6   2015        6 1. FSV Main…     34    14     8    12    46    42     4     50\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\ntail(liga)\n\n# A tibble: 6 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   1963       11 Eintracht B…     30    11     6    13    36    49   -13     39\n2   1963       12 1. FC Kaise…     30    10     6    14    48    69   -21     36\n3   1963       13 Karlsruher …     30     8     8    14    42    55   -13     32\n4   1963       14 Hertha BSC       30     9     6    15    45    65   -20     33\n5   1963       15 Preussen Mu…     30     7     9    14    34    52   -18     30\n6   1963       16 1. FC Saarb…     30     6     5    19    44    72   -28     23\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\n# summary statistics\nsummary(liga)\n\n     Season        Position          Team               Played     \n Min.   :1963   Min.   : 1.000   Length:952         Min.   :30.00  \n 1st Qu.:1976   1st Qu.: 5.000   Class :character   1st Qu.:34.00  \n Median :1989   Median : 9.000   Mode  :character   Median :34.00  \n Mean   :1989   Mean   : 9.486                      Mean   :33.95  \n 3rd Qu.:2002   3rd Qu.:14.000                      3rd Qu.:34.00  \n Max.   :2015   Max.   :20.000                      Max.   :38.00  \n       W               D                L               GF        \n Min.   : 2.00   Min.   : 2.000   Min.   : 1.00   Min.   : 15.00  \n 1st Qu.: 9.75   1st Qu.: 7.000   1st Qu.:10.00   1st Qu.: 42.00  \n Median :12.00   Median : 9.000   Median :13.00   Median : 50.00  \n Mean   :12.61   Mean   : 8.733   Mean   :12.61   Mean   : 52.01  \n 3rd Qu.:15.00   3rd Qu.:11.000   3rd Qu.:15.00   3rd Qu.: 61.00  \n Max.   :29.00   Max.   :18.000   Max.   :28.00   Max.   :101.00  \n       GA             GD               Points        Pts_pre_95   \n Min.   :10.0   Min.   :-60.0000   Min.   :10.00   Min.   : 8.00  \n 1st Qu.:43.0   1st Qu.:-13.0000   1st Qu.:38.00   1st Qu.:29.00  \n Median :51.0   Median : -2.0000   Median :44.00   Median :33.00  \n Mean   :51.7   Mean   :  0.3015   Mean   :46.56   Mean   :33.95  \n 3rd Qu.:60.0   3rd Qu.: 13.0000   3rd Qu.:55.00   3rd Qu.:39.00  \n Max.   :93.0   Max.   : 80.0000   Max.   :91.00   Max.   :62.00  \n\n# How many teams have played in the league over the years?\ntable(liga$Season)\n\n\n1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 \n  16   16   18   18   18   18   18   18   18   18   18   18   18   18   18   18 \n1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 \n  18   18   18   18   18   18   18   18   18   18   18   18   20   18   18   18 \n1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 \n  18   18   18   18   18   18   18   18   18   18   18   18   18   18   18   18 \n2011 2012 2013 2014 2015 \n  18   18   18   18   18 \n\n# Which teams have played Bundesliga\nunique(liga$Team)\n\n [1] \"FC Bayern Muenchen\"        \"Borussia Dortmund\"        \n [3] \"Bayer 04 Leverkusen\"       \"Borussia Moenchengladbach\"\n [5] \"FC Schalke 04\"             \"1. FSV Mainz 05\"          \n [7] \"Hertha BSC\"                \"VfL Wolfsburg\"            \n [9] \"1. FC Koeln\"               \"Hamburger SV\"             \n[11] \"FC Ingolstadt 04\"          \"FC Augsburg\"              \n[13] \"Werder Bremen\"             \"SV Darmstadt 98\"          \n[15] \"TSG 1899 Hoffenheim\"       \"Eintracht Frankfurt\"      \n[17] \"VfB Stuttgart\"             \"Hannover 96\"              \n[19] \"SC Freiburg\"               \"SC Paderborn 07\"          \n[21] \"1. FC Nuernberg\"           \"Eintracht Braunschweig\"   \n[23] \"Fortuna Duesseldorf\"       \"SpVgg Greuther Fuerth\"    \n[25] \"1. FC Kaiserslautern\"      \"FC St. Pauli\"             \n[27] \"VfL Bochum\"                \"Energie Cottbus\"          \n[29] \"Karlsruher SC\"             \"Arminia Bielefeld\"        \n[31] \"Hansa Rostock\"             \"MSV Duisburg\"             \n[33] \"Alemannia Aachen\"          \"TSV 1860 Muenchen\"        \n[35] \"SpVgg Unterhaching\"        \"SSV Ulm 1846\"             \n[37] \"KFC Uerdingen 05\"          \"Dynamo Dresden\"           \n[39] \"SG Wattenscheid 09\"        \"VfB Leipzig\"              \n[41] \"1. FC Saarbruecken\"        \"TSV Bayer 04 Leverkusen\"  \n[43] \"SV Werder Bremen\"          \"1. FC Dynamo Dresden\"     \n[45] \"Stuttgarter Kickers\"       \"FC Hansa Rostock\"         \n[47] \"SV Waldhof Mannheim\"       \"FC 08 Homburg\"            \n[49] \"FC Homburg\"                \"Blau-Weiss 90 Berlin\"     \n[51] \"Kickers Offenbach\"         \"Tennis Borussia Berlin\"   \n[53] \"Rot-Weiss Essen\"           \"Wuppertaler SV\"           \n[55] \"SC Fortuna Koeln\"          \"Rot-Weiss Oberhausen\"     \n[57] \"SC Rot-Weiss Oberhausen\"   \"Borussia Neunkirchen\"     \n[59] \"Meidericher SV\"            \"SC Tasmania 1900 Berlin\"  \n[61] \"Preussen Muenster\"        \n\n# How many teams have played Bundesliga\nn_distinct(liga$Team)\n\n[1] 61\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n\n     1. FC Dynamo Dresden      1. FC Kaiserslautern               1. FC Koeln \n                        1                        44                        45 \n          1. FC Nuernberg        1. FC Saarbruecken           1. FSV Mainz 05 \n                       32                         5                        10 \n         Alemannia Aachen         Arminia Bielefeld       Bayer 04 Leverkusen \n                        4                        17                        30 \n     Blau-Weiss 90 Berlin         Borussia Dortmund Borussia Moenchengladbach \n                        1                        49                        48 \n     Borussia Neunkirchen            Dynamo Dresden    Eintracht Braunschweig \n                        3                         3                        21 \n      Eintracht Frankfurt           Energie Cottbus             FC 08 Homburg \n                       47                         6                         2 \n              FC Augsburg        FC Bayern Muenchen          FC Hansa Rostock \n                        5                        51                         1 \n               FC Homburg          FC Ingolstadt 04             FC Schalke 04 \n                        1                         1                        48 \n             FC St. Pauli       Fortuna Duesseldorf              Hamburger SV \n                        8                        23                        53 \n              Hannover 96             Hansa Rostock                Hertha BSC \n                       28                        11                        33 \n            Karlsruher SC          KFC Uerdingen 05         Kickers Offenbach \n                       24                        14                         7 \n           Meidericher SV              MSV Duisburg         Preussen Muenster \n                        3                        25                         1 \n          Rot-Weiss Essen      Rot-Weiss Oberhausen          SC Fortuna Koeln \n                        7                         3                         1 \n              SC Freiburg           SC Paderborn 07   SC Rot-Weiss Oberhausen \n                       16                         1                         1 \n  SC Tasmania 1900 Berlin        SG Wattenscheid 09     SpVgg Greuther Fuerth \n                        1                         4                         1 \n       SpVgg Unterhaching              SSV Ulm 1846       Stuttgarter Kickers \n                        2                         1                         2 \n          SV Darmstadt 98       SV Waldhof Mannheim          SV Werder Bremen \n                        3                         7                         1 \n   Tennis Borussia Berlin       TSG 1899 Hoffenheim         TSV 1860 Muenchen \n                        2                         8                        20 \n  TSV Bayer 04 Leverkusen               VfB Leipzig             VfB Stuttgart \n                        7                         1                        51 \n               VfL Bochum             VfL Wolfsburg             Werder Bremen \n                       34                        19                        51 \n           Wuppertaler SV \n                        3 \n\n# summary of variable Season only\nsummary(liga$Season)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1963    1976    1989    1989    2002    2015 \n\n# summary of numeric of variables (Team is a character)\nliga |&gt;\n  select(Season, Position, Played, W, D, L, GF, GA, GD, Points, Pts_pre_95) |&gt;\n  summary()\n\n     Season        Position          Played            W        \n Min.   :1963   Min.   : 1.000   Min.   :30.00   Min.   : 2.00  \n 1st Qu.:1976   1st Qu.: 5.000   1st Qu.:34.00   1st Qu.: 9.75  \n Median :1989   Median : 9.000   Median :34.00   Median :12.00  \n Mean   :1989   Mean   : 9.486   Mean   :33.95   Mean   :12.61  \n 3rd Qu.:2002   3rd Qu.:14.000   3rd Qu.:34.00   3rd Qu.:15.00  \n Max.   :2015   Max.   :20.000   Max.   :38.00   Max.   :29.00  \n       D                L               GF               GA      \n Min.   : 2.000   Min.   : 1.00   Min.   : 15.00   Min.   :10.0  \n 1st Qu.: 7.000   1st Qu.:10.00   1st Qu.: 42.00   1st Qu.:43.0  \n Median : 9.000   Median :13.00   Median : 50.00   Median :51.0  \n Mean   : 8.733   Mean   :12.61   Mean   : 52.01   Mean   :51.7  \n 3rd Qu.:11.000   3rd Qu.:15.00   3rd Qu.: 61.00   3rd Qu.:60.0  \n Max.   :18.000   Max.   :28.00   Max.   :101.00   Max.   :93.0  \n       GD               Points        Pts_pre_95   \n Min.   :-60.0000   Min.   :10.00   Min.   : 8.00  \n 1st Qu.:-13.0000   1st Qu.:38.00   1st Qu.:29.00  \n Median : -2.0000   Median :44.00   Median :33.00  \n Mean   :  0.3015   Mean   :46.56   Mean   :33.95  \n 3rd Qu.: 13.0000   3rd Qu.:55.00   3rd Qu.:39.00  \n Max.   : 80.0000   Max.   :91.00   Max.   :62.00  \n\n# shorter alternative\nliga |&gt;\n  select(Season, Position, Played:Pts_pre_95) |&gt;\n  summary()\n\n     Season        Position          Played            W        \n Min.   :1963   Min.   : 1.000   Min.   :30.00   Min.   : 2.00  \n 1st Qu.:1976   1st Qu.: 5.000   1st Qu.:34.00   1st Qu.: 9.75  \n Median :1989   Median : 9.000   Median :34.00   Median :12.00  \n Mean   :1989   Mean   : 9.486   Mean   :33.95   Mean   :12.61  \n 3rd Qu.:2002   3rd Qu.:14.000   3rd Qu.:34.00   3rd Qu.:15.00  \n Max.   :2015   Max.   :20.000   Max.   :38.00   Max.   :29.00  \n       D                L               GF               GA      \n Min.   : 2.000   Min.   : 1.00   Min.   : 15.00   Min.   :10.0  \n 1st Qu.: 7.000   1st Qu.:10.00   1st Qu.: 42.00   1st Qu.:43.0  \n Median : 9.000   Median :13.00   Median : 50.00   Median :51.0  \n Mean   : 8.733   Mean   :12.61   Mean   : 52.01   Mean   :51.7  \n 3rd Qu.:11.000   3rd Qu.:15.00   3rd Qu.: 61.00   3rd Qu.:60.0  \n Max.   :18.000   Max.   :28.00   Max.   :101.00   Max.   :93.0  \n       GD               Points        Pts_pre_95   \n Min.   :-60.0000   Min.   :10.00   Min.   : 8.00  \n 1st Qu.:-13.0000   1st Qu.:38.00   1st Qu.:29.00  \n Median : -2.0000   Median :44.00   Median :33.00  \n Mean   :  0.3015   Mean   :46.56   Mean   :33.95  \n 3rd Qu.: 13.0000   3rd Qu.:55.00   3rd Qu.:39.00  \n Max.   : 80.0000   Max.   :91.00   Max.   :62.00  \n\n# shortest alternative\nliga |&gt;\n  select(-Team) |&gt;\n  filter(Season == 1999 | Season == 2010) |&gt;\n  summary()\n\n     Season        Position        Played         W               D         \n Min.   :1999   Min.   : 1.0   Min.   :34   Min.   : 4.00   Min.   : 3.000  \n 1st Qu.:1999   1st Qu.: 5.0   1st Qu.:34   1st Qu.: 9.75   1st Qu.: 6.000  \n Median :2004   Median : 9.5   Median :34   Median :12.00   Median : 8.000  \n Mean   :2004   Mean   : 9.5   Mean   :34   Mean   :12.83   Mean   : 8.333  \n 3rd Qu.:2010   3rd Qu.:14.0   3rd Qu.:34   3rd Qu.:14.25   3rd Qu.:10.250  \n Max.   :2010   Max.   :18.0   Max.   :34   Max.   :23.00   Max.   :15.000  \n       L               GF              GA              GD        \n Min.   : 3.00   Min.   :31.00   Min.   :22.00   Min.   :-34.00  \n 1st Qu.:10.75   1st Qu.:41.00   1st Qu.:44.00   1st Qu.:-10.25  \n Median :13.00   Median :47.00   Median :48.50   Median : -3.00  \n Mean   :12.83   Mean   :49.42   Mean   :49.42   Mean   :  0.00  \n 3rd Qu.:16.00   3rd Qu.:54.25   3rd Qu.:59.00   3rd Qu.:  4.75  \n Max.   :21.00   Max.   :81.00   Max.   :71.00   Max.   : 45.00  \n     Points        Pts_pre_95   \n Min.   :22.00   Min.   :18.00  \n 1st Qu.:39.75   1st Qu.:29.75  \n Median :44.00   Median :32.00  \n Mean   :46.83   Mean   :34.00  \n 3rd Qu.:50.75   3rd Qu.:37.50  \n Max.   :75.00   Max.   :52.00  \n\n# Most points ever received by a team\nliga |&gt;\n  filter(Points == max(Points))\n\n# A tibble: 1 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   2012        1 FC Bayern M…     34    29     4     1    98    18    80     91\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\n# Show only the team name\nliga |&gt;\n  filter(Points == max(Points)) |&gt;\n  select(Team) |&gt;\n  print()\n\n# A tibble: 1 × 1\n  Team              \n  &lt;chr&gt;             \n1 FC Bayern Muenchen\n\n# remove the variable `Pts_pre_95` from the data\nliga_post95 &lt;- liga |&gt;\n  select(-Pts_pre_95)\n\n# rename W, D, and L to Win, Draw, and Loss\n# additionally rename GF, GA, GD to Goals_shot, Goals_received, Goal_difference\nliga_longnames &lt;- liga |&gt;\n  rename(Win = W, Draw = D, Loss = L) |&gt;\n  rename(Goals_shot = GF, Goals_received = GA, Goal_difference = GD)\n\n# Remove the variable `Pts_pre_95` from `liga`\n# additionally remove all observations before the year 1996\nliga_no3point &lt;- liga |&gt;\n  select(-Pts_pre_95) |&gt;\n  filter(Season &gt;= 1996)\n\n# Remove the objects liga_post95, liga_longnames, and liga_no3point from the environment\nrm(liga_post95, liga_longnames, liga_no3point)\n\n# Rename all variables of `liga`to lower cases and store it as `dfb`\ndfb &lt;- liga |&gt;\n  rename_all(tolower)\n\n# Show the winner and the runner up after 2010\n# additionally show the points\ndfb |&gt;\n  filter(season &gt; 2010) |&gt;\n  group_by(season) |&gt;\n  arrange(desc(points)) |&gt;\n  slice_head(n = 2) |&gt;\n  select(team, points, position)\n\n# A tibble: 10 × 4\n# Groups:   season [5]\n   season team               points position\n    &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n 1   2011 Borussia Dortmund      81        1\n 2   2011 FC Bayern Muenchen     73        2\n 3   2012 FC Bayern Muenchen     91        1\n 4   2012 Borussia Dortmund      66        2\n 5   2013 FC Bayern Muenchen     90        1\n 6   2013 Borussia Dortmund      71        2\n 7   2014 FC Bayern Muenchen     79        1\n 8   2014 VfL Wolfsburg          69        2\n 9   2015 FC Bayern Muenchen     88        1\n10   2015 Borussia Dortmund      78        2\n\n# Create a variable that counts how often a team was ranked first\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(meister_count = sum(position == 1))\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n\n     1. FC Dynamo Dresden      1. FC Kaiserslautern               1. FC Koeln \n                        1                        44                        45 \n          1. FC Nuernberg        1. FC Saarbruecken           1. FSV Mainz 05 \n                       32                         5                        10 \n         Alemannia Aachen         Arminia Bielefeld       Bayer 04 Leverkusen \n                        4                        17                        30 \n     Blau-Weiss 90 Berlin         Borussia Dortmund Borussia Moenchengladbach \n                        1                        49                        48 \n     Borussia Neunkirchen            Dynamo Dresden    Eintracht Braunschweig \n                        3                         3                        21 \n      Eintracht Frankfurt           Energie Cottbus             FC 08 Homburg \n                       47                         6                         2 \n              FC Augsburg        FC Bayern Muenchen          FC Hansa Rostock \n                        5                        51                         1 \n               FC Homburg          FC Ingolstadt 04             FC Schalke 04 \n                        1                         1                        48 \n             FC St. Pauli       Fortuna Duesseldorf              Hamburger SV \n                        8                        23                        53 \n              Hannover 96             Hansa Rostock                Hertha BSC \n                       28                        11                        33 \n            Karlsruher SC          KFC Uerdingen 05         Kickers Offenbach \n                       24                        14                         7 \n           Meidericher SV              MSV Duisburg         Preussen Muenster \n                        3                        25                         1 \n          Rot-Weiss Essen      Rot-Weiss Oberhausen          SC Fortuna Koeln \n                        7                         3                         1 \n              SC Freiburg           SC Paderborn 07   SC Rot-Weiss Oberhausen \n                       16                         1                         1 \n  SC Tasmania 1900 Berlin        SG Wattenscheid 09     SpVgg Greuther Fuerth \n                        1                         4                         1 \n       SpVgg Unterhaching              SSV Ulm 1846       Stuttgarter Kickers \n                        2                         1                         2 \n          SV Darmstadt 98       SV Waldhof Mannheim          SV Werder Bremen \n                        3                         7                         1 \n   Tennis Borussia Berlin       TSG 1899 Hoffenheim         TSV 1860 Muenchen \n                        2                         8                        20 \n  TSV Bayer 04 Leverkusen               VfB Leipzig             VfB Stuttgart \n                        7                         1                        51 \n               VfL Bochum             VfL Wolfsburg             Werder Bremen \n                       34                        19                        51 \n           Wuppertaler SV \n                        3 \n\n# Make a ranking\ndfb |&gt;\n  group_by(team) |&gt;\n  summarise(appearances = n_distinct(season)) |&gt;\n  arrange(desc(appearances)) |&gt;\n  print(n = Inf)\n\n# A tibble: 61 × 2\n   team                      appearances\n   &lt;chr&gt;                           &lt;int&gt;\n 1 Hamburger SV                       53\n 2 FC Bayern Muenchen                 51\n 3 VfB Stuttgart                      51\n 4 Werder Bremen                      51\n 5 Borussia Dortmund                  49\n 6 Borussia Moenchengladbach          48\n 7 FC Schalke 04                      48\n 8 Eintracht Frankfurt                47\n 9 1. FC Koeln                        45\n10 1. FC Kaiserslautern               44\n11 VfL Bochum                         34\n12 Hertha BSC                         33\n13 1. FC Nuernberg                    32\n14 Bayer 04 Leverkusen                30\n15 Hannover 96                        28\n16 MSV Duisburg                       25\n17 Karlsruher SC                      24\n18 Fortuna Duesseldorf                23\n19 Eintracht Braunschweig             21\n20 TSV 1860 Muenchen                  20\n21 VfL Wolfsburg                      19\n22 Arminia Bielefeld                  17\n23 SC Freiburg                        16\n24 KFC Uerdingen 05                   14\n25 Hansa Rostock                      11\n26 1. FSV Mainz 05                    10\n27 FC St. Pauli                        8\n28 TSG 1899 Hoffenheim                 8\n29 Kickers Offenbach                   7\n30 Rot-Weiss Essen                     7\n31 SV Waldhof Mannheim                 7\n32 TSV Bayer 04 Leverkusen             7\n33 Energie Cottbus                     6\n34 1. FC Saarbruecken                  5\n35 FC Augsburg                         5\n36 Alemannia Aachen                    4\n37 SG Wattenscheid 09                  4\n38 Borussia Neunkirchen                3\n39 Dynamo Dresden                      3\n40 Meidericher SV                      3\n41 Rot-Weiss Oberhausen                3\n42 SV Darmstadt 98                     3\n43 Wuppertaler SV                      3\n44 FC 08 Homburg                       2\n45 SpVgg Unterhaching                  2\n46 Stuttgarter Kickers                 2\n47 Tennis Borussia Berlin              2\n48 1. FC Dynamo Dresden                1\n49 Blau-Weiss 90 Berlin                1\n50 FC Hansa Rostock                    1\n51 FC Homburg                          1\n52 FC Ingolstadt 04                    1\n53 Preussen Muenster                   1\n54 SC Fortuna Koeln                    1\n55 SC Paderborn 07                     1\n56 SC Rot-Weiss Oberhausen             1\n57 SC Tasmania 1900 Berlin             1\n58 SSV Ulm 1846                        1\n59 SV Werder Bremen                    1\n60 SpVgg Greuther Fuerth               1\n61 VfB Leipzig                         1\n\n# Add a variable to `dfb` that contains the number of appearances of a team in the league\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(appearances = n_distinct(season))\n\n# create a number that indicates how often a team has played Bundesliga in a given year\ndfb &lt;- dfb |&gt;\n  arrange(team, season) |&gt;\n  group_by(team) |&gt;\n  mutate(team_in_liga_count = row_number())\n\n# Make a ranking with the number of titles of all teams that ever won the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  filter(meister_count != 0) |&gt;\n  arrange(desc(meister_count)) |&gt;\n  select(meister_count, team)\n\n# A tibble: 12 × 2\n# Groups:   team [12]\n   meister_count team                     \n           &lt;int&gt; &lt;chr&gt;                    \n 1            25 FC Bayern Muenchen       \n 2             5 Borussia Dortmund        \n 3             5 Borussia Moenchengladbach\n 4             4 Werder Bremen            \n 5             3 Hamburger SV             \n 6             3 VfB Stuttgart            \n 7             2 1. FC Kaiserslautern     \n 8             2 1. FC Koeln              \n 9             1 1. FC Nuernberg          \n10             1 Eintracht Braunschweig   \n11             1 TSV 1860 Muenchen        \n12             1 VfL Wolfsburg            \n\n# Create a numeric identifying variable for each team\ndfb_teamid &lt;- dfb |&gt;\n  mutate(team_id = as.numeric(factor(team)))\n\n# When a team is in the league, what is the probability that it wins the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  mutate(prob_win = meister_count / appearances) |&gt;\n  filter(prob_win &gt; 0) |&gt;\n  arrange(desc(prob_win)) |&gt;\n  select(meister_count, prob_win, team)\n\n# A tibble: 12 × 3\n# Groups:   team [12]\n   meister_count prob_win team                     \n           &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                    \n 1            25   0.490  FC Bayern Muenchen       \n 2             5   0.104  Borussia Moenchengladbach\n 3             5   0.102  Borussia Dortmund        \n 4             4   0.0784 Werder Bremen            \n 5             3   0.0588 VfB Stuttgart            \n 6             3   0.0566 Hamburger SV             \n 7             1   0.0526 VfL Wolfsburg            \n 8             1   0.05   TSV 1860 Muenchen        \n 9             1   0.0476 Eintracht Braunschweig   \n10             2   0.0455 1. FC Kaiserslautern     \n11             2   0.0444 1. FC Koeln              \n12             1   0.0312 1. FC Nuernberg          \n\n# make a scatterplot with points on the y-axis and position on the x-axis\nggplot(dfb, aes(x = position, y = points)) +\n  geom_point()\n\n\n\n\n\n\n\n# Make a scatterplot with points on the y-axis and position on the x-axis.\n# Additionally, only consider seasons with 18 teams and\n# add lines that make clear how many points you needed to be placed\n# in between rank 2 and 15.\ndfb_18 &lt;- dfb |&gt;\n  group_by(season) |&gt;\n  mutate(teams_in_league = n_distinct(team)) |&gt;\n  filter(teams_in_league == 18)\n\nh_1 &lt;- dfb_18 |&gt;\n  filter(position == 16) |&gt;\n  mutate(ma = max(points))\n\nmax_points_rank_16 &lt;- max(h_1$ma) + 1\n\nh_2 &lt;- dfb_18 |&gt;\n  filter(position == 2) |&gt;\n  mutate(mb = max(points))\n\nmin_points_rank_2 &lt;- max(h_2$mb) + 1\n\ndfb_18 &lt;- dfb_18 |&gt;\n  mutate(season_category = case_when(\n    season &lt; 1970 ~ 1,\n    between(season, 1970, 1979) ~ 2,\n    between(season, 1980, 1989) ~ 3,\n    between(season, 1990, 1999) ~ 4,\n    between(season, 2000, 2009) ~ 5,\n    between(season, 2010, 2019) ~ 6,\n    TRUE ~ 7 # Adjust this line based on the actual range of your data\n  ))\n\nggplot(dfb_18, aes(x = position, y = points)) +\n  geom_point() +\n  labs(\n    title = \"Scatterplot of Points and Position\",\n    x = \"Position\",\n    y = \"Points\"\n  ) +\n  geom_vline(xintercept = c(1.5, 15.5), linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = max_points_rank_16, linetype = \"dashed\", color = \"blue\") +\n  geom_hline(yintercept = min_points_rank_2, linetype = \"dashed\", color = \"blue\") +\n  scale_y_continuous(breaks = c(min_points_rank_2, max_points_rank_16, seq(0, max(dfb_18$points), by = 5))) +\n  scale_x_continuous(breaks = c(seq(0, max(dfb_18$points), by = 1))) +\n  theme_classic()\n\n\n\n\n\n\n\n# Remove all objects except liga and dfb\nrm(list = setdiff(ls(), c(\"liga\", \"dfb\")))\n\n# Rank \"1. FC Kaiserslautern\" over time\ndfb_bal &lt;- dfb |&gt;\n  select(season, team, position) |&gt;\n  as_tibble() |&gt;\n  complete(season, team)\n\ntable(dfb_bal$team)\n\n\n     1. FC Dynamo Dresden      1. FC Kaiserslautern               1. FC Koeln \n                       53                        53                        53 \n          1. FC Nuernberg        1. FC Saarbruecken           1. FSV Mainz 05 \n                       53                        53                        53 \n         Alemannia Aachen         Arminia Bielefeld       Bayer 04 Leverkusen \n                       53                        53                        53 \n     Blau-Weiss 90 Berlin         Borussia Dortmund Borussia Moenchengladbach \n                       53                        53                        53 \n     Borussia Neunkirchen            Dynamo Dresden    Eintracht Braunschweig \n                       53                        53                        53 \n      Eintracht Frankfurt           Energie Cottbus             FC 08 Homburg \n                       53                        53                        53 \n              FC Augsburg        FC Bayern Muenchen          FC Hansa Rostock \n                       53                        53                        53 \n               FC Homburg          FC Ingolstadt 04             FC Schalke 04 \n                       53                        53                        53 \n             FC St. Pauli       Fortuna Duesseldorf              Hamburger SV \n                       53                        53                        53 \n              Hannover 96             Hansa Rostock                Hertha BSC \n                       53                        53                        53 \n            Karlsruher SC          KFC Uerdingen 05         Kickers Offenbach \n                       53                        53                        53 \n           Meidericher SV              MSV Duisburg         Preussen Muenster \n                       53                        53                        53 \n          Rot-Weiss Essen      Rot-Weiss Oberhausen          SC Fortuna Koeln \n                       53                        53                        53 \n              SC Freiburg           SC Paderborn 07   SC Rot-Weiss Oberhausen \n                       53                        53                        53 \n  SC Tasmania 1900 Berlin        SG Wattenscheid 09     SpVgg Greuther Fuerth \n                       53                        53                        53 \n       SpVgg Unterhaching              SSV Ulm 1846       Stuttgarter Kickers \n                       53                        53                        53 \n          SV Darmstadt 98       SV Waldhof Mannheim          SV Werder Bremen \n                       53                        53                        53 \n   Tennis Borussia Berlin       TSG 1899 Hoffenheim         TSV 1860 Muenchen \n                       53                        53                        53 \n  TSV Bayer 04 Leverkusen               VfB Leipzig             VfB Stuttgart \n                       53                        53                        53 \n               VfL Bochum             VfL Wolfsburg             Werder Bremen \n                       53                        53                        53 \n           Wuppertaler SV \n                       53 \n\ndfb_fck &lt;- dfb_bal |&gt;\n  filter(team == \"1. FC Kaiserslautern\")\n\nggplot(dfb_fck, aes(x = season, y = position)) +\n  geom_point() +\n  geom_line() +\n  scale_y_reverse(breaks = seq(1, 18, by = 1))\n\n\n\n\n\n\n\n# Make the plot nice\n\n# consider different rules for having to leave the league:\ndfb_fck &lt;- dfb_fck |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown))\n\n\nggplot(dfb_fck, aes(x = season)) +\n  geom_point(aes(y = position)) +\n  geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 18, by = 1)) +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"blue\")\n\n\n\n\n\n\n\ndfb_bal &lt;- dfb_bal |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown)) |&gt;\n  mutate(inliga = ifelse(is.na(position), 0, 1))\n\n\n\nrank_plot &lt;- ggplot(dfb_bal, aes(x = season)) +\n  geom_point(aes(y = position), shape = 1) +\n  # geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n  xlim(1963, 2015) +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n  geom_point(aes(y = position), shape = 1)\n\nrank_plot\n\n\n\n\n\n\n\n# !--&gt; in 1979 is a gap! Error?\n# No. Reason: two clubs shared the third place.\n\nrank_plot +\n  facet_wrap(~team)\n\n\n\n\n\n\n\n# Create \"test\" directory if it doesn't already exist\nif (!dir.exists(\"test\")) {\n  dir.create(\"test\")\n}\n\n\nplots &lt;- list()\nfor (club in unique(dfb_bal$team)) {\n  dfb_subset &lt;- subset(dfb_bal, team == club)\n\n  p &lt;- ggplot(dfb_subset, aes(x = season)) +\n    geom_point(aes(y = position), shape = 15) +\n    geom_line(aes(y = position)) +\n    geom_point(aes(y = godown), shape = 25) +\n    scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n    xlim(1963, 2015) +\n    theme(panel.grid.minor = element_blank()) +\n    geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n    geom_point(aes(y = position), shape = 1) +\n    labs(title = paste(\"Ranking History:\", club))\n  ggsave(filename = paste(\"test/r_\", club, \".png\", sep = \"\"))\n  plots[[club]] &lt;- p\n}\n\nprint(plots$`Meidericher SV`)\n\n\n\n\n\n\n\nprint(plots$`1. FC Koeln`)\n\n\n\n\n\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(\n  bundesligR,\n  tidyverse\n))\n\n# Remove the \"test\" directory and its contents after saving all graphs\nunlink(\"test\", recursive = TRUE)",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#okuns-law",
    "href": "80_exercises.html#okuns-law",
    "title": "9  Collection of exercises",
    "section": "9.16 Okun’s Law",
    "text": "9.16 Okun’s Law\nSuppose you aim to empirically examine unemployment and GDP for Germany and France. The data set that we use in the following is ‘forest.Rdata’ and should already been known to you from the lecture.\n\nWrite down your name, matriculation number, and date.\nSet your working directory.\n\n\nClear your global environment.\n\n\nInstall and load the following packages: ‘tidyverse’, ‘sjPlot’, and ‘ggpubr’\n\n\nDownload and load the data, respectively, with the following code:\n\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nIf that is not working, you can also download the data from ILIAS, save it in your working directory and load it from there with:\nload(\"forest.Rdata\")\n\nShow the first eight observations of the dataset df.\nShow the last observation of the dataset df.\nWhich type of data do we have here (Panel, cross-section,time series, …)? Name the variable(s) that are necessary to identify the observations in the dataset.\nExplain what the assignment operator in R is and what it is good for.\nWrite down the R code to store the number of observations and the number of variables that are in the dataset df. Name the object in which you store these numbers observations_df.\nIn the dataset df, rename the variable ‘country.x’ to ‘nation’ and the variable ‘date’ to ‘year’.\nExplain what the pipe operator in R is and what it is good for.\nFor the upcoming analysis you are only interested the following variables that are part of the dataframe df: nation, year, gdp, pop, gdppc, and unemployment. Drop all other variables from the dataframe df.\nCreate a variable that indicates the GDP per capita (‘gdp’ divided by ‘pop’). Name the variable ‘gdp_pc’. (Hint: If you fail here, use the variable ‘gdppc’ which is already in the dataset as a replacement for ‘gdp_pc’ in the following tasks.)\nFor the upcoming analysis you are only interested the following countries that are part of the dataframe df: Germany and France. Drop all other countries from the dataframe df.\nCreate a table showing the average unemployment rate and GDP per capita for Germany and France in the given years. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\n\n\nCreate a table showing the unemployment rate and GDP per capita for Germany and France in the year 2020. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\n\n\nCreate a table showing the highest unemployment rate and the highest GDP per capita for Germany and France during the given period. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\n\n\nCalculate the standard deviation of the unemployment rate and GDP per capita for Germany and France in the given years. (Hint: See below for how your result should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\n\n\nIn statistics, the coefficient of variation (COV) is a standardized measure of dispersion. It is defined as the ratio of the standard deviation (\\(\\sigma\\)) to the mean (\\(\\mu\\)): \\(COV={\\frac {\\sigma }{\\mu }}\\). Write down the R code to calculate the coefficient of variation (COV) for the unemployment rate in Germany and France. (Hint: See below for what your result should should look like.)\n\n\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\n\n\nWrite down the R code to calculate the coefficient of variation (COV) for the GDP per capita in Germany and France. (Hint: See below for what your result should should look like.)\n\nlook like.)\n\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\n\n\nCreate a chart (bar chart, line chart, or scatter plot) that shows the unemployment rate of Germany over the available years. Label the chart ‘Germany’ with ggtitle(\"Germany\"). Please note that you may choose any type of graphical representation. (Hint: Below you can see one of many possible examples of what your result may look like).\n\n\n\n\n\n\n\n\n\n\n\nand 23. (This task is worth 10 points) The following chart shows the simultaneous development of the unemployment rate and GDP per capita over time for France.\n\n\n\n\n\n\n\n\n\n\nSuppose you want to visualize the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany as well.\nSuppose further that you have found the following lines of code that create the kind of chart you are looking for.\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\n\nUse these lines of code and customize them to create the co-movement visualization for Germany using the available df data. The result should look something like this:\n\n\n\n\n\n\n\n\n\n\nInterpret the two graphs above, which show the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany and France. What are your expectations regarding the correlation between the unemployment rate and GDP per capita variables? Can you see this expectation in the figures? Discuss.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, dim, filter, geom_line, ggplot, ggtitle, group_by, head, load, max, mean, mutate, plot, rename, sd, select, summarise, tail, text, title, url.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\ntail(df, 1)\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\ndf_pger &lt;- df |&gt;\n  filter(nation == \"Germany\")\n\npger &lt;- ggplot(df_pger, aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\nplot(pger)\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\n# A tibble: 8 × 11\n# Groups:   country.x [1]\n  country.x     date     gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 United Arab…  1992 1.26e11     -2.48          1.84 Middl… High …   3.63 2.05e6\n2 United Arab…  1993 1.27e11     -4.34          1.85 Middl… High …   3.72 2.17e6\n3 United Arab…  1994 1.36e11      1.25          1.81 Middl… High …   3.81 2.29e6\n4 United Arab…  1995 1.45e11      1.35          1.80 Middl… High …   3.90 2.42e6\n5 United Arab…  1996 1.54e11      0.631         1.90 Middl… High …   3.99 2.54e6\n6 United Arab…  1997 1.66e11      2.83          1.98 Middl… High …   4.08 2.67e6\n7 United Arab…  1998 1.67e11     -4.77          2.14 Middl… High …   4.18 2.81e6\n8 United Arab…  1999 1.72e11     -2.40          2.22 Middl… High …   4.27 2.97e6\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\ntail(df, 1)\n\n# A tibble: 1 × 11\n# Groups:   country.x [1]\n  country.x  date        gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Zimbabwe   2020    1.94e10      -7.62         5.35 Sub-S… Lower…   45.1 1.49e7\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\ndf_pger &lt;- df |&gt;\n  filter(nation == \"Germany\")\n\npger &lt;- ggplot(df_pger, aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\nplot(pger)\n\n\n\n\n\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n\n\n\n\n\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\n\n\n\n\n\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exe_duplicates",
    "href": "80_exercises.html#sec-exe_duplicates",
    "title": "9  Collection of exercises",
    "section": "9.17 Names and duplicates",
    "text": "9.17 Names and duplicates\n\nLoad the required packages (pacman, tidyverse, janitor, babynames, stringr).\nLoad the dataset from the URL: https://github.com/hubchev/courses/raw/main/dta/df_names.RData. Make yourself familiar with the data.\nAfter loading the dataset, remove all objects except df_2022 and df_2022_error.\nReorder the data using the relocate function so that surname, name, and age appear first. Save the changed data in a tibble called df.\nSort the data according to surname, name, and age.\nMake a variable named born that contains the year of birth. How is the born variable calculated?\nCreate a new variable named id that identifies each person by surname, name, and their birth year (born). Why is this identifier useful?\nInvestigate how the data is identified. Are there any duplicates? If so, can you think of strategies to identify and how to deal with these duplicates.\nUnload the packages used in the script. Why is unloading packages considered good practice?\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: anti_join, arrange, c, cur_group_id, desc, dim, distinct, filter, get_dupes, glimpse, group_by, head, load, max, mutate, n, paste, relocate, row_number, setdiff, summary, tail, ungroup, url.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Find duplicates\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/test/initial_script\")\n\n# clear environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, babynames, stringr)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/df_names.RData\"))\n\n# Remove all objects except df_2022 and df_2022_error\nrm(list = setdiff(ls(), c(\"df_2022_error\", \"df_2022\")))\n\n# Re-order the data so that surname, name, and age appears first.\n# Save the changed data in a tibble called `df`.\ndf &lt;- df_2022 |&gt;\n  relocate(surname, name, age)\n\n# Sort the data according to surname, name, and age.\ndf &lt;- df |&gt;\n  arrange(surname, name, age)\n\n# Inspect df_2022 and df_2022_error\ndf\ndim(df)\nhead(df)\ntail(df)\nglimpse(df)\nsummary(df)\n\ndf_2022_error\n\n# Make a variable that contains the year of birth. Name the variable `born`\n# and new dataframe `df`.\ndf &lt;- df_2022 |&gt;\n  mutate(born = time - age)\n\n# Make a new variable that identifies each person by surname, name,\n# and their birth born. Name the variable `id`.\ndf &lt;- df |&gt;\n  mutate(id = paste(surname, name, born, sep = \"_\"))\n\n# How many different groups do exist?\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(id_num = cur_group_id()) |&gt;\n  ungroup()\n\nmax(df$id_num)\n\n# Show groups that exist more than once.\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(\n    dup_count = row_number(),\n    dup_sum   = n()\n  ) |&gt;\n  ungroup() |&gt;\n  arrange(id)\n\ndf |&gt; filter(dup_sum &gt; 1)\ndf |&gt; get_dupes(name, surname)\n\n# Make yourself familiar with the function `get_dupes()` from `janitor` package.\ndf |&gt; get_dupes()\ndf |&gt; get_dupes(surname, name)\ndf |&gt; get_dupes(id)\n\ndf_uni &lt;- df |&gt;\n  arrange() |&gt;\n  distinct(id, .keep_all = TRUE)\n\ndf_uni_b &lt;- df |&gt;\n  arrange(desc(dup_count)) |&gt;\n  distinct(id, .keep_all = TRUE)\n\nanti_join(df, df_uni)\nanti_join(df, df_uni_b)\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, janitor, babynames, stringr))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Find duplicates\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/test/initial_script\")\n\n# clear environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, babynames, stringr)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/df_names.RData\"))\n\n# Remove all objects except df_2022 and df_2022_error\nrm(list = setdiff(ls(), c(\"df_2022_error\", \"df_2022\")))\n\n# Re-order the data so that surname, name, and age appears first.\n# Save the changed data in a tibble called `df`.\ndf &lt;- df_2022 |&gt;\n  relocate(surname, name, age)\n\n# Sort the data according to surname, name, and age.\ndf &lt;- df |&gt;\n  arrange(surname, name, age)\n\n# Inspect df_2022 and df_2022_error\ndf\n\n# A tibble: 1,018 × 8\n   surname name       age sex      cm  time error error_desc\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n 1 Adams   Adonnis     30 M      192   2022     0 &lt;NA&gt;      \n 2 Adams   Adonnis     30 M      192   2022     1 duplicate \n 3 Adams   Aila        79 F      157   2022     0 &lt;NA&gt;      \n 4 Adams   Avenelle    69 F      157   2022     0 &lt;NA&gt;      \n 5 Adams   Brysan      39 M      192   2022     0 &lt;NA&gt;      \n 6 Adams   Eona        84 F      157   2022     0 &lt;NA&gt;      \n 7 Adams   Eveline     42 F      157   2022     0 &lt;NA&gt;      \n 8 Adams   Faithe      17 F      172.  2022     0 &lt;NA&gt;      \n 9 Adams   Ineisha     47 F      157   2022     0 &lt;NA&gt;      \n10 Adams   Kloeigh     31 F      157   2022     0 &lt;NA&gt;      \n# ℹ 1,008 more rows\n\ndim(df)\n\n[1] 1018    8\n\nhead(df)\n\n# A tibble: 6 × 8\n  surname name       age sex      cm  time error error_desc\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Adams   Adonnis     30 M       192  2022     0 &lt;NA&gt;      \n2 Adams   Adonnis     30 M       192  2022     1 duplicate \n3 Adams   Aila        79 F       157  2022     0 &lt;NA&gt;      \n4 Adams   Avenelle    69 F       157  2022     0 &lt;NA&gt;      \n5 Adams   Brysan      39 M       192  2022     0 &lt;NA&gt;      \n6 Adams   Eona        84 F       157  2022     0 &lt;NA&gt;      \n\ntail(df)\n\n# A tibble: 6 × 8\n  surname name       age sex      cm  time error error_desc                     \n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                          \n1 Young   Leiliana    54 F     157    2022     0 &lt;NA&gt;                           \n2 Young   Shamar      23 M     192    2022     0 &lt;NA&gt;                           \n3 Young   Tajanay      1 F      81.5  2022     0 &lt;NA&gt;                           \n4 huber   Stephan    186 M      41    2022     1 age/cm false, not capitalized …\n5 huber   Stephan     NA &lt;NA&gt;   NA    2022     1 wrong name                     \n6 &lt;NA&gt;    Zita         6 &lt;NA&gt;  110    2022     2 surname missing, sex unspecifi…\n\nglimpse(df)\n\nRows: 1,018\nColumns: 8\n$ surname    &lt;chr&gt; \"Adams\", \"Adams\", \"Adams\", \"Adams\", \"Adams\", \"Adams\", \"Adam…\n$ name       &lt;chr&gt; \"Adonnis\", \"Adonnis\", \"Aila\", \"Avenelle\", \"Brysan\", \"Eona\",…\n$ age        &lt;dbl&gt; 30, 30, 79, 69, 39, 84, 42, 17, 47, 31, 65, 80, 6, 5, 5, 20…\n$ sex        &lt;chr&gt; \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"F\",…\n$ cm         &lt;dbl&gt; 192.00000, 192.00000, 157.00000, 157.00000, 192.00000, 157.…\n$ time       &lt;dbl&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022,…\n$ error      &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ error_desc &lt;chr&gt; NA, \"duplicate\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\nsummary(df)\n\n   surname              name                age             sex           \n Length:1018        Length:1018        Min.   :  1.00   Length:1018       \n Class :character   Class :character   1st Qu.: 21.00   Class :character  \n Mode  :character   Mode  :character   Median : 43.00   Mode  :character  \n                                       Mean   : 45.75                     \n                                       3rd Qu.: 69.00                     \n                                       Max.   :399.00                     \n                                       NA's   :2                          \n       cm             time          error          error_desc       \n Min.   : 41.0   Min.   :2022   Min.   :0.00000   Length:1018       \n 1st Qu.:157.0   1st Qu.:2022   1st Qu.:0.00000   Class :character  \n Median :157.0   Median :2022   Median :0.00000   Mode  :character  \n Mean   :163.2   Mean   :2022   Mean   :0.02456                     \n 3rd Qu.:192.0   3rd Qu.:2022   3rd Qu.:0.00000                     \n Max.   :295.0   Max.   :2022   Max.   :3.00000                     \n NA's   :4                                                          \n\ndf_2022_error\n\n# A tibble: 18 × 8\n   sex   name    surname    age    cm  time error error_desc                    \n   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                         \n 1 M     Savier  Campbell    72 192    2022     1 duplicate                     \n 2 F     Tina    Adams        5  98.0  2022     1 duplicate                     \n 3 F     Abery   Allen       79 157    2022     1 duplicate                     \n 4 M     Adonnis Adams       30 192    2022     1 duplicate                     \n 5 M     Stephan Maier       41 186    2022     1 wrong surname                 \n 6 &lt;NA&gt;  Stephan huber       NA  NA    2022     1 wrong name                    \n 7 M     stephan Huber      186  41    2022     1 age/cm false, not capitalized…\n 8 M     Stephan huber      186  41    2022     1 age/cm false, not capitalized…\n 9 M     Stephan Huber       41 186    2022     1 duplicate                     \n10 M     Stephan Huber       41  NA    2022     1 duplicate, cm NA              \n11 F     Rosa    Huber        9  NA    2022     3 only age and sex given        \n12 &lt;NA&gt;  Rosa    Huber       NA 130    2022     3 age missing, sex unspecified  \n13 &lt;NA&gt;  Ignaz   Huber        7  NA    2022     2 cm missing, sex unspecified   \n14 &lt;NA&gt;  Zita    &lt;NA&gt;         6 110    2022     2 surname missing, sex unspecif…\n15 &lt;NA&gt;  Alois   Huber        3 295    2022     2 cm not possible, sex unspecif…\n16 F     Martina Huber      399 169    2022     2 age not possible              \n17 M     Stephan Huber       41 186    2022     0 no error                      \n18 M     Stephan Huber       41 186    2022     1 duplicate                     \n\n# Make a variable that contains the year of birth. Name the variable `born`\n# and new dataframe `df`.\ndf &lt;- df_2022 |&gt;\n  mutate(born = time - age)\n\n# Make a new variable that identifies each person by surname, name,\n# and their birth born. Name the variable `id`.\ndf &lt;- df |&gt;\n  mutate(id = paste(surname, name, born, sep = \"_\"))\n\n# How many different groups do exist?\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(id_num = cur_group_id()) |&gt;\n  ungroup()\n\nmax(df$id_num)\n\n[1] 1011\n\n# Show groups that exist more than once.\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(\n    dup_count = row_number(),\n    dup_sum   = n()\n  ) |&gt;\n  ungroup() |&gt;\n  arrange(id)\n\ndf |&gt; filter(dup_sum &gt; 1)\n\n# A tibble: 12 × 13\n   sex   name    surname    age    cm  time error error_desc   born id    id_num\n   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n 1 M     Adonnis Adams       30 192    2022     0 &lt;NA&gt;         1992 Adam…      1\n 2 M     Adonnis Adams       30 192    2022     1 duplicate    1992 Adam…      1\n 3 F     Tina    Adams        5  98.0  2022     1 duplicate    2017 Adam…     13\n 4 F     Tina    Adams        5  98.0  2022     0 &lt;NA&gt;         2017 Adam…     13\n 5 F     Abery   Allen       79 157    2022     0 &lt;NA&gt;         1943 Alle…     15\n 6 F     Abery   Allen       79 157    2022     1 duplicate    1943 Alle…     15\n 7 M     Savier  Campbell    72 192    2022     0 &lt;NA&gt;         1950 Camp…    100\n 8 M     Savier  Campbell    72 192    2022     1 duplicate    1950 Camp…    100\n 9 M     Stephan Huber       41 186    2022     1 duplicate    1981 Hube…    383\n10 M     Stephan Huber       41 186    2022     0 no error     1981 Hube…    383\n11 M     Stephan Huber       41 186    2022     1 duplicate    1981 Hube…    383\n12 M     Stephan Huber       41  NA    2022     1 duplicate,…  1981 Hube…    383\n# ℹ 2 more variables: dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\ndf |&gt; get_dupes(name, surname)\n\n# A tibble: 18 × 14\n   name  surname dupe_count sex     age    cm  time error error_desc  born id   \n   &lt;chr&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1 Step… Huber            4 M        41 186    2022     1 duplicate   1981 Hube…\n 2 Step… Huber            4 M        41 186    2022     0 no error    1981 Hube…\n 3 Step… Huber            4 M        41 186    2022     1 duplicate   1981 Hube…\n 4 Step… Huber            4 M        41  NA    2022     1 duplicate…  1981 Hube…\n 5 Abery Allen            2 F        79 157    2022     0 &lt;NA&gt;        1943 Alle…\n 6 Abery Allen            2 F        79 157    2022     1 duplicate   1943 Alle…\n 7 Adon… Adams            2 M        30 192    2022     0 &lt;NA&gt;        1992 Adam…\n 8 Adon… Adams            2 M        30 192    2022     1 duplicate   1992 Adam…\n 9 Merl… Miller           2 F        12 153.   2022     0 &lt;NA&gt;        2010 Mill…\n10 Merl… Miller           2 F         2  99.9  2022     0 &lt;NA&gt;        2020 Mill…\n11 Rosa  Huber            2 F         9  NA    2022     3 only age …  2013 Hube…\n12 Rosa  Huber            2 &lt;NA&gt;     NA 130    2022     3 age missi…    NA Hube…\n13 Savi… Campbe…          2 M        72 192    2022     0 &lt;NA&gt;        1950 Camp…\n14 Savi… Campbe…          2 M        72 192    2022     1 duplicate   1950 Camp…\n15 Step… huber            2 M       186  41    2022     1 age/cm fa…  1836 hube…\n16 Step… huber            2 &lt;NA&gt;     NA  NA    2022     1 wrong name    NA hube…\n17 Tina  Adams            2 F         5  98.0  2022     1 duplicate   2017 Adam…\n18 Tina  Adams            2 F         5  98.0  2022     0 &lt;NA&gt;        2017 Adam…\n# ℹ 3 more variables: id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\n# Make yourself familiar with the function `get_dupes()` from `janitor` package.\ndf |&gt; get_dupes()\n\nNo variable names specified - using all columns.\n\n\nNo duplicate combinations found of: sex, name, surname, age, cm, time, error, error_desc, born, ... and 4 other variables\n\n\n# A tibble: 0 × 14\n# ℹ 14 variables: sex &lt;chr&gt;, name &lt;chr&gt;, surname &lt;chr&gt;, age &lt;dbl&gt;, cm &lt;dbl&gt;,\n#   time &lt;dbl&gt;, error &lt;dbl&gt;, error_desc &lt;chr&gt;, born &lt;dbl&gt;, id &lt;chr&gt;,\n#   id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;, dupe_count &lt;int&gt;\n\ndf |&gt; get_dupes(surname, name)\n\n# A tibble: 18 × 14\n   surname name  dupe_count sex     age    cm  time error error_desc  born id   \n   &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1 Huber   Step…          4 M        41 186    2022     1 duplicate   1981 Hube…\n 2 Huber   Step…          4 M        41 186    2022     0 no error    1981 Hube…\n 3 Huber   Step…          4 M        41 186    2022     1 duplicate   1981 Hube…\n 4 Huber   Step…          4 M        41  NA    2022     1 duplicate…  1981 Hube…\n 5 Adams   Adon…          2 M        30 192    2022     0 &lt;NA&gt;        1992 Adam…\n 6 Adams   Adon…          2 M        30 192    2022     1 duplicate   1992 Adam…\n 7 Adams   Tina           2 F         5  98.0  2022     1 duplicate   2017 Adam…\n 8 Adams   Tina           2 F         5  98.0  2022     0 &lt;NA&gt;        2017 Adam…\n 9 Allen   Abery          2 F        79 157    2022     0 &lt;NA&gt;        1943 Alle…\n10 Allen   Abery          2 F        79 157    2022     1 duplicate   1943 Alle…\n11 Campbe… Savi…          2 M        72 192    2022     0 &lt;NA&gt;        1950 Camp…\n12 Campbe… Savi…          2 M        72 192    2022     1 duplicate   1950 Camp…\n13 Huber   Rosa           2 F         9  NA    2022     3 only age …  2013 Hube…\n14 Huber   Rosa           2 &lt;NA&gt;     NA 130    2022     3 age missi…    NA Hube…\n15 Miller  Merl…          2 F        12 153.   2022     0 &lt;NA&gt;        2010 Mill…\n16 Miller  Merl…          2 F         2  99.9  2022     0 &lt;NA&gt;        2020 Mill…\n17 huber   Step…          2 M       186  41    2022     1 age/cm fa…  1836 hube…\n18 huber   Step…          2 &lt;NA&gt;     NA  NA    2022     1 wrong name    NA hube…\n# ℹ 3 more variables: id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\ndf |&gt; get_dupes(id)\n\n# A tibble: 12 × 14\n   id    dupe_count sex   name  surname   age    cm  time error error_desc  born\n   &lt;chr&gt;      &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Hube…          4 M     Step… Huber      41 186    2022     1 duplicate   1981\n 2 Hube…          4 M     Step… Huber      41 186    2022     0 no error    1981\n 3 Hube…          4 M     Step… Huber      41 186    2022     1 duplicate   1981\n 4 Hube…          4 M     Step… Huber      41  NA    2022     1 duplicate…  1981\n 5 Adam…          2 M     Adon… Adams      30 192    2022     0 &lt;NA&gt;        1992\n 6 Adam…          2 M     Adon… Adams      30 192    2022     1 duplicate   1992\n 7 Adam…          2 F     Tina  Adams       5  98.0  2022     1 duplicate   2017\n 8 Adam…          2 F     Tina  Adams       5  98.0  2022     0 &lt;NA&gt;        2017\n 9 Alle…          2 F     Abery Allen      79 157    2022     0 &lt;NA&gt;        1943\n10 Alle…          2 F     Abery Allen      79 157    2022     1 duplicate   1943\n11 Camp…          2 M     Savi… Campbe…    72 192    2022     0 &lt;NA&gt;        1950\n12 Camp…          2 M     Savi… Campbe…    72 192    2022     1 duplicate   1950\n# ℹ 3 more variables: id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\ndf_uni &lt;- df |&gt;\n  arrange() |&gt;\n  distinct(id, .keep_all = TRUE)\n\ndf_uni_b &lt;- df |&gt;\n  arrange(desc(dup_count)) |&gt;\n  distinct(id, .keep_all = TRUE)\n\nanti_join(df, df_uni)\n\nJoining with `by = join_by(sex, name, surname, age, cm, time, error,\nerror_desc, born, id, id_num, dup_count, dup_sum)`\n\n\n# A tibble: 7 × 13\n  sex   name    surname    age    cm  time error error_desc    born id    id_num\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 M     Adonnis Adams       30 192    2022     1 duplicate     1992 Adam…      1\n2 F     Tina    Adams        5  98.0  2022     0 &lt;NA&gt;          2017 Adam…     13\n3 F     Abery   Allen       79 157    2022     1 duplicate     1943 Alle…     15\n4 M     Savier  Campbell    72 192    2022     1 duplicate     1950 Camp…    100\n5 M     Stephan Huber       41 186    2022     0 no error      1981 Hube…    383\n6 M     Stephan Huber       41 186    2022     1 duplicate     1981 Hube…    383\n7 M     Stephan Huber       41  NA    2022     1 duplicate, …  1981 Hube…    383\n# ℹ 2 more variables: dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\nanti_join(df, df_uni_b)\n\nJoining with `by = join_by(sex, name, surname, age, cm, time, error,\nerror_desc, born, id, id_num, dup_count, dup_sum)`\n\n\n# A tibble: 7 × 13\n  sex   name    surname    age    cm  time error error_desc  born id      id_num\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;\n1 M     Adonnis Adams       30 192    2022     0 &lt;NA&gt;        1992 Adams_…      1\n2 F     Tina    Adams        5  98.0  2022     1 duplicate   2017 Adams_…     13\n3 F     Abery   Allen       79 157    2022     0 &lt;NA&gt;        1943 Allen_…     15\n4 M     Savier  Campbell    72 192    2022     0 &lt;NA&gt;        1950 Campbe…    100\n5 M     Stephan Huber       41 186    2022     1 duplicate   1981 Huber_…    383\n6 M     Stephan Huber       41 186    2022     0 no error    1981 Huber_…    383\n7 M     Stephan Huber       41 186    2022     1 duplicate   1981 Huber_…    383\n# ℹ 2 more variables: dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, janitor, babynames, stringr))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#zipfs-law",
    "href": "80_exercises.html#zipfs-law",
    "title": "9  Collection of exercises",
    "section": "9.18 Zipf’s law",
    "text": "9.18 Zipf’s law\nThe data under investigation includes population information for various German cities, identified by the variable stadt, spanning the years 1970, 1987, and 2010. The variable status provides details about the legislative status of the cities, and the variable state (Bundesland) indicates the state in which each respective city is situated.\nPreamble\n\nSet your working directory.\n\n\nClear your global environment.\n\n\nInstall and load the following packages: ‘tidyverse’, ‘haven’, and ‘janitor’.\n\nRead in, inspect, and clean the data\n\nDownload and load the data, respectively, with the following code:\n\n\ndf &lt;- read_dta(\n  \"https://github.com/hubchev/courses/raw/main/dta/city.dta\",\n  encoding = \"latin1\"\n) |&gt;\n  as_tibble()\n\nIf that is not working, you can also download the data from ILIAS, save it in your working directory and load it from there with:\nload(\"city.RData\")\n\nShow the first six and the last six observations of the dataset df.\nHow many observations (rows) and variables (columns) are in the dataset?\nShow for all numerical variables the summary statistics including the mean, median, minimum, and the maximum.\nRename the variable stadt to city.\nRemove the variables pop1970 and pop1987.\nReplicate the following table which contains some summary statistics.\n\n\n\n# A tibble: 17 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Wrttemberg                 7580            7580\n 2 Baden-Württemberg               23680.        7837917\n 3 Bayern                          23996.        7558677\n 4 Berlin                        3292365         3292365\n 5 Brandenburg                     18472.        1865632\n 6 Bremen                         325432.         650863\n 7 Hamburg                       1706696         1706696\n 8 Hessen                          22996.        5036121\n 9 Mecklenburg-Vorpommern          27034.         811005\n10 Niedersachsen                   24107.        6219515\n11 Nordrhein-Westfalen             47465.       18036727\n12 Rheinland-Pfalz                 25644.        1871995\n13 Saarland                           NA              NA\n14 Sachsen                         27788.        2973351\n15 Sachsen-Anhalt                  21212.        1993915\n16 Schleswig-Holstein              24157.        1739269\n17 Th_ringen                       29192.        1167692\n\n\n\nThe states “Baden-Wrttemberg” and “Th_ringen” are falsely pronounced. Correct the names and regenerate the summary statistics table presented above. Your result should look like this:\n\n\n\n# A tibble: 16 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Württemberg               23631.        7845497\n 2 Bayern                          23996.        7558677\n 3 Berlin                        3292365         3292365\n 4 Brandenburg                     18472.        1865632\n 5 Bremen                         325432.         650863\n 6 Hamburg                       1706696         1706696\n 7 Hessen                          22996.        5036121\n 8 Mecklenburg-Vorpommern          27034.         811005\n 9 Niedersachsen                   24107.        6219515\n10 Nordrhein-Westfalen             47465.       18036727\n11 Rheinland-Pfalz                 25644.        1871995\n12 Saarland                           NA              NA\n13 Sachsen                         27788.        2973351\n14 Sachsen-Anhalt                  21212.        1993915\n15 Schleswig-Holstein              24157.        1739269\n16 Thüringen                       29192.        1167692\n\n\n\nTo investigate the reason for observing only NAs for Saarland, examine all cities within Saarland. Therefore, please display all observations for cities in Saarland in the Console, as illustrated below.\n\n\n\n# A tibble: 47 × 5\n   city                status  state    pop2011 rankX\n   &lt;chr&gt;               &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 Perl                Commune Saarland    7775  2003\n 2 Freisen             Commune Saarland    8270  1894\n 3 Großrosseln         Commune Saarland    8403  1868\n 4 Nonnweiler          Commune Saarland    8844  1775\n 5 Nalbach             Commune Saarland    9302  1678\n 6 Wallerfangen        Commune Saarland    9542  1642\n 7 Kirkel              Commune Saarland   10058  1541\n 8 Merchweiler         Commune Saarland   10219  1515\n 9 Nohfelden           Commune Saarland   10247  1511\n10 Friedrichsthal      City    Saarland   10409  1489\n11 Marpingen           Commune Saarland   10590  1461\n12 Mandelbachtal       Commune Saarland   11107  1390\n13 Kleinblittersdorf   Commune Saarland   11396  1354\n14 Überherrn           Commune Saarland   11655  1317\n15 Mettlach            Commune Saarland   12180  1241\n16 Tholey              Commune Saarland   12385  1217\n17 Saarwellingen       Commune Saarland   13348  1104\n18 Quierschied         Commune Saarland   13506  1088\n19 Spiesen-Elversberg  Commune Saarland   13509  1086\n20 Rehlingen-Siersburg Commune Saarland   14526   996\n21 Riegelsberg         Commune Saarland   14763   982\n22 Ottweiler           City    Saarland   14934   969\n23 Beckingen           Commune Saarland   15355   931\n24 Losheim am See      Commune Saarland   15906   887\n25 Schiffweiler        Commune Saarland   15993   882\n26 Wadern              City    Saarland   16181   874\n27 Schmelz             Commune Saarland   16435   857\n28 Sulzbach/Saar       City    Saarland   16591   849\n29 Illingen            Commune Saarland   16978   827\n30 Schwalbach          Commune Saarland   17320   812\n31 Eppelborn           Commune Saarland   17726   793\n32 Wadgassen           Commune Saarland   17885   785\n33 Bexbach             City    Saarland   18038   777\n34 Heusweiler          Commune Saarland   18201   762\n35 Püttlingen          City    Saarland   19134   718\n36 Lebach              City    Saarland   19484   701\n37 Dillingen/Saar      City    Saarland   20253   654\n38 Blieskastel         City    Saarland   21255   601\n39 St. Wendel          City    Saarland   26220   460\n40 Merzig              City    Saarland   29727   392\n41 Saarlouis           City    Saarland   34479   323\n42 St. Ingbert         City    Saarland   36645   299\n43 Völklingen          City    Saarland   38809   279\n44 Homburg             City    Saarland   41502   247\n45 Neunkirchen         City    Saarland   46172   206\n46 Saarbrücken         City    Saarland  175853    43\n47 Perl                Commune Saarland      NA    NA\n\n\n\nWith reference to the table above, we have identified an entry for the city of Perl that solely consists of NAs. This city is duplicated in the dataset, appearing at positions 1 and 47. The latter duplicate contains only NAs and can be safely removed without the loss of valuable information. Please eliminate this duplification and regenerate the list of all cities in the Saarland.\nCalculate the total population and average size of cities in Saarland.\nCheck if any other city is recorded more than once in the dataset. To do so, reproduce the table below.\n\n\n\n# A tibble: 23 × 5\n# Groups:   city [11]\n   city        status                  state               pop2011 unique_count\n   &lt;chr&gt;       &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt;        &lt;int&gt;\n 1 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 2 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 3 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 4 Brühl       Commune                 Baden-Württemberg     13805            2\n 5 Brühl       City                    Nordrhein-Westfalen   43568            2\n 6 Erbach      City                    Baden-Württemberg     13024            2\n 7 Erbach      City                    Hessen                13245            2\n 8 Fürth       City with County Rights Bayern               115613            2\n 9 Fürth       Commune                 Hessen                10481            2\n10 Lichtenau   City                    Nordrhein-Westfalen   10473            2\n11 Lichtenau   Commune                 Sachsen                7544            2\n12 Münster     Commune                 Hessen                14071            2\n13 Münster     City with County Rights Nordrhein-Westfalen  289576            2\n14 Neunkirchen Commune                 Nordrhein-Westfalen   13930            2\n15 Neunkirchen City                    Saarland              46172            2\n16 Neuried     Commune                 Baden-Württemberg      9383            2\n17 Neuried     Commune                 Bayern                 8277            2\n18 Petersberg  Commune                 Hessen                14766            2\n19 Petersberg  Commune                 Sachsen-Anhalt        10097            2\n20 Senden      City                    Bayern                21560            2\n21 Senden      Commune                 Nordrhein-Westfalen   19976            2\n22 Staufenberg City                    Hessen                 8114            2\n23 Staufenberg Commune                 Niedersachsen          7983            2\n\n\n\nThe table indicates that the city of Bonn appears three times in the dataset, and all three observations contain identical information. Thus, remove two of these observations to ensure that Bonn is uniquely represented in the dataset. All other cities that occur more than once in the data are situated in different states. That means, these are distinct cities that coincidentally share the same name.\n\nData analysis (Zipf’s Law)\n*Note: If you have failed to solve the data cleaning tasks above, you can download the cleaned data from ILIAS, save it in your working directory and load it from there with: load(\"city_clean.RData\")\nIn the following, you aim to examine the validity of Zipf’s Law for Germany. Zipf’s Law postulates how the size of cities is distributed. The “law” states that there is a special relationship between the size of a city and the rank it occupies in a series sorted by city size. In the estimation equation \\[\n\\log(M_j) = c - q \\log(R_j),\n\\] the law postulates a coefficient of \\(( q=1 )\\). \\(c\\) is a constant; \\(M_j\\) is the size of city \\(j\\); \\(R_j\\) is the rank that city \\(j\\) occupies in a series sorted by city size.\n\n\n\nCreate a variable named rank that includes a ranking of cities based on the population size in the year 2011. Therefore, Berlin should have a rank of 1, Hamburg a rank of 2, Munich a rank of 3, and so on.\nNote: If you cannot solve this task, use the variable rankX as a substitute for the variable rank that was not generated.\n\n\n# A tibble: 6 × 3\n  city                    pop2011  rank\n  &lt;chr&gt;                     &lt;dbl&gt; &lt;int&gt;\n1 Berlin                  3292365     1\n2 Hamburg                 1706696     2\n3 München [Munich]        1348335     3\n4 Köln [Cologne]          1005775     4\n5 Frankfurt am Main        667925     5\n6 Düsseldorf [Dusseldorf]  586291     6\n\n\n\nCalculate the Pearson Correlation Coefficient of the two variables pop2011 and rank. The result should be:\n\n\n\n[1] -0.2948903\n\n\n\nCreate a scatter plot. On the x-axis, plot the variable rank, and on the y-axis, plot pop2011. Add a regression line representing the observed relationship to the same scatter plot.\n\n\n\n\n\n\n\n\n\n\n\nLogarithmize the variables rank and pop2011. Title the new variables as lnrank and lnpop2011, respectively. Here is a snapshot of the resulting variables:\n\n\n\n# A tibble: 6 × 5\n  city                     rank lnrank pop2011 lnpop2011\n  &lt;chr&gt;                   &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1 Berlin                      1  0     3292365      15.0\n2 Hamburg                     2  0.693 1706696      14.4\n3 München [Munich]            3  1.10  1348335      14.1\n4 Köln [Cologne]              4  1.39  1005775      13.8\n5 Frankfurt am Main           5  1.61   667925      13.4\n6 Düsseldorf [Dusseldorf]     6  1.79   586291      13.3\n\n\n\nCalculate the Pearson Correlation Coefficient of the two variables lnpop2011 and lnrank. The result should be:\n\n\n\n[1] -0.9990053\n\n\n\nCreate a scatter plot. On the x-axis, plot the variable lnrank, and on the y-axis, plot lnpop2011. Add a regression line representing the observed relationship to the same scatter plot. Additionally, add a title and label the axes like is shown here:\n\n\n\n\n\n\n\n\n\n\n\nNow, test the relationship postulated in Zipf’s Law. Regress the logarithmic city size in the year 2011 on the logarithmic rank of a city in a series sorted by city size. Briefly interpret the results, addressing the coefficient of determination. Show the regression results. Here is one way to present the results of the regression (Note: The way how you present your regression results do not matter):\n\n\n\n\nCall:\nlm(formula = lnpop2011 ~ lnrank, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.28015 -0.01879  0.01083  0.02005  0.25973 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14.947859   0.005141    2908   &lt;2e-16 ***\nlnrank      -0.780259   0.000766   -1019   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03454 on 2067 degrees of freedom\nMultiple R-squared:  0.998, Adjusted R-squared:  0.998 \nF-statistic: 1.038e+06 on 1 and 2067 DF,  p-value: &lt; 2.2e-16\n\n\n\nExplain the following lines of code.\n\n\ndf &lt;- df |&gt;\n  mutate(prediction = predict(zipf, newdata = df)) |&gt;\n  mutate(pred_pop = exp(prediction))\ndf |&gt;\n  select(city, pop2011, pred_pop) |&gt;\n  filter(city == \"Regensburg\")\n\n# A tibble: 1 × 3\n  city       pop2011 pred_pop\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Regensburg  135403  134194.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, arrange, as_tibble, c, case_when, cor, desc, dim, exp, filter, geom_point, geom_smooth, ggplot, group_by, head, is.na, labs, lm, log, mean, mutate, n, predict, print, read_dta, rename, row_number, save, select, starts_with, sum, summarise, summary, tail, ungroup.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\nsuppressMessages(pacman::p_unload(all))\n# setwd(\"~/Dropbox/hsf/exams/24-01/Rmd\")\n\nrm(list = ls())\n\npacman::p_load(tidyverse, haven, janitor, jtools)\n\ndf &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/city.dta\",\n  encoding = \"latin1\"\n) |&gt;\n  as_tibble()\n\nhead(df)\ntail(df)\n\ndim(df)\n\nsummary(df)\n\ndf &lt;- df |&gt;\n  rename(city = stadt)\n\ndf &lt;- df |&gt;\n  select(-pop1970, -pop1987)\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\ndf &lt;- df |&gt;\n  mutate(state = case_when(\n    state == \"Baden-Wrttemberg\" ~ \"Baden-Württemberg\",\n    state == \"Th_ringen\" ~ \"Thüringen\",\n    TRUE ~ state\n  ))\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\ndf &lt;- df |&gt;\n  filter(!(city == \"Perl\" & is.na(pop2011)))\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\ndf |&gt;\n  group_by(city) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n\ndf &lt;- df |&gt;\n  group_by(city, state) |&gt;\n  mutate(n_row = row_number()) |&gt;\n  filter(n_row == 1) |&gt;\n  select(-n_row)\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\nsave(df, file = \"city_clean.RData\")\n\ndf &lt;- df |&gt;\n  ungroup() |&gt;\n  arrange(desc(pop2011)) |&gt;\n  mutate(rank = row_number())\n\ndf |&gt;\n  select(-rankX, -status, -state) |&gt;\n  head()\n\n\ncor(df$pop2011, df$rank, method = c(\"pearson\"))\n\nggplot(df, aes(x = rank, y = pop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\")\n\ndf &lt;- df |&gt;\n  mutate(lnrank = log(rank)) |&gt;\n  mutate(lnpop2011 = log(pop2011))\n\ndf |&gt;\n  select(city, rank, lnrank, pop2011, lnpop2011) |&gt;\n  head()\n\n\ncor(df$lnpop2011, df$lnrank, method = c(\"pearson\"))\n\nggplot(df, aes(x = lnrank, y = lnpop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Scatterplot with Regression Line\",\n    x = \"lnrank (Logarithmized Rank)\",\n    y = \"lnpop2011 (Logarithmized Population 2011)\"\n  )\n\nzipf &lt;- lm(lnpop2011 ~ lnrank, data = df)\nsummary(zipf)\n\ndf &lt;- df |&gt;\n  mutate(prediction = predict(zipf, newdata = df)) |&gt;\n  mutate(pred_pop = exp(prediction))\ndf |&gt;\n  select(city, pop2011, pred_pop) |&gt;\n  filter(city == \"Regensburg\")\n\nsuppressMessages(pacman::p_unload(tidyverse, haven, janitor, jtools))\n\n# rmarkdown::render(\"24-01_dsda.Rmd\", \"all\")\n\n# knitr::purl(input = \"24-01_dsda.Rmd\", output = \"24-01_dsda_solution.R\",documentation = 0)\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\nsuppressMessages(pacman::p_unload(all))\n# setwd(\"~/Dropbox/hsf/exams/24-01/Rmd\")\n\nrm(list = ls())\n\npacman::p_load(tidyverse, haven, janitor, jtools)\n\ndf &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/city.dta\",\n  encoding = \"latin1\"\n) |&gt;\n  as_tibble()\n\nhead(df)\n\n# A tibble: 6 × 7\n  stadt              status  state              pop1970 pop1987 pop2011 rankX\n  &lt;chr&gt;              &lt;chr&gt;   &lt;chr&gt;                &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Vohenstrauß        City    Bayern                7349    7059    7500  2069\n2 Stockstadt a. Main Commune Bayern                6416    6615    7504  2068\n3 Jesteburg          Commune Niedersachsen         4141    5818    7510  2067\n4 Bordesholm         Commune Schleswig-Holstein    6011    6726    7513  2066\n5 Herrieden          City    Bayern                5631    6250    7516  2065\n6 Weida              City    Th_ringen               NA      NA    7522  2064\n\ntail(df)\n\n# A tibble: 6 × 7\n  stadt             status                  state  pop1970 pop1987 pop2011 rankX\n  &lt;chr&gt;             &lt;chr&gt;                   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Frankfurt am Main City with County Rights Hessen  699297  618266  667925     5\n2 Köln [Cologne]    City with County Rights Nordr…  994705  928309 1005775     4\n3 München [Munich]  City with County Rights Bayern 1293599 1185421 1348335     3\n4 Hamburg           City with County Rights Hambu… 1793823 1592770 1706696     2\n5 Berlin            City with County Rights Berlin 3210000 3260000 3292365     1\n6 Perl              Commune                 Saarl…      NA      NA      NA    NA\n\ndim(df)\n\n[1] 2072    7\n\nsummary(df)\n\n    stadt              status             state              pop1970       \n Length:2072        Length:2072        Length:2072        Min.   :   1604  \n Class :character   Class :character   Class :character   1st Qu.:   8149  \n Mode  :character   Mode  :character   Mode  :character   Median :  11912  \n                                                          Mean   :  30504  \n                                                          3rd Qu.:  21318  \n                                                          Max.   :3210000  \n                                                          NA's   :355      \n    pop1987           pop2011            rankX       \n Min.   :   4003   Min.   :   7500   Min.   :   1.0  \n 1st Qu.:   9194   1st Qu.:   9998   1st Qu.: 516.5  \n Median :  13118   Median :  13937   Median :1034.0  \n Mean   :  30854   Mean   :  30772   Mean   :1034.0  \n 3rd Qu.:  23074   3rd Qu.:  24096   3rd Qu.:1551.5  \n Max.   :3260000   Max.   :3292365   Max.   :2069.0  \n NA's   :248       NA's   :1         NA's   :1       \n\ndf &lt;- df |&gt;\n  rename(city = stadt)\n\ndf &lt;- df |&gt;\n  select(-pop1970, -pop1987)\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\n# A tibble: 17 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Wrttemberg                 7580            7580\n 2 Baden-Württemberg               23680.        7837917\n 3 Bayern                          23996.        7558677\n 4 Berlin                        3292365         3292365\n 5 Brandenburg                     18472.        1865632\n 6 Bremen                         325432.         650863\n 7 Hamburg                       1706696         1706696\n 8 Hessen                          22996.        5036121\n 9 Mecklenburg-Vorpommern          27034.         811005\n10 Niedersachsen                   24107.        6219515\n11 Nordrhein-Westfalen             47465.       18036727\n12 Rheinland-Pfalz                 25644.        1871995\n13 Saarland                           NA              NA\n14 Sachsen                         27788.        2973351\n15 Sachsen-Anhalt                  21212.        1993915\n16 Schleswig-Holstein              24157.        1739269\n17 Th_ringen                       29192.        1167692\n\ndf &lt;- df |&gt;\n  mutate(state = case_when(\n    state == \"Baden-Wrttemberg\" ~ \"Baden-Württemberg\",\n    state == \"Th_ringen\" ~ \"Thüringen\",\n    TRUE ~ state\n  ))\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\n# A tibble: 16 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Württemberg               23631.        7845497\n 2 Bayern                          23996.        7558677\n 3 Berlin                        3292365         3292365\n 4 Brandenburg                     18472.        1865632\n 5 Bremen                         325432.         650863\n 6 Hamburg                       1706696         1706696\n 7 Hessen                          22996.        5036121\n 8 Mecklenburg-Vorpommern          27034.         811005\n 9 Niedersachsen                   24107.        6219515\n10 Nordrhein-Westfalen             47465.       18036727\n11 Rheinland-Pfalz                 25644.        1871995\n12 Saarland                           NA              NA\n13 Sachsen                         27788.        2973351\n14 Sachsen-Anhalt                  21212.        1993915\n15 Schleswig-Holstein              24157.        1739269\n16 Thüringen                       29192.        1167692\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\n# A tibble: 47 × 5\n   city                status  state    pop2011 rankX\n   &lt;chr&gt;               &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 Perl                Commune Saarland    7775  2003\n 2 Freisen             Commune Saarland    8270  1894\n 3 Großrosseln         Commune Saarland    8403  1868\n 4 Nonnweiler          Commune Saarland    8844  1775\n 5 Nalbach             Commune Saarland    9302  1678\n 6 Wallerfangen        Commune Saarland    9542  1642\n 7 Kirkel              Commune Saarland   10058  1541\n 8 Merchweiler         Commune Saarland   10219  1515\n 9 Nohfelden           Commune Saarland   10247  1511\n10 Friedrichsthal      City    Saarland   10409  1489\n11 Marpingen           Commune Saarland   10590  1461\n12 Mandelbachtal       Commune Saarland   11107  1390\n13 Kleinblittersdorf   Commune Saarland   11396  1354\n14 Überherrn           Commune Saarland   11655  1317\n15 Mettlach            Commune Saarland   12180  1241\n16 Tholey              Commune Saarland   12385  1217\n17 Saarwellingen       Commune Saarland   13348  1104\n18 Quierschied         Commune Saarland   13506  1088\n19 Spiesen-Elversberg  Commune Saarland   13509  1086\n20 Rehlingen-Siersburg Commune Saarland   14526   996\n21 Riegelsberg         Commune Saarland   14763   982\n22 Ottweiler           City    Saarland   14934   969\n23 Beckingen           Commune Saarland   15355   931\n24 Losheim am See      Commune Saarland   15906   887\n25 Schiffweiler        Commune Saarland   15993   882\n26 Wadern              City    Saarland   16181   874\n27 Schmelz             Commune Saarland   16435   857\n28 Sulzbach/Saar       City    Saarland   16591   849\n29 Illingen            Commune Saarland   16978   827\n30 Schwalbach          Commune Saarland   17320   812\n31 Eppelborn           Commune Saarland   17726   793\n32 Wadgassen           Commune Saarland   17885   785\n33 Bexbach             City    Saarland   18038   777\n34 Heusweiler          Commune Saarland   18201   762\n35 Püttlingen          City    Saarland   19134   718\n36 Lebach              City    Saarland   19484   701\n37 Dillingen/Saar      City    Saarland   20253   654\n38 Blieskastel         City    Saarland   21255   601\n39 St. Wendel          City    Saarland   26220   460\n40 Merzig              City    Saarland   29727   392\n41 Saarlouis           City    Saarland   34479   323\n42 St. Ingbert         City    Saarland   36645   299\n43 Völklingen          City    Saarland   38809   279\n44 Homburg             City    Saarland   41502   247\n45 Neunkirchen         City    Saarland   46172   206\n46 Saarbrücken         City    Saarland  175853    43\n47 Perl                Commune Saarland      NA    NA\n\ndf &lt;- df |&gt;\n  filter(!(city == \"Perl\" & is.na(pop2011)))\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\n# A tibble: 46 × 5\n   city                status  state    pop2011 rankX\n   &lt;chr&gt;               &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 Perl                Commune Saarland    7775  2003\n 2 Freisen             Commune Saarland    8270  1894\n 3 Großrosseln         Commune Saarland    8403  1868\n 4 Nonnweiler          Commune Saarland    8844  1775\n 5 Nalbach             Commune Saarland    9302  1678\n 6 Wallerfangen        Commune Saarland    9542  1642\n 7 Kirkel              Commune Saarland   10058  1541\n 8 Merchweiler         Commune Saarland   10219  1515\n 9 Nohfelden           Commune Saarland   10247  1511\n10 Friedrichsthal      City    Saarland   10409  1489\n11 Marpingen           Commune Saarland   10590  1461\n12 Mandelbachtal       Commune Saarland   11107  1390\n13 Kleinblittersdorf   Commune Saarland   11396  1354\n14 Überherrn           Commune Saarland   11655  1317\n15 Mettlach            Commune Saarland   12180  1241\n16 Tholey              Commune Saarland   12385  1217\n17 Saarwellingen       Commune Saarland   13348  1104\n18 Quierschied         Commune Saarland   13506  1088\n19 Spiesen-Elversberg  Commune Saarland   13509  1086\n20 Rehlingen-Siersburg Commune Saarland   14526   996\n21 Riegelsberg         Commune Saarland   14763   982\n22 Ottweiler           City    Saarland   14934   969\n23 Beckingen           Commune Saarland   15355   931\n24 Losheim am See      Commune Saarland   15906   887\n25 Schiffweiler        Commune Saarland   15993   882\n26 Wadern              City    Saarland   16181   874\n27 Schmelz             Commune Saarland   16435   857\n28 Sulzbach/Saar       City    Saarland   16591   849\n29 Illingen            Commune Saarland   16978   827\n30 Schwalbach          Commune Saarland   17320   812\n31 Eppelborn           Commune Saarland   17726   793\n32 Wadgassen           Commune Saarland   17885   785\n33 Bexbach             City    Saarland   18038   777\n34 Heusweiler          Commune Saarland   18201   762\n35 Püttlingen          City    Saarland   19134   718\n36 Lebach              City    Saarland   19484   701\n37 Dillingen/Saar      City    Saarland   20253   654\n38 Blieskastel         City    Saarland   21255   601\n39 St. Wendel          City    Saarland   26220   460\n40 Merzig              City    Saarland   29727   392\n41 Saarlouis           City    Saarland   34479   323\n42 St. Ingbert         City    Saarland   36645   299\n43 Völklingen          City    Saarland   38809   279\n44 Homburg             City    Saarland   41502   247\n45 Neunkirchen         City    Saarland   46172   206\n46 Saarbrücken         City    Saarland  175853    43\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\n# A tibble: 1 × 2\n  `mean(pop2011)` `sum(pop2011)`\n            &lt;dbl&gt;          &lt;dbl&gt;\n1          20850.         959110\n\ndf |&gt;\n  group_by(city) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n# A tibble: 23 × 5\n# Groups:   city [11]\n   city        status                  state               pop2011 unique_count\n   &lt;chr&gt;       &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt;        &lt;int&gt;\n 1 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 2 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 3 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 4 Brühl       Commune                 Baden-Württemberg     13805            2\n 5 Brühl       City                    Nordrhein-Westfalen   43568            2\n 6 Erbach      City                    Baden-Württemberg     13024            2\n 7 Erbach      City                    Hessen                13245            2\n 8 Fürth       City with County Rights Bayern               115613            2\n 9 Fürth       Commune                 Hessen                10481            2\n10 Lichtenau   City                    Nordrhein-Westfalen   10473            2\n11 Lichtenau   Commune                 Sachsen                7544            2\n12 Münster     Commune                 Hessen                14071            2\n13 Münster     City with County Rights Nordrhein-Westfalen  289576            2\n14 Neunkirchen Commune                 Nordrhein-Westfalen   13930            2\n15 Neunkirchen City                    Saarland              46172            2\n16 Neuried     Commune                 Baden-Württemberg      9383            2\n17 Neuried     Commune                 Bayern                 8277            2\n18 Petersberg  Commune                 Hessen                14766            2\n19 Petersberg  Commune                 Sachsen-Anhalt        10097            2\n20 Senden      City                    Bayern                21560            2\n21 Senden      Commune                 Nordrhein-Westfalen   19976            2\n22 Staufenberg City                    Hessen                 8114            2\n23 Staufenberg Commune                 Niedersachsen          7983            2\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n# A tibble: 3 × 5\n# Groups:   city, state [1]\n  city  status                  state               pop2011 unique_count\n  &lt;chr&gt; &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt;        &lt;int&gt;\n1 Bonn  City with County Rights Nordrhein-Westfalen  305765            3\n2 Bonn  City with County Rights Nordrhein-Westfalen  305765            3\n3 Bonn  City with County Rights Nordrhein-Westfalen  305765            3\n\ndf &lt;- df |&gt;\n  group_by(city, state) |&gt;\n  mutate(n_row = row_number()) |&gt;\n  filter(n_row == 1) |&gt;\n  select(-n_row)\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n# A tibble: 0 × 5\n# Groups:   city, state [0]\n# ℹ 5 variables: city &lt;chr&gt;, status &lt;chr&gt;, state &lt;chr&gt;, pop2011 &lt;dbl&gt;,\n#   unique_count &lt;int&gt;\n\nsave(df, file = \"city_clean.RData\")\n\ndf &lt;- df |&gt;\n  ungroup() |&gt;\n  arrange(desc(pop2011)) |&gt;\n  mutate(rank = row_number())\n\ndf |&gt;\n  select(-rankX, -status, -state) |&gt;\n  head()\n\n# A tibble: 6 × 3\n  city                    pop2011  rank\n  &lt;chr&gt;                     &lt;dbl&gt; &lt;int&gt;\n1 Berlin                  3292365     1\n2 Hamburg                 1706696     2\n3 München [Munich]        1348335     3\n4 Köln [Cologne]          1005775     4\n5 Frankfurt am Main        667925     5\n6 Düsseldorf [Dusseldorf]  586291     6\n\ncor(df$pop2011, df$rank, method = c(\"pearson\"))\n\n[1] -0.2948903\n\nggplot(df, aes(x = rank, y = pop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\ndf &lt;- df |&gt;\n  mutate(lnrank = log(rank)) |&gt;\n  mutate(lnpop2011 = log(pop2011))\n\ndf |&gt;\n  select(city, rank, lnrank, pop2011, lnpop2011) |&gt;\n  head()\n\n# A tibble: 6 × 5\n  city                     rank lnrank pop2011 lnpop2011\n  &lt;chr&gt;                   &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1 Berlin                      1  0     3292365      15.0\n2 Hamburg                     2  0.693 1706696      14.4\n3 München [Munich]            3  1.10  1348335      14.1\n4 Köln [Cologne]              4  1.39  1005775      13.8\n5 Frankfurt am Main           5  1.61   667925      13.4\n6 Düsseldorf [Dusseldorf]     6  1.79   586291      13.3\n\ncor(df$lnpop2011, df$lnrank, method = c(\"pearson\"))\n\n[1] -0.9990053\n\nggplot(df, aes(x = lnrank, y = lnpop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Scatterplot with Regression Line\",\n    x = \"lnrank (Logarithmized Rank)\",\n    y = \"lnpop2011 (Logarithmized Population 2011)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nzipf &lt;- lm(lnpop2011 ~ lnrank, data = df)\nsummary(zipf)\n\n\nCall:\nlm(formula = lnpop2011 ~ lnrank, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.28015 -0.01879  0.01083  0.02005  0.25973 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14.947859   0.005141    2908   &lt;2e-16 ***\nlnrank      -0.780259   0.000766   -1019   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03454 on 2067 degrees of freedom\nMultiple R-squared:  0.998, Adjusted R-squared:  0.998 \nF-statistic: 1.038e+06 on 1 and 2067 DF,  p-value: &lt; 2.2e-16\n\ndf &lt;- df |&gt;\n  mutate(prediction = predict(zipf, newdata = df)) |&gt;\n  mutate(pred_pop = exp(prediction))\ndf |&gt;\n  select(city, pop2011, pred_pop) |&gt;\n  filter(city == \"Regensburg\")\n\n# A tibble: 1 × 3\n  city       pop2011 pred_pop\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Regensburg  135403  134194.\n\nsuppressMessages(pacman::p_unload(tidyverse, haven, janitor, jtools))\n\n# rmarkdown::render(\"24-01_dsda.Rmd\", \"all\")\n\n# knitr::purl(input = \"24-01_dsda.Rmd\", output = \"24-01_dsda_solution.R\",documentation = 0)\n\n\n\n\n\n\n\n\n\nFigure 9.1: The logo of the DatasauRus package\nWeight vs. Calories\nFigure 9.2: Ranking history: 1. FC Kaiserslautern\nFigure 9.3: Ranking history: 1. FC Köln\n\n\n\nHortaçsu, A., & Syverson, C. (2015). The ongoing evolution of US retail: A format tug-of-war. Journal of Economic Perspectives, 29(4), 89–112.",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  }
]