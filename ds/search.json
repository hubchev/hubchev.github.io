[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "How to Use R for Data Science",
    "section": "",
    "text": "Preface\n\nAbout R\nThe programming language R enables you to handle, visualize, and analyze data. It is compatible with various operating systems (Windows, Mac, Linux) and can do a lot of things better compared to other programs like Python, Stata, Eviews, SPSS, SAS, and Excel. R is open source, extensively utilized, and there are abundant resources available for learning it. These notes are just my five cents.\n\n\nAbout the cover of the notes\nData science is a buzzword that combines different fields of knowledge such as computer science, software engineering, informatics, database management, statistics, econometrics, business intelligence, and mathematics. However, there is no universally accepted definition of it and I think it is not important to define it precisely. Kelleher & Tierney (2018, p. 97) wrote “Data science is best understood as a partnership between a data scientist and a computer.” So data science is about embracing the power of computers for scientific, commercial or social purposes. Of course, empirical models and statistics play a role in gaining meaningful insights. The graphic on the cover page may illustrate that R combines four important fields, that are, data, science, computer, and statistics.\n\n\nAbout the notes\n\n\n\n\n\n\nA PDF version of these notes is available here.\n\n\n\nPlease note that while the PDF contains the same content, it has not been optimized for PDF format. Therefore, some parts may not appear as intended.\n\n\n\nThese notes aims to support my lecture at the HS Fresenius but are incomplete and no substitute for taking actively part in class.\nI hope you find this book helpful. Any feedback is both welcome and appreciated.\nThis is work in progress so please check for updates regularly.\nThese notes offer a curated collection of explanations, exercises, and tips to facilitate learning R without causing unnecessary frustration. However, these notes don’t aim to rival comprehensive textbooks such as Wickham & Grolemund (2023).\nThese notes are published under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. This means it can be reused, remixed, retained, revised and redistributed as long as appropriate credit is given to the authors. If you remix, or modify the original version of this open textbook, you must redistribute all versions of this open textbook under the same license. This script draws from the work of Navarro (2020), Muschelli & Jaffe (2022), Thulin (2021), and Ismay & Kim (2022) which is also published under the same license. \nI host the notes in a GitHub repo.\n\n\n\nStructure of these notes\n\n\n\n\n\n\n\nChapter\nExplanations\n\n\n\n\nGetting started with R\nLearn the basics everyone should know about R and RStudio, including how to install them.\n\n\nKickstart\nA quick start guide for beginners on how to dive into R, showcasing some of its capabilities.\n\n\nPitfalls\nDiscover common mistakes beginners often make and how to avoid them to save time on troubleshooting.\n\n\nAn interactive introduction using Swirl\nA hands-on tutorial on how to use the swirl package. This section is optional.\n\n\nWorking with R scripts\nLearn how to use R scripts and their benefits.\n\n\nManaging data\nLearn how to manipulate data in R.\n\n\nVisualizing data\nA quick guide on where to find resources to learn about creating graphical visualizations in R.\n\n\nCollection of exercises\nA set of exercises to practice R programming skills.\n\n\nAppendix\nA set of useful stuff that will help you to navigate through your file system, find the reight operator and function, or to learn some usefull shortcuts.\n\n\n\n\n\nAbout the author\n\n\n\n\n\n\nContact:\n\n\n\n\n\nProf. Dr. Stephan Huber\nHochschule Fresenius für Wirtschaft & Medien GmbH\nIm MediaPark 4c\n50670 Cologne\nOffice: 4e OG-3\nTelefon: +49 221 973199-523\nMail: stephan.huber@hs-fresenius.de\nPrivate homepage: www.hubchev.github.io\nGithub: https://github.com/hubchev\n\n\n\n\n\n\nFigure 1: Prof. Dr. Stephan Huber\n\n\n\n\n\n\nI am a Professor of International Economics and Data Science at HS Fresenius, holding a Diploma in Economics from the University of Regensburg and a Doctoral Degree (summa cum laude) from the University of Trier. I completed postgraduate studies at the Interdisciplinary Graduate Center of Excellence at the Institute for Labor Law and Industrial Relations in the European Union (IAAEU) in Trier. Prior to my current position, I worked as a research assistant to Prof. Dr. Dr. h.c. Joachim Möller at the University of Regensburg, a post-doc at the Leibniz Institute for East and Southeast European Studies (IOS) in Regensburg, and a freelancer at Charles University in Prague.\nThroughout my career, I have also worked as a lecturer at various institutions, including the TU Munich, the University of Regensburg, Saarland University, and the Universities of Applied Sciences in Frankfurt and Augsburg. Additionally, I have had the opportunity to teach abroad for the University of Cordoba in Spain, the University of Perugia in Italy, and the Petra Christian University in Surabaya, Indonesia. My published work can be found in international journals such as the Canadian Journal of Economics and the Stata Journal. For more information on my work, please visit my private homepage at hubchev.github.io.\nI was always fascinated by data and statistics. For example, in 1992 I could name all soccer players in Germany’s first division including how many goals they scored. Later, in 2003 I joined the introductory statistics course of Daniel Rösch. I learned among others that probabilities often play a role when analyzing data. I continued my data science journey with Harry Haupt’s Introductory Econometrics course, where I studied the infamous Jeffrey M. Wooldridge (2002) textbook. It got me hooked and so I took all the courses Rolf Tschernig offered at his chair of Econometrics, where I became a tutor at the University of Regensburg and a research assistant of Joachim Möller. Despite everything we did had to do with how to make sense out of data, we never actually used the term data science which is also absent in the more 850 pages long textbook by Wooldridge (2002). The book also remains silent about machine learning or artificial intelligence. These terms became popular only after I graduated. The Harvard Business Review article by Davenport & Patil (2012) who claimed that data scientist is “The Sexiest Job of the 21st Century” may have boosted the popularity.\nThe term “data scientist” has become remarkably popular, and many people are eager to adopt this title. Although I am a professor of data science, my professional identity is more like that of an applied, empirically-oriented international economist. My hesitation to adopt the title “data scientist” also stems from the deep respect I have developed through my interactions with econometricians and statisticians. Considering their in-depth expertise, I feel like a passionate amateur.\nUltimately, I poke around in data to find something interesting. Much like my ten-year-old younger self who analyzed soccer statistics to gain a deeper understanding of the sport. The only thing that has changed since then is that I know more promising methods and can efficiently use tools for data processing and data analysis.\n\n\n\nFigure 1: Prof. Dr. Stephan Huber\n\n\n\nDavenport, T. H., & Patil, D. (2012). Data scientist: The sexiest job of the 21st century. Harvard Business Review, 90(5), 70–76.\n\n\nIsmay, C., & Kim, A. Y. (2022). Statistical inference via data science: A ModernDive into R and the tidyverse. CRC Press. https://moderndive.com/\n\n\nKelleher, J. D., & Tierney, B. (2018). Data science. MIT Press.\n\n\nMuschelli, J., & Jaffe, A. (2022). Introduction to R for public health researchers. GitHub. https://github.com/muschellij2/intro_to_r\n\n\nNavarro, D. (2020). Learning statistics with r (Version 0.6). https://learningstatisticswithr.com\n\n\nThulin, M. (2021). Modern statistics with R: From wrangling and exploring data to inference and predictive modelling. Eos Chasma Press. https://www.modernstatisticswithr.com/\n\n\nWickham, H., & Grolemund, G. (2023). R for data science (2e). https://r4ds.hadley.nz/\n\n\nWooldridge, J. M. (2002). Introductory econometrics: A modern approach. In Delhi: Cengage Learnng (2nd ed.). South-Western.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01_install.html",
    "href": "01_install.html",
    "title": "1  …with R",
    "section": "",
    "text": "1.1 Why R?\nR is an open-source programming language that allows to analyse and manipulate data, create state-of-the-art graphics, and many more. It supports larger data sets, reads any type of data, and runs on multiple platforms (Windows, Mac, Linux) and CPU architectures (x86_64, arm64). R makes it easier to automate tasks, organize projects, ensure reproducibility, and find and fix errors, and anyone can contribute packages to improve its functionality. Moreover, the following points are worth to emphasize:",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#sec:whyR",
    "href": "01_install.html#sec:whyR",
    "title": "1  …with R",
    "section": "",
    "text": "R is an artist! Check out:\n\nThe R Graph Gallery\nR CHARTS by R CODER\n\nR is an employment insurance! Programming is a core skill in research, economics, and business. If you can write code, you have plenty of opportunities to earn a decent salary. R is one of the most widely used programming languages in the world today. It is used in almost every industry such as finance, banking, medicine or manufacturing. R is used for portfolio management, risk analytics in finance and banking industries. Even if you need to learn a new programming language later, knowing R makes it much easier to pick up another one.\nR uses the computer and computers are great! Doing statistics on a computer is faster, easier and more powerful than doing it by hand. Computers are an extension to your brain and can do repetitive tasks better and faster without making logical errors. The only reason to do statistical calculations with pencil and paper is for learning purposes.\nLow-code and no-code applications such as Excel are limited! Using spreadsheets software like Microsoft Excel for research can be problematic. It’s easy to lose track of operations, making the process difficult to oversee and document. Command-line programs are maybe not as easy to learn but offer a more straightforward approach that allows the results to be replicated easily.\nR is open source! Proprietary software expansive, support can only be provided by the copyright owner which means the software expires and you can’t do anything against it. Moreover, security issues cannot be checked as the source code is not available, and possibilities for customization are limited. R is yours and everybody can contribute to its success.\nR is big! When you download and install R, you get some basic packages, that contain functions that allow you to do already a lot of things. Beyond that, you can write your own packages or install user-written packages that extend your possibilities. With over 20,684 packages on the CRAN repository and many more available on GitHub and other platforms, R’s extensive library supports a wide variety of data science tasks. Its widespread use and open-source availability have cemented R as a standard tool in data science and ensured that there are multiple approaches to most data handling processes. These can be easily adopted.\n\n\n\n\n\n\n\nR has weaknesses\n\n\n\nFor newcomers to programming, the learning curve is rather flat at the beginning. One reason is that R tools are spread across many packages, which can overwhelm beginners. There is no centralized support and the helpful and active online community have different backgrounds. It can be difficult for beginners to find the right solution as there are often many different ways to tackle the same problem. Moreover, R can be slower than languages like Python, MATLAB, C/C++ or Java.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#howtolearnr",
    "href": "01_install.html#howtolearnr",
    "title": "1  …with R",
    "section": "1.2 How to learn R",
    "text": "1.2 How to learn R\nThere are many different approaches to learning R. It pretty much depends on your preferences, needs, goals, prerequisites and limitations. It is up to you to search and find a suitable way to achieve your learning goals. While I hope you find my notes helpful, I additionally provide in section Section 1.3 a list of other resources that are worth considering. To start with, I recommend my swirl courses that provide an interactive learning environment, see Chapter 4.\n\n\n\n\n\n\nMake your hands dirty!\n\n\n\nLearning a programming language can, like learning a foreign language, be daunting and frustrating. However, if you put in the effort and are not afraid to make mistakes, anybody can learn it. You don’t have to be a nerd. To have a guide next to you can help and speed up your progress significantly. The key is taking action and getting involved. I mean, do write code. Try to copy the code that you read here and elsewhere. Explore what the code does on your machine. Don’t be afraid to make errors. Your PC will not explode. In this paper, most of the code is written in a manner that allows you to effortlessly copy and reproduce the output on your PC. Take advantage of this opportunity and go for it! Hands-on practice is far more enjoyable than merely reading through the material.\n\n\n\n\n\nFigure 1.1: Play around with code\n\n\n\nSource: DEV Community on GitHub\n\n\n\nHere are some comments that may help you to learn efficiently:\n\nComputers need clear and precise instructions to work: They can’t handle mistakes or unclear directions. They are actually sort of stupid as they do not have an intuition. They just take you literally. Even small errors like a missing comma or an unclosed bracket can cause your code to not work. Computers do exactly what you tell them, no more and no less.\n\n\n\n\n\n\n\nComputers take you literally\n\n\n\n\n\nLet me illustrate what I mean: Suppose you send your grandfather the following message:\n\n“Let’s eat grandpa.”\n\nHe will probably understand that you’re inviting him to dinner. However, if you sent the same message to a computer, it would interpret the sentence literally due to the missing comma:\n\n“Let’s eat, grandpa.”\n\nThe comma makes all the difference in clarifying that you’re speaking to your grandpa, not about eating him! Similarly, in programming, an incorrectly placed comma can break your code or change the meaning of your code.\n\n\n\n\nCopy, paste, and tweak: While learning code from scratch is sometimes essential, you can speed up your work by modifying code that already exists. I call this the “copy, paste, and tweak” approach. While this is not the only way to learn code, it gets a job done quick, and it is fun, see Figure 1.1.\nHave a purpose when coding: Rather than learning to code for its own sake, it is more fun and you’ll probably learn faster when you have a goal in mind. Try to analyze data that you are interested in. Another good exercise is replicating a research paper.\nPractice is key: The best method to improving your coding skills is through lots of practice. Consequently, these notes give you plenty of exercises.\nUse ChatGPT: The usage of supporting tools is not forbidden. ChatGPT can help you to understand code and brainstorm solutions. However, it’s important to know that ChatGPT might suggest complex methods when there are shorter and more elegant solutions available Absolute beginners might find ChatGPT’s solutions overwhelming and have difficulties to tweak the proposed sketch of a solution. So, use it thoughtfully.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#sec-Rlearninglit",
    "href": "01_install.html#sec-Rlearninglit",
    "title": "1  …with R",
    "section": "1.3 Learning resources",
    "text": "1.3 Learning resources\nThousand of freely available books and resources exist. bookdown.org and the Big Book of R are two vast collections of links to R books that might verify my claim.\nIn RStudio you find in the right side at the bottom a panel that is called Help. There you find a lot of links, manuals, and references that offer you tons of resources to learn R for free including: education.rstudio.com and Links for Getting Help with R. At the top right of RStudio you find a panel called tutorial. Here you can install the learnr package that offers some nice interactive tutorials.\nSince you may feel overwhelmed by the number of resources, I would like to highlight some books:\n\n\n\n\nFigure 1.2: A collection of textbooks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWickham & Grolemund (2023): R for Data Science: Import, Tidy, Transform, Visualize, and Model Data is the most popular source to learn R. It focuses on introducing the tidyverse package and is freely available online.\nHealy (2018): Data Visualization: A Practical Introduction is a hands-on introduction to the principles and practice of looking at and presenting data using R and ggplot.\nIrizarry (2022): Introduction to Data Science: Data Analysis and Prediction Algorithms With R is a complete, up to date, and applied introduction.\nVenables et al. (2022) An Introduction to R: Notes on R: A Programming Environment for Data Analysis and Graphics is a manual from the R Core Development Team that shows how to use R without having to install and load additional packages.\nNeth (2023): Data Science for Psychologists is a comprehensive introduction to R and data science for non experts of both programming and data science. It uses a variety of data types and includes many examples and exercises.\nKabacoff (2024): Modern Data Visualization with R teaches how to create graphs from scratch providing a lot of examples that you can copy, paste and tweak.\n\nSome other sources that are worth mentioning are these:\n\nThe search engine www.rseek.org is R specific and often better than www.google.com as it only searches for content that has to do with the programming language R.\nOn rdocumentation.org you can find the complete documentation of all R packages.\nMany find these cheatsheets helpful.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#what-is-a-function-in-r",
    "href": "01_install.html#what-is-a-function-in-r",
    "title": "1  …with R",
    "section": "1.4 What is a function in R?",
    "text": "1.4 What is a function in R?\nR is a functional programming language. If you want R to do something, you need to use a function. Or, in the words of Chambers (2017, p. 4):\n\n“Everything that happens is a function call.”\n\nFor example, when you like to exit R, you do it with the function q():\n&gt; q()\nSave workspace image? [y/n/c]: \nIf you want to specify what exactly you want R to do for you, you need to refer to the arguments of a function. For example, if you don’t want to be asked interactively what you want to do with your workspace (this is the place where you store all your objects, see section Section 1.5), you can do this with an argument that is part of the q() function:\n&gt; q(save = \"no\")\nTo learn more about a function, you can access its documentation by typing a question mark followed by the function name into the Console:\n?q()\nUnfortunately, the documentation can sometimes be a bit confusing for beginners in applied contexts. However, the documentation for all functions is structured similarly, typically featuring several key sections:\n\nDescription: A brief overview of what the function does.\nUsage: How to use the function, including the function name and its arguments.\nArguments: Detailed descriptions of each argument the function accepts, including what types of values are expected.\nDetails: Additional details about the function’s behavior and any important notes.\nExamples: Practical examples demonstrating how to use the function in various contexts.\n\nUnderstanding these sections can significantly enhance your ability to navigate and utilize R.\nAn excerpt of the R Documentation for the function q() is shown in Figure 1.3. Here, we observe that the function has three arguments that you can manipulate. If you do not specify any of these arguments explicitly, we see that by default, R sets the three arguments as shown.\n\n\n\nFigure 1.3: The R Documentation of q()",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#sec-objects",
    "href": "01_install.html#sec-objects",
    "title": "1  …with R",
    "section": "1.5 What are objects in R?",
    "text": "1.5 What are objects in R?\nR is an object oriented programming language. That means,\n\n“everything that exists in R is an object” (Chambers, 2017, p. 4).\n\nObjects are the fundamental units that are used to store information. Objects can be a variety of data types, including vectors, matrices, data frames, lists, functions. Moreover, you can store empirical results, tables, figures and many more in form of so-called objects. All objects are shown in the workspace which is shown in the Environment panel.\nIn R, you can show the content of the workspace with ls(). The function rm() allows to remove objects and with rm(list=ls()) you clear all objects from the workspace.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#sec-r-rstudio",
    "href": "01_install.html#sec-r-rstudio",
    "title": "1  …with R",
    "section": "1.6 What are R and RStudio?",
    "text": "1.6 What are R and RStudio?\nWhile R has a command line interface, there are multiple third-party graphical user interfaces available that improve the user experience a lot. The most successful graphical user interface or integrated development environment (IDE) is RStudio. Throughout this book, I will assume that you are using R via RStudio. First time users often confuse the two. At its simplest, R is like a car’s engine while RStudio is like a car’s dashboard as illustrated in Figure Figure 1.4.\n\n\n\nFigure 1.4: Analogy of difference between R and RStudio\n\n\n\n\n\n\nMore precisely, R is a functional programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. So just as the way of having access to a speedometer, rearview mirrors, and a navigation system makes driving much easier, using RStudio’s interface makes using R much easier as well.\nMuch as we don’t drive a car by interacting directly with the engine but rather by interacting with elements on the car’s dashboard, we won’t be using R directly but rather we will use RStudio’s interface. After you install R and RStudio on your computer, you’ll have two new programs (also called applications) you can open. We’ll always work in RStudio and not in the R application. Figure Figure 1.5 shows what icon you should be clicking on your computer.\n\n\n\nFigure 1.5: Icons of R versus RStudio on your computer\n\n\n\n\n\n\nAfter you open RStudio, you should see something similar to Figure Figure 1.6 where three or four panels dividing the screen.\n\n\n\nFigure 1.6: A sketch of RStudio interface to R\n\n\n\n\n\n\n\n\nThe Environment panel, where a list of all objects is shown.\nThe Files, Plots and Help panel, allow you to manage files, preview plots, and find help for different functions of R.\nThe Console panel, used for running code.\nThe Script panel, used for writing code.\n\n\n\n\n\n\n\nIf you don’t have panel number 4,\n\n\n\n\n\nopen it by opening an existing R-script or creating a new one. You can create a new on by clicking Ctrl+Shift+N (alternatively, you can use the menu: File\\(\\rightarrow\\)New File\\(\\rightarrow\\)R Script).\n\n\n\nThe Console panel will contain R’s startup message, which shows information about which version of R you’re running. My startup message at the time of writing was as follows:\n\n\n\n\n\n\n R version 4.3.3 (2024-02-29) -- \"Angel Food Cake\"\n Copyright (C) 2024 The R Foundation for Statistical Computing\n Platform: x86_64-pc-linux-gnu (64-bit)\n\n R is free software and comes with ABSOLUTELY NO WARRANTY.\n You are welcome to redistribute it under certain conditions.\n Type 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\n R is a collaborative project with many contributors.\n Type 'contributors()' for more information and\n 'citation()' on how to cite R or R packages in publications.\n\n Type 'demo()' for some demos, 'help()' for on-line help, or\n 'help.start()' for an HTML browser interface to help.\n Type 'q()' to quit R.\n\n\n\nYou can resize the panels as you like, either by clicking and dragging their borders or using the minimise/maximise buttons in the upper right corner of each panel. Clicking Ctrl++ and Ctrl+- allows to make the fonts larger or smaller.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#sec-writeandrun",
    "href": "01_install.html#sec-writeandrun",
    "title": "1  …with R",
    "section": "1.7 How to write and run code in R and RStudio",
    "text": "1.7 How to write and run code in R and RStudio\nIn the Console you can type in code and push Enter to run the line of code. For example, you can calculate:\n\n1+4\n\n[1] 5\n\n\nWhile working in the Console is possible, we usually work in RStudio using so-called scripts. These scripts are plain text files with the file extension “.R”. Scripts are discussed in detail in Chapter 3. To create a script, go to the File menu, select New File and then choose R Script.\nWith the key shortcut Ctrl+Enter for Windows and Linux user or by Cmd+Enter for MacOs users (or by clicking Run) you can run a line of a script, that means you send one line of code to the Console. See Figure 1.7 how this looks like in RStudio.\n\n\n\nFigure 1.7: One plus four in a R script",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#sec-installing",
    "href": "01_install.html#sec-installing",
    "title": "1  …with R",
    "section": "1.8 How to install R, RStudio, and R packages",
    "text": "1.8 How to install R, RStudio, and R packages\n\n\n\nFigure 1.8: Set up R in three steps\n\n\n\n\n\n\n\nAs shown in Figure 1.8, setting up R on your personal computer (Windows, Mac, Linux) is a three step process: You will first need to download and install R. After that has been successful you can download and install RStudio. Please note that it is important that you install R first and then install RStudio. As a third but optional step you can install R packages.\n\nDo this firstly: Download and install R here.\n\nIf you are a Windows user: Click on “Download R for Windows”, then click on “base”, then click on the Download link.\nIf you are macOS user: Click on “Download R for (Mac) OS X”, then under “Latest release:” click on R-X.X.X.pkg, where R-X.X.X is the version number. For example, the latest version of R as of March 29, 2024 was R-4.3.3.\nIf you are a Linux user: Click on “Download R for Linux” and choose your distribution for more information on installing R for your setup.\n\nDo this secondly: Download and install RStudio here.\n\nScroll down to “Installers for Supported Platforms” near the bottom of the page.\nClick on the download link corresponding to your computer’s operating system.\n\nDo this thirdly: Install R packages. This step is optionally as you can install R packages at any time. However, it may be a good idea to install frequently used packages in one take because the installation of some packages can be time consuming. Therefore, I recommend to read Section 1.9 and follow the instructions therein.\n\n\n\n\n\n\n\nHow to use R and RStudio without installation\n\n\n\n\n\nIf you don’t want to install R on your PC or you don’t have admin rights to do so or if you want to run R on your tablet (IPad or Chromebook) or even your smartphone, you can use RStudio online doing cloud computing on https://posit.cloud. Posit Cloud (formerly RStudio Cloud) is a cloud-based solution that allows anyone to use RStudio online and navigate it through your web browser. It is free for individuals with some restrictions and limited capacities.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#sec-packages",
    "href": "01_install.html#sec-packages",
    "title": "1  …with R",
    "section": "1.9 What are R packages?",
    "text": "1.9 What are R packages?\nA package is a collection of functions, data sets and other R objects that are all grouped together under a common name. More than 20,000 packages are available at the official repository (CRAN)1 and many more are publicly available through the internet.\nHowever, before we get started, there’s a critical distinction that you need to understand, which is the difference between having a package installed on your computer, and having a package loaded in R. When you install R on your computer only a small number of packages come bundled with the basic R installation. The installed packages are on your computer. The critical thing to remember is that just because something is on your computer doesn’t mean R can use it. In order for R to be able to use one of your installed packages, that package must also be loaded. Generally, when you open up R, only a few of these packages (about 7 or 8) are actually loaded.\n\n\n\n\n\n\nPackage management\n\n\n\n\nA package must be installed before it can be loaded.\nA package must be loaded before it can be used.\n\n\n\nWe only need to install a package once on our computer. However, to use the package, we need to load it every time we start a new R environment or R Studio, respectively.\n\n1.9.1 Package installation\nTo install an R package you can use the GUI of R Studio or the command line. In R Studio you can click on the Packages tab, then on the Install button, then you must search for a package and click Install. An alternative way to install a package is by typing\n\ninstall.packages(\"package_name\")\n\nin the console pane of RStudio and pressing Return/Enter on your keyboard. Note you must include the quotation marks around the name of the package.\nIf you want to update a previously installed package to a newer version, you need to re-install it by repeating the earlier steps or you use update.packages(). To uninstall packages you can use remove.packages().\n\n\n\n\n\n\nHow to speed up the installation of packages\n\n\n\n\n\nThe installation of packages can take some time. However, if your CPU has many cores, you can speed up the process a lot using the argument Ncpus like this update.packages(ask = F, Ncpus = 4L). This option allows you to adjust the number of parallel processes R can use on your PC. So, if you have a CPU with many cores you can increase that number. A tutorial on how to set the number of cores used by R permanently can be found here.\n\n\n\n\n\n1.9.2 Package loading\nRecall that after you’ve installed a package, you need to load it. We do this by using the library() command. For example, to load the ggplot2 package, run the following code in the console pane. What do we mean by “run the following code”? Either type or copy-and-paste the following code into the console pane and then hit the Enter key.\n\nlibrary(\"ggplot2\")\n\nIf after running the earlier code, a blinking cursor returns next to the &gt; “prompt” sign, it means you were successful and the ggplot2 package is now loaded and ready to use. If, however, you get a red “error message” that reads\n\nError in library(ggplot2) : there is no package called ‘ggplot2’\n\nIt means that you didn’t successfully install it. If you get this error message, go back to section Section 1.9.1 on R package installation and make sure to install the ggplot2 package before proceeding.\nOne very common mistake new R users make when wanting to use particular packages is they forget to load them first by using the library() command we just saw. Remember: you have to load each package you want to use every time you start RStudio. If you don’t first load a package, but attempt to use one of its features, you’ll see an error message similar to:\n\nError: could not find function\n\nR is informing you that you are attempting to use a function from a package that has not yet been loaded. Forgetting to load packages is a common mistake made by new users, and it can be a bit frustrating to get used to at first. However, with practice, it will become second nature for you. Unloading packages can be done with detach(package:ggplot2, unload=TRUE).\n\n\n1.9.3 Simplified package management with p_load\nI recommend to install and load packages using the p_load() function of the pacman package. It is superior because\n\nit only installs a package if it is has not been installed yet,\nit loads the package, and\ndoes not require quotes nor the c()function.\n\nFor example, instead of the traditional approach:\n\ninstall.packages(\n  c(\"tidyverse\", \"janitor\", \"haven\", \"readxl\")\n  )\nlibrary(\n  c(\"tidyverse\", \"janitor\", \"haven\", \"readxl\")\n  )\n\nYou can streamline the process as follows:\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, haven, readxl)\n\nThe line if (!require(pacman)) install.packages(\"pacman\") ensures the installation of the pacman package, which is necessary for using the p_load function.\nBefore you load packages in a script, I recommend to unload all other packages with\n\npacman::p_unload(all)\n\nto avoid conflicts of functions (see Section 7.5).\n\n\n\n\n\n\nTip 1.1: Install everything now\n\n\n\nThroughout the lecture notes and in the exercises, I will use different packages. The installation can be time consuming and hence I recommend to install all packages by running the following lines of code in the Console. This takes some minutes depending on your PC and your internet connection. However, after installing all these packages you have all packages that are used in my exercises, my lecture notes How to Use R for Data Science, and the book R for Data Science (2e) by Wickham & Grolemund (2023).\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n      arrow, babynames, car, curl, devtools, dplyr, duckdb, \n      expss, gapminder, ggplot2, ggrepel, ggridges, ggpubr, \n      ggstats, ggthemes, haven, HH, janitor, kableExtra, knitr, \n      Lahman, labelled, likert, magick, maps, MASS, \n      nycflights13, openxlsx, palmerpenguins, papaja, plm, \n      psych, rempsyc, repurrrsive, rstatix, skimr, sjlabelled, \n      sjmisc, sjPlot, stargazer, texreg, tidymodels, tidyr, \n      tidyverse, tinylabels, usethis, WDI, wbstats, writexl\n)\n\nIn addition to these packages, I recommend to install a package that I created to offer you some tutorials and functions. I host this package on my GitHub account and you can install it as follows:\n\n\nSkipping install of 'hubchev' from a github remote, the SHA1 (935b7194) has not changed since last install.\n  Use `force = TRUE` to force installation",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#base-r-and-the-tidyverse-universe",
    "href": "01_install.html#base-r-and-the-tidyverse-universe",
    "title": "1  …with R",
    "section": "1.10 Base R and the tidyverse universe",
    "text": "1.10 Base R and the tidyverse universe\nUpon successfully installing R, you gain access to functions that are part of Base R. This includes standard packages automatically installed and loaded with each R session, such as stats, utils, and graphics, providing a broad spectrum of functionalities for statistical analysis and graphical capabilities (see Venables et al., 2022). However, the syntax in Base R can become complex and less intuitive for users. Consequently, many individuals, including Hadley Wickham, the Chief Data Scientist at Posit (formerly RStudio), and his team, have developed an alternative suite of packages known as the tidyverse. These packages share a common philosophy and syntax, emphasizing readability and ease of use. We will heavily utilize the tidyverse in the following sections.\n\n\n\nFigure 1.9: The tidyverse universe\n\n\n\n\n\n\nThe R package tidyverse (see Figure 1.9) is a comprehensive collection of R packages including popular packages such are ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, and forcats, which together offer extensive capabilities for data modeling, transformation, and visualization.\nHow to do data science with tidyverse is the subject of multiple books and tutorials. In particular, the popular book R for Data Science by Wickham & Grolemund (2023) is all about the tidyverse universe. Thus, I highly recommend reading sections Workflow: basics), Data transformation, and Data tidying. Additionally, explore www.tidyverse.org for more resources, and consider completing the tidyverse module in my swirl package, swirl-it, as detailed in section Chapter 4.\nTo install and load tidyverse run the following lines of code:\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse)\n\n\n\n\n\n\n\n\nExercise 1.1 Set up R, RStudio, and R packages\nOpen this interactive tutorial and work through it.\n\n\n\n\n\n\n\nFigure 1.1: Play around with code\nFigure 1.2: A collection of textbooks\nFigure 1.2: A collection of textbooks\nFigure 1.2: A collection of textbooks\nFigure 1.2: A collection of textbooks\nFigure 1.3: The R Documentation of q()\nFigure 1.4: Analogy of difference between R and RStudio\nFigure 1.5: Icons of R versus RStudio on your computer\nFigure 1.6: A sketch of RStudio interface to R\nFigure 1.7: One plus four in a R script\nFigure 1.8: Set up R in three steps\nFigure 1.9: The tidyverse universe\n\n\n\nChambers, J. M. (2017). Extending R. CRC Press.\n\n\nHealy, K. (2018). Data visualization: A practical introduction. Accessed January 30, 2023; Princeton University Press. https://socviz.co/\n\n\nIrizarry, R. A. (2022). Introduction to data science: Data analysis and prediction algorithms with R. Accessed January 30, 2023; CRC Press. https://rafalab.github.io/dsbook/\n\n\nKabacoff, R. (2024). Modern data visualization with R. Chapman; Hall/CRC. https://rkabacoff.github.io/datavis/\n\n\nNeth, H. (2023). ds4psy: Data science for psychologists. Social Psychology; Decision Sciences, University of Konstanz. https://doi.org/10.5281/zenodo.7229812\n\n\nVenables, W. N., Smith, D. M., & R Core Team. (2022). An introduction to R: Notes on R: A programming environment for data analysis and graphics (Version 4.3.2 (2023-10-31)). http://cran.r-project.org/doc/manuals/R-intro.pdf\n\n\nWickham, H., & Grolemund, G. (2023). R for data science (2e). https://r4ds.hadley.nz/",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "01_install.html#footnotes",
    "href": "01_install.html#footnotes",
    "title": "1  …with R",
    "section": "",
    "text": "CRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R, see: https://cran.r-project.org.↩︎",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>...with R</span>"
    ]
  },
  {
    "objectID": "03_recipe.html",
    "href": "03_recipe.html",
    "title": "2  …writing code",
    "section": "",
    "text": "2.1 Bake a cake\nAs a teacher, I often contemplate how I can teach students to communicate with a computer. In this section, I will attempt to translate a cake baking recipe into a programming language, using R. I hope you find this both amusing and insightful. Let’s start by examining a simplified cake recipe:\nAlthough this recipe is simplified, it illustrates a process you might be familiar with. Now, let’s assume a computer is tasked with baking a cake. How would we explain the necessary steps to the computer using the R programming language?\nIn R, a functional programming language, we understand that everything that happens is a function call, and every entity is an object. Therefore, we must translate all actions into functions and all items into objects.\nHere’s what the translated recipe could look like in R:\nbuy(oven, springform, bowl, mixer, flour, sugar, butter, eggs, soda)\nclean(oven, springform, bowl, mixer)\nturn_on(oven)\nprepare(springform, bowl, mixer)\nweigh(flour, sugar, butter, eggs, soda)\ndough &lt;- bowl |&gt;\n  put(flour, sugar, butter, eggs, soda) |&gt; \n  action(tool = mixer, time = 3) \n\ndough_springform &lt;- springform |&gt; \n  put(dough) |&gt; \n  \ndough_oven &lt;- oven |&gt; \n  put(dough_springform) |&gt;\n  action(tool = oven, time = 30) |&gt; \n  pull()\n\nturn_of(oven)\nclean(oven, springform, bowl, mixer)\nUnderstanding the translation of a recipe into code becomes clearer when we familiarize ourselves with two key programming operators:\nFor example, the following lines:\ndough &lt;- bowl |&gt;\n  put(flour, sugar, butter, eggs, soda) |&gt; \n  action(tool = mixer, time = 3)\ncan be interpreted as:\nIn the preceding functions, you’ll notice objects separated by commas and parameters like tool = mixer, time = 3. These parameters define the behavior of the function. When there’s nothing within the brackets, as in pull(), the input is merely the output of the preceding pipe operator.\nEven though R is no good as a cook and the recipe is missing some steps, this analogy helps to illustrate how programming languages work: they allow us to instruct the computer in a sequential way. Next, I will showcase why coding is appealing.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>...writing code</span>"
    ]
  },
  {
    "objectID": "03_recipe.html#bake-a-cake",
    "href": "03_recipe.html#bake-a-cake",
    "title": "2  …writing code",
    "section": "",
    "text": "Instructions to bake a cake:\n\n\n\n\n\n\nBuy an oven.\nBuy ingredients (flour, sugar, butter, eggs, soda).\nBuy tools.\nClean everything..\n\nHeat up the oven.\nPrepare the tools (springform, bowl, mixer).\nWeight all ingredients.\nTake a bow and all the weighted ingredients and put everything in a bowl.\nTake the mixer and mix all ingredients in the bowl for 3 minutes.\nPut all the mixed ingredients in a springform pan.\nTake the springform pan with the mixed ingredients and put it in the oven.\nBake for 30 minutes, take the springform pan it out of the oven, and turn off the oven.\nClean the kitchen and the tools.\n\n\n\n\n\n\n\n\n\n\nThe “&lt;-” is known as the assignment operator. It saves or stores data into a new object. It might be helpful to think of it as saying, “I create the object &lt;name of object&gt; and store therein”\nThe “|&gt;” is known as the pipe operator. It passes the output of one action to serve as the input for the next. Think of it as saying “and then.”\n\n\n\n\nI create the object `dough` and I store therein the bowl, and then \n  I put flour, sugar, butter, eggs, and soda to it, and then\n  I take action with the mixer for 3 minutes",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>...writing code</span>"
    ]
  },
  {
    "objectID": "03_recipe.html#elegant-code",
    "href": "03_recipe.html#elegant-code",
    "title": "2  …writing code",
    "section": "2.2 Elegant code",
    "text": "2.2 Elegant code\nLet’s make our code more elegant, that is, easy to read, understand, and modify. For example, while it is equivalent to write everything in one line\n\ndough &lt;- bowl |&gt; put(flour, sugar, butter, eggs, soda) |&gt; action(tool = mixer, time = 3) \n\nor spread out over three lines,\n\ndough &lt;- bowl |&gt;\n  put(flour, sugar, butter, eggs, soda) |&gt; \n  action(tool = mixer, time = 3) \n\nit is easier for the human eye to read the text in spread out form.\n\n\n\n\n\n\nStyle in Writing Code\n\n\n\nWriting code involves certain conventions, often referred to as a coding style. Although not strictly necessary, a consistent style can significantly enhance clarity and prevent common pitfalls. Numerous style guides aim to standardize coding practices. For example, you might find The tidyverse style guide by Hadley Wickham particularly helpful in adopting a harmonious coding style in R.\n\n\nBy using the assignment operator &lt;-, we can create two objects: ingredients and tools. These objects are used multiple times throughout the process.\nHere is an improved version of the script:\n\ningredients &lt;- c(flour, sugar, butter, eggs, soda)\ntools &lt;- c(oven, springform, bowl, mixer)\n\nbuy(tools, ingredients)\n\nclean(tools)\nturn_on(oven)\nprepare(tools)\nweight(ingredients)\ndough &lt;- bowl |&gt;\n  put(ingredients) |&gt; \n  action(tool = mixer, time = 3) \n\ndough_springform &lt;- springform |&gt; \n  put(dough) \n  \ndough_oven &lt;- oven |&gt; \n  put(dough_springform) |&gt;\n  action(tool = oven, time = 30) |&gt; \n  pull()\n\nturn_of(oven)\nclean(, tools)\n\nThis version refines the process, making the code more streamlined and easier to follow.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>...writing code</span>"
    ]
  },
  {
    "objectID": "03_recipe.html#bake-a-cheese-cake",
    "href": "03_recipe.html#bake-a-cheese-cake",
    "title": "2  …writing code",
    "section": "2.3 Bake a cheese cake",
    "text": "2.3 Bake a cheese cake\nNow, let’s assume you want to bake another cake, this time with chocolate and banana, but without eggs. Moreover, you need to bake it for 45 minutes. We can easily adapt the code snippet from above to accommodate the ingredients for this new recipe:\n\ningredients &lt;- c(flour, sugar, butter, soda, banana, chocolate)\ntools &lt;- c(oven, springform, bowl, mixer)\n\nbuy(tools, ingredients)\n\nclean(tools)\nturn_on(oven)\nprepare(tools)\nweight(ingredients)\ndough &lt;- bowl |&gt;\n  put(ingredients) |&gt; \n  action(tool = mixer, time = 3) \n\ndough_springform &lt;- springform |&gt; \n  put(dough) \n  \ndough_oven &lt;- oven |&gt; \n  put(dough_springform) |&gt;\n  action(tool = oven, time = 45) |&gt; \n  pull()\n\nturn_of(oven)\nclean(kitchen, tools)",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>...writing code</span>"
    ]
  },
  {
    "objectID": "03_recipe.html#comment-what-you-do",
    "href": "03_recipe.html#comment-what-you-do",
    "title": "2  …writing code",
    "section": "2.4 Comment what you do",
    "text": "2.4 Comment what you do\nSometimes code can be difficult to understand for humans. It is therefore helpful to add comments to clarify what the individual code sections are supposed to do. In R, comments can be added with a leading hashtag, #.\n\n# Decide on tools and ingredients \ningredients &lt;- c(flour, sugar, butter, soda, banana, chocolate)\ntools &lt;- c(oven, springform, bowl, mixer)\n\n# Go shopping\nbuy(tools, ingredients)\n\n# Prepare the kitchen, tools, and ingredients\nclean(tools)\nturn_on(oven)\nprepare(tools)\nweight(ingredients)\n\n# Make the dough\ndough &lt;- bowl |&gt;\n  put(ingredients) |&gt; \n  action(tool = mixer, time = 3) \ndough_springform &lt;- springform |&gt; \n  put(dough) |&gt; \n\n# bake the cake\ndough_oven &lt;- oven |&gt; \n  put(dough_springform) |&gt;\n  action(tool = oven, time = 45) |&gt; \n  pull()\n\n# Clean up\nturn_of(oven)\nclean(kitchen, tools)",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>...writing code</span>"
    ]
  },
  {
    "objectID": "03_recipe.html#bake-10-cakes",
    "href": "03_recipe.html#bake-10-cakes",
    "title": "2  …writing code",
    "section": "2.5 Bake 10 cakes",
    "text": "2.5 Bake 10 cakes\nAs a computer can reproduce a cake within seconds (I mean, not really, just in my little fun exercise here), we now have the opportunity to experiment with several versions of the cake by varying the baking time from 35 to 45 minutes. Here’s how the corresponding code might look:\n\ningredients &lt;- c(flour, sugar, butter, soda, banana, chocolate)\ntools &lt;- c(springform, bowl, mixer)\n\nbuy(tools, ingredients)\n\nclean(tools)\nturn_on(oven)\nprepare(tools)\nweight(ingredients)\ndough &lt;- bowl |&gt;\n  put(ingredients) |&gt; \n  action(tool = mixer, time = 3) \n\ndough_springform &lt;- springform |&gt; \n  put(dough) \n\nfor (timing in 35:44) {\n  dough_oven &lt;- oven |&gt; \n    put(dough_springform) |&gt;\n    action(tool = oven, time = timing) |&gt; \n    pull()\n  assign(paste(\"dough_oven_min_\", timing, sep = \"\"), dough_oven)\n}\n\nturn_of(oven)\nclean(tools)\n\nYou can see a loop with some new and tweaked lines:\n\nfor (timing in 35:44) {\n  dough_oven &lt;- oven |&gt; \n    put(dough_springform) |&gt;\n    action(tool = oven, time = timing) |&gt; \n    pull()\n  assign(paste(\"dough_oven_min_\", timing, sep = \"\"), dough_oven)\n}\n\nThese lines sequentially execute the following actions:\nLet the object timing be 35, make a cake, and save it in the object `dough_oven_min_35` then start again and\nlet the object timing be 36, make a cake, and save it in the object `dough_oven_min_36` then start again and\nlet the object timing be 37, make a cake, and save it in the object `dough_oven_min_37` then start again and\nlet the object timing be 38, make a cake, and save it in the object `dough_oven_min_38` then start again and\nlet the object timing be 39, make a cake, and save it in the object `dough_oven_min_39` then start again and\nlet the object timing be 40, make a cake, and save it in the object `dough_oven_min_40` then start again and\nlet the object timing be 41, make a cake, and save it in the object `dough_oven_min_41` then start again and\nlet the object timing be 42, make a cake, and save it in the object `dough_oven_min_42` then start again and\nlet the object timing be 43, make a cake, and save it in the object `dough_oven_min_43` then start again and\nlet the object timing be 44, make a cake, and save it in the object `dough_oven_min_44` then start again \nAfter all, we have ten cakes. This shows how we can harness the processing power of a computer. Computers are excellent at performing everyday, repetitive tasks so that we can automate processes and perform procedures effortlessly over and over again.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>...writing code</span>"
    ]
  },
  {
    "objectID": "03_recipe.html#writing-real-code",
    "href": "03_recipe.html#writing-real-code",
    "title": "2  …writing code",
    "section": "2.6 Writing real code",
    "text": "2.6 Writing real code\nOf course, computers can’t bake a cake. The R programming language can do none of the above. Nevertheless, there are analogies to the programming language R. Let me present a few lines of code and explain these lines of code to you, and you will see that the similarities are striking.\nCopy that code chunk, paste it into a R script and run it.\n\n# This script demonstrates a typical data analysis workflow in R\n# ---------------------------------------------------------------\n\n# Install and load required libraries\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_unload(all)\npacman::p_load(tidyverse,haven, janitor)\n\n# Set the working directory to a project-specific folder\nsetwd(\"~/Documents\")\n\n# Clear the current environment of any objects\nrm(list = ls())\n\n# Load data from a Stata file available online\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r18/auto.dta\")\n\n# Display basic information about the dataset\nncol(auto) # Number of columns\nnrow(auto) # Number of rows\ndim(auto) # Dimensions of the dataset\nnames(auto) # Names of variables\nhead(auto) # First few rows\ntail(auto) # Last few rows\nsummary(auto) # Summary statistics for each column\nglimpse(auto) # Compact display of the structure of the dataset\nprint(auto, n = Inf) # Print all rows of the dataset\n\n# Check for duplicate entries based on the 'make' variable\nauto |&gt;\n  get_dupes(make)\n\n# Create and display a scatter plot of car price versus weight\nplot_weight_price &lt;- ggplot(auto, aes(x = weight, y = price)) +\n  geom_point()\nplot_weight_price\n\n# Save the plot to a file\nggsave(\"plot_weight_price.png\", plot = plot_weight_price, dpi = 300)",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>...writing code</span>"
    ]
  },
  {
    "objectID": "22_script.html",
    "href": "22_script.html",
    "title": "3  …writing R scripts",
    "section": "",
    "text": "3.1 The limitations of no-code applications\nNo-Code Applications (NCA) such as Microsoft Excel, RapidMiner, KNIME, DataRobot, Tableau, Microsoft Power BI, and Google AutoML are popular for good reasons. They enable the application of advanced empirical methods with no or minimal programming effort. Their intuitive graphical user interfaces comes with pre-built templates and drag-and-drop functionality which helps to get things done quick, without having to study the programm documentation for hours. Despite their apparent ease of use and efficiency, these platforms come with several disadvantages compared to traditional ways of working with computer by scripting and coding. Understanding these weaknesses helps to see why professional researchers, especially those actively publishing in academic journals, tend to rely on scripting languages like R and Python. These programming languages offer full control, are customizeable and extendable, offer extensive opportunities for automation and reproducibility, and are often better suited for demanding data science tasks.\nIn summary, while low-code and no-code platforms offer quick deployment and ease of use, they can lack the depth, flexibility, and control provided by traditional scripting. Researchers and businesses must consider these trade-offs, especially when planning for long-term scalability, complex customizations, or in-depth integrations.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>...writing R scripts</span>"
    ]
  },
  {
    "objectID": "22_script.html#the-limitations-of-no-code-applications",
    "href": "22_script.html#the-limitations-of-no-code-applications",
    "title": "3  …writing R scripts",
    "section": "",
    "text": "Disadvantages of No-Code Applications (NCA)\n\n\n\n\nNCA lack flexibility and are limited in their adaptability.\nNCA often have problems scaling with increasing data volumes or user requirements.\nNCA are often closed systems that make it difficult to integrate other systems or applications.\nNCA often bind a company to a specific ecosystem. This can lead to dependencies and vendor lock-in.\nNCA can obscure the underlying logic of how applications work, which can make troubleshooting more difficult.\nNCA abstracts the coding process and prevents users from understanding fundamental concepts that could be beneficial to their professional growth and ability to tackle more complex problems.\n\n\n\n\n\n\n\n\n\n\nA hypothetical but realistic example with Excel\n\n\n\nSuppose you work with a spreadsheet software like Excel. You import a CSV file using the implemented import tool, you save the converted file. You notice that Excel has messed up the dates during the import, so you spend a few minutes cleanig that manually. Then, you visualize the data and you save the visualisations in various tabs. Maybe, you can spot some outliers and you document in footnote that these outliers are the result of some issues with the raw data. As these errors cannot be solved, you delete the observations and variables that contain a significant amount of errors. Finally, you use filters to calculate some summary statistics. All your results are written in a new tab. You’re convinced that you’ve done a great job. However, you send the file to your supervisor and you ask him for her opinion.\n\nShe probably asks you what you have done to the data. How can you efficiently and completely communicate that?\nShe comes back to you some time later and asks you to do the same analysis with an updated version of the data. How can you exactly redo the analysis and how long do you think it will take you to complete the job?\nShe finds an error in your work or she has an idea to improve your analysis by making a few adjustments. Can you implement the adjustments easily, or do you have to redo everything from scratch?\nShe sends you back the file with the comment that she has worked out some things in the file and now everything should be fine. How do you know what she has done to the data?\n\nTo say it in the words of Stephenson (2023, sec. 5.1):\n\n“Spreadsheets are a nightmare for quality control and reproducibility, and you should always think twice before using one. Spreadsheets will always be a handy way to manipulate tabular datasets, and you’ll probably find them useful for data collection and quick back-of-the-envelope calculations, but they’re often more trouble than they’re worth.”",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>...writing R scripts</span>"
    ]
  },
  {
    "objectID": "22_script.html#r-scripts-why-they-are-useful",
    "href": "22_script.html#r-scripts-why-they-are-useful",
    "title": "3  …writing R scripts",
    "section": "3.2 R Scripts: Why they are useful",
    "text": "3.2 R Scripts: Why they are useful\nI have already discussed in Section 1.7 that you can run code either directly by typing your code into the console of R or by writing a script and then sending the code with Ctrl+Enter or with the Run button to the console of R. Typing functions into the console to run code may seem simple, but this interactive style has limitations:\n\nTyping commands one at a time can be cumbersome and time-consuming.\nIt’s hard to save your work effectively.\nGoing back to the beginning when you make a mistake is annoying.\nYou can’t leave notes for yourself.\nReusing and adapting analyses can be difficult.\nIt’s hard to do anything except the basics.\nSharing your work with others can be challenging.\n\nThat’s where having a transcript of all the code, which can be re-run and edited at any time, becomes useful. An R script is just plain text that is interpreted as code or as a comment if the text follows a hastag #. A script comes with important advantages.\nScripts…\n\n… provide a record of everything you did during your data analysis.\n… can easily be edited and re-run.\n… allow you to leave notes for yourself.\n… make it easy to reuse and adapt analyses.\n… allow you to do more complex analyses.\n… make it easy to share your work with others.",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>...writing R scripts</span>"
    ]
  },
  {
    "objectID": "22_script.html#create-write-and-run-r-scripts",
    "href": "22_script.html#create-write-and-run-r-scripts",
    "title": "3  …writing R scripts",
    "section": "3.3 Create, write, and run R scripts",
    "text": "3.3 Create, write, and run R scripts\n\n3.3.1 Create\n\n\n\n\n\n\n3 equivalent ways to create a script\n\n\n\n\nUse the menu: File &gt; New File &gt; R Script\nUse the keyboard shortcut: Ctrl+Shift+N (Windows/Linux) or Cmd+Shift+N (Mac) or\nType the following in the console:\n\n\nfile.create(\"hello.R\")\n\n\n\nIn the first two ways, a new R script window will open which can be edited and should be saved either by clicking on the File menu and selecting Save, clicking the disk icon, or by using the shortcut Ctrl+S (Windows/Linux) or Cmd+S (Mac). If you go for the third way, you need to open it manually.\n\n\n3.3.2 Write\nRegardless of your preferred way of generating a script, we can now start writing our first script:\n\nx &lt;- \"hello world\"\nprint(x)\n\nThen save the script using the menus (File &gt; Save) as hello.R.\nThe above lines of code do the following:\n\nWith the assignment operator &lt;- we create an object that stores the words “hello world” in an object entitled x. In Section 7.1.1 the assignment operator is further explained.\nWith the third input we print the content of the object x.\n\n\n\n3.3.3 Run\nSo how do we run the script? Assuming that the hello.R file has been saved to your working directory, then you can run the script using the following command:\n\nsource( \"hello.R\" )\n\nSuppose you saved the script in a sub-folder called scripts of your working directory, then you need to run the script using the following command:\n\nsource(\"./scripts/hello.R\") \n\nJust note that the dot, ., means the current folder. Instead of using the source function, you can click on the source button in Rstudio.\nWith the character # you can write a comment in a script and R will simply ignore everything that follows in that line onwards.\n\n\n\n\n\n\n\nExercise 3.1 Run a script and round numbers\nPlease copy and paste the following lines of code into an R script, run it on your computer, and try to understand how it works.\n\n# Create a vector that contains the sales data\nsales_by_month &lt;- c(0, 100, 200, 50, 3, 4, 8, 0, 0, 0, 0, 0)\nsales_by_month\nsales_by_month[2]\nsales_by_month[4]\nfebruary_sales &lt;- sales_by_month[2]\nfebruary_sales\nsales_by_month[5] &lt;- 25 # added May sales data\nsales_by_month\n# Do I have 12 month?\nlength( x = sales_by_month )\n# Assume each unit costs 7 Euro, then the revenue is\nprice &lt;- 7\nrevenue &lt;- sales_by_month*price\nrevenue\n# To get statistics for daily revenue we define the number of days:\ndays_per_month &lt;- c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)\n# Calculate the daily revenue\nrevenue_per_day &lt;- revenue/days_per_month\nrevenue_per_day \n# round number \nround(revenue_per_day) \n\nUse the “?” to search for the documentation of all functions used. In particular, do you understand how the function round() works? What arguments does the function contain? How can you manipulate the pre-defined arguments. For example, can you calculate the rounded revenue per day with two or four digits? Try it out!\n\n?round()\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nround(revenue_per_day, digits = 4)\n\n\n\n\n\n\n\n\n\n\n\nStephenson, P. (2023). Data science practice. Accessed January 30, 2023. https://datasciencepractice.study/",
    "crumbs": [
      "Getting started...",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>...writing R scripts</span>"
    ]
  },
  {
    "objectID": "10_swirl.html",
    "href": "10_swirl.html",
    "title": "4  Interactive introduction with swirl",
    "section": "",
    "text": "4.1 Set up swirl\nTo install swirl and my learning modules, please follow my instructions precisely!\nOpen Rstudio and type in the console the following:\ninstall.packages(\"swirl\")\nlibrary(\"swirl\")\ninstall_course_github(\"hubchev\", \"swirl-it\")\nswirl()\nThe above four lines of code do the following:\nAfter initiating the swirl environment, follow the instructions displayed in the Console. Specifically, select the swirl-it course and the huber-intro-1 learning module to begin. You can exit swirl at any moment by typing bye() into the Console or pressing the Esc key on your keyboard.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive introduction with swirl</span>"
    ]
  },
  {
    "objectID": "10_swirl.html#set-up-swirl",
    "href": "10_swirl.html#set-up-swirl",
    "title": "4  Interactive introduction with swirl",
    "section": "",
    "text": "Install the swirl package, ensuring it’s available for use in R.\nLoad the swirl package, making its functions accessible.\nInstall my swirl course that is hosted on GitHub, making its functions accessible.\nBy entering swirl into the Console (located at the bottom-left in RStudio) and pressing the Enter key, you initiate swirl. This begins your interactive learning experience with the package.\n\n\n\n\n\n\n\nTip 4.1: If the course has failed to install,\n\n\n\n\n\nyou can try to download the file swirl-it.swc from github.com/hubchev/swirl-it and install the course with loading the swirl package and typing install_course() into the console.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive introduction with swirl</span>"
    ]
  },
  {
    "objectID": "10_swirl.html#swirl-it-huber-intro-1",
    "href": "10_swirl.html#swirl-it-huber-intro-1",
    "title": "4  Interactive introduction with swirl",
    "section": "4.2 swirl-it: huber-intro-1",
    "text": "4.2 swirl-it: huber-intro-1\n\n\n\n\n\n\nClick to see the full content of the module\n\n\n\n\n\nWelcome to this swirl course. If you find any errors or if you have suggestions for improvement, please let me know via stephan.huber@hs-fresenius.de.\nThe RStudio interface consists of several windows. You can change the size of the windows by dragging the grey bars between the windows. We’ll go through the most important windows now.\nBottom left is the Console window (also called command window/line). Here you can type commands after the &gt; prompt and R will then execute your command. This is the most important window, because this is where R actually does stuff.\nTop left is the Editor window (also called script window). Here collections of commands (scripts) can be edited and saved. When you do not get this window, you can open it with ‘File’ &gt; ‘New’ &gt; ‘R script’.\nJust typing a command in the editor window is not enough, it has to be send to the Console before R executes the command. If you want to run a line from the script window (or the whole script), you can click ‘Run’ or press ‘CTRL+ENTER’ to send it to the command window.\nThe shortcut to send the current line to the console and run it there is _________.\n\nCTRL+SHIFT\nCTRL+ENTER\nCTRL+SPACE\nSHIFT+ENTER\n\nHint: You find all shortcuts in the menu at Tools &gt; Keyboard Shortcuts Help or click ALT+SHIFT+K. If you are a Mac user, your shortcut is ‘Cmd+Return’ instead of ‘SHIFT+ENTER’. To move on type skip().\n\n\n\n\n\n\nSolution\n\n\n\n\n\nanswer: b\n\n\n\nTop right is the environment window (a.k.a workspace). Here you can see which data R has in its memory. You can view and edit the values by clicking on them.\nBottom right is the plots / packages / help window. Here you can view plots, install and load packages or use the help function.\nThe first thing you should do whenever you start Rstudio is to check if you are happy with your working directory. That directory is the folder on your computer in which you are currently working. That means, when you ask R to open a certain file, it will look in the working directory for this file, and when you tell R to save a data file or figure, it will save it in the working directory.\nYou can check your working directory with the function getwd(). So let’s do that. Type in the command window getwd() .\n\ngetwd()\n\n[1] \"/home/sthu/Dropbox/hsf/courses/dsr\"\n\n\nAre you happy with that place? if not, you should set your working directory to where all your data and script files are (or will be). Within RStudio you can go to ‘Session’ &gt; ‘Set working directory’ &gt; ‘Choose directory’. Please do this now.\nInstead of clicking, you can use the function setwd(\"/YOURPATH\"). For example, setwd(\"/Users/MYNAME/MYFOLDER\") or setwd(\"C:/Users/jenny/myrstuff\"). Make sure that the slashes are forward slashes and that you do not forget the apostrophes. R is case sensitive, so make sure you write capitals where necessary.\nWhenever you want R to do something you need to use a function. It is like a command. All functions of R are organized in so-called packages or libraries. With the standard installation many packages are already installed. However, many more exist and some of them are really cool. For example, with installed.packages() all installed packages are listed. Or, with swirl(), you started swirl.\nOf course, you can also go to the Packages window at the bottom right. If the box in front of the package name is ticked, the package is loaded (activated) and can be used. To see via Console which packages are loaded type in the console (.packages())\n\n(.packages())\n\n[1] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[7] \"base\"     \n\n\nThere are many more packages available on the R website. If you want to install and use a package (for example, the package called geometry) you should first install the package. Type install.packages(\"geometry\") in the console. Don’t be afraid about the many messages. Depending on your PC and your internet connection this may take some time.\n\ninstall.packages(\"geometry\")\n\nAfter having installed a package, you need to load the package. That is a bit annoying but essential. Type in library(\"geometry\") in the Console. You also did this for the swirl package (otherwise you couldn’t have been doing these exercises).\n\nlibrary(\"geometry\")\n\nCheck if the package is loaded typing (.packages())\n\n(.packages())\n\nNow, let’s get started with the real programming.\nR can be used as a calculator. You can just type your equation in the command window after the &gt;. Type 10^2 + 36.\n\n10^2 + 36\n\n[1] 136\n\n\nAnd R gave the answer directly. By the way, spaces do not matter.\nIf you use brackets and forget to add the closing bracket, the &gt; on the command line changes into a +. The + can also mean that R is still busy with some heavy computation. If you want R to quit what it was doing and give back the &gt;, press ESC.\nYou can also give numbers a name. By doing so, they become so-called variables which can be used later. For example, you can type in the command window A &lt;- 4.\n\nA &lt;- 4\n\nThe &lt;- is the so-called assignment operator. It allows you to assign data to a named object in order to store the data.\nDon’t be confussed about the term object. All sorts of data are stored in so-called objects in R. All objects of a session are shown in the Environment window. In the second part of this course, I will introduce different data types.\nYou can see that A appeared in the environment window in the top right corner, which means that R now remembers what A is.\nYou can also ask R what A is. Just type A in the command window.\n\nA\n\n[1] 4\n\n\nYou can also do calculations with A. Type A * 5 .\n\nA * 5\n\n[1] 20\n\n\nIf you specify A again, it will forget what value it had before. You can also assign a new value to A using the old one. Type A &lt;- A + 10 .\n\nA &lt;- A + 10\n\nYou can see that the value in the environment window changed.\nTo remove all variables from R’s memory, type rm(list=ls()) .\n\nrm(list = ls())\n\nYou see that the environment window is now empty. You can also click the broom icon (clear all) in the environment window. You can see that RStudio then empties the environment window. If you only want to remove the variable A, you can type rm(A).\nLike in many other programs, R organizes numbers in scalars (a single number, 0-dimensional), vectors (a row of numbers, also called arrays, 1-dimensional) and matrices (like a table, 2-dimensional).\nThe A you defined before was a scalar. To define a vector with the numbers 3, 4 and 5, you need the function c(), which is short for concatenate (paste together). Type B=c(3,4,5).\n\nB &lt;- c(3, 4, 5)\n\nIf you would like to compute the mean of all the elements in the vector B from the example above, you could type (3+4+5)/3. Try this\n\n(3 + 4 + 5) / 3\n\n[1] 4\n\n\nBut when the vector is very long, this is very boring and time-consuming work. This is why things you do often are automated in so-called functions. For example, type mean(x=B) and guess what this function mean() can do for you.\n\nmean(x = B)\n\n[1] 4\n\n\nWithin the brackets you specify the arguments. Arguments give extra information to the function. In this case, the argument x says of which set of numbers (vector) the mean should be computed (namely of B). Sometimes, the name of the argument is not necessary; mean(B) works as well. Try it.\n\nmean(B)\n\n[1] 4\n\n\nCompute the sum of 4, 5, 8 and 11 by first combining them into a vector and then using the function sum. Use the function c inside the function sum.\n\nsum(c(4, 5, 8, 11))\n\n[1] 28\n\n\nThe function rnorm, as another example, is a standard R function which creates random samples from a normal distribution. Type rnorm(10) and you will see 10 random numbers\n\nrnorm(10)\n\n [1] -0.4737134 -0.6263207 -1.4829385 -0.3013489 -0.5884019 -1.3523406\n [7] -1.4055011  1.2225050 -0.5682587  0.3207065\n\n\nHere rnorm is the function and the 10 is an argument specifying how many random numbers you want - in this case 10 numbers (typing n=10 instead of just 10 would also work). The result is 10 random numbers organised in a vector with length 10.\nIf you want 10 random numbers out of normal distribution with mean 1.2 and standard deviation 3.4 you can type rnorm(10, mean=1.2, sd=3.4). Try this.\n\nrnorm(10, mean = 1.2, sd = 3.4)\n\n [1] -1.4142823 -3.2334395 -0.9678065  4.9051208 -1.4670372  1.5519167\n [7]  2.3503194 -5.4270976 -1.2708216  0.9477567\n\n\nThis shows that the same function (rnorm()) may have different interfaces and that R has so called named arguments (in this case mean and sd).\nComparing this example to the previous one also shows that for the function rnorm only the first argument (the number 10) is compulsory, and that R gives default values to the other so-called optional arguments. Use the help function to see which values are used as default by typing ?rnorm.\n\n?rnorm\n\nYou see the help page for this function in the help window on the right. RStudio has a nice features such as autocompletion and snapshots of the R documentation. For example, when you type rnorm( in the command window and press TAB, RStudio will show the possible arguments.\nYou can also store the output of the function in a variable. Type x=rnorm(100).\n\nx &lt;- rnorm(100)\n\nNow 100 random numbers are assigned to the variable x, which becomes a vector by this operation. You can see it appears in the Environment window.\nR can also make graphs. Type plot(x) for a very simple example.\n\nplot(x)\n\n\n\n\n\n\n\n\nThe 100 random numbers are now plotted in the plots window on the right.\nYou now are more familiar to RStudio and you know some basic R stuff. In particular, you know…\n…that everything in R is said with functions,\n…that functions can but don’t have to have arguments,\n…that you can install packages which contain functions,\n…that you must load the installed packages every time you start a session in RStudio, and\n…that this is just the beginning. Thus, please continue with the second module of this introduction.\n\n\n\nAfter you have successfully finished learning module huber-intro-1 please go ahead with the learning module huber-intro-2 that is also part of my swirl course swirl-it.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive introduction with swirl</span>"
    ]
  },
  {
    "objectID": "10_swirl.html#swirl-it-huber-intro-2",
    "href": "10_swirl.html#swirl-it-huber-intro-2",
    "title": "4  Interactive introduction with swirl",
    "section": "4.3 swirl-it: huber-intro-2",
    "text": "4.3 swirl-it: huber-intro-2\n\n\n\n\n\n\nClick to see the full content of the module\n\n\n\n\n\nWelcome to the second module. Again, if you find any errors or if you have suggestions for improvement, please let me know via stephan.huber@hs-fresenius.de .\nBefore you start working, you should set your working directory to where all your data and script files are or should be stored. Within RStudio you can go to ‘Session’&gt; ‘Set working directory’, or you can type in setwd(YOURPATH). Please do this now.\n\nsetwd(\"/home/sthu/Documents/mydir\")\n\nHint: Instead of clicking, you can also type setwd(“path”), where you replace “path” with the location of your folder, for example setwd(“D:/R/swirl”).\nR is an interpreter that uses a command line based environment. This means that you have to type commands, rather than use the mouse and menus. This has many advantages. Foremost, it is easy to get a full transcript of everything you did and you can replicate your work easy.\nAs already mentioned, all commands in R are functions where arguments come (or do not come) in round brackets after the function name.\nYou can store your workflow in files, the so-called scripts. These scripts have typically file names with the extension, e.g., foo.R .\nYou can open an editor window to edit these files by clicking ‘File’ and ‘New’. Try this. Under ‘File’ you also find the options ‘Open file…’, ‘Save’ and ‘Save as’. Alternatively, just type CTRL+SHIFT+N.\nYou can run (send to the Console window) part of the code by selecting lines and pressing CTRL+ENTER or click ‘Run’ in the editor window. If you do not select anything, R will run the line your cursor is on.\nYou can always run the whole script with the console command source, so e.g. for the script in the file foo.R you type source(‘foo.R’). You can also click ‘Run all’ in the editor window or type CTRL+SHIFT+S to run the whole script at once.\nMake a script called firstscript.R. Therefore, open the editor window with ‘File’ &gt; ‘New’. Type plot(rnorm(100)) in the script, save it as firstscript.R in the working directory. Then type source(\"firstscript.R\") on the command line.\n\nsource(\"firstscript.R\")\n\nRun your script again with source(\"firstscript.R\"). The plot will change because new numbers are generated.\n\nsource(\"firstscript.R\")\n\nHint: Type source(“firstscript.R”) again or type skip() if you are not interested.\nVectors were already introduced, but they can do more. Make a vector with numbers 1, 4, 6, 8, 10 and call it vec1.\nHint: Type vec1 &lt;- c(1,4,6,8,10).\n\nvec1 &lt;- c(1, 4, 6, 8, 10)\n\nElements in vectors can be addressed by standard [i] indexing. Select the 5th element of this vector by typing vec1[5].\n\nvec1[5]\n\nReplace the 3rd element with a new number by typing vec1[3]=12.\n\nvec1[3] &lt;- 12\n\nAsk R what the new version is of vec1.\n\nvec1\n\nYou can also see the numbers of vec1 in the environment window. Make a new vector vec2 using the seq() (sequence) function by typing seq(from=0, to=1, by=0.25) and check its values in the environment window.\nHint: Type vec2 &lt;- seq(from=0, to=1, by=0.25).\n\nvec2 &lt;- seq(from = 0, to = 1, by = 0.25)\n\nType sum(vec1).\n\nsum(vec1)\n\nThe function sum sums up the elements within a vector, leading to one number (a scalar). Now use + to add the two vectors.\nHint: Type vec1 + vec2.\n\nvec1 + vec2\n\nIf you add two vectors of the same length, the first elements of both vectors are summed, and the second elements, etc., leading to a new vector of length 5 (just like in regular vector calculus).\nMatrices are nothing more than 2-dimensional vectors. To define a matrix, use the function matrix. Make a matrix with matrix(data=c(9,2,3,4,5,6),ncol=3) and call it mat.\nHint: Type mat &lt;- matrix(data=c(9,2,3,4,5,6),ncol=3) or type skip() if you are not interested.\n\nmat &lt;- matrix(data = c(9, 2, 3, 4, 5, 6), ncol = 3)\n\nThe third type of data structure treated here is the data frame. Time series are often ordered in data frames. A data frame is a matrix with names above the columns. This is nice, because you can call and use one of the columns without knowing in which position it is. Make a data frame with t = data.frame(x = c(11,12,14), y = c(19,20,21), z = c(10,9,7)).\n\nt &lt;- data.frame(x = c(11, 12, 14), y = c(19, 20, 21), z = c(10, 9, 7))\n\nAsk R what t is.\nHint: Type t or skip() if you are not interested.\n\nt\n\nThe data frame is called t and the columns have the names x, y and z. You can select one column by typing t$z. Try this.\n\nt$z\n\nAnother option is to type t[[\"z\"]]. Try this as well.\n\nt[[\"z\"]]\n\nCompute the mean of column z in data frame t.\nHint: Use function mean or type skip() if you are not interested.\n\nmean(t$z)\n\nIn the following question you will be asked to modify a script that will appear as soon as you move on from this question. When you have finished modifying the script, save your changes to the script and type submit() and the script will be evaluated. There will be some comments in the script that opens up. Be sure to read them!\nMake a script file which constructs three random normal vectors of length 100. Call these vectors x1, x2 and x3. Make a data frame called t with three columns (called a, b and c) containing respectively x1, x1+x2 and x1+x2+x3. Call plot(t) for this data frame. Then, save it and type submit() on the command line.\nHint: Type plot(rnorm(100)) in the script, save it and type submit() on the command line.\n\n# Text behind the #-sign is not evaluated as code by R.\n# This is useful, because it allows you to add comments explaining what the script does.\n\n# In this script, replace the ... with the appropriate commands.\n\n\nx1 &lt;- ...\nx2 &lt;- ...\nx3 &lt;- ...\nt &lt;- ...\nplot(...)\n\n\n\n\n\n\n\nResult\n\n\n\n\n\n\n# Text behind the #-sign is not evaluated as code by R.\n# This is useful, because it allows you to add comments explaining what the script does.\n\n# In this script, replace the ... with the appropriate commands.\n\nx1 &lt;- rnorm(100)\nx2 &lt;- rnorm(100)\nx3 &lt;- rnorm(100)\nt &lt;- data.frame(a = x1, b = x1 + x2, c = x1 + x2 + x3)\nplot(t)\n\n\n\n\nDo you understand the results?\nAnother basic structure in R is a list. The main advantage of lists is that the columns (they are not really ordered in columns any more, but are more a collection of vectors) don’t have to be of the same length, unlike matrices and data frames. Make this list L &lt;- list(one=1, two=c(1,2), five=seq(0, 1, length=5)).\n\nL &lt;- list(one = 1, two = c(1, 2), five = seq(0, 1, length = 5))\n\nThe list L has names and values. You can type L to see the contents.\n\nL\n\nL also appeared in the environment window. To find out what’s in the list, type names(L).\n\nnames(L)\n\nAdd 10 to the column called five.\nHint: Type L$five + 10\n\nL$five + 10\n\nPlotting is an important statistical activity. So it should not come as a surprise that R has many plotting facilities. Type plot(rnorm(100), type=\"l\", col=\"gold\").\nHint: The symbol between quotes after the type=, is the letter l, not the number 1. To see the result you can also just type skip().\n\nplot(rnorm(100), type = \"l\", col = \"gold\")\n\nHundred random numbers are plotted by connecting the points by lines in a gold color.\nAnother very simple example is the classical statistical histogram plot, generated by the simple command hist. Make a histogram of 100 random numbers.\nHint: Type hist(rnorm(100))\n\nhist(rnorm(100))\n\nThe script that opens up is the same as the script you made before, but with more plotting commands. Type submit() on the command line to run it (you don’t have to change anything yet).\nHint: Change plotting parameters in the script, save it and type submit() on the command line.\n\n# Text behind the #-sign is not evaluated as code by R.\n# This is useful, because it allows you to add comments explaining what the script does.\n\n# Make data frame\nx1 &lt;- rnorm(100)\nx2 &lt;- rnorm(100)\nx3 &lt;- rnorm(100)\nt &lt;- data.frame(a = x1, b = x1 + x2, c = x1 + x2 + x3)\n\n# Plot data frame\nplot(t$a, type = \"l\", ylim = range(t), lwd = 3, col = rgb(1, 0, 0, 0.3))\nlines(t$b, type = \"s\", lwd = 2, col = rgb(0.3, 0.4, 0.3, 0.9))\npoints(t$c, pch = 20, cex = 4, col = rgb(0, 0, 1, 0.3))\n\n# Note that with plot you get a new plot window while points and lines add to the previous plot.\n\nTry to find out by experimenting what the meaning is of rgb, the last argument of rgb, lwd, pch, cex. Type play() on the command line to experiment. Modify lines 11, 12 and 13 of the script by putting your cursor there and pressing CTRL+ENTER. When you are finished, type nxt() and then ?par.\nHint: Type ?par or type skip() if you are not interested.\n\n?par\n\nYou searched for par in the R help. This is a useful page to learn more about formatting plots. Google ‘R color chart’ for a pdf file with a wealth of color options.\nTo copy your plot to a document, go to the plots window, click the ‘Export’ button, choose the nicest width and height and click ‘Copy’ or ‘Save’.\nAfter having almost completed the second learning module, you are getting closer to become a nerd as you know…\n…that everything in R is stored in objects (values, vectors, matrices, lists, or data frames),\n…that you should always work in scripts and send code from scripts to the Console,\n…that you can do it if you don’t give up.\nPlease continue choosing another swirl learning module.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive introduction with swirl</span>"
    ]
  },
  {
    "objectID": "10_swirl.html#swirl-it-data-analytical-basics",
    "href": "10_swirl.html#swirl-it-data-analytical-basics",
    "title": "4  Interactive introduction with swirl",
    "section": "4.4 swirl-it: Data analytical basics",
    "text": "4.4 swirl-it: Data analytical basics\nIn my swirl modules huber-data-1, huber-data-2, and huber-data-3 I introduce some very basic statistical principles on how to analyse data.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive introduction with swirl</span>"
    ]
  },
  {
    "objectID": "10_swirl.html#swirl-it-the-tidyverse-package",
    "href": "10_swirl.html#swirl-it-the-tidyverse-package",
    "title": "4  Interactive introduction with swirl",
    "section": "4.5 swirl-it: The tidyverse package",
    "text": "4.5 swirl-it: The tidyverse package\nI compiled a short swirl module to introduce the tidyverse universe. This is a powerful collection of packages which I discuss later on. The learning module is also part of my swirl-it course.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive introduction with swirl</span>"
    ]
  },
  {
    "objectID": "10_swirl.html#other-swirl-modules",
    "href": "10_swirl.html#other-swirl-modules",
    "title": "4  Interactive introduction with swirl",
    "section": "4.6 Other swirl modules",
    "text": "4.6 Other swirl modules\nYou can also install some other courses. You find a list of courses here http://swirlstats.com/scn/index.html or here https://github.com/swirldev/swirl_courses.\nI recommend this one as it gives a general overview on very basic principles of R:\n\nlibrary(swirl)\ninstall_course_github(\"swirldev\", \"R_Programming_E\")\nswirl()\n\n\n\n\n\nIrizarry, R. A. (2022). Introduction to data science: Data analysis and prediction algorithms with R. Accessed January 30, 2023; CRC Press. https://rafalab.github.io/dsbook/",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive introduction with swirl</span>"
    ]
  },
  {
    "objectID": "05_workflow.html",
    "href": "05_workflow.html",
    "title": "5  Kickstart",
    "section": "",
    "text": "5.1 Analysing the association of weight and the price of cars\nBefore we start, we need to ensure that all necessary libraries are installed and loaded. We use the pacman package for convenient package management.\n# Install and load required libraries\n# Installs 'pacman' if not already available, which is used for package management\nif (!require(pacman)) install.packages(\"pacman\")\n  \n# Unload all previously loaded packages to start fresh\nsuppressMessages(pacman::p_unload(all))\n  \n# Load necessary packages for data manipulation, cleaning, and visualization\npacman::p_load(\n  tidyverse, # A suite of packages designed for data science that includes tools for data manipulation, plotting, and more.\n  haven,     # Used for importing and exporting data with SPSS, Stata, and SAS formats.\n  janitor,   # Provides functions for examining and cleaning data, such as `clean_names()` and `tabyl()`.\n  WDI,       # Facilitates downloading data from the World Bank's World Development Indicators database.\n  wbstats    # Provides an interface to the World Bank's APIs for a comprehensive range of data sets.\n)\n  \n# Set the working directory to a project-specific folder\nsetwd(\"~/Dropbox/hsf/courses/dsr\")\n  \n# Clear the current environment of any objects\nrm(list = ls())\nNow, let us load the dataset from a Stata file (auto.dta) and explore its basic properties.\n# Load data from a Stata file available online\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r18/auto.dta\")\n# 'auto': Dataset contains information about different car models\n\n# Display basic information about the dataset\nncol(auto)  # Number of columns\n\n[1] 12\n\nnrow(auto)  # Number of rows\n\n[1] 74\n\ndim(auto)   # Dimensions of the dataset\n\n[1] 74 12\n\nnames(auto) # Names of variables\n\n [1] \"make\"         \"price\"        \"mpg\"          \"rep78\"        \"headroom\"    \n [6] \"trunk\"        \"weight\"       \"length\"       \"turn\"         \"displacement\"\n[11] \"gear_ratio\"   \"foreign\"     \n\nhead(auto)  # First few rows\n\n# A tibble: 6 × 12\n  make         price   mpg rep78 headroom trunk weight length  turn displacement\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 AMC Concord   4099    22     3      2.5    11   2930    186    40          121\n2 AMC Pacer     4749    17     3      3      11   3350    173    40          258\n3 AMC Spirit    3799    22    NA      3      12   2640    168    35          121\n4 Buick Centu…  4816    20     3      4.5    16   3250    196    40          196\n5 Buick Elect…  7827    15     4      4      20   4080    222    43          350\n6 Buick LeSab…  5788    18     3      4      21   3670    218    43          231\n# ℹ 2 more variables: gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\n\ntail(auto)  # Last few rows\n\n# A tibble: 6 × 12\n  make         price   mpg rep78 headroom trunk weight length  turn displacement\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 Toyota Coro…  5719    18     5      2      11   2670    175    36          134\n2 VW Dasher     7140    23     4      2.5    12   2160    172    36           97\n3 VW Diesel     5397    41     5      3      15   2040    155    35           90\n4 VW Rabbit     4697    25     4      3      15   1930    155    35           89\n5 VW Scirocco   6850    25     4      2      16   1990    156    36           97\n6 Volvo 260    11995    17     5      2.5    14   3170    193    37          163\n# ℹ 2 more variables: gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\n\nsummary(auto) # Summary statistics for each column\n\n     make               price            mpg            rep78      \n Length:74          Min.   : 3291   Min.   :12.00   Min.   :1.000  \n Class :character   1st Qu.: 4220   1st Qu.:18.00   1st Qu.:3.000  \n Mode  :character   Median : 5006   Median :20.00   Median :3.000  \n                    Mean   : 6165   Mean   :21.30   Mean   :3.406  \n                    3rd Qu.: 6332   3rd Qu.:24.75   3rd Qu.:4.000  \n                    Max.   :15906   Max.   :41.00   Max.   :5.000  \n                                                    NA's   :5      \n    headroom         trunk           weight         length           turn      \n Min.   :1.500   Min.   : 5.00   Min.   :1760   Min.   :142.0   Min.   :31.00  \n 1st Qu.:2.500   1st Qu.:10.25   1st Qu.:2250   1st Qu.:170.0   1st Qu.:36.00  \n Median :3.000   Median :14.00   Median :3190   Median :192.5   Median :40.00  \n Mean   :2.993   Mean   :13.76   Mean   :3019   Mean   :187.9   Mean   :39.65  \n 3rd Qu.:3.500   3rd Qu.:16.75   3rd Qu.:3600   3rd Qu.:203.8   3rd Qu.:43.00  \n Max.   :5.000   Max.   :23.00   Max.   :4840   Max.   :233.0   Max.   :51.00  \n                                                                               \n  displacement     gear_ratio       foreign      \n Min.   : 79.0   Min.   :2.190   Min.   :0.0000  \n 1st Qu.:119.0   1st Qu.:2.730   1st Qu.:0.0000  \n Median :196.0   Median :2.955   Median :0.0000  \n Mean   :197.3   Mean   :3.015   Mean   :0.2973  \n 3rd Qu.:245.2   3rd Qu.:3.353   3rd Qu.:1.0000  \n Max.   :425.0   Max.   :3.890   Max.   :1.0000  \n                                                 \n\nglimpse(auto) # Compact display of the structure of the dataset\n\nRows: 74\nColumns: 12\n$ make         &lt;chr&gt; \"AMC Concord\", \"AMC Pacer\", \"AMC Spirit\", \"Buick Century\"…\n$ price        &lt;dbl&gt; 4099, 4749, 3799, 4816, 7827, 5788, 4453, 5189, 10372, 40…\n$ mpg          &lt;dbl&gt; 22, 17, 22, 20, 15, 18, 26, 20, 16, 19, 14, 14, 21, 29, 1…\n$ rep78        &lt;dbl&gt; 3, 3, NA, 3, 4, 3, NA, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2, 3…\n$ headroom     &lt;dbl&gt; 2.5, 3.0, 3.0, 4.5, 4.0, 4.0, 3.0, 2.0, 3.5, 3.5, 4.0, 3.…\n$ trunk        &lt;dbl&gt; 11, 11, 12, 16, 20, 21, 10, 16, 17, 13, 20, 16, 13, 9, 20…\n$ weight       &lt;dbl&gt; 2930, 3350, 2640, 3250, 4080, 3670, 2230, 3280, 3880, 340…\n$ length       &lt;dbl&gt; 186, 173, 168, 196, 222, 218, 170, 200, 207, 200, 221, 20…\n$ turn         &lt;dbl&gt; 40, 40, 35, 40, 43, 43, 34, 42, 43, 42, 44, 43, 45, 34, 4…\n$ displacement &lt;dbl&gt; 121, 258, 121, 196, 350, 231, 304, 196, 231, 231, 425, 35…\n$ gear_ratio   &lt;dbl&gt; 3.58, 2.53, 3.08, 2.93, 2.41, 2.73, 2.87, 2.93, 2.93, 3.0…\n$ foreign      &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\nprint(auto, n = Inf) # Print all rows of the dataset\n\n# A tibble: 74 × 12\n   make        price   mpg rep78 headroom trunk weight length  turn displacement\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n 1 AMC Concord  4099    22     3      2.5    11   2930    186    40          121\n 2 AMC Pacer    4749    17     3      3      11   3350    173    40          258\n 3 AMC Spirit   3799    22    NA      3      12   2640    168    35          121\n 4 Buick Cent…  4816    20     3      4.5    16   3250    196    40          196\n 5 Buick Elec…  7827    15     4      4      20   4080    222    43          350\n 6 Buick LeSa…  5788    18     3      4      21   3670    218    43          231\n 7 Buick Opel   4453    26    NA      3      10   2230    170    34          304\n 8 Buick Regal  5189    20     3      2      16   3280    200    42          196\n 9 Buick Rivi… 10372    16     3      3.5    17   3880    207    43          231\n10 Buick Skyl…  4082    19     3      3.5    13   3400    200    42          231\n11 Cad. Devil… 11385    14     3      4      20   4330    221    44          425\n12 Cad. Eldor… 14500    14     2      3.5    16   3900    204    43          350\n13 Cad. Sevil… 15906    21     3      3      13   4290    204    45          350\n14 Chev. Chev…  3299    29     3      2.5     9   2110    163    34          231\n15 Chev. Impa…  5705    16     4      4      20   3690    212    43          250\n16 Chev. Mali…  4504    22     3      3.5    17   3180    193    31          200\n17 Chev. Mont…  5104    22     2      2      16   3220    200    41          200\n18 Chev. Monza  3667    24     2      2       7   2750    179    40          151\n19 Chev. Nova   3955    19     3      3.5    13   3430    197    43          250\n20 Dodge Colt   3984    30     5      2       8   2120    163    35           98\n21 Dodge Dipl…  4010    18     2      4      17   3600    206    46          318\n22 Dodge Magn…  5886    16     2      4      17   3600    206    46          318\n23 Dodge St. …  6342    17     2      4.5    21   3740    220    46          225\n24 Ford Fiesta  4389    28     4      1.5     9   1800    147    33           98\n25 Ford Musta…  4187    21     3      2      10   2650    179    43          140\n26 Linc. Cont… 11497    12     3      3.5    22   4840    233    51          400\n27 Linc. Mark… 13594    12     3      2.5    18   4720    230    48          400\n28 Linc. Vers… 13466    14     3      3.5    15   3830    201    41          302\n29 Merc. Bobc…  3829    22     4      3       9   2580    169    39          140\n30 Merc. Coug…  5379    14     4      3.5    16   4060    221    48          302\n31 Merc. Marq…  6165    15     3      3.5    23   3720    212    44          302\n32 Merc. Mona…  4516    18     3      3      15   3370    198    41          250\n33 Merc. XR-7   6303    14     4      3      16   4130    217    45          302\n34 Merc. Zeph…  3291    20     3      3.5    17   2830    195    43          140\n35 Olds 98      8814    21     4      4      20   4060    220    43          350\n36 Olds Cutl …  5172    19     3      2      16   3310    198    42          231\n37 Olds Cutla…  4733    19     3      4.5    16   3300    198    42          231\n38 Olds Delta…  4890    18     4      4      20   3690    218    42          231\n39 Olds Omega   4181    19     3      4.5    14   3370    200    43          231\n40 Olds Starf…  4195    24     1      2      10   2730    180    40          151\n41 Olds Toron… 10371    16     3      3.5    17   4030    206    43          350\n42 Plym. Arrow  4647    28     3      2      11   3260    170    37          156\n43 Plym. Champ  4425    34     5      2.5    11   1800    157    37           86\n44 Plym. Hori…  4482    25     3      4      17   2200    165    36          105\n45 Plym. Sapp…  6486    26    NA      1.5     8   2520    182    38          119\n46 Plym. Vola…  4060    18     2      5      16   3330    201    44          225\n47 Pont. Cata…  5798    18     4      4      20   3700    214    42          231\n48 Pont. Fire…  4934    18     1      1.5     7   3470    198    42          231\n49 Pont. Gran…  5222    19     3      2      16   3210    201    45          231\n50 Pont. Le M…  4723    19     3      3.5    17   3200    199    40          231\n51 Pont. Phoe…  4424    19    NA      3.5    13   3420    203    43          231\n52 Pont. Sunb…  4172    24     2      2       7   2690    179    41          151\n53 Audi 5000    9690    17     5      3      15   2830    189    37          131\n54 Audi Fox     6295    23     3      2.5    11   2070    174    36           97\n55 BMW 320i     9735    25     4      2.5    12   2650    177    34          121\n56 Datsun 200   6229    23     4      1.5     6   2370    170    35          119\n57 Datsun 210   4589    35     5      2       8   2020    165    32           85\n58 Datsun 510   5079    24     4      2.5     8   2280    170    34          119\n59 Datsun 810   8129    21     4      2.5     8   2750    184    38          146\n60 Fiat Strada  4296    21     3      2.5    16   2130    161    36          105\n61 Honda Acco…  5799    25     5      3      10   2240    172    36          107\n62 Honda Civic  4499    28     4      2.5     5   1760    149    34           91\n63 Mazda GLC    3995    30     4      3.5    11   1980    154    33           86\n64 Peugeot 604 12990    14    NA      3.5    14   3420    192    38          163\n65 Renault Le…  3895    26     3      3      10   1830    142    34           79\n66 Subaru       3798    35     5      2.5    11   2050    164    36           97\n67 Toyota Cel…  5899    18     5      2.5    14   2410    174    36          134\n68 Toyota Cor…  3748    31     5      3       9   2200    165    35           97\n69 Toyota Cor…  5719    18     5      2      11   2670    175    36          134\n70 VW Dasher    7140    23     4      2.5    12   2160    172    36           97\n71 VW Diesel    5397    41     5      3      15   2040    155    35           90\n72 VW Rabbit    4697    25     4      3      15   1930    155    35           89\n73 VW Scirocco  6850    25     4      2      16   1990    156    36           97\n74 Volvo 260   11995    17     5      2.5    14   3170    193    37          163\n# ℹ 2 more variables: gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\nThe data seems to be a cross-section of cars. Let us check if the variable make identifies each line uniquely:\n# Check for duplicate entries based on the 'make' variable\nauto |&gt;\n  get_dupes(make)\n\nNo duplicate combinations found of: make\n\n\n# A tibble: 0 × 13\n# ℹ 13 variables: make &lt;chr&gt;, dupe_count &lt;int&gt;, price &lt;dbl&gt;, mpg &lt;dbl&gt;,\n#   rep78 &lt;dbl&gt;, headroom &lt;dbl&gt;, trunk &lt;dbl&gt;, weight &lt;dbl&gt;, length &lt;dbl&gt;,\n#   turn &lt;dbl&gt;, displacement &lt;dbl&gt;, gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\nIndeed, the variable make has no duplicates. Now, let’s make and save some graphical visualizations:\n# Create and display a scatter plot of car price versus weight\nplot_weight_price &lt;- ggplot(auto, aes(x = weight, y = price)) +\n  geom_point()\nplot_weight_price\n\n\n\n\n\n\n\n# Save the plot to a file\nggsave(\"fig/plot_weight_price.png\", plot = plot_weight_price, dpi = 300)\n\nSaving 7 x 5 in image\n\n# Create a scatter plot with a linear regression line of price vs weight\nplot_weight_price_fit &lt;- ggplot(auto, aes(x = weight, y = price)) +\n  geom_point() +\n  geom_smooth(method = lm, se = FALSE)  # 'lm' denotes linear model, 'se' is standard error\nplot_weight_price_fit\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Save the plot to a file\nggsave(\"fig/plot_weight_price_fit.png\", plot = plot_weight_price_fit, dpi = 300)\n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\nLet us perform a linear regression to quantify the impact of weight on price:\n# Perform a linear regression to analyze the relationship between weight and price\nreg_result &lt;- lm(price ~ weight , data = auto)\nsummary(reg_result) # Display the regression results\n\n\nCall:\nlm(formula = price ~ weight, data = auto)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3341.9 -1828.3  -624.1  1232.1  7143.7 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -6.7074  1174.4296  -0.006    0.995    \nweight         2.0441     0.3768   5.424 7.42e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2502 on 72 degrees of freedom\nMultiple R-squared:  0.2901,    Adjusted R-squared:  0.2802 \nF-statistic: 29.42 on 1 and 72 DF,  p-value: 7.416e-07",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kickstart</span>"
    ]
  },
  {
    "objectID": "05_workflow.html#sec-wbexample",
    "href": "05_workflow.html#sec-wbexample",
    "title": "5  Kickstart",
    "section": "5.2 Accessing World Bank’s World Development Indicators",
    "text": "5.2 Accessing World Bank’s World Development Indicators\nThe World Wide Web is a treasure trove of data, and most major databases offer researchers direct download options. Numerous user-supplied packages are available for seamless access to such data. In this section, I present two popular packages that facilitate the downloading of data from the World Bank’s World Development Indicators:\nWDI (World Development Indicators) Package - Official CRAN package documentation: WDI on CRAN - Source code on GitHub: WDI GitHub Repository\nwbstats (World Bank Statistics) Package - Official CRAN package documentation: wbstats on CRAN - Source code on GitHub: wbstats GitHub Repository\nNow, let’s download some GDP data and explore how to manipulate it. This exercise will demonstrate practical applications of the tools.\n\n# Search for GDP indicators and display the first 10\nWDIsearch(\"gdp\")[1:10, ]\n\n                indicator                                                 name\n712        5.51.01.10.gdp                                Per capita GDP growth\n714       6.0.GDP_current                                      GDP (current $)\n715        6.0.GDP_growth                                GDP growth (annual %)\n716           6.0.GDP_usd                                GDP (constant 2005 $)\n717    6.0.GDPpc_constant GDP per capita, PPP (constant 2011 international $) \n1557    BG.GSR.NFSV.GD.ZS                         Trade in services (% of GDP)\n1558 BG.KAC.FNEI.GD.PP.ZS          Gross private capital flows (% of GDP, PPP)\n1559    BG.KAC.FNEI.GD.ZS               Gross private capital flows (% of GDP)\n1560 BG.KLT.DINV.GD.PP.ZS      Gross foreign direct investment (% of GDP, PPP)\n1561    BG.KLT.DINV.GD.ZS           Gross foreign direct investment (% of GDP)\n\n# Retrieve GDP per capita data for specified countries and years\ndf_WDI &lt;- WDI(\n  indicator = \"NY.GDP.PCAP.KD\",\n  country = c(\"MX\", \"CA\", \"US\"),\n  start = 1960,\n  end = 2012\n)\n\n# Plot GDP per capita over time for the specified countries\nggplot(df_WDI, aes(year, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita\")\n\n\n\n\n\n\n\n# Retrieve GDP per capita data for specified countries and years using the wbstats package\ndf_wb &lt;- wb(\n  indicator = \"NY.GDP.PCAP.KD\",\n  country = c(\"MX\", \"CA\", \"US\"),\n  start = 1960,\n  end = 2012,\n  return_wide = TRUE\n)\n\nWarning: `wb()` was deprecated in wbstats 1.0.0.\nℹ Please use `wb_data()` instead.\n\n\nWarning: `spread_()` was deprecated in tidyr 1.2.0.\nℹ Please use `spread()` instead.\nℹ The deprecated feature was likely used in the wbstats package.\n  Please report the issue at &lt;https://github.com/nset-ornl/wbstats/issues&gt;.\n\n# Plot GDP per capita over time for the specified countries\nggplot(df_wb, aes(date, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita (constant 2010 US$)\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\nThe latter graph appears empty. Why? Let’s take a closer look at the data to identify any discrepancies that might explain this issue:\n\n# Look at the data types year and date are different:\nglimpse(df_WDI)\n\nRows: 159\nColumns: 5\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ year           &lt;int&gt; 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 42319.63, 42043.51, 41165.57, 40377.82, 42067.80, 42106…\n\nglimpse(df_wb)\n\nRows: 159\nColumns: 5\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ date           &lt;chr&gt; \"1960\", \"1961\", \"1962\", \"1963\", \"1964\", \"1965\", \"1966\",…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 14229.83, 14389.40, 15173.02, 15689.70, 16419.39, 17143…\n\n\nThe answer is: A lineplot with a character variable (date is &lt;chr&gt;) on the x-axis does not work!\nNow, let us manipulate the df_wb data so that the two dataset are equal:\n\ndf_wb_cln &lt;- df_wb |&gt;\n  # Convert 'date' in df_wb from character to integer\n  mutate(year = as.integer(date)) |&gt;\n  # Since 'year' has been created, remove the original 'date' column\n  select(-date) |&gt;\n  # Relocate columns to organize the data frame\n  relocate(country, iso2c, iso3c, year, NY.GDP.PCAP.KD)\n\nglimpse(df_WDI)\n\nRows: 159\nColumns: 5\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ year           &lt;int&gt; 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 42319.63, 42043.51, 41165.57, 40377.82, 42067.80, 42106…\n\nglimpse(df_wb_cln)\n\nRows: 159\nColumns: 5\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ year           &lt;int&gt; 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 14229.83, 14389.40, 15173.02, 15689.70, 16419.39, 17143…\n\n\nNow it works:\n\n# Plot GDP per capita over time for the specified countries\nggplot(df_wb_cln, aes(year, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita (constant 2010 US$)\")\n\n\n\n\n\n\n\n\nLoading required package: funcuse\nLoading required package: pacman\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, as.integer, c, dim, geom_line, geom_point, geom_smooth, get_dupes, ggplot, ggsave, glimpse, head, lm, mutate, names, ncol, nrow, print, read_dta, relocate, select, setwd, summary, tail, wb, WDI, WDIsearch, xlab, ylab.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# This script demonstrates a typical data analysis workflow in R\n# ---------------------------------------------------------------\n\n# Install and load required libraries\n# Installs 'pacman' if not already available, which is used for package management\nif (!require(pacman)) install.packages(\"pacman\")\n\n# Unload all previously loaded packages to start fresh\nsuppressMessages(pacman::p_unload(all))\n\n# Load necessary packages for data manipulation, cleaning, and visualization\npacman::p_load(\n  tidyverse, # A suite of packages designed for data science that includes tools for data manipulation, plotting, and more.\n  haven, # Used for importing and exporting data with SPSS, Stata, and SAS formats.\n  janitor, # Provides functions for examining and cleaning data, such as `clean_names()` and `tabyl()`.\n  WDI, # Facilitates downloading data from the World Bank's World Development Indicators database.\n  wbstats # Provides an interface to the World Bank's APIs for a comprehensive range of data sets.\n)\n\n# Set the working directory to a project-specific folder\nsetwd(\"~/Dropbox/hsf/courses/dsr\")\n\n# Clear the current environment of any objects\nrm(list = ls())\n\n# ---------------------------------------------------------------\n\n# Load data from a Stata file available online\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r8/auto.dta\")\n# 'auto': Dataset contains information about different car models\n\n# Display basic information about the dataset\nncol(auto) # Number of columns\nnrow(auto) # Number of rows\ndim(auto) # Dimensions of the dataset\nnames(auto) # Names of variables\nhead(auto) # First few rows\ntail(auto) # Last few rows\nsummary(auto) # Summary statistics for each column\nglimpse(auto) # Compact display of the structure of the dataset\nprint(auto, n = Inf) # Print all rows of the dataset\n\n# Check for duplicate entries based on the 'make' variable\nauto |&gt;\n  get_dupes(make)\n\n# Create and display a scatter plot of car price versus weight\nplot_weight_price &lt;- ggplot(auto, aes(x = weight, y = price)) +\n  geom_point()\nplot_weight_price\n\n# Save the plot to a file\nggsave(\"fig/plot_weight_price.png\", plot = plot_weight_price, dpi = 300)\n\n# Create a scatter plot with a linear regression line of price vs weight\nplot_weight_price_fit &lt;- ggplot(auto, aes(x = weight, y = price)) +\n  geom_point() +\n  geom_smooth(method = lm, se = FALSE) # 'lm' denotes linear model, 'se' is standard error\nplot_weight_price_fit\n\n# Save the plot to a file\nggsave(\"fig/plot_weight_price_fit.png\", plot = plot_weight_price_fit, dpi = 300)\n\n# Perform a linear regression to analyze the relationship between weight and price\nreg_result &lt;- lm(price ~ weight, data = auto)\nsummary(reg_result) # Display the regression results\n\n# Load and demonstrate usage of World Development Indicators (WDI) data\n# Two different packages can help here:\n# WDI:\n# --- https://cran.r-project.org/web/packages/WDI/WDI.pdf\n# --- https://github.com/vincentarelbundock/WDI\n# wbstats:\n# --- https://cran.r-project.org/web/packages/wbstats/wbstats.pdf\n# --- https://github.com/gshs-ornl/wbstats\n# ?WDI  # Access documentation for the WDI package\n# ?wbstats # # Access documentation for the wbstats package\n\n# Search for GDP indicators and display the first 10\nWDIsearch(\"gdp\")[1:10, ]\n\n# Retrieve GDP per capita data for specified countries and years\ndf_WDI &lt;- WDI(\n  indicator = \"NY.GDP.PCAP.KD\",\n  country = c(\"MX\", \"CA\", \"US\"),\n  start = 1960,\n  end = 2012\n)\n\n# Plot GDP per capita over time for the specified countries\nggplot(df_WDI, aes(year, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita\")\n\n# Retrieve GDP per capita data for specified countries and years using the wbstats package\ndf_wb &lt;- wb(\n  indicator = \"NY.GDP.PCAP.KD\",\n  country = c(\"MX\", \"CA\", \"US\"),\n  start = 1960,\n  end = 2012,\n  return_wide = TRUE\n)\n\n# Plot GDP per capita over time for the specified countries\nggplot(df_wb, aes(date, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita (constant 2010 US$)\")\n\n# !!! This does not work !!!\n# Why?\n\n# Look at the data types year and date are different:\nglimpse(df_WDI)\nglimpse(df_wb)\n\n# Answer: A lineplot with a character variable on the x-axis does not work!\n\n# make the two dataframe equal:\ndf_wb_cln &lt;- df_wb |&gt;\n  # Convert 'date' in df_wb from character to integer\n  mutate(year = as.integer(date)) |&gt;\n  # Since 'year' has been created, remove the original 'date' column\n  select(-date) |&gt;\n  # Relocate columns to organize the data frame\n  relocate(country, iso2c, iso3c, year, NY.GDP.PCAP.KD)\n\nglimpse(df_WDI)\nglimpse(df_wb_cln)\n\n# Now it works:\n# Plot GDP per capita over time for the specified countries\nggplot(df_wb_cln, aes(year, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita (constant 2010 US$)\")\n\nsuppressMessages(pacman::p_unload(\n  tidyverse, # A suite of packages designed for data science that includes tools for data manipulation, plotting, and more.\n  haven, # Used for importing and exporting data with SPSS, Stata, and SAS formats.\n  janitor, # Provides functions for examining and cleaning data, such as `clean_names()` and `tabyl()`.\n  WDI, # Facilitates downloading data from the World Bank's World Development Indicators database.\n  wbstats # Provides an interface to the World Bank's APIs for a comprehensive range of data sets.\n))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# This script demonstrates a typical data analysis workflow in R\n# ---------------------------------------------------------------\n\n# Install and load required libraries\n# Installs 'pacman' if not already available, which is used for package management\nif (!require(pacman)) install.packages(\"pacman\")\n\n# Unload all previously loaded packages to start fresh\nsuppressMessages(pacman::p_unload(all))\n\n# Load necessary packages for data manipulation, cleaning, and visualization\npacman::p_load(\n  tidyverse, # A suite of packages designed for data science that includes tools for data manipulation, plotting, and more.\n  haven, # Used for importing and exporting data with SPSS, Stata, and SAS formats.\n  janitor, # Provides functions for examining and cleaning data, such as `clean_names()` and `tabyl()`.\n  WDI, # Facilitates downloading data from the World Bank's World Development Indicators database.\n  wbstats # Provides an interface to the World Bank's APIs for a comprehensive range of data sets.\n)\n\n# Set the working directory to a project-specific folder\nsetwd(\"~/Dropbox/hsf/courses/dsr\")\n\n# Clear the current environment of any objects\nrm(list = ls())\n\n# ---------------------------------------------------------------\n\n# Load data from a Stata file available online\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r8/auto.dta\")\n# 'auto': Dataset contains information about different car models\n\n# Display basic information about the dataset\nncol(auto) # Number of columns\n\n[1] 12\n\nnrow(auto) # Number of rows\n\n[1] 74\n\ndim(auto) # Dimensions of the dataset\n\n[1] 74 12\n\nnames(auto) # Names of variables\n\n [1] \"make\"         \"price\"        \"mpg\"          \"rep78\"        \"headroom\"    \n [6] \"trunk\"        \"weight\"       \"length\"       \"turn\"         \"displacement\"\n[11] \"gear_ratio\"   \"foreign\"     \n\nhead(auto) # First few rows\n\n# A tibble: 6 × 12\n  make         price   mpg rep78 headroom trunk weight length  turn displacement\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 AMC Concord   4099    22     3      2.5    11   2930    186    40          121\n2 AMC Pacer     4749    17     3      3      11   3350    173    40          258\n3 AMC Spirit    3799    22    NA      3      12   2640    168    35          121\n4 Buick Centu…  4816    20     3      4.5    16   3250    196    40          196\n5 Buick Elect…  7827    15     4      4      20   4080    222    43          350\n6 Buick LeSab…  5788    18     3      4      21   3670    218    43          231\n# ℹ 2 more variables: gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\n\ntail(auto) # Last few rows\n\n# A tibble: 6 × 12\n  make         price   mpg rep78 headroom trunk weight length  turn displacement\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 Toyota Coro…  5719    18     5      2      11   2670    175    36          134\n2 VW Dasher     7140    23     4      2.5    12   2160    172    36           97\n3 VW Diesel     5397    41     5      3      15   2040    155    35           90\n4 VW Rabbit     4697    25     4      3      15   1930    155    35           89\n5 VW Scirocco   6850    25     4      2      16   1990    156    36           97\n6 Volvo 260    11995    17     5      2.5    14   3170    193    37          163\n# ℹ 2 more variables: gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\n\nsummary(auto) # Summary statistics for each column\n\n     make               price            mpg            rep78      \n Length:74          Min.   : 3291   Min.   :12.00   Min.   :1.000  \n Class :character   1st Qu.: 4220   1st Qu.:18.00   1st Qu.:3.000  \n Mode  :character   Median : 5006   Median :20.00   Median :3.000  \n                    Mean   : 6165   Mean   :21.30   Mean   :3.406  \n                    3rd Qu.: 6332   3rd Qu.:24.75   3rd Qu.:4.000  \n                    Max.   :15906   Max.   :41.00   Max.   :5.000  \n                                                    NA's   :5      \n    headroom         trunk           weight         length           turn      \n Min.   :1.500   Min.   : 5.00   Min.   :1760   Min.   :142.0   Min.   :31.00  \n 1st Qu.:2.500   1st Qu.:10.25   1st Qu.:2250   1st Qu.:170.0   1st Qu.:36.00  \n Median :3.000   Median :14.00   Median :3190   Median :192.5   Median :40.00  \n Mean   :2.993   Mean   :13.76   Mean   :3019   Mean   :187.9   Mean   :39.65  \n 3rd Qu.:3.500   3rd Qu.:16.75   3rd Qu.:3600   3rd Qu.:203.8   3rd Qu.:43.00  \n Max.   :5.000   Max.   :23.00   Max.   :4840   Max.   :233.0   Max.   :51.00  \n                                                                               \n  displacement     gear_ratio       foreign      \n Min.   : 79.0   Min.   :2.190   Min.   :0.0000  \n 1st Qu.:119.0   1st Qu.:2.730   1st Qu.:0.0000  \n Median :196.0   Median :2.955   Median :0.0000  \n Mean   :197.3   Mean   :3.015   Mean   :0.2973  \n 3rd Qu.:245.2   3rd Qu.:3.353   3rd Qu.:1.0000  \n Max.   :425.0   Max.   :3.890   Max.   :1.0000  \n                                                 \n\nglimpse(auto) # Compact display of the structure of the dataset\n\nRows: 74\nColumns: 12\n$ make         &lt;chr&gt; \"AMC Concord\", \"AMC Pacer\", \"AMC Spirit\", \"Buick Century\"…\n$ price        &lt;dbl&gt; 4099, 4749, 3799, 4816, 7827, 5788, 4453, 5189, 10372, 40…\n$ mpg          &lt;dbl&gt; 22, 17, 22, 20, 15, 18, 26, 20, 16, 19, 14, 14, 21, 29, 1…\n$ rep78        &lt;dbl&gt; 3, 3, NA, 3, 4, 3, NA, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2, 3…\n$ headroom     &lt;dbl&gt; 2.5, 3.0, 3.0, 4.5, 4.0, 4.0, 3.0, 2.0, 3.5, 3.5, 4.0, 3.…\n$ trunk        &lt;dbl&gt; 11, 11, 12, 16, 20, 21, 10, 16, 17, 13, 20, 16, 13, 9, 20…\n$ weight       &lt;dbl&gt; 2930, 3350, 2640, 3250, 4080, 3670, 2230, 3280, 3880, 340…\n$ length       &lt;dbl&gt; 186, 173, 168, 196, 222, 218, 170, 200, 207, 200, 221, 20…\n$ turn         &lt;dbl&gt; 40, 40, 35, 40, 43, 43, 34, 42, 43, 42, 44, 43, 45, 34, 4…\n$ displacement &lt;dbl&gt; 121, 258, 121, 196, 350, 231, 304, 196, 231, 231, 425, 35…\n$ gear_ratio   &lt;dbl&gt; 3.58, 2.53, 3.08, 2.93, 2.41, 2.73, 2.87, 2.93, 2.93, 3.0…\n$ foreign      &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\nprint(auto, n = Inf) # Print all rows of the dataset\n\n# A tibble: 74 × 12\n   make        price   mpg rep78 headroom trunk weight length  turn displacement\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n 1 AMC Concord  4099    22     3      2.5    11   2930    186    40          121\n 2 AMC Pacer    4749    17     3      3      11   3350    173    40          258\n 3 AMC Spirit   3799    22    NA      3      12   2640    168    35          121\n 4 Buick Cent…  4816    20     3      4.5    16   3250    196    40          196\n 5 Buick Elec…  7827    15     4      4      20   4080    222    43          350\n 6 Buick LeSa…  5788    18     3      4      21   3670    218    43          231\n 7 Buick Opel   4453    26    NA      3      10   2230    170    34          304\n 8 Buick Regal  5189    20     3      2      16   3280    200    42          196\n 9 Buick Rivi… 10372    16     3      3.5    17   3880    207    43          231\n10 Buick Skyl…  4082    19     3      3.5    13   3400    200    42          231\n11 Cad. Devil… 11385    14     3      4      20   4330    221    44          425\n12 Cad. Eldor… 14500    14     2      3.5    16   3900    204    43          350\n13 Cad. Sevil… 15906    21     3      3      13   4290    204    45          350\n14 Chev. Chev…  3299    29     3      2.5     9   2110    163    34          231\n15 Chev. Impa…  5705    16     4      4      20   3690    212    43          250\n16 Chev. Mali…  4504    22     3      3.5    17   3180    193    31          200\n17 Chev. Mont…  5104    22     2      2      16   3220    200    41          200\n18 Chev. Monza  3667    24     2      2       7   2750    179    40          151\n19 Chev. Nova   3955    19     3      3.5    13   3430    197    43          250\n20 Dodge Colt   3984    30     5      2       8   2120    163    35           98\n21 Dodge Dipl…  4010    18     2      4      17   3600    206    46          318\n22 Dodge Magn…  5886    16     2      4      17   3600    206    46          318\n23 Dodge St. …  6342    17     2      4.5    21   3740    220    46          225\n24 Ford Fiesta  4389    28     4      1.5     9   1800    147    33           98\n25 Ford Musta…  4187    21     3      2      10   2650    179    43          140\n26 Linc. Cont… 11497    12     3      3.5    22   4840    233    51          400\n27 Linc. Mark… 13594    12     3      2.5    18   4720    230    48          400\n28 Linc. Vers… 13466    14     3      3.5    15   3830    201    41          302\n29 Merc. Bobc…  3829    22     4      3       9   2580    169    39          140\n30 Merc. Coug…  5379    14     4      3.5    16   4060    221    48          302\n31 Merc. Marq…  6165    15     3      3.5    23   3720    212    44          302\n32 Merc. Mona…  4516    18     3      3      15   3370    198    41          250\n33 Merc. XR-7   6303    14     4      3      16   4130    217    45          302\n34 Merc. Zeph…  3291    20     3      3.5    17   2830    195    43          140\n35 Olds 98      8814    21     4      4      20   4060    220    43          350\n36 Olds Cutl …  5172    19     3      2      16   3310    198    42          231\n37 Olds Cutla…  4733    19     3      4.5    16   3300    198    42          231\n38 Olds Delta…  4890    18     4      4      20   3690    218    42          231\n39 Olds Omega   4181    19     3      4.5    14   3370    200    43          231\n40 Olds Starf…  4195    24     1      2      10   2730    180    40          151\n41 Olds Toron… 10371    16     3      3.5    17   4030    206    43          350\n42 Plym. Arrow  4647    28     3      2      11   3260    170    37          156\n43 Plym. Champ  4425    34     5      2.5    11   1800    157    37           86\n44 Plym. Hori…  4482    25     3      4      17   2200    165    36          105\n45 Plym. Sapp…  6486    26    NA      1.5     8   2520    182    38          119\n46 Plym. Vola…  4060    18     2      5      16   3330    201    44          225\n47 Pont. Cata…  5798    18     4      4      20   3700    214    42          231\n48 Pont. Fire…  4934    18     1      1.5     7   3470    198    42          231\n49 Pont. Gran…  5222    19     3      2      16   3210    201    45          231\n50 Pont. Le M…  4723    19     3      3.5    17   3200    199    40          231\n51 Pont. Phoe…  4424    19    NA      3.5    13   3420    203    43          231\n52 Pont. Sunb…  4172    24     2      2       7   2690    179    41          151\n53 Audi 5000    9690    17     5      3      15   2830    189    37          131\n54 Audi Fox     6295    23     3      2.5    11   2070    174    36           97\n55 BMW 320i     9735    25     4      2.5    12   2650    177    34          121\n56 Datsun 200   6229    23     4      1.5     6   2370    170    35          119\n57 Datsun 210   4589    35     5      2       8   2020    165    32           85\n58 Datsun 510   5079    24     4      2.5     8   2280    170    34          119\n59 Datsun 810   8129    21     4      2.5     8   2750    184    38          146\n60 Fiat Strada  4296    21     3      2.5    16   2130    161    36          105\n61 Honda Acco…  5799    25     5      3      10   2240    172    36          107\n62 Honda Civic  4499    28     4      2.5     5   1760    149    34           91\n63 Mazda GLC    3995    30     4      3.5    11   1980    154    33           86\n64 Peugeot 604 12990    14    NA      3.5    14   3420    192    38          163\n65 Renault Le…  3895    26     3      3      10   1830    142    34           79\n66 Subaru       3798    35     5      2.5    11   2050    164    36           97\n67 Toyota Cel…  5899    18     5      2.5    14   2410    174    36          134\n68 Toyota Cor…  3748    31     5      3       9   2200    165    35           97\n69 Toyota Cor…  5719    18     5      2      11   2670    175    36          134\n70 VW Dasher    7140    23     4      2.5    12   2160    172    36           97\n71 VW Diesel    5397    41     5      3      15   2040    155    35           90\n72 VW Rabbit    4697    25     4      3      15   1930    155    35           89\n73 VW Scirocco  6850    25     4      2      16   1990    156    36           97\n74 Volvo 260   11995    17     5      2.5    14   3170    193    37          163\n# ℹ 2 more variables: gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\n\n# Check for duplicate entries based on the 'make' variable\nauto |&gt;\n  get_dupes(make)\n\nNo duplicate combinations found of: make\n\n\n# A tibble: 0 × 13\n# ℹ 13 variables: make &lt;chr&gt;, dupe_count &lt;int&gt;, price &lt;dbl&gt;, mpg &lt;dbl&gt;,\n#   rep78 &lt;dbl&gt;, headroom &lt;dbl&gt;, trunk &lt;dbl&gt;, weight &lt;dbl&gt;, length &lt;dbl&gt;,\n#   turn &lt;dbl&gt;, displacement &lt;dbl&gt;, gear_ratio &lt;dbl&gt;, foreign &lt;dbl+lbl&gt;\n\n# Create and display a scatter plot of car price versus weight\nplot_weight_price &lt;- ggplot(auto, aes(x = weight, y = price)) +\n  geom_point()\nplot_weight_price\n\n\n\n\n\n\n\n# Save the plot to a file\nggsave(\"fig/plot_weight_price.png\", plot = plot_weight_price, dpi = 300)\n\nSaving 7 x 5 in image\n\n# Create a scatter plot with a linear regression line of price vs weight\nplot_weight_price_fit &lt;- ggplot(auto, aes(x = weight, y = price)) +\n  geom_point() +\n  geom_smooth(method = lm, se = FALSE) # 'lm' denotes linear model, 'se' is standard error\nplot_weight_price_fit\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Save the plot to a file\nggsave(\"fig/plot_weight_price_fit.png\", plot = plot_weight_price_fit, dpi = 300)\n\nSaving 7 x 5 in image\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n# Perform a linear regression to analyze the relationship between weight and price\nreg_result &lt;- lm(price ~ weight, data = auto)\nsummary(reg_result) # Display the regression results\n\n\nCall:\nlm(formula = price ~ weight, data = auto)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3341.9 -1828.3  -624.1  1232.1  7143.7 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -6.7074  1174.4296  -0.006    0.995    \nweight         2.0441     0.3768   5.424 7.42e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2502 on 72 degrees of freedom\nMultiple R-squared:  0.2901,    Adjusted R-squared:  0.2802 \nF-statistic: 29.42 on 1 and 72 DF,  p-value: 7.416e-07\n\n# Load and demonstrate usage of World Development Indicators (WDI) data\n# Two different packages can help here:\n# WDI:\n# --- https://cran.r-project.org/web/packages/WDI/WDI.pdf\n# --- https://github.com/vincentarelbundock/WDI\n# wbstats:\n# --- https://cran.r-project.org/web/packages/wbstats/wbstats.pdf\n# --- https://github.com/gshs-ornl/wbstats\n# ?WDI  # Access documentation for the WDI package\n# ?wbstats # # Access documentation for the wbstats package\n\n# Search for GDP indicators and display the first 10\nWDIsearch(\"gdp\")[1:10, ]\n\n                indicator                                                 name\n712        5.51.01.10.gdp                                Per capita GDP growth\n714       6.0.GDP_current                                      GDP (current $)\n715        6.0.GDP_growth                                GDP growth (annual %)\n716           6.0.GDP_usd                                GDP (constant 2005 $)\n717    6.0.GDPpc_constant GDP per capita, PPP (constant 2011 international $) \n1557    BG.GSR.NFSV.GD.ZS                         Trade in services (% of GDP)\n1558 BG.KAC.FNEI.GD.PP.ZS          Gross private capital flows (% of GDP, PPP)\n1559    BG.KAC.FNEI.GD.ZS               Gross private capital flows (% of GDP)\n1560 BG.KLT.DINV.GD.PP.ZS      Gross foreign direct investment (% of GDP, PPP)\n1561    BG.KLT.DINV.GD.ZS           Gross foreign direct investment (% of GDP)\n\n# Retrieve GDP per capita data for specified countries and years\ndf_WDI &lt;- WDI(\n  indicator = \"NY.GDP.PCAP.KD\",\n  country = c(\"MX\", \"CA\", \"US\"),\n  start = 1960,\n  end = 2012\n)\n\n# Plot GDP per capita over time for the specified countries\nggplot(df_WDI, aes(year, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita\")\n\n\n\n\n\n\n\n# Retrieve GDP per capita data for specified countries and years using the wbstats package\ndf_wb &lt;- wb(\n  indicator = \"NY.GDP.PCAP.KD\",\n  country = c(\"MX\", \"CA\", \"US\"),\n  start = 1960,\n  end = 2012,\n  return_wide = TRUE\n)\n\n# Plot GDP per capita over time for the specified countries\nggplot(df_wb, aes(date, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita (constant 2010 US$)\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n# !!! This does not work !!!\n# Why?\n\n# Look at the data types year and date are different:\nglimpse(df_WDI)\n\nRows: 159\nColumns: 5\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ year           &lt;int&gt; 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 42319.63, 42043.51, 41165.57, 40377.82, 42067.80, 42106…\n\nglimpse(df_wb)\n\nRows: 159\nColumns: 5\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ date           &lt;chr&gt; \"1960\", \"1961\", \"1962\", \"1963\", \"1964\", \"1965\", \"1966\",…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 14229.83, 14389.40, 15173.02, 15689.70, 16419.39, 17143…\n\n# Answer: A lineplot with a character variable on the x-axis does not work!\n\n# make the two dataframe equal:\ndf_wb_cln &lt;- df_wb |&gt;\n  # Convert 'date' in df_wb from character to integer\n  mutate(year = as.integer(date)) |&gt;\n  # Since 'year' has been created, remove the original 'date' column\n  select(-date) |&gt;\n  # Relocate columns to organize the data frame\n  relocate(country, iso2c, iso3c, year, NY.GDP.PCAP.KD)\n\nglimpse(df_WDI)\n\nRows: 159\nColumns: 5\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ year           &lt;int&gt; 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 42319.63, 42043.51, 41165.57, 40377.82, 42067.80, 42106…\n\nglimpse(df_wb_cln)\n\nRows: 159\nColumns: 5\n$ country        &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Cana…\n$ iso2c          &lt;chr&gt; \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"…\n$ iso3c          &lt;chr&gt; \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\",…\n$ year           &lt;int&gt; 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1…\n$ NY.GDP.PCAP.KD &lt;dbl&gt; 14229.83, 14389.40, 15173.02, 15689.70, 16419.39, 17143…\n\n# Now it works:\n# Plot GDP per capita over time for the specified countries\nggplot(df_wb_cln, aes(year, NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  xlab(\"Year\") +\n  ylab(\"GDP per capita (constant 2010 US$)\")\n\n\n\n\n\n\n\nsuppressMessages(pacman::p_unload(\n  tidyverse, # A suite of packages designed for data science that includes tools for data manipulation, plotting, and more.\n  haven, # Used for importing and exporting data with SPSS, Stata, and SAS formats.\n  janitor, # Provides functions for examining and cleaning data, such as `clean_names()` and `tabyl()`.\n  WDI, # Facilitates downloading data from the World Bank's World Development Indicators database.\n  wbstats # Provides an interface to the World Bank's APIs for a comprehensive range of data sets.\n))",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kickstart</span>"
    ]
  },
  {
    "objectID": "08_error.html",
    "href": "08_error.html",
    "title": "6  Pitfalls",
    "section": "",
    "text": "6.1 No clue about the “working directory”\nProblem: Students start their R sessions unaware of their current working directory. This can lead to difficulties when reading and writing files.\nSolution: At the beginning of your R script set a working directory using setwd(). Consider using R Studio projects, see Section A.4. For more information, see Appendix A: Navigating the file system and Workflow: scripts and projects of Wickham & Grolemund (2023).",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#no-consistent-directory-structure",
    "href": "08_error.html#no-consistent-directory-structure",
    "title": "6  Pitfalls",
    "section": "6.2 No consistent directory structure",
    "text": "6.2 No consistent directory structure\nProblem: Students save files in different directories without a clear scheme. This disorganization often leads to problems: Scripts and data gets lost and code breaks.\nSolution: Organize your project into a clear directory structure from the beginning. Here is my suggestion for a directory structure but feel free to come up with your own:\n\n\n\nTable 6.1: Typical folder structure\n\n\n\n\n\nSub-Directory\nWhat to save here\n\n\n\n\ndoc/\ndocumentation\n\n\ndta/\nprocessed data\n\n\nfig/\nfigures\n\n\nlit/\nliterature and pdfs\n\n\nori/\noriginal raw data that you should never change\n\n\nqmd/\nreports\n\n\nscr/\nR scripts\n\n\ntab/\ntables\n\n\ntmp/\ntemporary files\n\n\n\n\n\n\nThis structure will save time and headaches when navigating projects.\n\n\n\n\n\n\nTip 6.1: Do not save processed data unless necessary\n\n\n\nIt may seem reasonable to save data after editing, but this often isn’t necessary if you’re using scripts to create your data. These scripts can be rerun whenever needed, regenerating the dataset each time. To avoid wasting disk space and maintain an organized project folder, it’s advisable to save processed datasets only when the preprocessing steps are time-consuming. This way, you can keep your project folder more organized and ensure that your data analyses are always reproducible with the latest updates to your code.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#working-manually-outside-r",
    "href": "08_error.html#working-manually-outside-r",
    "title": "6  Pitfalls",
    "section": "6.3 Working manually outside R",
    "text": "6.3 Working manually outside R\nProblem: Students want to get their work done quickly. This sometimes leads to them relying on manual processes that they have already mastered for their data work. This approach can lead to serious problems when it comes to the reproducibility of their data work.\nConsider a typical three-step process for loading data: (1) downloading the data, (2) unpacking the data, and finally (3) importing the data into R. Many students often take a manual approach by using their Internet browser to download the data, then using their operating system’s unpacking application, and finally importing the data into an R script. While this method is not inherently wrong, there is a risk that students will forget to unpack the downloaded data, resulting in them accidentally working with outdated data. In the kickstart example provided by Section 5.2, I show that all three steps can be performed seamlessly in R. This way you ensure that you are always working with the most up-to-date data.\nSolution: Do as much as possible in the script. Invest some time to find out how to download and manipulate the data within R. If it is not possible or if alternatives are superior, describe what you do outside of R explicitly and write a warning note at the top of your script.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#no-active-r-packages-management",
    "href": "08_error.html#no-active-r-packages-management",
    "title": "6  Pitfalls",
    "section": "6.4 No active R Packages management",
    "text": "6.4 No active R Packages management\nProblem: Students often forget to install and/or load the packages correctly at the beginning of a script. Some unnecessarily install packages repeatedly when running a script. All this can lead to errors and interruptions.\nSolution: At the beginning of each script, make sure that all required packages are loaded correctly. Use the pacman package, which provides the p_load() function to load and, if necessary, install packages and the p_unload(all) function to unload all packages.\n\n\n\n\n\n\nTip 6.2: Start your script with\n\n\n\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_unload(all)\npacman::p_load(tidyverse, janitor)\nsetwd(\"~/your-directory/\")\nrm(list = ls())",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#confusion-between-console-and-script",
    "href": "08_error.html#confusion-between-console-and-script",
    "title": "6  Pitfalls",
    "section": "6.5 Confusion between console and script",
    "text": "6.5 Confusion between console and script\nProblem: Alternating between running code in the console and from the script without a systematic approach can lead to untracked changes and confusion about the current state of objects in the workspace. Additionally, students often borrow code snippets from others and run only the sections that seem immediately relevant. This practice can lead to errors or unexpected results, as such code often relies on previous commands or setups.\nSolution: Develop the habit of testing small blocks of code in the console but run the complete script regularly to ensure everything works in sequence. Use shortcuts like Ctrl + Alt + R to source the entire script or Ctrl + Alt + B/E to execute it up to a specific point.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#misunderstanding-data-types-and-formats",
    "href": "08_error.html#misunderstanding-data-types-and-formats",
    "title": "6  Pitfalls",
    "section": "6.6 Misunderstanding data types and formats",
    "text": "6.6 Misunderstanding data types and formats\nProblem: Misusing or misunderstanding R’s data types and structures can lead to errors in data manipulation and analysis. Many functions require certain types of data. For example, the tidyverse packages required data to be “tidy”. Moreover, data often comes with errors and/or missings (NA). Beginners overlook data cleaning and considering missings.\nSolution: Familiarize yourself with basic data types and structures like vectors, lists, data frames/tibbles, and factors. For more information, see Section 7.2 and Data tidying of Wickham & Grolemund (2023). Moreover, spend adequate time on data cleaning and preprocessing. Techniques such as handling missing values, normalizing data, and correcting data types are critical. For more information, see Missing values of Wickham & Grolemund (2023).",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#lack-of-knowledge-about-data-identification",
    "href": "08_error.html#lack-of-knowledge-about-data-identification",
    "title": "6  Pitfalls",
    "section": "6.7 Lack of knowledge about data identification",
    "text": "6.7 Lack of knowledge about data identification\nProblem: Students often handle data without understanding which variables uniquely identify the information contained in other variables. It is crucial to recognize these identifying variables and verify their uniqueness to ensure data integrity.\nSolution: Perform checks for uniqueness at the beginning of their data analysis process. See exercise Names and duplicates in Section 9.15 and the get_dupes fuction introduced in Section 7.4.3.2.\n\n\n\n\n\n\nTip 6.3: Always check your data with get_dupes\n\n\n\nFor example, you expect that your dataframe df is a panel dataset. With\n\nget_dupes(df, country, year)\n\nyou can check whether the two variables country and year indeed identify each row uniquely.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#losing-track-of-data-due-to-excessive-overwriting",
    "href": "08_error.html#losing-track-of-data-due-to-excessive-overwriting",
    "title": "6  Pitfalls",
    "section": "6.8 Losing track of data due to excessive overwriting",
    "text": "6.8 Losing track of data due to excessive overwriting\nProblem: Students often manipulate their data by repeatedly overwriting the same object. This can lead to confusion about the data`s current state and the transformations applied.\nSolution: Minimize the number of assignments to a single object. Instead, create a new object with a descriptive and concise name each time you alter the data. This practice helps maintain clarity about each stage of data manipulation.\nFor example, if you’re working with data df, you might store the cleanded data as df_cln, then after filtering for specific criteria, you could use df_cln_flt, and finally, if you aggregate the data, name it df_cln_flt_agg. Having some clear naming convention makes it clear what each dataset represents and the transformations it has undergone.\n\n\n\n\n\n\nTip 6.4: Do clear the environment at the beginning of a script with\n\n\n\n\nrm(list = ls())",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#no-documentation",
    "href": "08_error.html#no-documentation",
    "title": "6  Pitfalls",
    "section": "6.9 No documentation",
    "text": "6.9 No documentation\nProblem: Students do not comment code. This makes it hard to remember the purpose of various lines of code and difficult for other people to read and understand the code.\nSolution: Regularly comment your code, explaining why something is done, not just what is done. Use clear, concise comments to improve readability and maintainability.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#ignoring-error-messages-and-warnings",
    "href": "08_error.html#ignoring-error-messages-and-warnings",
    "title": "6  Pitfalls",
    "section": "6.10 Ignoring error messages and warnings",
    "text": "6.10 Ignoring error messages and warnings\nProblem: Students see that their code doesn’t work but do not read the error message which often contains hints for solving the problem.\nSolution: Read and follow error messages. Do not ignore warnings or errors unless you know what they mean. Study what the error message might mean. Use online resources such as Google and ChatGPT, see Figure 6.1. Finally, have the confidence to implement the suggested solution. Don’t be frustrated if the first attempt does not work: Try again and play around.\n\n\n\nFigure 6.1: Googlling the error message\n\n\n\nSource: DEV Community on GitHub\n\n\n\n\n\n\n\n\n\nTip 6.5: Common error messages\n\n\n\nStudents often come to me with error messages suggesting that they install the tinytex package or the RTools compiler for Windows. Since they are not familiar with these R and software packages, they wonder if it is safe to proceed with the installation. My answer here is: yes, it is recommendable to install it.\nBased the report of Noam Ross who examine roughly 10,000 R error messages, the most frequently encountered error messages of R are shown in Table 6.2 with some ideas of mine what to do.\n\n\n\nTable 6.2: Most frequent errors\n\n\n\n\n\n\n\n\n\nError Type\nSome suggestions on what to do\n\n\n\n\nCould not find function\nCheck spelling of the function and whether the respective packages are loaded properly.\n\n\nError in if\nThis suggests an issue with non-logical or missing values in a conditional statement. Check syntax and spelling. Maybe use ChatGPT to debug the code.\n\n\nError in eval\nPoints to references to non-existent objects.\n\n\nCannot open\nCheck if the files exist at the place you try to call them.\n\n\nNo applicable method\nCheck your data type and whether it fits to the requirements of the functions you’re trying to use.\n\n\nPackage errors\nThis can stem from issues with installing, compiling, or loading a package. Maybe you try to re-install the package and their dependencies, or update the packages.",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#no-attempt-to-identify-the-problem-and-troubleshoot",
    "href": "08_error.html#no-attempt-to-identify-the-problem-and-troubleshoot",
    "title": "6  Pitfalls",
    "section": "6.11 No attempt to identify the problem and troubleshoot",
    "text": "6.11 No attempt to identify the problem and troubleshoot\nProblem: Students often do not fully understand the problems they encounter, which can lead to difficulties in seeking solutions. It’s common for students to feel overwhelmed and seek help without attempting to find the source of the problem and without attempting to work out possible solutions first.\n\n\nSolution: When you encounter an issue in your R code, it’s crucial to methodically dissect the problem. Here’s how you can effectively troubleshoot, that is, a problem-solving skill that is essential for becoming proficient in programming:\n\nIdentify the problem: Attempt to identify the issue to better understand its nature. Once you know which line of code is causing some trouble, you are often close to a solution. Commenting out parts of your script or going back until there is no error can help here.\nActive solution search: Once you’ve identified the problem, actively look for solutions. This can include consulting the R documentation, searching for similar issues online, or asking others for help.\nTrial and error process: Don’t hesitate to experiment with different solutions to see what works best.\nSeek Help: If you’re stuck, ask for help from more experienced R users or communities.\nMinimal Reproducible Example (MRE): When asking for help, explain your problem precisely and provide a MRE. That is the simplest version of the code that still produces the error, including only essential data and code. This practice not only aids in self-troubleshooting but also makes it easier for others to help by providing a clear, concise context.\nAdditional information: Sometime the interplay of your the packages loaded, your operating system, the version of R, and/or the RStudio version may play a role in your problem. Thus, when seeking help, be sure to provide information about your machine, including the operating system, the version of R, and the packages you have loaded. You can use the sessionInfo() function to gather this information.\n\n\n\n\n\n\n\nHere’s an example from my machine:\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Debian GNU/Linux 12 (bookworm)\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3\nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.21.so\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.2.2    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.2.2       htmltools_0.5.7   rstudioapi_0.15.0 rmarkdown_2.25   \n [9] knitr_1.45        jsonlite_1.8.8    xfun_0.41         digest_0.6.33    \n[13] rlang_1.1.2       evaluate_0.23    \n\n\n\n\n\nFor more information, see Workflow: getting help of Wickham & Grolemund (2023).\n\n\n\n\n\n\nExample of a minimal reproducible example\n\n\n\n\n\nFor example, the following script is a MRE:\n\nlibrary(ggplot2)\ndata &lt;- data.frame(x = 1:4, y = c(2, 3, 5, 3.4))\nggplot(data, aes(x, y))\n\n\n\n\n\n\n\n+geom_point()\n\nError:\n! Cannot use `+` with a single argument.\nℹ Did you accidentally put `+` on a new line?\n\n\nEverybody who copies these few lines of code can reproduce the shown error message and hence can work on a solution. Obviously, the + was set falsly. It must be placed in the line of ggplot:\n\nlibrary(ggplot2)\ndata &lt;- data.frame(x = 1:4, y = c(2, 3, 5, 3.4))\nggplot(data, aes(x, y)) +\n  geom_point()",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "08_error.html#unstylish-code",
    "href": "08_error.html#unstylish-code",
    "title": "6  Pitfalls",
    "section": "6.12 Unstylish code",
    "text": "6.12 Unstylish code\nTo avoid issues while programming in R, it’s essential to understand and adhere to various conventions, rules, and best practices specific to the language. Following these conventions makes your code more readable and simplifies your own experience with R. Below, you will find a non-exhaustive list of these guidelines.\n\nDo remember that R programming language is case sensitive.\nDo start names of objects such as vectors, numbers, variables, and data frames with a letter, not a number.\nDo avoid using dots in names of objects.\nDo avoid using certain keywords in naming objects, such as if, else, repeat, while, function, for, in, next, break, TRUE, FALSE, NULL, Inf, NaN, and NA.\nDo use front slash / instead of backslash \\ for navigating the file system (see Appendix A).\nDo not use whitespace and indentation for naming files, directories, or objects.\nDo define objects to represent hard-coded values instead of using them directly in code.\nDo remember to (install and) load packages that contain functions you want to use.\nDo use &lt;- instead of = for assignment.\n\n\n\n\n\n\n\nTip 6.6\n\n\n\nThere are two packages, styler and lintr, that support you writing code according to the The tidyverse style guide of Wickham (2024).\n\n\n\n\n\nFigure 6.1: Googlling the error message\n\n\n\nWickham, H. (2024). The tidyverse style guide. https://style.tidyverse.org/\n\n\nWickham, H., & Grolemund, G. (2023). R for data science (2e). https://r4ds.hadley.nz/",
    "crumbs": [
      "Basics of coding",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pitfalls</span>"
    ]
  },
  {
    "objectID": "40_manage.html",
    "href": "40_manage.html",
    "title": "7  Manage data",
    "section": "",
    "text": "7.1 Import and generate data",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Manage data</span>"
    ]
  },
  {
    "objectID": "40_manage.html#import-and-generate-data",
    "href": "40_manage.html#import-and-generate-data",
    "title": "7  Manage data",
    "section": "",
    "text": "7.1.1 Assigning data to an object using the assignment operator &lt;-\nSuppose I’m trying to calculate how much money I’m going to make from selling an item. Let’s assume you sell 350 units. To create a variable called sales and assigns a value to it, we need to use the assignment operator of R, that is, &lt;-:\n\nsales &lt;- 350\n\nWhen you send that line of code to the console, it doesn’t print out any output but it creates the object sales. In Rstudio, you can see the object in the environment panel at the top right. Alternatively, you can call the object in the console:\n\nsales\n\n[1] 350\n\n\nR also allows to use -&gt; and = for the assigment. For example, the following ways of assigning data are equivalent:\n\n350 -&gt; sales\nsales = 350\nsales &lt;- 350\n\nHowever, it is common practice and “good style” to use &lt;- and I recommend only to use this one because it is easier to read in scripts.\n\n\n7.1.2 Vectors and matrices\nWe already got known to the c() function which allows to combine multiple values into a vector or list. Here are some examples how you can use this function to create vectors and matrices:\n\n# defining multiple vectors using the colon operator `:`\nv_a &lt;- c(1:3)\nv_a\n\n[1] 1 2 3\n\nv_b &lt;- c(10:12)\nv_b\n\n[1] 10 11 12\n\n# creating matrix\nm_ab &lt;- matrix(c(v_a, v_b), ncol = 2)\nm_cbind &lt;- cbind(v_a, v_b)\nm_rbind &lt;- rbind(v_a, v_b)\n\n# print matrix\nprint(m_ab)\n\n     [,1] [,2]\n[1,]    1   10\n[2,]    2   11\n[3,]    3   12\n\nprint(m_cbind)\n\n     v_a v_b\n[1,]   1  10\n[2,]   2  11\n[3,]   3  12\n\nprint(m_rbind)\n\n    [,1] [,2] [,3]\nv_a    1    2    3\nv_b   10   11   12\n\n# defining row names and column names\nrown &lt;- c(\"row_1\", \"row_2\", \"row_3\")\ncoln &lt;- c(\"col_1\", \"col_2\")\n\n# creating matrix\nm_ab_label &lt;- matrix(m_ab,\n  ncol = 2, byrow = FALSE,\n  dimnames = list(rown, coln)\n)\n\n# print matrix\nprint(m_ab_label)\n\n      col_1 col_2\nrow_1     1    10\nrow_2     2    11\nrow_3     3    12\n\n\nThe two most common formats to store and work with data in R are dataframe and tibble. Both formats store table-like structures of data in rows and columns. We will learn more on that in section Section 7.2.\n\n# convert the matrix into dataframe\ndf_ab &lt;- as.data.frame(m_ab_label)\ntbl_ab &lt;- data.frame(m_ab_label)\n\n\n\n\n\n\n\nExercise\n\n\n\nSee exercise in Section 9.1: Import data with c().\n\n\n\n\n7.1.3 Open RData files\nYou can save some of your objects with save() or all with save.image(). Load data that are stored in the .RData format can be loaded with load(). Please note, when you delete an object in R, you cannot recover it by clicking some Undo button. With rm() you remove objects from your workspace and with rm(list = ls()) you clear all objects from the workspace.\n\n\n7.1.4 Open datasets of packages\nThe datasets package contains numerous datasets that are commonly used in textbooks. To get an overview of all the datasets provided by the package, you can use the command help(package = datasets). One such dataset that we will be using further is the mtcars dataset:\n\nlibrary(\"datasets\")\nhead(mtcars, 3)\n\n               mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n\n?mtcars # data dictionary\n\n\n\n7.1.5 Import data using public APIs\nAn API which stands for application programming interface specifies how computers can exchange information. There are many R packages available that provide a convenient way to access data from various online sources directly within R using the API of webpages. In most cases, it’s better to download and import data within R using these tools than to navigate through the website’s interface. This ensures that changes can be made easily at any time and that the data is always up-to-date. For example, wbstats provides access to World Bank data, eurostat allows users to access Eurostat databases, fredr makes it easy to obtain data from the Federal Reserve Economic Data (FRED) platform, which offers economic data for the United States, ecb provides an interface to the European Central Bank’s Statistical Data Warehouse, and the OECD package facilitates the extraction of data from the Organization for Economic Cooperation and Development (OECD). Here is an example using the wbstats package:\n\n# install.packages(\"wbstats\")\nlibrary(\"wbstats\")\n# GDP at market prices (current US$) for all available countries and regions\ndf_gdp &lt;- wb(indicator = \"NY.GDP.MKTP.CD\")\n\nWarning: `wb()` was deprecated in wbstats 1.0.0.\nℹ Please use `wb_data()` instead.\n\nhead(df_gdp, 3)\n\n  iso3c date        value    indicatorID         indicator iso2c\n2   AFE 2022 1.185138e+12 NY.GDP.MKTP.CD GDP (current US$)    ZH\n3   AFE 2021 1.086531e+12 NY.GDP.MKTP.CD GDP (current US$)    ZH\n4   AFE 2020 9.288802e+11 NY.GDP.MKTP.CD GDP (current US$)    ZH\n                      country\n2 Africa Eastern and Southern\n3 Africa Eastern and Southern\n4 Africa Eastern and Southern\n\nglimpse(df_gdp)\n\nRows: 13,198\nColumns: 7\n$ iso3c       &lt;chr&gt; \"AFE\", \"AFE\", \"AFE\", \"AFE\", \"AFE\", \"AFE\", \"AFE\", \"AFE\", \"A…\n$ date        &lt;chr&gt; \"2022\", \"2021\", \"2020\", \"2019\", \"2018\", \"2017\", \"2016\", \"2…\n$ value       &lt;dbl&gt; 1.185138e+12, 1.086531e+12, 9.288802e+11, 1.006191e+12, 1.…\n$ indicatorID &lt;chr&gt; \"NY.GDP.MKTP.CD\", \"NY.GDP.MKTP.CD\", \"NY.GDP.MKTP.CD\", \"NY.…\n$ indicator   &lt;chr&gt; \"GDP (current US$)\", \"GDP (current US$)\", \"GDP (current US…\n$ iso2c       &lt;chr&gt; \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\"…\n$ country     &lt;chr&gt; \"Africa Eastern and Southern\", \"Africa Eastern and Souther…\n\nsummary(df_gdp)\n\n    iso3c               date               value           indicatorID       \n Length:13198       Length:13198       Min.   :8.825e+06   Length:13198      \n Class :character   Class :character   1st Qu.:2.435e+09   Class :character  \n Mode  :character   Mode  :character   Median :1.786e+10   Mode  :character  \n                                       Mean   :1.224e+12                     \n                                       3rd Qu.:2.264e+11                     \n                                       Max.   :1.009e+14                     \n  indicator            iso2c             country         \n Length:13198       Length:13198       Length:13198      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\n\n\n\n7.1.6 Import various file formats\n\n\n\nFigure 7.1: The logo of the packages readr, haven, and readxl\n\n\n\n\n\n\nRStudio provides convenient data import tools that can be accessed by clicking File &gt; Import Dataset. In addition, tidyverse offers packages for importing data in various formats. This cheatsheet, for example, is about the packages readr, readxl and googlesheets4. The first allows you to read data in various file formats, including fixed-width files like .csv and .tsv. The package readxl can read in Excel files, i.e., .xls and .xlsx file formats and googlesheets4 allows to read and write data from Google Sheets directly from R.\nFor more information, I recommend once again the second version book R for Data Science by Wickham & Grolemund (2023). In particular, check out the “Data tidying” section for importing CSV and TSV files, the “Spreadsheets” section for Excel files, the “Databases” section for retrieving data with SQL, the “Arrow” section for working with large datasets, and the “Web scraping” section for extracting data from web pages.\nFor an overview on packages for reading data that are provided by the tidyverse universe, see here.\n\n\n7.1.7 Examples\nFlat files such as CSV (Comma-Separated Values) are among the most common and straightforward data formats to work with.\n\ndata_csv &lt;- read_csv(\"https://github.com/hubchev/courses/raw/main/dta/classdata.csv\")\n\nExcel files, due to their wide use in business and research, require a specific approach specifying sheets and cell ranges.\n\nBWL_Zeitschriftenliste &lt;-\n  read_excel(\n    \"https://www.forschungsmonitoring.org/VWL_Zeitschriftenliste%202023.xlsx\",\n    sheet = \"SJR main\",\n    range = \"A1:D1977\"\n  )",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Manage data</span>"
    ]
  },
  {
    "objectID": "40_manage.html#sec-tidy",
    "href": "40_manage.html#sec-tidy",
    "title": "7  Manage data",
    "section": "7.2 Data",
    "text": "7.2 Data\n\n7.2.1 Data frames and tibbles\n\n\n\nFigure 7.2: The logos of the tidyr and tibble packages\n\n\n\n\n\n\nBoth data frames and tibbles are two of the most commonly used data structures in R for handling tabular data. A tibble actually is a data frame and you can use all functions that work with a data frame also with a tibble. However, a tibble has some additional features in printing and subsetting. Please note, data frames are provided by base R while tibbles are provided by the tidyverse package. This means that if you want to use tibbles you must load tidyverse. It turned out that it is helpful that a tibble has the folllowing features to simplify working with data: - Each vector is labeled by the variable name. - Variable names don’t have spaces and are not put in quotes. - All variables have the same length. - Each variable is of a single type (numeric, character, logical, or a categorical).\n\n\n7.2.2 Tidy data\nA popular quote from Hadley Wickham is that\n\n“tidy datasets are all alike, but every messy dataset is messy in its own way” (Hadley, 2014, p. 2).\n\nIt paraphrases the fact that it is a good idea to set rules how a dataset should structure its information to make it easier to work with the data. The tidyverse requires the data to be structured like is illustrated in Figure Figure 7.3. The rules are:\n\nEach variable is a column and vice versa.\nEach observation is a row and vice verse.\nEach value is a cell.\n\n\n\n\nFigure 7.3: Features of a tidy dataset: variables are columns, observations are rows, and values are cells\n\n\n\nSource: Wickham & Grolemund (2023). \n\n\n\nWhenever data follow that consistent structure, we speak of tidy data. The underlying uniformity of tidy data facilitates learning and using data manipulation tools.\nOne difference between data frames and tibbles is that dataframes store the row names. For example, take the mtcars dataset which consists of 32 different cars and the names of the cars are not stored as rownames:\n\nclass(mtcars) # mtcars is a data frame\n\n[1] \"data.frame\"\n\nrownames(mtcars)\n\n [1] \"Mazda RX4\"           \"Mazda RX4 Wag\"       \"Datsun 710\"         \n [4] \"Hornet 4 Drive\"      \"Hornet Sportabout\"   \"Valiant\"            \n [7] \"Duster 360\"          \"Merc 240D\"           \"Merc 230\"           \n[10] \"Merc 280\"            \"Merc 280C\"           \"Merc 450SE\"         \n[13] \"Merc 450SL\"          \"Merc 450SLC\"         \"Cadillac Fleetwood\" \n[16] \"Lincoln Continental\" \"Chrysler Imperial\"   \"Fiat 128\"           \n[19] \"Honda Civic\"         \"Toyota Corolla\"      \"Toyota Corona\"      \n[22] \"Dodge Challenger\"    \"AMC Javelin\"         \"Camaro Z28\"         \n[25] \"Pontiac Firebird\"    \"Fiat X1-9\"           \"Porsche 914-2\"      \n[28] \"Lotus Europa\"        \"Ford Pantera L\"      \"Ferrari Dino\"       \n[31] \"Maserati Bora\"       \"Volvo 142E\"         \n\n\nTo store mtcars as a tibble, we can use the as_tibble function:\n\ntbl_mtcars &lt;- as_tibble(mtcars)\nclass(tbl_mtcars) # check if it is a tibble now\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nis_tibble(tbl_mtcars) # alternative check\n\n[1] TRUE\n\nhead(tbl_mtcars, 3)\n\n# A tibble: 3 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n\n\nWhen we look at the data, we’ve lost the names of the cars. To store the these, you need to first add a column to the dataframe containing the rownames and then you can generate the tibble:\n\ntbl_mtcars &lt;- mtcars |&gt;\n  rownames_to_column(var = \"car\") |&gt;\n  as_tibble()\nclass(tbl_mtcars)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nhead(tbl_mtcars, 3)\n\n# A tibble: 3 × 12\n  car            mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Mazda RX4     21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2 Mazda RX4 W…  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3 Datsun 710    22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n\n\n\n\n7.2.3 Data types\nIn R, different data classes, or types of data exist:\n\nnumeric: can be any real number\ncharacter: strings and characters\ninteger: any whole numbers\nfactor: any categorical or qualitative variable with finite number of distinct outcomes\nlogical: contain either TRUE or FALSE\nDate: special format that describes time\n\nThe following example should exemplify these types of data:\n\ninteger_var &lt;- c(1, 2, 3, 4, 5)\nnumeric_var &lt;- c(1.1, 2.2, NA, 4.4, 5.5)\ncharacter_var &lt;- c(\"apple\", \"banana\", \"orange\", \"cherry\", \"grape\")\nfactor_var &lt;- factor(c(\"red\", \"yellow\", \"red\", \"blue\", \"green\"))\nlogical_var &lt;- c(TRUE, TRUE, TRUE, FALSE, TRUE)\ndate_var &lt;- as.Date(c(\"2022-01-01\", \"2022-02-01\", \"2022-03-01\", \"2022-04-01\", \"2022-05-01\"))\n\ndate_var[2] - date_var[5] # number of days in between these two dates\n\nTime difference of -89 days\n\n\nThere are some special data values used in R that needs further explanation:\n\nNA stands for not available or missing and is used to represent missing or undefined values.\nInf stands for infinity and is used to represent mathematical infinity, such as the result of dividing a non-zero number by zero. Can be positive or negative.\n\nNULL represents an empty or non-existent object. It is often used as a placeholder when a value or object is not yet available or when an object is intentionally removed.\nNaN stands for not a number and is used to represent an undefined or unrepresentable value, such as the result of taking the square root of a negative number. It can also occur as a result of certain arithmetic operations that are undefined. In contrast to NA it can only exist in numerical data.",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Manage data</span>"
    ]
  },
  {
    "objectID": "40_manage.html#operators",
    "href": "40_manage.html#operators",
    "title": "7  Manage data",
    "section": "7.3 Operators",
    "text": "7.3 Operators\nAn overview of the most important operators of R is proided in Appendix B.\n\n7.3.1 Algebraic operators\nR can perform any kind of arithmetic calculation using the operators listed in Table 7.1.\n\n\n\nTable 7.1: Basic algebraic operators\n\n\n\n\n\nOperation\nOperator\nExample input\nExample output\n\n\n\n\naddition\n+\n10+2\n12\n\n\nsubtraction\n-\n9-3\n6\n\n\nmultiplication\n*\n5*5\n25\n\n\ndivision\n/\n10/3\n3\n\n\npower\n^\n5^2\n25\n\n\n\n\n\n\n\n\n7.3.2 The pipe operator: |&gt;\nThe pipe operator, %&gt;%, comes from the magrittr package, which is also part of the tidyverse package. The pipe operator, |&gt;, has been part of base R since version 4.1.0. For most cases, these two operators are identical. The pipe operator is designed to help you write code in a way that is easier to read and understand. As R is a functional language, code often contains a lot of parentheses, ( and ). Nesting these parentheses together can be complex and make your R code hard to read and understand, which is where |&gt; comes to the rescue! It allows you to use the output of a function as the input of the next function.\n\n\n\n\n\n\nTip 7.1: Set the native pipe in RStudio\n\n\n\nWith the keyboard shortcut Ctrl+Shift+M, RStudio inserts %&gt;%. To change that behavior, simply check the box labeled “Use native pipe operator, |&gt;” in the Global Options, see: Tools &gt; Global Options &gt; Code &gt; Editing.\n\n\nConsider the following example of code to explain the usage of the pipe operator:\n\n# create some data `x`\nx &lt;- c(1, 1.002, 1.004, .99, .99)\n# take the logarithm of `x`,\nlog_x &lt;- log(x)\n# compute the lagged and iterated differences (see `diff()`)\ngrowth_rate_x &lt;- diff(log_x)\ngrowth_rate_x\n\n[1]  0.001998003  0.001994019 -0.014042357  0.000000000\n\n# round the result (4 digit)\ngrowth_rate_x_round &lt;- round(growth_rate_x, 4)\ngrowth_rate_x_round\n\n[1]  0.002  0.002 -0.014  0.000\n\n\nThat is rather long and we actually don’t need objects log_x, growth_rate_x, and growth_rate_x_round. Well, then let us write that in a nested function:\n\nround(diff(log(x)), 4)\n\n[1]  0.002  0.002 -0.014  0.000\n\n\nThis is short but hard to read and understand. The solution is the “pipe”:\n\n# load one of these packages: `magrittr` or `tidyverse`\nlibrary(tidyverse)\n\n# Perform the same computations on `x` as above\nx |&gt;\n  log() |&gt;\n  diff() |&gt;\n  round(4)\n\n[1]  0.002  0.002 -0.014  0.000\n\n\nYou can read the |&gt; with “and then” because it takes the results of some function “and then” does something with that in the next. For example, reading out loud the following code would sound something like this:\n\nI take the mtcars data, and then\nI consider only cars with more than 4 cylinders, and then\nI group the cars by the number of cylinders the cars have, and then\nI summarize the data and show the means of miles per gallon (mpg) and horse powers (hp) by groups of cars that distinguish by their number of cylinders.\n\n\nmtcars |&gt;\n  filter(cyl &gt; 4) |&gt;\n  group_by(cyl) |&gt;\n  summarise_at(c(\"mpg\", \"hp\"), mean)\n\n# A tibble: 2 × 3\n    cyl   mpg    hp\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     6  19.7  122.\n2     8  15.1  209.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSee exercise in Section 9.3: Base R,%in% operator, and the pipe |&gt;.\n\n\n\n\n7.3.3 The %in% operator\n%in% is used to subset a vector by comparison. Here’s an example:\n\nx &lt;- c(1, 3, 5, 7)\ny &lt;- c(2, 4, 6, 8)\nz &lt;- c(1, 2, 3)\n\nx %in% y\n\n[1] FALSE FALSE FALSE FALSE\n\nx %in% z\n\n[1]  TRUE  TRUE FALSE FALSE\n\nz %in% x\n\n[1]  TRUE FALSE  TRUE\n\n\nThe %in% operator can be used in combination with other functions like subset() and filter().\n\n\n\n\n\n\nExercise\n\n\n\nSee exercise in Section 9.3: Base R,%in% operator, and the pipe |&gt;.\n\n\n\n\n7.3.4 Extract operators\nThe extract operators are used to retrieve data from objects in R. The operator may take four forms, including [], [[]], and $.\n[] allows to extract content from vector, lists, or data frames. For example,\n\na &lt;- mtcars[3, ]\nb &lt;- mtcars[\"Datsun 710\", ]\nidentical(a, b)\n\n[1] TRUE\n\na\n\n            mpg cyl disp hp drat   wt  qsec vs am gear carb\nDatsun 710 22.8   4  108 93 3.85 2.32 18.61  1  1    4    1\n\n\nextracts the third observation of the mtcars dataset, and\n\nc &lt;- mtcars[, \"cyl\"]\nd &lt;- mtcars[, 2]\nidentical(x, y)\n\n[1] FALSE\n\nc\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nextracts the variable/vector cyl.\nThe operators, [[]] and $ extract a single item from an object. It is used to refer to an element in a list or a column in a data frame. For example,\n\ne &lt;- mtcars$cyl\nf &lt;- mtcars[[\"cyl\"]]\nidentical(e, f)\n\n[1] TRUE\n\ne\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nwill return the values of the variable cyl from the data frame mtcars. Thus, x$y is actually just a short form for x[[“y”]].\n\n\n7.3.5 Logical operators\nThe extract operators can be combined with the logical operators (more precisely, I should call these binary relational operators) that are shown in Table 7.2.\n\n\n\nTable 7.2: Logical operators\n\n\n\n\n\n\n\n\n\n\n\noperation\noperator\nexample input\nanswer\n\n\n\n\nless than\n&lt;\n2 &lt; 3\nTRUE\n\n\nless than or equal to\n&lt;=\n2 &lt;= 2\nTRUE\n\n\ngreater than\n&gt;\n2 &gt; 3\nFALSE\n\n\ngreater than or equal to\n&gt;=\n2 &gt;= 2\nTRUE\n\n\nequal to\n==\n2 == 3\nFALSE\n\n\nnot equal to\n!=\n2 != 3\nTRUE\n\n\n\n\n\n\n\n\nnot\n!\n!(1==1)\nFALSE\n\n\nor\n\\(\\vert\\)\n(1==1) \\(\\vert\\) (2==3)\nTRUE\n\n\nand\n&\n(1==1) & (2==3)\nFALSE\n\n\n\n\n\n\nHere are some examples: Select rows where the number of cylinders is greater than or equal to 6:\n\nmtcars[mtcars$cyl &gt;= 6, ]\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n\n\nSelect rows where the number of cylinders is either 4 or 6:\n\nmtcars[mtcars$cyl == 4 | mtcars$cyl == 6, ]\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nSelect rows where the number of cylinders is 4 and the mpg is greater than 22:\n\nmtcars[mtcars$cyl == 4 & mtcars$mpg &gt; 22, ]\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n\n\nSelect rows where the weight is less than 3.5 or the number of gears is greater than 4:\n\nmtcars[mtcars$wt &lt; 3.5 | mtcars$gear &gt; 4, ]\n\n                   mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 240D         24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230          22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C         17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128          32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic       30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla    33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona     21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nAMC Javelin       15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nFiat X1-9         27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2     26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa      30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L    15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino      19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora     15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E        21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nSelect rows where either mpg is greater than 25 or carb is less than 2, and the number of cylinders is either 4 or 8.\n\nmtcars[(mtcars$mpg &gt; 25 | mtcars$carb &lt; 2) & mtcars$cyl %in% c(4, 8), ]\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Manage data</span>"
    ]
  },
  {
    "objectID": "40_manage.html#data-manipulation",
    "href": "40_manage.html#data-manipulation",
    "title": "7  Manage data",
    "section": "7.4 Data manipulation",
    "text": "7.4 Data manipulation\n\n7.4.1 dplyr: A human readable grammar of data manipulation\n\n\n\nFigure 7.4: The logo of the dplyr package\n\n\n\n\n\n\nThe dplyr package is part of tidyverse and makes data manipulation easy as it works well with the pipe operator |&gt;. The most important function are the following:\n\nReorder the rows with arrange().\nPick observations by their values with filter().\nPick variables by their names with select().\nCreate new variables with functions of existing variables with mutate().\nCollapse many values down to a single summary with summarise().\nRename variables with rename().\nChange the position of variables with relocate().\n\nThese functions can be used in conjunction with group_by() and/or rowwise(), which changes the scope of each function from operating on the entire dataset to operating on it group-by-group or by rows. Moreover, you can check for conditions and take action with, for example, if_else() and case_when().\nAll functions work similarly:\n\nThe first argument is a data frame.\nThe subsequent arguments describe what to do with the data frame.\nThe result is a new data frame.\n\n\n\n\n\n\n\nRead the vignette of dplyr that you find here or with:\n\n\n\n\nvignette(\"dplyr\")\n\n\n\nHere are some examples that may help to understand these functions:\n\nlibrary(tidyverse)\n\n# load mtcars dataset\ndata(mtcars)\n\n# filter only cars with four gears \nmtcars_gear_4 &lt;- mtcars |&gt; \n  filter(carb == 4)\n\n# arrange rows by mpg in descending order\nmtcars_gear_4 |&gt;\n  arrange(desc(mpg))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\n# Change the order of the variables\nglimpse(mtcars_gear_4)\n\nRows: 10\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 14.3, 19.2, 17.8, 10.4, 10.4, 14.7, 13.3, 15.8\n$ cyl  &lt;dbl&gt; 6, 6, 8, 6, 6, 8, 8, 8, 8, 8\n$ disp &lt;dbl&gt; 160.0, 160.0, 360.0, 167.6, 167.6, 472.0, 460.0, 440.0, 350.0, 35…\n$ hp   &lt;dbl&gt; 110, 110, 245, 123, 123, 205, 215, 230, 245, 264\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.21, 3.92, 3.92, 2.93, 3.00, 3.23, 3.73, 4.22\n$ wt   &lt;dbl&gt; 2.620, 2.875, 3.570, 3.440, 3.440, 5.250, 5.424, 5.345, 3.840, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 15.84, 18.30, 18.90, 17.98, 17.82, 17.42, 15.41, 14…\n$ vs   &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 0\n$ am   &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 0, 0, 0, 1\n$ gear &lt;dbl&gt; 4, 4, 3, 4, 4, 3, 3, 3, 3, 5\n$ carb &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n\nmtcars_gear_4 |&gt; \n  relocate(cyl, disp, carb) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 11\n$ cyl  &lt;dbl&gt; 6, 6, 8, 6, 6, 8, 8, 8, 8, 8\n$ disp &lt;dbl&gt; 160.0, 160.0, 360.0, 167.6, 167.6, 472.0, 460.0, 440.0, 350.0, 35…\n$ carb &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 14.3, 19.2, 17.8, 10.4, 10.4, 14.7, 13.3, 15.8\n$ hp   &lt;dbl&gt; 110, 110, 245, 123, 123, 205, 215, 230, 245, 264\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.21, 3.92, 3.92, 2.93, 3.00, 3.23, 3.73, 4.22\n$ wt   &lt;dbl&gt; 2.620, 2.875, 3.570, 3.440, 3.440, 5.250, 5.424, 5.345, 3.840, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 15.84, 18.30, 18.90, 17.98, 17.82, 17.42, 15.41, 14…\n$ vs   &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 0\n$ am   &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 0, 0, 0, 1\n$ gear &lt;dbl&gt; 4, 4, 3, 4, 4, 3, 3, 3, 3, 5\n\nmtcars_gear_4 |&gt;  \n  relocate(sort(names(mtcars_gear_4))) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 11\n$ am   &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 0, 0, 0, 1\n$ carb &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n$ cyl  &lt;dbl&gt; 6, 6, 8, 6, 6, 8, 8, 8, 8, 8\n$ disp &lt;dbl&gt; 160.0, 160.0, 360.0, 167.6, 167.6, 472.0, 460.0, 440.0, 350.0, 35…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.21, 3.92, 3.92, 2.93, 3.00, 3.23, 3.73, 4.22\n$ gear &lt;dbl&gt; 4, 4, 3, 4, 4, 3, 3, 3, 3, 5\n$ hp   &lt;dbl&gt; 110, 110, 245, 123, 123, 205, 215, 230, 245, 264\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 14.3, 19.2, 17.8, 10.4, 10.4, 14.7, 13.3, 15.8\n$ qsec &lt;dbl&gt; 16.46, 17.02, 15.84, 18.30, 18.90, 17.98, 17.82, 17.42, 15.41, 14…\n$ vs   &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 0\n$ wt   &lt;dbl&gt; 2.620, 2.875, 3.570, 3.440, 3.440, 5.250, 5.424, 5.345, 3.840, 3.…\n\n# filter rows where cyl = 4\nmtcars_gear_4 |&gt;\n  filter(cyl == 4)\n\n [1] mpg  cyl  disp hp   drat wt   qsec vs   am   gear carb\n&lt;0 rows&gt; (or 0-length row.names)\n\n# select columns mpg, cyl, and hp\nmtcars_gear_4 |&gt;\n  select(mpg, cyl, hp) |&gt;\n  head()\n\n                    mpg cyl  hp\nMazda RX4          21.0   6 110\nMazda RX4 Wag      21.0   6 110\nDuster 360         14.3   8 245\nMerc 280           19.2   6 123\nMerc 280C          17.8   6 123\nCadillac Fleetwood 10.4   8 205\n\n# select columns all variables except wt and hp\nmtcars_gear_4 |&gt;\n  select(-wt, -hp) |&gt;\n  head()\n\n                    mpg cyl  disp drat  qsec vs am gear carb\nMazda RX4          21.0   6 160.0 3.90 16.46  0  1    4    4\nMazda RX4 Wag      21.0   6 160.0 3.90 17.02  0  1    4    4\nDuster 360         14.3   8 360.0 3.21 15.84  0  0    3    4\nMerc 280           19.2   6 167.6 3.92 18.30  1  0    4    4\nMerc 280C          17.8   6 167.6 3.92 18.90  1  0    4    4\nCadillac Fleetwood 10.4   8 472.0 2.93 17.98  0  0    3    4\n\n# select only variables starting with `c`\nmtcars_gear_4 |&gt;\n  select(starts_with(\"c\"))\n\n                    cyl carb\nMazda RX4             6    4\nMazda RX4 Wag         6    4\nDuster 360            8    4\nMerc 280              6    4\nMerc 280C             6    4\nCadillac Fleetwood    8    4\nLincoln Continental   8    4\nChrysler Imperial     8    4\nCamaro Z28            8    4\nFord Pantera L        8    4\n\n# summarize avg mpg by number of cylinders\nmtcars_gear_4 |&gt;\n  group_by(cyl) |&gt;\n  summarize(avg_mpg = mean(mpg))\n\n# A tibble: 2 × 2\n    cyl avg_mpg\n  &lt;dbl&gt;   &lt;dbl&gt;\n1     6    19.8\n2     8    13.2\n\n# create new column wt_kg, which is wt in kg\nmtcars_gear_4 |&gt;\n  select(wt) |&gt;\n  mutate(wt_kg = wt / 2.205) |&gt;\n  head()\n\n                      wt    wt_kg\nMazda RX4          2.620 1.188209\nMazda RX4 Wag      2.875 1.303855\nDuster 360         3.570 1.619048\nMerc 280           3.440 1.560091\nMerc 280C          3.440 1.560091\nCadillac Fleetwood 5.250 2.380952\n\n# Create a new variable by calculating hp divided by wt\nmtcars_new &lt;- mtcars |&gt;\n  select(wt, hp) |&gt;\n  mutate(hp_per_t = hp / wt) |&gt;\n  head()\n\n# Print the first few rows of the updated dataset\nhead(mtcars_new)\n\n                     wt  hp hp_per_t\nMazda RX4         2.620 110 41.98473\nMazda RX4 Wag     2.875 110 38.26087\nDatsun 710        2.320  93 40.08621\nHornet 4 Drive    3.215 110 34.21462\nHornet Sportabout 3.440 175 50.87209\nValiant           3.460 105 30.34682\n\n# Rename hp to horsepower\nmtcars_gear_4 |&gt;\n  rename(horsepower = hp) |&gt;\n  glimpse()\n\nRows: 10\nColumns: 11\n$ mpg        &lt;dbl&gt; 21.0, 21.0, 14.3, 19.2, 17.8, 10.4, 10.4, 14.7, 13.3, 15.8\n$ cyl        &lt;dbl&gt; 6, 6, 8, 6, 6, 8, 8, 8, 8, 8\n$ disp       &lt;dbl&gt; 160.0, 160.0, 360.0, 167.6, 167.6, 472.0, 460.0, 440.0, 350…\n$ horsepower &lt;dbl&gt; 110, 110, 245, 123, 123, 205, 215, 230, 245, 264\n$ drat       &lt;dbl&gt; 3.90, 3.90, 3.21, 3.92, 3.92, 2.93, 3.00, 3.23, 3.73, 4.22\n$ wt         &lt;dbl&gt; 2.620, 2.875, 3.570, 3.440, 3.440, 5.250, 5.424, 5.345, 3.8…\n$ qsec       &lt;dbl&gt; 16.46, 17.02, 15.84, 18.30, 18.90, 17.98, 17.82, 17.42, 15.…\n$ vs         &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 0\n$ am         &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 0, 0, 0, 1\n$ gear       &lt;dbl&gt; 4, 4, 3, 4, 4, 3, 3, 3, 3, 5\n$ carb       &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSee exercise:\n\nSection 9.4: Generate and drop variables\nSection 9.5: Subsetting\n\n\n\n\n\n7.4.2 If statements\nIn many cases, it’s necessary to execute certain code only when a particular condition is met. To achieve this, there are several conditional statements that can be used in code. These include:\n\nThe if statement: This is used to execute a block of code if a specified condition is true.\nThe else statement: This is used to execute a block of code if the same condition is false.\nThe else if statement: This is used to specify a new condition to test if the first condition is false.\nThe if_else() function: This is used to check a condition for every element of a vector.\n\nThe following examples should exemplify how these statements work:\n\n# Example of if statement\nif (mean(mtcars$mpg) &gt; 20) {\n  print(\"The average miles per gallon is greater than 20.\")\n}\n\n[1] \"The average miles per gallon is greater than 20.\"\n\n# Example of if-else statement\nif (mean(mtcars$mpg) &gt; 20) {\n  print(\"The average miles per gallon is greater than 20.\")\n} else {\n  print(\"The average miles per gallon is less than or equal to 20.\")\n}\n\n[1] \"The average miles per gallon is greater than 20.\"\n\n# Example of if-else if statement\nif (mean(mtcars$mpg) &gt; 25) {\n  print(\"The average miles per gallon is greater than 25.\")\n} else if (mean(mtcars$mpg) &gt; 20) {\n  print(\"The average miles per gallon is between 20 and 25.\")\n} else {\n  print(\"The average miles per gallon is less than or equal to 20.\")\n}\n\n[1] \"The average miles per gallon is between 20 and 25.\"\n\n# Example of if_else function\nmtcars_2 &lt;- mtcars\nmtcars_2$mpg_category &lt;- if_else(mtcars_2$mpg &gt; 20, \"High\", \"Low\")\n\nWhen you have a fixed number of cases and don’t want to use a long chain of if-else statements, you can use case_when();\n\nmtcars_cyl &lt;- mtcars |&gt;\n  mutate(cyl_category = case_when(\n    cyl == 4 ~ \"four\",\n    cyl == 6 ~ \"six\",\n    cyl == 8 ~ \"eight\"\n  ))\n\nThe mutate() function is used to add the new variable, and case_when() is used to assign the values “four”, “six”, or “eight” to the new variable based on the number of cylinders in each car. Both functions are part of the dplyr package (see chapter Section 7.4.1).\n\n\n7.4.3 Examining and cleaning data with the janitor package\nThe janitor package follows the principles of the tidyverse and works well with the pipe operator |&gt;. The janitor functions has many usefull functions for the initial data exploration and cleaning that are essential when you load any new data set.\nFirst, make sure the janitor package is installed and loaded:\n\n7.4.3.1 Clean data.frame names with clean_names()\nI call this function frequently when I read in new data. It handles problematic variable names, especially those that are so well-preserved by readxl::read_excel() and readr::read_csv(). For example, it does the following:\n\nParses letter cases and separators to a consistent format.\nHandles special characters and spaces, including transliterating characters like œ to oe.\nAppends numbers to duplicated names\nConverts “%” to “percent” and “#” to “number” to retain meaning\nSpacing (or lack thereof) around numbers is preserved\n\nTo exemplify what it does, let’s create some data with akward names and then clean them:\n\ndf_test &lt;- as.data.frame(matrix(ncol = 6))\nnames(df_test) &lt;- c(\n  \"firstName\", \"ábc@!*\", \"% successful (2009)\",\n  \"REPEAT VALUE\", \"REPEAT VALUE\", \"\"\n)\ndf_cln &lt;- df_test |&gt;\n  clean_names()\nnames(df_test)\n\n[1] \"firstName\"           \"ábc@!*\"              \"% successful (2009)\"\n[4] \"REPEAT VALUE\"        \"REPEAT VALUE\"        \"\"                   \n\nnames(df_cln)\n\n[1] \"first_name\"              \"abc\"                    \n[3] \"percent_successful_2009\" \"repeat_value\"           \n[5] \"repeat_value_2\"          \"x\"                      \n\n\n\n\n7.4.3.2 Find duplicated values for specific combinations of variables with get_dupes()\nget_dupes allows you to check for the indentifying variable. In other words, it shows you duplicates for specific combinations of variables.\nFor example, consider the following tibble:\n\ndf_panel &lt;- tibble(\n  country = c(rep(\"a\", 3), rep(\"b\", 3), rep(\"c\", 3)),\n  year = rep(1:3, 3),\n  GDP = c(1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000)\n)\ndf_panel\n\n# A tibble: 9 × 3\n  country  year   GDP\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1 a           1  1000\n2 a           2  2000\n3 a           3  3000\n4 b           1  4000\n5 b           2  5000\n6 b           3  6000\n7 c           1  7000\n8 c           2  8000\n9 c           3  9000\n\n\nwith\n\nget_dupes(df_panel, country, year)\n\nNo duplicate combinations found of: country, year\n\n\n# A tibble: 0 × 4\n# ℹ 4 variables: country &lt;chr&gt;, year &lt;int&gt;, dupe_count &lt;int&gt;, GDP &lt;dbl&gt;\n\n\nwe see that this is a panel dataset identified by a combination of country and year. Now let us introduce a duplicate and check again:\n\nnew_obs &lt;- tibble(country = \"b\", year = 2, GDP = 5000)\ndf_panel_dup &lt;- bind_rows(df_panel, new_obs)\nget_dupes(df_panel_dup, country, year)\n\n# A tibble: 2 × 4\n  country  year dupe_count   GDP\n  &lt;chr&gt;   &lt;dbl&gt;      &lt;int&gt; &lt;dbl&gt;\n1 b           2          2  5000\n2 b           2          2  5000\n\n\n\n\n\n\n\n\nTip 7.2: The plm package\n\n\n\nSpeaking of panel datasets, it’s worth mentioning the plm package, which is excellent for managing such data. For example, you can use is.pbalanced to verify whether a panel is balanced, meaning it has the same years for all countries.\n\npacman::p_load(plm)\nis.pbalanced(df_panel)\n\n[1] TRUE\n\n\nIf your panel is unbalanced, you can use make.pbalanced to rectify it:\n\ndf_unbal &lt;- df_panel |&gt; \n  filter(row_number() != 7)\ndf_unbal\n\n# A tibble: 8 × 3\n  country  year   GDP\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1 a           1  1000\n2 a           2  2000\n3 a           3  3000\n4 b           1  4000\n5 b           2  5000\n6 b           3  6000\n7 c           2  8000\n8 c           3  9000\n\nis.pbalanced(df_unbal)\n\n[1] FALSE\n\ndf_unbal_balanced &lt;- make.pbalanced(df_unbal)\ndf_unbal_balanced\n\n  country year  GDP\n1       a    1 1000\n2       a    2 2000\n3       a    3 3000\n4       b    1 4000\n5       b    2 5000\n6       b    3 6000\n7       c    1   NA\n8       c    2 8000\n9       c    3 9000\n\n\n\n\n\n\n7.4.3.3 remove_empty() rows and columns\nFor cleaning Excel files that contain empty rows and columns after being read into R, remove_empty can be very helpful:\n\nq &lt;- data.frame(\n  v1 = c(1, NA, 3),\n  v2 = c(NA, NA, NA),\n  v3 = c(\"a\", NA, \"b\")\n)\nq |&gt;\n  remove_empty(c(\"rows\", \"cols\"))\n\n  v1 v3\n1  1  a\n3  3  b\n\n\n\n\n7.4.3.4 remove_constant() columns\nRemoves variables from data that contain only a single constant value (with an na.rm option to control whether NAs should be considered as different values from the constant).\n\na &lt;- data.frame(good = 1:3, boring = \"the same\")\na\n\n  good   boring\n1    1 the same\n2    2 the same\n3    3 the same\n\na |&gt; \n  remove_constant()\n\n  good\n1    1\n2    2\n3    3\n\n\n\n\n\n7.4.4 tabyl() - a better version of table()\ntabyl() is a tidyverse-oriented replacement for table(). It counts combinations of one, two, or three variables, and then can be formatted with a suite of adorn_* functions to look just how you want. For example:\n\nmtcars |&gt;\n  tabyl(gear, cyl) |&gt;\n  adorn_totals(\"col\") |&gt;\n  adorn_percentages(\"row\") |&gt;\n  adorn_pct_formatting(digits = 2) |&gt;\n  adorn_ns() |&gt;\n  adorn_title()\n\n             cyl                                    \n gear          4          6           8        Total\n    3  6.67% (1) 13.33% (2) 80.00% (12) 100.00% (15)\n    4 66.67% (8) 33.33% (4)  0.00%  (0) 100.00% (12)\n    5 40.00% (2) 20.00% (1) 40.00%  (2) 100.00%  (5)\n\n\nLearn more in the tabyls vignette.",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Manage data</span>"
    ]
  },
  {
    "objectID": "40_manage.html#sec-generics",
    "href": "40_manage.html#sec-generics",
    "title": "7  Manage data",
    "section": "7.5 User-defined functions and conflicts",
    "text": "7.5 User-defined functions and conflicts\nOne of the great strengths of R is the user’s ability to add functions. Sometimes there is a small task (or series of tasks) you need done and you find yourself having to repeat it multiple times. In these types of situations it can be helpful to create your own custom function. The structure of a function is given below:\n\nname_of_function &lt;- function(argument1, argument2) {\n    statements or code that does something\n    return(something)\n}\n\nFirst you give your function a name. Then you assign value to it, where the value is the function. When defining the function you will want to provide the list of arguments required (inputs and/or options to modify behavior of the function), and wrapped between curly brackets place the tasks that are being executed on/using those arguments. The argument(s) can be any type of object (like a scalar, a matrix, a dataframe, a vector, a logical, etc), and it’s not necessary to define what it is in any way. Finally, you can return the value of the object from the function, meaning pass the value of it into the global environment. The important idea behind functions is that objects that are created within the function are local to the environment of the function – they don’t exist outside of the function. Note, a function doesn’t require any arguments.\nLet’s try creating a simple example function. This function will take in a numeric value as input, and return the squared value.\n\nsquare_it &lt;- function(x) { \n   square &lt;- x * x\n   return(square)\n} \n\nNow, we can use the function as we would any other function. We type out the name of the function, and inside the parentheses we provide a numeric value x:\n\nsquare_it(5)\n\n[1] 25\n\n\nLet us get back to script with sales and try to calculate the monthly growth rates of revenue using a self-written function.\nThe formula of a growth rate is clear:\n\\[ g=\\left(\\frac{y_t-y_{t-1}}{y_{t-1}}\\right)\\cdot 100=\\left(\\frac{y_t}{y_{t-1}}-1\\right)\\cdot 100 \\]\nSo the challenge is to divide the value of revenue with the value of the previous period, a.k.a. the lagged value. Let us assume that the function lag() can give you exactly that value of a vector. Lets try it out:\n\nlag(revenue)\n\n [1]    0  700 1400  350  175   28   56    0    0    0    0    0\nattr(,\"tsp\")\n[1]  0 11  1\n\n(revenue/lag(revenue)-1)*100 \n\n [1] NaN   0   0   0   0   0   0 NaN NaN NaN NaN NaN\nattr(,\"tsp\")\n[1]  0 11  1\n\n\nUnfortunately, this does not work out. The lag() function does not work as we think it should. Well, the reason is simply that we are using the wrong function. The current lag() function is part of the stats package which is part of the package stats which is part of R base and is loaded automatically. The lag() function we aim to use stems from the dplyr package which we must install and load to be able to use it. So let’s do it:\n\n# check if the package is installed\nfind.package(\"dplyr\")\n\n[1] \"/home/sthu/R/x86_64-pc-linux-gnu-library/4.2/dplyr\"\n\n# I already installed the package so I can just load it\n# install.packages(\"dplyr\")\nlibrary(\"dplyr\")\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:plm':\n\n    between, lag, lead\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nThis message informs us that among other functions the lag() function is masked. That means that now the function of the newly loaded package is active. This is one example of why I highly recommend to unload all packages at the beginning of a script and then to use p_load to install and load the packages that should be used in the upcoming script:\n\npacman::p_unload(all)\npacman::p_load(dplyr)\n\nSo, let’s try again:\n\nlag(revenue)\n\n [1]   NA    0  700 1400  350  175   28   56    0    0    0    0\n\n(revenue/lag(revenue)-1)*100 \n\n [1]   NA  Inf  100  -75  -50  -84  100 -100  NaN  NaN  NaN  NaN\n\n\nThat looks good now. And here is a way to calculate growth rates with a self-written function:\n\ngrowth_rate &lt;- function(x) {\n  (x / lag(x) - 1) * 100\n}\ngrowth_rate(revenue)\n\n [1]   NA  Inf  100  -75  -50  -84  100 -100  NaN  NaN  NaN  NaN\n\nsales_gr_rate &lt;- growth_rate(revenue)\nsales_gr_rate\n\n [1]   NA  Inf  100  -75  -50  -84  100 -100  NaN  NaN  NaN  NaN\n\n\nIn R, all functions are written by users, and it is not uncommon for two people to name their functions identically. In such cases, we must resolve the conflict by choosing which function to use. To use the lag function from the stats package, you can use the double colon operator :: like this stats::lag().",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Manage data</span>"
    ]
  },
  {
    "objectID": "40_manage.html#example-how-to-explore-a-dataset",
    "href": "40_manage.html#example-how-to-explore-a-dataset",
    "title": "7  Manage data",
    "section": "7.6 Example: How to explore a dataset",
    "text": "7.6 Example: How to explore a dataset\n\n# Creating dataframe\ndf &lt;- tibble(\n  integer_var, numeric_var, character_var, factor_var, logical_var, date_var,\n)\n\n# Overview of the data\nhead(df)\n\n# A tibble: 5 × 6\n  integer_var numeric_var character_var factor_var logical_var date_var  \n        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;         &lt;fct&gt;      &lt;lgl&gt;       &lt;date&gt;    \n1           1         1.1 apple         red        TRUE        2022-01-01\n2           2         2.2 banana        yellow     TRUE        2022-02-01\n3           3        NA   orange        red        TRUE        2022-03-01\n4           4         4.4 cherry        blue       FALSE       2022-04-01\n5           5         5.5 grape         green      TRUE        2022-05-01\n\nsummary(df)\n\n  integer_var  numeric_var    character_var       factor_var logical_var    \n Min.   :1    Min.   :1.100   Length:5           blue  :1    Mode :logical  \n 1st Qu.:2    1st Qu.:1.925   Class :character   green :1    FALSE:1        \n Median :3    Median :3.300   Mode  :character   red   :2    TRUE :4        \n Mean   :3    Mean   :3.300                      yellow:1                   \n 3rd Qu.:4    3rd Qu.:4.675                                                 \n Max.   :5    Max.   :5.500                                                 \n              NA's   :1                                                     \n    date_var         \n Min.   :2022-01-01  \n 1st Qu.:2022-02-01  \n Median :2022-03-01  \n Mean   :2022-03-02  \n 3rd Qu.:2022-04-01  \n Max.   :2022-05-01  \n                     \n\nglimpse(df)\n\nRows: 5\nColumns: 6\n$ integer_var   &lt;dbl&gt; 1, 2, 3, 4, 5\n$ numeric_var   &lt;dbl&gt; 1.1, 2.2, NA, 4.4, 5.5\n$ character_var &lt;chr&gt; \"apple\", \"banana\", \"orange\", \"cherry\", \"grape\"\n$ factor_var    &lt;fct&gt; red, yellow, red, blue, green\n$ logical_var   &lt;lgl&gt; TRUE, TRUE, TRUE, FALSE, TRUE\n$ date_var      &lt;date&gt; 2022-01-01, 2022-02-01, 2022-03-01, 2022-04-01, 2022-05-…\n\n# look closer at variables\n\n# unique values\nunique(df$integer_var)\n\n[1] 1 2 3 4 5\n\nunique(df$factor_var)\n\n[1] red    yellow blue   green \nLevels: blue green red yellow\n\ntable(df$factor_var)\n\n\n  blue  green    red yellow \n     1      1      2      1 \n\nlength(unique(df$factor_var))\n\n[1] 4\n\n# distributions\ndf |&gt; count(factor_var)\n\n# A tibble: 4 × 2\n  factor_var     n\n  &lt;fct&gt;      &lt;int&gt;\n1 blue           1\n2 green          1\n3 red            2\n4 yellow         1\n\nprop.table(table(df$factor_var))\n\n\n  blue  green    red yellow \n   0.2    0.2    0.4    0.2 \n\ndf |&gt;\n  count(factor_var) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 4 × 3\n  factor_var     n  prop\n  &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n1 blue           1   0.2\n2 green          1   0.2\n3 red            2   0.4\n4 yellow         1   0.2\n\naggregate(df$numeric_var,\n  by = list(fruit = df$factor_var),\n  mean\n)\n\n   fruit   x\n1   blue 4.4\n2  green 5.5\n3    red  NA\n4 yellow 2.2\n\n# --&gt; the mean of red cannot be calculated as there is a NA in it\n# Solution: exclude NAs from calculation:\naggregate(df$numeric_var,\n  by = list(fruit = df$factor_var),\n  mean,\n  na.rm = TRUE\n)\n\n   fruit   x\n1   blue 4.4\n2  green 5.5\n3    red 1.1\n4 yellow 2.2\n\n# install.packages(\"janitor\")\nrequire(\"janitor\")\nmtcars |&gt;\n  tabyl(cyl)\n\n cyl  n percent\n   4 11 0.34375\n   6  7 0.21875\n   8 14 0.43750\n\nmtcars |&gt;\n  tabyl(cyl, hp)\n\n cyl 52 62 65 66 91 93 95 97 105 109 110 113 123 150 175 180 205 215 230 245\n   4  1  1  1  2  1  1  1  1   0   1   0   1   0   0   0   0   0   0   0   0\n   6  0  0  0  0  0  0  0  0   1   0   3   0   2   0   1   0   0   0   0   0\n   8  0  0  0  0  0  0  0  0   0   0   0   0   0   2   2   3   1   1   1   2\n 264 335\n   0   0\n   0   0\n   1   1\n\n\n\n\n\nFigure 7.1: The logo of the packages readr, haven, and readxl\nFigure 7.2: The logos of the tidyr and tibble packages\nFigure 7.3: Features of a tidy dataset: variables are columns, observations are rows, and values are cells\nFigure 7.4: The logo of the dplyr package\n\n\n\nHadley, W. (2014). Tidy data. Journal of Statistical Software, 59(10), 1–23.\n\n\nWickham, H., & Grolemund, G. (2023). R for data science (2e). https://r4ds.hadley.nz/",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Manage data</span>"
    ]
  },
  {
    "objectID": "50_graph.html",
    "href": "50_graph.html",
    "title": "8  Visualize data",
    "section": "",
    "text": "Data visualization is an art. The purposes of visualizing data are manifold. You can emphasize facts, get known to data, detect anomalies, and communicate a large amount of information simply and intuitive. Whatever your goal is, thousand of appropriate ways exist to visualize data. Many decisions to take are simply a matter of taste. However, there are some conventions and guidelines that help you to make on average better decisions when designing a visualization:\n\nGood graphs are easy to understand and eye catching.\nGraphs can be misleading and manipulative and that is opposing to the ideas of science. Thus, be responsible and honest.\nMinimize colors and other attention-grabbing elements that are not directly related to the data of interest. Worldwide, there are approximately 300 million color blind people. In particular, red, green or blue light are problematic to color blind people. Thus, better rely on color schemes that are designed for colorblind people.\nDon’t truncate an axis or change the scaling within an axis just to make you your story more appealing. Show the full scale of the graph, then zoom to show the data of interest, if necessary.\nLabel and describe your chart sufficiently so that everybody can fully understand the content of the shown data set and statistics without having to study the notes of the graph for too long.\nDon’t do pie charts. They may look simple, but they’re tricky to get right and there are usually better alternatives. Humans are not very good at comparing the size of angles and as there’s no scale in pie plots, reading accurate values is difficult. Figure Figure 8.1 may proof this.\n\n\n\n\nFigure 8.1: Pie charts are problematic\n\n\n\nSource: https://en.wikipedia.org/wiki/Pie_chart\n\n\n\n\n\n\n\n\n\nMore tips\n\n\n\n\nData Visualization: Chart Dos and Don’ts (by Duke University)\nGraphs and Visualising Data by Oliver Kirchkamp. In particular, I highly recommend his handout (Kirchkamp, 2018). It discusses many pitfalls of visualizing data, instructs how to do good graphs, and he shows the corresponding R code of all graphs.\n\nThe From Data to Viz website leads you to the most appropriate graph for your data. It links to the code to build it and lists common caveats you should avoid.\nThe R Graph Gallery and R CHARTS by R CODER shows graphs and the corresponding R code to replicate the graphs\nThe work of Edward Tufte and his book The Visual Display of Quantitative Information (Tufte, 2022) are classical readings.\n\n\n\nA great resource to learn how to visualize data is Wickham & Grolemund (2023). As I cannot do that any better, I refer to that source and refrain from writing section myself. It introduces the ggplot function which is part of the ggplot2 package which, in turn, is part of the tidyverse package. Thus, if you’ve installed and loaded tidyverse, you automatically have access to ggplot. Creating beautiful and informative graphs is easy with ggplot. To proof that claim, study the chapter (Data visualization) of Wickham & Grolemund (2023). Another good resource on modern data visualization is Kabacoff (2024).\n\n\n\n\n\n\nTo reap the best benefits from studying,\n\n\n\nI recommend to copy all the code that is shown in the book into a R script and try to run it on your PC. That is the best way to learn, understand, and create your own notes that may guide you later on. Whenever you see interesting code somewhere, try to run it on your PC. Moreover, I recommend the exercises of the book, they are challenging sometimes but to really understand code you need to run code yourself.\n\n\n\n\n\nFigure 8.1: Pie charts are problematic\n\n\n\nKabacoff, R. (2024). Modern data visualization with R. Chapman; Hall/CRC. https://rkabacoff.github.io/datavis/\n\n\nKirchkamp, O. (2018). Using graphs and visualising data.\n\n\nTufte, E. R. (2022). The visual display of quantitative information (2nd ed.). Graphics Press.\n\n\nWickham, H., & Grolemund, G. (2023). R for data science (2e). https://r4ds.hadley.nz/",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualize data</span>"
    ]
  },
  {
    "objectID": "80_exercises.html",
    "href": "80_exercises.html",
    "title": "9  Collection of exercises",
    "section": "",
    "text": "9.1 Import data with c()\nTable 9.1 shows COVID for three states in Germany:\nWrite down the code you would need to put into the R-console…",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exeimportdata",
    "href": "80_exercises.html#sec-exeimportdata",
    "title": "9  Collection of exercises",
    "section": "",
    "text": "Table 9.1: Covid cases and deaths till August 2022\n\n\n\n\n\n\n\n\n\n\n\nstate\nBavaria\nNorth Rhine-Westphalia\nBaden-Württemberg\n\n\n\n\ndeaths (in mio)\n4,92M\n5,32M\n3,69M\n\n\ncases\n24.111\n25.466\n16.145\n\n\n\n\n\n\n\n\n…to store each of variables state and deaths in a vector.\n…to store both vectors in a data frame with the name df_covid.\n…to store both vectors in a tibble with the name tbl_covid.\n\nLoading required package: pacman\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: c, data.frame, tibble.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Solution to excercise \"Import data\":\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tibble)\n\nstate &lt;- c(\"BY\", \"NRW\", \"BW\")\ndeaths &lt;- c(4.92, 5.32, 3.69)\ncases &lt;- c(24111, 25466, 16145)\ndf_covid &lt;- data.frame(state, deaths)\ntbl_covid &lt;- tibble(state, deaths)\n\nsuppressMessages(pacman::p_unload(tibble))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Solution to excercise \"Import data\":\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tibble)\n\nstate &lt;- c(\"BY\", \"NRW\", \"BW\")\ndeaths &lt;- c(4.92, 5.32, 3.69)\ncases &lt;- c(24111, 25466, 16145)\ndf_covid &lt;- data.frame(state, deaths)\ntbl_covid &lt;- tibble(state, deaths)\n\nsuppressMessages(pacman::p_unload(tibble))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#filter-and-select-observations",
    "href": "80_exercises.html#filter-and-select-observations",
    "title": "9  Collection of exercises",
    "section": "9.2 Filter and select observations",
    "text": "9.2 Filter and select observations\nSet up R, RStudio, and R packages\nOpen this interactive tutorial and work through it.\n\n\n\n\n\n\nThe script uses among others the following functions: filter, is.na, select.",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-baseinoperator",
    "href": "80_exercises.html#sec-baseinoperator",
    "title": "9  Collection of exercises",
    "section": "9.3 Base R,%in% operator, and the pipe |>",
    "text": "9.3 Base R,%in% operator, and the pipe |&gt;\n\nUsing the mtcars dataset, write code to create a new dataframe that includes only the rows where the number of cylinders is either 4 or 6, and the weight (wt) is less than 3.5.\n\nDo this in two different ways using:\n\nThe %in% operator and the pipe |&gt; .\nBase R without the pipe |&gt;.\n\nCompare the resulting dataframes using the identical() function.\n\nUsing the mtcars dataset, generate a logical variable that indicates with TRUE all cars with either 4 or 6 cylinders that wt is less than 3.5 and add this variable to a new dataset.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: c, filter, identical, if_else, mutate, subset, transform, with.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Base R or pipe\n# exe_base_pipe.R\n# Stephan Huber; 2023-05-08\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list=ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\n# Using the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf1 &lt;- mtcars |&gt; \n  filter(cyl %in% c(4, 6) & wt &lt; 3.5)  \ndf1\n\n# Without the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf2 &lt;- subset(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\ndf2\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df1, df2)\n\n\n# b)\n# Using the pipe |&gt; and tidyverse (mutate)\ndf3 &lt;- mtcars |&gt; \n  mutate(cyl_4_or_6 = \n           if_else(cyl %in% c(4, 6) & wt &lt; 3.5, TRUE, FALSE))\ndf3\n\n# without pipe and with base R (transform)\ndf4 &lt;- mtcars\ndf4$cyl_4_or_6 &lt;- with(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\n\n# Alternatively in one line:\ndf5 &lt;- transform(mtcars, cyl_4_or_6 = cyl %in% c(4,6) & wt &lt; 3.5)\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df3, df4)\nidentical(df3, df5)\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Base R or pipe\n# exe_base_pipe.R\n# Stephan Huber; 2023-05-08\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list=ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\n# Using the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf1 &lt;- mtcars |&gt; \n  filter(cyl %in% c(4, 6) & wt &lt; 3.5)  \ndf1\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# Without the pipe |&gt; \n# Select rows where cyl is 4 or 6 and wt is less than 3.5\ndf2 &lt;- subset(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\ndf2\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df1, df2)\n\n[1] TRUE\n\n# b)\n# Using the pipe |&gt; and tidyverse (mutate)\ndf3 &lt;- mtcars |&gt; \n  mutate(cyl_4_or_6 = \n           if_else(cyl %in% c(4, 6) & wt &lt; 3.5, TRUE, FALSE))\ndf3\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n                    cyl_4_or_6\nMazda RX4                 TRUE\nMazda RX4 Wag             TRUE\nDatsun 710                TRUE\nHornet 4 Drive            TRUE\nHornet Sportabout        FALSE\nValiant                   TRUE\nDuster 360               FALSE\nMerc 240D                 TRUE\nMerc 230                  TRUE\nMerc 280                  TRUE\nMerc 280C                 TRUE\nMerc 450SE               FALSE\nMerc 450SL               FALSE\nMerc 450SLC              FALSE\nCadillac Fleetwood       FALSE\nLincoln Continental      FALSE\nChrysler Imperial        FALSE\nFiat 128                  TRUE\nHonda Civic               TRUE\nToyota Corolla            TRUE\nToyota Corona             TRUE\nDodge Challenger         FALSE\nAMC Javelin              FALSE\nCamaro Z28               FALSE\nPontiac Firebird         FALSE\nFiat X1-9                 TRUE\nPorsche 914-2             TRUE\nLotus Europa              TRUE\nFord Pantera L           FALSE\nFerrari Dino              TRUE\nMaserati Bora            FALSE\nVolvo 142E                TRUE\n\n# without pipe and with base R (transform)\ndf4 &lt;- mtcars\ndf4$cyl_4_or_6 &lt;- with(mtcars, cyl %in% c(4, 6) & wt &lt; 3.5)\n\n# Alternatively in one line:\ndf5 &lt;- transform(mtcars, cyl_4_or_6 = cyl %in% c(4,6) & wt &lt; 3.5)\n\n# Check if the resulting dataframe is identical to the expected output\nidentical(df3, df4)\n\n[1] TRUE\n\nidentical(df3, df5)\n\n[1] TRUE\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exe_genanddrop",
    "href": "80_exercises.html#sec-exe_genanddrop",
    "title": "9  Collection of exercises",
    "section": "9.4 Generate and drop variables",
    "text": "9.4 Generate and drop variables\nUse the mtcars dataset. It is part of the package datasets and can be called with\n\nmtcars\n\n\nCreate a new tibble called mtcars_new using the pipe operator |&gt;. Generate a new dummy variable called d_cyl_6to8 that takes the value 1 if the number of cylinders (cyl) is greater than 6, and 0 otherwise. Do all of this in a single pipe.\nGenerate a new dummy variable called posercar that takes a value of 1 if a car has more than 6 cylinders (cyl) and can drive less than 18 miles per gallon (mpg), and 0 otherwise. Add this variable to the tibble mtcars_new.\nRemove the variable d_cyl_6to8 from the data frame.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: as_tibble, if_else, mutate, rownames_to_column, select.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Generate and drop variables\n# exe_genanddrop.R\n# Stephan Huber; 2023-05-09\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\nmtcars_new &lt;- mtcars |&gt;\n  rownames_to_column(var = \"car\") |&gt;\n  as_tibble() |&gt;\n  mutate(d_cyl_6to8 = if_else(cyl &gt; 6, 1, 0))\nmtcars_new\n\n# b)\nmtcars_new &lt;- mtcars_new |&gt;\n  mutate(posercar = if_else(cyl &gt; 6 & mpg &lt; 18, 1, 0))\nmtcars_new\n\n# c)\nmtcars_new &lt;- mtcars_new |&gt;\n  select(-d_cyl_6to8)\nmtcars_new\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Generate and drop variables\n# exe_genanddrop.R\n# Stephan Huber; 2023-05-09\n\n# setwd(\"/home/sthu/Dropbox/hsf/test\")\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasets, tidyverse)\n\n# a)\nmtcars_new &lt;- mtcars |&gt;\n  rownames_to_column(var = \"car\") |&gt;\n  as_tibble() |&gt;\n  mutate(d_cyl_6to8 = if_else(cyl &gt; 6, 1, 0))\nmtcars_new\n\n# A tibble: 32 × 13\n   car           mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n# ℹ 1 more variable: d_cyl_6to8 &lt;dbl&gt;\n\n# b)\nmtcars_new &lt;- mtcars_new |&gt;\n  mutate(posercar = if_else(cyl &gt; 6 & mpg &lt; 18, 1, 0))\nmtcars_new\n\n# A tibble: 32 × 14\n   car           mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n# ℹ 2 more variables: d_cyl_6to8 &lt;dbl&gt;, posercar &lt;dbl&gt;\n\n# c)\nmtcars_new &lt;- mtcars_new |&gt;\n  select(-d_cyl_6to8)\nmtcars_new\n\n# A tibble: 32 × 13\n   car           mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n# ℹ 1 more variable: posercar &lt;dbl&gt;\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasets, tidyverse))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exe_subset",
    "href": "80_exercises.html#sec-exe_subset",
    "title": "9  Collection of exercises",
    "section": "9.5 Subsetting",
    "text": "9.5 Subsetting\n\nCheck to see if you have the mtcars dataset by entering the command mtcars.\nSave the mtcars dataset in an object named cars.\nWhat class is cars?\nHow many observations (rows) and variables (columns) are in the mtcars dataset?\nRename mpg in cars to MPG. Use rename().\nConvert the column names of cars to all upper case. Use rename_all, and the toupper command.\nConvert the rownames of cars to a column called car using rownames_to_column.\nSubset the columns from cars that end in “p” and call it pvars using ends_with().\nCreate a subset cars that only contains the columns: wt, qsec, and hp and assign this object to carsSub. (Use select().)\nWhat are the dimensions of carsSub? (Use dim().)\nConvert the column names of carsSub to all upper case. Use rename_all(), and toupper() (or colnames()).\nSubset the rows of cars that get more than 20 miles per gallon (mpg) of fuel efficiency. How many are there? (Use filter().)\nSubset the rows that get less than 16 miles per gallon (mpg) of fuel efficiency and have more than 100 horsepower (hp). How many are there? (Use filter() and the pipe operator.)\nCreate a subset of the cars data that only contains the columns: wt, qsec, and hp for cars with 8 cylinders (cyl) and reassign this object to carsSub. What are the dimensions of this dataset? Do not use the pipe operator.\nCreate a subset of the cars data that only contains the columns: wt, qsec, and hp for cars with 8 cylinders (cyl) and reassign this object to carsSub2. Use the pipe operator.\nRe-order the rows of carsSub by weight (wt) in increasing order. (Use arrange().)\nCreate a new variable in carsSub called wt2, which is equal to wt^2, using mutate() and piping |&gt;.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: arrange, class, dim, ends_with, filter, mutate, ncol, nrow, rename, rename_all, rownames_to_column, select.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Subsetting with \\R\n# exe_subset.R\n# Stephan Huber; 2022-06-07\n\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsda/work/\")\nrm(list = ls())\n\n# 0\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, dplyr, tibble)\n\n# 1\nmtcars\n\n# 2\ncars &lt;- mtcars\n\n# 3\nclass(cars)\n\n# 4\ndim(cars)\n\n# Alternative\nncol(cars)\nnrow(cars)\n\n# 5\ncars &lt;- rename(cars, MPG = mpg)\n\n# 6\ncars &lt;- rename_all(cars, toupper)\n# if you like lower cases:\n# cars &lt;- rename_all(cars, tolower)\n\n# 7\ncars &lt;- rownames_to_column(mtcars, var = \"car\")\n\n# 8\npvars &lt;- select(cars, car, ends_with(\"p\"))\n\n# 9\ncarsSub &lt;- select(cars, car, wt, qsec, hp)\n\n# 10\ndim(carsSub)\n\n# 11\ncarsSub &lt;- rename_all(carsSub, toupper)\n\n# 12\ncars_mpg &lt;- filter(cars, mpg &gt; 20)\ndim(cars_mpg)\n\n# 13\ncars_whattever &lt;- filter(cars, mpg &lt; 16 & hp &gt; 100)\n\n# 14\ncarsSub &lt;- filter(cars, cyl == 8)\ncarsSub &lt;- select(carsSub, wt, qsec, hp, car)\ndim(carsSub)\n\n# 15\n# Alternative with pipe operator:\ncarsSub &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car)\n\n# 16\ncarsSub &lt;- arrange(carsSub, wt)\n\n# 17\ncarsSub &lt;- carsSub |&gt;\n  mutate(wt2 = wt^2)\n\n# Alternatively you can put everything into one pipe:\ncarsSub2 &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car) |&gt;\n  arrange(carsSub, wt) |&gt;\n  mutate(wt2 = wt^2)\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, dplyr, tibble))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Subsetting with \\R\n# exe_subset.R\n# Stephan Huber; 2022-06-07\n\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsda/work/\")\nrm(list = ls())\n\n# 0\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, dplyr, tibble)\n\n# 1\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# 2\ncars &lt;- mtcars\n\n# 3\nclass(cars)\n\n[1] \"data.frame\"\n\n# 4\ndim(cars)\n\n[1] 32 11\n\n# Alternative\nncol(cars)\n\n[1] 11\n\nnrow(cars)\n\n[1] 32\n\n# 5\ncars &lt;- rename(cars, MPG = mpg)\n\n# 6\ncars &lt;- rename_all(cars, toupper)\n# if you like lower cases:\n# cars &lt;- rename_all(cars, tolower)\n\n# 7\ncars &lt;- rownames_to_column(mtcars, var = \"car\")\n\n# 8\npvars &lt;- select(cars, car, ends_with(\"p\"))\n\n# 9\ncarsSub &lt;- select(cars, car, wt, qsec, hp)\n\n# 10\ndim(carsSub)\n\n[1] 32  4\n\n# 11\ncarsSub &lt;- rename_all(carsSub, toupper)\n\n# 12\ncars_mpg &lt;- filter(cars, mpg &gt; 20)\ndim(cars_mpg)\n\n[1] 14 12\n\n# 13\ncars_whattever &lt;- filter(cars, mpg &lt; 16 & hp &gt; 100)\n\n# 14\ncarsSub &lt;- filter(cars, cyl == 8)\ncarsSub &lt;- select(carsSub, wt, qsec, hp, car)\ndim(carsSub)\n\n[1] 14  4\n\n# 15\n# Alternative with pipe operator:\ncarsSub &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car)\n\n# 16\ncarsSub &lt;- arrange(carsSub, wt)\n\n# 17\ncarsSub &lt;- carsSub |&gt;\n  mutate(wt2 = wt^2)\n\n# Alternatively you can put everything into one pipe:\ncarsSub2 &lt;- cars |&gt;\n  filter(cyl == 8) |&gt;\n  select(wt, qsec, hp, car) |&gt;\n  arrange(carsSub, wt) |&gt;\n  mutate(wt2 = wt^2)\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, dplyr, tibble))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#load-the-stata-dataset-auto-using-r",
    "href": "80_exercises.html#load-the-stata-dataset-auto-using-r",
    "title": "9  Collection of exercises",
    "section": "9.6 Load the Stata dataset “auto” using R",
    "text": "9.6 Load the Stata dataset “auto” using R\n\nCreate a scatter plot illustrating the relationship between the price and weight of a car. Provide a meaningful title for the graph and try to make it clear which car each observation corresponds to.\nSave this graph in the formats of .png and .pdf.\nCreate a variable “`lp100km’” that indicates the fuel consumption of an average car in liters per 100 kilometers. (Note: One gallon is approximately equal to 3.8 liters, and one mile is about 1.6 kilometers.)\nCreate a dummy variable “`larger6000’” that is equal to 1 if the price of a car is above $6000.\nNow, search for the “most unreasonable poser car” that costs no more than $6000. A “poser” car is defined as one that is expensive, has a large turning radius, consumes a lot of fuel, and is often defective (rep78 is low). For this purpose, create a metric indicator for each corresponding variable that indicates a value of 1 for the car that is the most unreasonable in that variable and 0 for the most reasonable car. All other cars should fall between 0 and 1.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, arrange, desc, dir.create, dir.exists, filter, geom_point, geom_text_repel, ggplot, head, ifelse, max, min, min_max_norm, mutate, na.omit, read_dta, select, tail, theme_minimal, xlab, ylab.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Load the required libraries\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven, ggrepel)\n\n# setwd(\"~/Dropbox/hsf/23-ws/R_begin\")\n\nrm(list = ls())\n\n# Read the Stata dataset\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r8/auto.dta\")\n\n\n# Create a scatter plot of price vs. weight\nscatter_plot &lt;- ggplot(auto, aes(x = mpg, y = price, label = make)) +\n  geom_point() +\n  geom_text_repel() +\n  xlab(\"Miles per Gallon\") +\n  ylab(\"Price in Dollar\") +\n  theme_minimal()\n\nscatter_plot\n\n# Create \"fig\" directory if it doesn't already exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\n# Save the scatter plot in different formats\n# ggsave(\"fig/scatter_plot.png\", plot = scatter_plot, device = \"png\")\n# ggsave(\"fig/scatter_plot.pdf\", plot = scatter_plot, device = \"pdf\")\n\n# Create 'lp100km' variable for fuel consumption\nn_auto &lt;- auto |&gt;\n  mutate(lp100km = (1 / (mpg * 1.6 / 3.8)) * 100)\n\n# Create 'larger6000' dummy variable\nn_auto &lt;- n_auto |&gt;\n  mutate(larger6000 = ifelse(price &gt; 6000, 1, 0))\n\n\n\n# Normalize variables\n\n## Do it slowly\nn_auto &lt;- n_auto |&gt;\n  mutate(sprice = (price - min(auto$price)) / (max(auto$price) - min(auto$price)))\n\nn_auto &lt;- n_auto |&gt;\n  filter(larger6000 == 0)\n\n## Do it with a self-written function\nmin_max_norm &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = min_max_norm(mpg)) |&gt;\n  mutate(sturn = min_max_norm(turn)) |&gt;\n  mutate(slp100km = min_max_norm(lp100km)) |&gt;\n  mutate(sprice = min_max_norm(price)) |&gt;\n  mutate(srep78 = min_max_norm(rep78))\n\n## With a loop:\n\n# vars_to_normalize &lt;- c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")\n#\n# # Loop through the selected variables and apply min_max_norm\n# for (var in c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")) {\n#   auto &lt;- auto |&gt;\n#     mutate(!!paste0(\"s\", var) := min_max_norm(!!sym(var))) |&gt;\n#     select(make, starts_with(\"s\"))\n# }\n\n## mpg and rep78 need to be changed because a SMALL value is poser-like\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = 1 - smpg) |&gt;\n  mutate(srep78 = 1 - srep78)\n\n## create the poser (composite) indicator\nn_auto &lt;- n_auto |&gt;\n  mutate(poser = (sturn + smpg + sprice + srep78) / 4)\n\n## filter results\nn_auto |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  head(5)\n\ndf_poser &lt;- n_auto |&gt;\n  filter(larger6000 == 0) |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  na.omit()\n\n# Five top poser cars\nhead(df_poser, 15)\n\n# Five top non-poser cars\ntail(df_poser, 5)\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven, ggrepel))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Load the required libraries\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven, ggrepel)\n\n# setwd(\"~/Dropbox/hsf/23-ws/R_begin\")\n\nrm(list = ls())\n\n# Read the Stata dataset\nauto &lt;- read_dta(\"http://www.stata-press.com/data/r8/auto.dta\")\n\n\n# Create a scatter plot of price vs. weight\nscatter_plot &lt;- ggplot(auto, aes(x = mpg, y = price, label = make)) +\n  geom_point() +\n  geom_text_repel() +\n  xlab(\"Miles per Gallon\") +\n  ylab(\"Price in Dollar\") +\n  theme_minimal()\n\nscatter_plot\n\nWarning: ggrepel: 43 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n# Create \"fig\" directory if it doesn't already exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\n# Save the scatter plot in different formats\n# ggsave(\"fig/scatter_plot.png\", plot = scatter_plot, device = \"png\")\n# ggsave(\"fig/scatter_plot.pdf\", plot = scatter_plot, device = \"pdf\")\n\n# Create 'lp100km' variable for fuel consumption\nn_auto &lt;- auto |&gt;\n  mutate(lp100km = (1 / (mpg * 1.6 / 3.8)) * 100)\n\n# Create 'larger6000' dummy variable\nn_auto &lt;- n_auto |&gt;\n  mutate(larger6000 = ifelse(price &gt; 6000, 1, 0))\n\n\n\n# Normalize variables\n\n## Do it slowly\nn_auto &lt;- n_auto |&gt;\n  mutate(sprice = (price - min(auto$price)) / (max(auto$price) - min(auto$price)))\n\nn_auto &lt;- n_auto |&gt;\n  filter(larger6000 == 0)\n\n## Do it with a self-written function\nmin_max_norm &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = min_max_norm(mpg)) |&gt;\n  mutate(sturn = min_max_norm(turn)) |&gt;\n  mutate(slp100km = min_max_norm(lp100km)) |&gt;\n  mutate(sprice = min_max_norm(price)) |&gt;\n  mutate(srep78 = min_max_norm(rep78))\n\n## With a loop:\n\n# vars_to_normalize &lt;- c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")\n#\n# # Loop through the selected variables and apply min_max_norm\n# for (var in c(\"mpg\", \"turn\", \"lp100km\", \"price\", \"rep78\")) {\n#   auto &lt;- auto |&gt;\n#     mutate(!!paste0(\"s\", var) := min_max_norm(!!sym(var))) |&gt;\n#     select(make, starts_with(\"s\"))\n# }\n\n## mpg and rep78 need to be changed because a SMALL value is poser-like\nn_auto &lt;- n_auto |&gt;\n  mutate(smpg = 1 - smpg) |&gt;\n  mutate(srep78 = 1 - srep78)\n\n## create the poser (composite) indicator\nn_auto &lt;- n_auto |&gt;\n  mutate(poser = (sturn + smpg + sprice + srep78) / 4)\n\n## filter results\nn_auto |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  make             poser\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Dodge Magnum     0.888\n2 Pont. Firebird   0.782\n3 Merc. Cougar     0.763\n4 Buick LeSabre    0.754\n5 Pont. Grand Prix 0.720\n\ndf_poser &lt;- n_auto |&gt;\n  filter(larger6000 == 0) |&gt;\n  arrange(desc(poser)) |&gt;\n  select(make, poser) |&gt;\n  na.omit()\n\n# Five top poser cars\nhead(df_poser, 15)\n\n# A tibble: 15 × 2\n   make              poser\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Dodge Magnum      0.888\n 2 Pont. Firebird    0.782\n 3 Merc. Cougar      0.763\n 4 Buick LeSabre     0.754\n 5 Pont. Grand Prix  0.720\n 6 Chev. Impala      0.702\n 7 Dodge Diplomat    0.690\n 8 Chev. Monte Carlo 0.684\n 9 Pont. Catalina    0.678\n10 Olds Cutl Supr    0.671\n11 Plym. Volare      0.665\n12 Buick Regal       0.663\n13 Olds Cutlass      0.629\n14 Olds Starfire     0.626\n15 AMC Pacer         0.619\n\n# Five top non-poser cars\ntail(df_poser, 5)\n\n# A tibble: 5 × 2\n  make           poser\n  &lt;chr&gt;          &lt;dbl&gt;\n1 VW Diesel      0.261\n2 Dodge Colt     0.227\n3 Toyota Corolla 0.195\n4 Datsun 210     0.195\n5 Subaru         0.178\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven, ggrepel))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#datasaurus",
    "href": "80_exercises.html#datasaurus",
    "title": "9  Collection of exercises",
    "section": "9.7 DatasauRus",
    "text": "9.7 DatasauRus\n\n\n\nFigure 9.1: The logo of the DatasauRus package\n\n\n\nSource: https://github.com/jumpingrivers/datasauRus _\n\n\n\n\nLoad the packages datasauRus and tidyverse. If necessary, install these packages.\nThe packagedatasauRus comes with a dataset in two different formats: datasaurus_dozen and datasaurus_dozen_wide. Store them as ds and ds_wide.\nOpen and read the R vignette of the datasauRus package. Also open the R documentation of the dataset datasaurus_dozen.\nExplore the dataset: What are the dimensions of this dataset? Look at the descriptive statistics.\nHow many unique values does the variable dataset of the tibble ds have? Hint: The function unique() return the unique values of a variable and the function length() returns the length of a vector, such as the unique elements.\nCompute the mean values of the x and y variables for each entry in dataset. Hint: Use the group_by() function to group the data by the appropriate column and then the summarise() function to calculate the mean.\nCompute the standard deviation, the correlation, and the median in the same way. Round the numbers.\nWhat can you conclude?\nPlot all datasets of ds. Hide the legend. Hint: Use the facet_wrap() and the theme() function.\nCreate a loop that generates separate scatter plots for each unique datatset of the tibble ds. Export each graph as a png file.\nWatch the video Animating the Datasaurus Dozen Dataset in R from The Data Digest on YouTube.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, cor, dim, dir.create, dir.exists, facet_wrap, filter, geom_point, ggplot, ggsave, glimpse, group_by, head, labs, length, mean, median, paste, paste0, round, sd, select, summarise, summary, theme, theme_bw, unique, view.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/23-ws/ds_mim/\")\nrm(list = ls())\n\n# Load the packages datasauRus and tidyverse. If necessary, install these packages.\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasauRus, tidyverse)\n\n# The packagedatasauRus comes with a dataset in two different formats:\n#   datasaurus_dozen and datasaurus_dozen_wide. Store them as ds and ds_wide.\n\nds &lt;- datasaurus_dozen\nds_wide &lt;- datasaurus_dozen_wide\n\n# Open and read the R vignette of the datasauRus package.\n#   Also open the R documentation of the dataset datasaurus_dozen.\n\n??datasaurus\n\n# Explore the dataset: What are the dimensions of this dataset? Look at the descriptive statistics.\n\nds\ndim(ds)\nhead(ds)\nglimpse(ds)\nview(ds)\nsummary(ds)\n\n# How many unique values does the variable dataset of the tibble ds have?\n#   Hint: The function unique() return the unique values of a variable and the\n#   function length() returns the length of a vector, such as the unique elements.\n\nunique(ds$dataset)\n\nunique(ds$dataset) |&gt;\n  length()\n\n# Compute the mean values of the x and y variables for each entry in dataset.\n#   Hint: Use the group_by() function to group the data by the appropriate column and\n#   then the summarise() function to calculate the mean.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = mean(x),\n    mean_y = mean(y)\n  )\n\n# Compute the standard deviation, the correlation, and the median in the same way. Round the numbers.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = round(mean(x), 2),\n    mean_y = round(mean(y), 2),\n    sd_x = round(sd(x), 2),\n    sd_y = round(sd(y), 2),\n    med_x = round(median(x), 2),\n    med_y = round(median(y), 2),\n    cor = round(cor(x, y), digits = 4)\n  )\n\n# What can you conclude?\n#   --&gt; The standard deviation, the mean, and the correlation are basically the\n#   same for all datasets. The median is different.\n\n# Plot all datasets of ds. Hide the legend. Hint: Use the facet_wrap() and the theme() function.\n\nggplot(ds, aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\n# Create a loop that generates separate scatter plots for each unique datatset of the tibble ds.\n#   Export each graph as a png file.\n\n# Assuming uni_ds is a vector of unique values for the 'dataset' variable\nuni_ds &lt;- unique(ds$dataset)\n\n# Create the 'pic' folder if it doesn't exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\nfor (uni_v in uni_ds) {\n  # Select data for the current value\n  subset_ds &lt;- ds |&gt;\n    filter(dataset == uni_v) |&gt;\n    select(x, y)\n\n  # Make plot\n  graph &lt;- ggplot(subset_ds, aes(x = x, y = y)) +\n    geom_point() +\n    labs(\n      title = paste(\"Dataset:\", uni_v),\n      x = \"X\",\n      y = \"Y\"\n    ) +\n    theme_bw()\n\n  # Save the plot as a PNG file\n  filename &lt;- paste0(\"fig/\", \"plot_ds_\", uni_v, \".png\")\n  ggsave(filename, plot = graph)\n}\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasauRus, tidyverse))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/23-ws/ds_mim/\")\nrm(list = ls())\n\n# Load the packages datasauRus and tidyverse. If necessary, install these packages.\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(datasauRus, tidyverse)\n\n# The packagedatasauRus comes with a dataset in two different formats:\n#   datasaurus_dozen and datasaurus_dozen_wide. Store them as ds and ds_wide.\n\nds &lt;- datasaurus_dozen\nds_wide &lt;- datasaurus_dozen_wide\n\n# Open and read the R vignette of the datasauRus package.\n#   Also open the R documentation of the dataset datasaurus_dozen.\n\n??datasaurus\n\n# Explore the dataset: What are the dimensions of this dataset? Look at the descriptive statistics.\n\nds\n\n# A tibble: 1,846 × 3\n   dataset     x     y\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# ℹ 1,836 more rows\n\ndim(ds)\n\n[1] 1846    3\n\nhead(ds)\n\n# A tibble: 6 × 3\n  dataset     x     y\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 dino     55.4  97.2\n2 dino     51.5  96.0\n3 dino     46.2  94.5\n4 dino     42.8  91.4\n5 dino     40.8  88.3\n6 dino     38.7  84.9\n\nglimpse(ds)\n\nRows: 1,846\nColumns: 3\n$ dataset &lt;chr&gt; \"dino\", \"dino\", \"dino\", \"dino\", \"dino\", \"dino\", \"dino\", \"dino\"…\n$ x       &lt;dbl&gt; 55.3846, 51.5385, 46.1538, 42.8205, 40.7692, 38.7179, 35.6410,…\n$ y       &lt;dbl&gt; 97.1795, 96.0256, 94.4872, 91.4103, 88.3333, 84.8718, 79.8718,…\n\nview(ds)\nsummary(ds)\n\n   dataset                x               y           \n Length:1846        Min.   :15.56   Min.   : 0.01512  \n Class :character   1st Qu.:41.07   1st Qu.:22.56107  \n Mode  :character   Median :52.59   Median :47.59445  \n                    Mean   :54.27   Mean   :47.83510  \n                    3rd Qu.:67.28   3rd Qu.:71.81078  \n                    Max.   :98.29   Max.   :99.69468  \n\n# How many unique values does the variable dataset of the tibble ds have?\n#   Hint: The function unique() return the unique values of a variable and the\n#   function length() returns the length of a vector, such as the unique elements.\n\nunique(ds$dataset)\n\n [1] \"dino\"       \"away\"       \"h_lines\"    \"v_lines\"    \"x_shape\"   \n [6] \"star\"       \"high_lines\" \"dots\"       \"circle\"     \"bullseye\"  \n[11] \"slant_up\"   \"slant_down\" \"wide_lines\"\n\nunique(ds$dataset) |&gt;\n  length()\n\n[1] 13\n\n# Compute the mean values of the x and y variables for each entry in dataset.\n#   Hint: Use the group_by() function to group the data by the appropriate column and\n#   then the summarise() function to calculate the mean.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = mean(x),\n    mean_y = mean(y)\n  )\n\n# A tibble: 13 × 3\n   dataset    mean_x mean_y\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 away         54.3   47.8\n 2 bullseye     54.3   47.8\n 3 circle       54.3   47.8\n 4 dino         54.3   47.8\n 5 dots         54.3   47.8\n 6 h_lines      54.3   47.8\n 7 high_lines   54.3   47.8\n 8 slant_down   54.3   47.8\n 9 slant_up     54.3   47.8\n10 star         54.3   47.8\n11 v_lines      54.3   47.8\n12 wide_lines   54.3   47.8\n13 x_shape      54.3   47.8\n\n# Compute the standard deviation, the correlation, and the median in the same way. Round the numbers.\n\nds |&gt;\n  group_by(dataset) |&gt;\n  summarise(\n    mean_x = round(mean(x), 2),\n    mean_y = round(mean(y), 2),\n    sd_x = round(sd(x), 2),\n    sd_y = round(sd(y), 2),\n    med_x = round(median(x), 2),\n    med_y = round(median(y), 2),\n    cor = round(cor(x, y), digits = 4)\n  )\n\n# A tibble: 13 × 8\n   dataset    mean_x mean_y  sd_x  sd_y med_x med_y     cor\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 away         54.3   47.8  16.8  26.9  53.3  47.5 -0.0641\n 2 bullseye     54.3   47.8  16.8  26.9  53.8  47.4 -0.0686\n 3 circle       54.3   47.8  16.8  26.9  54.0  51.0 -0.0683\n 4 dino         54.3   47.8  16.8  26.9  53.3  46.0 -0.0645\n 5 dots         54.3   47.8  16.8  26.9  51.0  51.3 -0.0603\n 6 h_lines      54.3   47.8  16.8  26.9  53.1  50.5 -0.0617\n 7 high_lines   54.3   47.8  16.8  26.9  54.2  32.5 -0.0685\n 8 slant_down   54.3   47.8  16.8  26.9  53.1  46.4 -0.069 \n 9 slant_up     54.3   47.8  16.8  26.9  54.3  45.3 -0.0686\n10 star         54.3   47.8  16.8  26.9  56.5  50.1 -0.063 \n11 v_lines      54.3   47.8  16.8  26.9  50.4  47.1 -0.0694\n12 wide_lines   54.3   47.8  16.8  26.9  64.6  46.3 -0.0666\n13 x_shape      54.3   47.8  16.8  26.9  47.1  39.9 -0.0656\n\n# What can you conclude?\n#   --&gt; The standard deviation, the mean, and the correlation are basically the\n#   same for all datasets. The median is different.\n\n# Plot all datasets of ds. Hide the legend. Hint: Use the facet_wrap() and the theme() function.\n\nggplot(ds, aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n# Create a loop that generates separate scatter plots for each unique datatset of the tibble ds.\n#   Export each graph as a png file.\n\n# Assuming uni_ds is a vector of unique values for the 'dataset' variable\nuni_ds &lt;- unique(ds$dataset)\n\n# Create the 'pic' folder if it doesn't exist\nif (!dir.exists(\"fig\")) {\n  dir.create(\"fig\")\n}\n\nfor (uni_v in uni_ds) {\n  # Select data for the current value\n  subset_ds &lt;- ds |&gt;\n    filter(dataset == uni_v) |&gt;\n    select(x, y)\n\n  # Make plot\n  graph &lt;- ggplot(subset_ds, aes(x = x, y = y)) +\n    geom_point() +\n    labs(\n      title = paste(\"Dataset:\", uni_v),\n      x = \"X\",\n      y = \"Y\"\n    ) +\n    theme_bw()\n\n  # Save the plot as a PNG file\n  filename &lt;- paste0(\"fig/\", \"plot_ds_\", uni_v, \".png\")\n  ggsave(filename, plot = graph)\n}\n\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\n\n# unload packages\nsuppressMessages(pacman::p_unload(datasauRus, tidyverse))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#convergence",
    "href": "80_exercises.html#convergence",
    "title": "9  Collection of exercises",
    "section": "9.8 Convergence",
    "text": "9.8 Convergence\nThe dataset convergence.dta, see https://github.com/hubchev/courses/blob/main/dta/convergence.dta, contains the per capita GDP of 1960 (gdppc60) and the average growth rate of GDP per capita between 1960 and 1995 (growth) for different countries (country), as well as 3 dummy variables indicating the belonging of a country to the region Asia (asia), Western Europe (weurope) or Africa (africa).\n\nSome countries are not assigned to a certain country group. Name the countries which are assign to be part of Western Europe, Africa or Asia. If you find countries that are members of the EU, assign them a ‘1’ in the variable weurope.\nCreate a table that shows the average GDP per capita for all available points in time. Group by Western European, Asian, African, and the remaining countries.\nCreate the growth rate of GDP per capita from 1960 to 1995 and call it gdpgrowth. (Note: The log value X minus the log value X of the previous period is approximately equal to the growth rate).\nCalculate the unconditional convergence of all countries by constructing a graph in which a scatterplot shows the GDP per capita growth rate between 1960 and 1995 (gdpgrowth) on the y-axis and the 1960 GDP per capita (gdppc60) on the x-axis. Add to the same graph the estimated linear relationship. You do not need to label the graph further, just two things: title the graph world and label the individual observations with the country names.\nCreate three graphs describing the same relationship for the sample of Western European, African and Asian countries. Title the graph accordingly with weurope, africa and asia.\nCombine the four graphs into one image. Discuss how an upward or downward sloping regression line can be interpreted.\nEstimate the relationships illustrated in the 4 graphs using the least squares method. Present the 4 estimation results in a table, indicating the significance level with stars. In addition, the Akaike information criterion, and the number of observations should be displayed in the table. Interpret the four estimation results regarding their significance.\nPut the data set into the so-called long format and calculate the GDP per capita growth rates for the available time points in the countries.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, as.numeric, c, cor, describe, diff, filter, gather, geom_point, geom_text, ggarrange, ggplot, ggtitle, group_by, head, ifelse, lag, list, lm, log, mean, mutate, names, read_dta, select, set_label, starts_with, stat_smooth, stat.desc, str, subset, substr, summarise, summarise_all, summarise_at, summary, tab_model, tail, tbl_summary, vars, view.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Convergence\n\n# set working directory\n# setwd(\"/home/sthu/Dropbox/hsf/github/courses/\")\n\n# clear the environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot, psych\n)\n\n# import data\ndata &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/convergence.dta\")\n\n# inspect data\nnames(data)\nstr(data)\ndata\nhead(data)\ntail(data)\nsummary(data)\nview(data)\n\n# library(vtable)\n# vtable(data, missing=TRUE)\n\n# library(pastecs)\nstat.desc(data)\n\n# library(Hmisc)\ndescribe(data)\n\n# library(gtsummary)\ntbl_summary(data)\n\n# check the assignments of countries to continents\ndata |&gt;\n  select(country, africa, asia, weurope) |&gt;\n  view()\n\ndata &lt;- mutate(data, x_1 = africa + asia + weurope)\n\ndata |&gt;\n  filter(x_1 == 0) |&gt;\n  select(africa, asia, weurope, country) |&gt;\n  view()\n\n# correct the assignment manually\ndata$weurope[data$country == \"Austria\"] &lt;- 1\ndata$weurope[data$country == \"Greece\"] &lt;- 1\ndata$weurope[data$country == \"Cyprus\"] &lt;- 1\n\nfilter(data, data$weurope == 1) # check changes\n\n# In the following, I do the same with a loop\n# c_europe &lt;- c(\"Austria\",\"Greece\",\"Cyprus\")\n# sum(data$weurope)                       # check changes\n# for (i in c_europe){\n#   print(i)\n#   data$weurope[data$country == i] &lt;- 1\n#   }\n# sum(data$weurope)                       # check changes\n# data$weurope[data$country == \"Austria\"] # check changes\n\n# create a category for the remaining countries\n# use ifelse -- ifelse(condition, result if TRUE, result if FALSE)\ndata$rest &lt;- ifelse(data$africa == 0 & data$asia == 0 & data$weurope == 0, 1, 0)\ndata$rest &lt;- set_label(data$rest, label = \"=1 if not in Africa, W.Europe, or Asia\")\n\n# create table with means across country groups\ntable_gdp &lt;- data |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  summarise_at(vars(gdppc60:gdppc95), list(name = mean))\n\ndata |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  select(gdppc60:gdppc95) |&gt;\n  summarise_all(mean)\n\n# create growth rate\ndata$gr1 &lt;- (data$gdppc95 - data$gdppc60) / data$gdppc60\ndata$gr2 &lt;- log(data$gdppc95) - log(data$gdppc60)\ncor(data$gr1, data$gr2)\n\nggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0)\n\np1 &lt;- ggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"World\")\n\np2 &lt;- data |&gt;\n  filter(weurope == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Western Europe\")\n\np3 &lt;- data |&gt;\n  filter(asia == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Asia\")\n\np4 &lt;- data |&gt;\n  filter(africa == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  #  geom_text( hjust=0, vjust=0) +\n  ggtitle(\"Africa\")\n\nggarrange(p1, p2, p3, p4,\n  labels = c(\"A\", \"B\", \"C\", \"D\"),\n  ncol = 2, nrow = 2\n)\n\n# Regression analysis\nm1 &lt;- lm(growth ~ gdppc60, data = data)\nm2 &lt;- lm(growth ~ gdppc60, data = subset(data, weurope == 1))\nm3 &lt;- lm(growth ~ gdppc60, data = subset(data, asia == 1))\nm4 &lt;- lm(growth ~ gdppc60, data = subset(data, africa == 1))\n\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE,\n  show.aic = TRUE,\n  dv.labels = c(\"World\", \"W.Europe\", \"Asia\", \"Africa\")\n)\n\n# reshape data (see: https://stackoverflow.com/questions/2185252/reshaping-data-frame-from-wide-to-long-format)\ndata_long &lt;- gather(data, condition, measurement, gdppc60:gdppc95, factor_key = TRUE)\ndata_long$year &lt;- as.numeric(substr(data_long$condition, 6, 7))\n\ndata_long$gr_long &lt;- data_long |&gt;\n  select(country, measurement) |&gt;\n  group_by(country) |&gt;\n  mutate(gr = c(NA, diff(measurement)) / lag(measurement, 1))\n\n# erase all helping variables\ndata &lt;- select(data, -starts_with(\"h_\"))\n\n# generate and remove variables in a dataframe\ndata &lt;- mutate(data, Land = country)\ndata &lt;- select(data, -country)\n\ndata |&gt;\n  summarise(\n    y65 = mean(gdppc65, na.rm = TRUE),\n    y70 = mean(gdppc70, na.rm = TRUE),\n    y75 = mean(gdppc75, na.rm = TRUE),\n    y80 = mean(gdppc80, na.rm = TRUE),\n    y85 = mean(gdppc85, na.rm = TRUE),\n    y90 = mean(gdppc90, na.rm = TRUE),\n    y95 = mean(gdppc95, na.rm = TRUE)\n  )\n\nsuppressMessages(pacman::p_unload(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot\n))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Convergence\n\n# set working directory\n# setwd(\"/home/sthu/Dropbox/hsf/github/courses/\")\n\n# clear the environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot, psych\n)\n\n# import data\ndata &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/convergence.dta\")\n\n# inspect data\nnames(data)\n\n [1] \"country\" \"gdppc60\" \"gdppc65\" \"gdppc70\" \"gdppc75\" \"gdppc80\" \"gdppc85\"\n [8] \"gdppc90\" \"gdppc95\" \"africa\"  \"asia\"    \"weurope\" \"growth\" \n\nstr(data)\n\ntibble [107 × 13] (S3: tbl_df/tbl/data.frame)\n $ country: chr [1:107] \"Algeria\" \"Angola\" \"Argentina\" \"Australia\" ...\n  ..- attr(*, \"format.stata\")= chr \"%24s\"\n $ gdppc60: num [1:107] 2848 2642 7879 11436 7842 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1960\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc65: num [1:107] 3536 3072 8802 13192 9387 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1965\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc70: num [1:107] 3670 3558 9903 15842 11946 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1970\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc75: num [1:107] 3917 2230 10609 16716 14198 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1975\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc80: num [1:107] 5094 2059 11359 18300 16869 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1980\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc85: num [1:107] 5876 1988 9246 19669 17919 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1985\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc90: num [1:107] 5307 2081 7716 21446 21178 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1990\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ gdppc95: num [1:107] 4935 1339 10973 23827 22474 ...\n  ..- attr(*, \"label\")= chr \"real gdp per capita 1995\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ africa : num [1:107] 1 1 0 0 0 0 0 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"=1 if in Africa\"\n  ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n $ asia   : num [1:107] 0 0 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"=1 if in Asia\"\n  ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n $ weurope: num [1:107] 0 0 0 0 0 0 0 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"=1 if in Western Europe\"\n  ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n $ growth : num [1:107] 0.55 -0.68 0.331 0.734 1.053 ...\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n\ndata\n\n# A tibble: 107 × 13\n   country    gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95\n   &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Algeria      2848.   3536.   3670.   3917.   5094.   5876.   5307.   4935.\n 2 Angola       2642.   3072.   3558.   2230.   2059.   1988.   2081.   1339.\n 3 Argentina    7879.   8802.   9903.  10609.  11359.   9246.   7716.  10973.\n 4 Australia   11436.  13192.  15842.  16716.  18300.  19669.  21446.  23827.\n 5 Austria      7842.   9387.  11946.  14198.  16869.  17919.  21178.  22474.\n 6 Bangladesh   1130.   1164.   1181.   1030.   1040.   1245.   1366.   1568.\n 7 Barbados     3632.   4632.   6456.   8827.  10911.  11090.  14411.  14636.\n 8 Belgium      8314.  10454.  12980.  15024.  17451.  18109.  21246.  22356.\n 9 Benin        1140.   1188.   1170.   1048.   1069.   1252.   1069.   1139.\n10 Bolivia      2516.   2880.   2670.   3124.   3264.   2718.   2615.   2795.\n# ℹ 97 more rows\n# ℹ 4 more variables: africa &lt;dbl&gt;, asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;\n\nhead(data)\n\n# A tibble: 6 × 13\n  country gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95 africa\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Algeria   2848.   3536.   3670.   3917.   5094.   5876.   5307.   4935.      1\n2 Angola    2642.   3072.   3558.   2230.   2059.   1988.   2081.   1339.      1\n3 Argent…   7879.   8802.   9903.  10609.  11359.   9246.   7716.  10973.      0\n4 Austra…  11436.  13192.  15842.  16716.  18300.  19669.  21446.  23827.      0\n5 Austria   7842.   9387.  11946.  14198.  16869.  17919.  21178.  22474.      0\n6 Bangla…   1130.   1164.   1181.   1030.   1040.   1245.   1366.   1568.      0\n# ℹ 3 more variables: asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;\n\ntail(data)\n\n# A tibble: 6 × 13\n  country gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95 africa\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 United…  10341.  11633.  12917.  14072.  15302.  16878.  19585.  20963.      0\n2 United…  13118.  15697.  17478.  19284.  22806.  25251.  28281.  30366.      0\n3 Uruguay   6279.   5936.   6553.   6949.   8580.   6625.   7763.   9399.      0\n4 Venezu…   8381.  10618.  11253.   8815.   8516.   7274.   7431.   7582.      0\n5 Zambia    1290.   1564.   1427.   1446.   1324.   1167.   1091.    870.      1\n6 Zimbab…   1317.   1539.   2303.   2694.   2816.   2923.   3115.   2832.      1\n# ℹ 3 more variables: asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;\n\nsummary(data)\n\n   country             gdppc60           gdppc65           gdppc70       \n Length:107         Min.   :  407.8   Min.   :  513.6   Min.   :  354.5  \n Class :character   1st Qu.: 1153.2   1st Qu.: 1364.5   1st Qu.: 1488.0  \n Mode  :character   Median : 2484.7   Median : 2884.4   Median : 3072.2  \n                    Mean   : 3634.3   Mean   : 4367.5   Mean   : 5128.4  \n                    3rd Qu.: 4354.0   3rd Qu.: 5873.3   3rd Qu.: 6994.6  \n                    Max.   :16010.3   Max.   :18928.9   Max.   :22030.9  \n    gdppc75           gdppc80           gdppc85           gdppc90       \n Min.   :  617.9   Min.   :  473.6   Min.   :  542.3   Min.   :  527.7  \n 1st Qu.: 1480.7   1st Qu.: 1708.6   1st Qu.: 1598.8   1st Qu.: 1829.0  \n Median : 3741.7   Median : 4306.2   Median : 4200.7   Median : 4034.0  \n Mean   : 5759.1   Mean   : 6553.6   Mean   : 6900.3   Mean   : 7775.1  \n 3rd Qu.: 8355.8   3rd Qu.: 9968.6   3rd Qu.:10037.2   3rd Qu.:11716.2  \n Max.   :21808.9   Max.   :23860.1   Max.   :25251.4   Max.   :28744.1  \n    gdppc95            africa            asia           weurope      \n Min.   :  499.3   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.: 1673.7   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median : 4467.9   Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   : 8468.2   Mean   :0.3738   Mean   :0.1308   Mean   :0.1402  \n 3rd Qu.:13627.8   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000  \n Max.   :36741.1   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n     growth       \n Min.   :-0.6888  \n 1st Qu.: 0.2458  \n Median : 0.6587  \n Mean   : 0.6345  \n 3rd Qu.: 1.0505  \n Max.   : 2.3493  \n\nview(data)\n\n# library(vtable)\n# vtable(data, missing=TRUE)\n\n# library(pastecs)\nstat.desc(data)\n\n         country      gdppc60      gdppc65      gdppc70      gdppc75\nnbr.val       NA 1.070000e+02 1.070000e+02 1.070000e+02 1.070000e+02\nnbr.null      NA 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\nnbr.na        NA 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\nmin           NA 4.078180e+02 5.135667e+02 3.545075e+02 6.178639e+02\nmax           NA 1.601025e+04 1.892888e+04 2.203095e+04 2.180892e+04\nrange         NA 1.560243e+04 1.841531e+04 2.167644e+04 2.119105e+04\nsum           NA 3.888715e+05 4.673224e+05 5.487424e+05 6.162241e+05\nmedian        NA 2.484720e+03 2.884388e+03 3.072176e+03 3.741725e+03\nmean          NA 3.634313e+03 4.367500e+03 5.128433e+03 5.759103e+03\nSE.mean       NA 3.314566e+02 4.021934e+02 4.736475e+02 5.272377e+02\nCI.mean       NA 6.571449e+02 7.973875e+02 9.390523e+02 1.045300e+03\nvar           NA 1.175539e+07 1.730827e+07 2.400459e+07 2.974381e+07\nstd.dev       NA 3.428613e+03 4.160321e+03 4.899448e+03 5.453789e+03\ncoef.var      NA 9.434006e-01 9.525635e-01 9.553499e-01 9.469857e-01\n              gdppc80      gdppc85      gdppc90      gdppc95       africa\nnbr.val  1.070000e+02 1.070000e+02 1.070000e+02 1.070000e+02 107.00000000\nnbr.null 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00  67.00000000\nnbr.na   0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00   0.00000000\nmin      4.735793e+02 5.422725e+02 5.277151e+02 4.993415e+02   0.00000000\nmax      2.386009e+04 2.525136e+04 2.874414e+04 3.674105e+04   1.00000000\nrange    2.338651e+04 2.470909e+04 2.821642e+04 3.624171e+04   1.00000000\nsum      7.012400e+05 7.383373e+05 8.319308e+05 9.061030e+05  40.00000000\nmedian   4.306217e+03 4.200733e+03 4.034010e+03 4.467940e+03   0.00000000\nmean     6.553645e+03 6.900349e+03 7.775054e+03 8.468253e+03   0.37383178\nSE.mean  6.018749e+02 6.552251e+02 7.711596e+02 8.456513e+02   0.04699273\nCI.mean  1.193276e+03 1.299048e+03 1.528899e+03 1.676586e+03   0.09316766\nvar      3.876112e+07 4.593724e+07 6.363152e+07 7.651850e+07   0.23628990\nstd.dev  6.225843e+03 6.777701e+03 7.976937e+03 8.747486e+03   0.48609659\ncoef.var 9.499817e-01 9.822259e-01 1.025965e+00 1.032974e+00   1.30030838\n                 asia      weurope      growth\nnbr.val  107.00000000 107.00000000 107.0000000\nnbr.null  93.00000000  92.00000000   0.0000000\nnbr.na     0.00000000   0.00000000   0.0000000\nmin        0.00000000   0.00000000  -0.6887722\nmax        1.00000000   1.00000000   2.3493433\nrange      1.00000000   1.00000000   3.0381155\nsum       14.00000000  15.00000000  67.8899760\nmedian     0.00000000   0.00000000   0.6586871\nmean       0.13084112   0.14018692   0.6344858\nSE.mean    0.03275433   0.03372119   0.0601857\nCI.mean    0.06493865   0.06685553   0.1193240\nvar        0.11479457   0.12167166   0.3875881\nstd.dev    0.33881347   0.34881465   0.6225657\ncoef.var   2.58950297   2.48821120   0.9812131\n\n# library(Hmisc)\ndescribe(data)\n\n         vars   n    mean      sd  median trimmed     mad    min      max\ncountry*    1 107   54.00   31.03   54.00   54.00   40.03   1.00   107.00\ngdppc60     2 107 3634.31 3428.61 2484.72 3032.19 2027.76 407.82 16010.25\ngdppc65     3 107 4367.50 4160.32 2884.39 3673.42 2579.50 513.57 18928.88\ngdppc70     4 107 5128.43 4899.45 3072.18 4370.29 2854.11 354.51 22030.95\ngdppc75     5 107 5759.10 5453.79 3741.72 4977.54 3708.25 617.86 21808.92\ngdppc80     6 107 6553.64 6225.84 4306.22 5707.40 4476.29 473.58 23860.09\ngdppc85     7 107 6900.35 6777.70 4200.73 5929.46 4382.44 542.27 25251.36\ngdppc90     8 107 7775.05 7976.94 4034.01 6660.00 4258.37 527.72 28744.14\ngdppc95     9 107 8468.25 8747.49 4467.94 7235.12 4935.09 499.34 36741.05\nafrica     10 107    0.37    0.49    0.00    0.34    0.00   0.00     1.00\nasia       11 107    0.13    0.34    0.00    0.05    0.00   0.00     1.00\nweurope    12 107    0.14    0.35    0.00    0.06    0.00   0.00     1.00\ngrowth     13 107    0.63    0.62    0.66    0.63    0.59  -0.69     2.35\n            range skew kurtosis     se\ncountry*   106.00 0.00    -1.23   3.00\ngdppc60  15602.43 1.53     1.55 331.46\ngdppc65  18415.31 1.41     1.16 402.19\ngdppc70  21676.44 1.29     0.74 473.65\ngdppc75  21191.05 1.15     0.09 527.24\ngdppc80  23386.51 1.07    -0.11 601.87\ngdppc85  24709.09 1.14     0.01 655.23\ngdppc90  28216.42 1.13    -0.10 771.16\ngdppc95  36241.71 1.14     0.12 845.65\nafrica       1.00 0.51    -1.75   0.05\nasia         1.00 2.16     2.69   0.03\nweurope      1.00 2.04     2.20   0.03\ngrowth       3.04 0.15     0.07   0.06\n\n# library(gtsummary)\ntbl_summary(data)\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1071\n\n\n\n\ncountry\n\n\n\n\n    Algeria\n1 (0.9%)\n\n\n    Angola\n1 (0.9%)\n\n\n    Argentina\n1 (0.9%)\n\n\n    Australia\n1 (0.9%)\n\n\n    Austria\n1 (0.9%)\n\n\n    Bangladesh\n1 (0.9%)\n\n\n    Barbados\n1 (0.9%)\n\n\n    Belgium\n1 (0.9%)\n\n\n    Benin\n1 (0.9%)\n\n\n    Bolivia\n1 (0.9%)\n\n\n    Botswana\n1 (0.9%)\n\n\n    Brazil\n1 (0.9%)\n\n\n    Burkina Faso\n1 (0.9%)\n\n\n    Burundi\n1 (0.9%)\n\n\n    Cameroon\n1 (0.9%)\n\n\n    Canada\n1 (0.9%)\n\n\n    Cape Verde\n1 (0.9%)\n\n\n    Central African Republic\n1 (0.9%)\n\n\n    Chad\n1 (0.9%)\n\n\n    Chile\n1 (0.9%)\n\n\n    China\n1 (0.9%)\n\n\n    Colombia\n1 (0.9%)\n\n\n    Comoros\n1 (0.9%)\n\n\n    Congo, Republic of\n1 (0.9%)\n\n\n    Costa Rica\n1 (0.9%)\n\n\n    Cote d'lvoire\n1 (0.9%)\n\n\n    Cyprus\n1 (0.9%)\n\n\n    Denmark\n1 (0.9%)\n\n\n    Dominican Republic\n1 (0.9%)\n\n\n    Ecuador\n1 (0.9%)\n\n\n    Egypt\n1 (0.9%)\n\n\n    El Salvador\n1 (0.9%)\n\n\n    Ethiopia\n1 (0.9%)\n\n\n    Fiji\n1 (0.9%)\n\n\n    Finland\n1 (0.9%)\n\n\n    France\n1 (0.9%)\n\n\n    Gabon\n1 (0.9%)\n\n\n    Gambia, The\n1 (0.9%)\n\n\n    Ghana\n1 (0.9%)\n\n\n    Greece\n1 (0.9%)\n\n\n    Guatemala\n1 (0.9%)\n\n\n    Guinea\n1 (0.9%)\n\n\n    Guinea-Bissau\n1 (0.9%)\n\n\n    Guyana\n1 (0.9%)\n\n\n    Honduras\n1 (0.9%)\n\n\n    Hong Kong\n1 (0.9%)\n\n\n    Iceland\n1 (0.9%)\n\n\n    India\n1 (0.9%)\n\n\n    Indonesia\n1 (0.9%)\n\n\n    Iran\n1 (0.9%)\n\n\n    Ireland\n1 (0.9%)\n\n\n    Israel\n1 (0.9%)\n\n\n    Italy\n1 (0.9%)\n\n\n    Jamaica\n1 (0.9%)\n\n\n    Japan\n1 (0.9%)\n\n\n    Jordan\n1 (0.9%)\n\n\n    Kenya\n1 (0.9%)\n\n\n    Lesotho\n1 (0.9%)\n\n\n    Luxembourg\n1 (0.9%)\n\n\n    Madagascar\n1 (0.9%)\n\n\n    Malawi\n1 (0.9%)\n\n\n    Malaysia\n1 (0.9%)\n\n\n    Mali\n1 (0.9%)\n\n\n    Mauritania\n1 (0.9%)\n\n\n    Mauritius\n1 (0.9%)\n\n\n    Mexico\n1 (0.9%)\n\n\n    Morocco\n1 (0.9%)\n\n\n    Mozambique\n1 (0.9%)\n\n\n    Namibia\n1 (0.9%)\n\n\n    Nepal\n1 (0.9%)\n\n\n    Netherlands\n1 (0.9%)\n\n\n    New Zealand\n1 (0.9%)\n\n\n    Nicaragua\n1 (0.9%)\n\n\n    Niger\n1 (0.9%)\n\n\n    Nigeria\n1 (0.9%)\n\n\n    Norway\n1 (0.9%)\n\n\n    Pakistan\n1 (0.9%)\n\n\n    Panama\n1 (0.9%)\n\n\n    Papua New Guinea\n1 (0.9%)\n\n\n    Paraguay\n1 (0.9%)\n\n\n    Peru\n1 (0.9%)\n\n\n    Philippines\n1 (0.9%)\n\n\n    Portugal\n1 (0.9%)\n\n\n    Romania\n1 (0.9%)\n\n\n    Rwanda\n1 (0.9%)\n\n\n    Senegal\n1 (0.9%)\n\n\n    Seychelles\n1 (0.9%)\n\n\n    Singapore\n1 (0.9%)\n\n\n    South Africa\n1 (0.9%)\n\n\n    South Korea\n1 (0.9%)\n\n\n    Spain\n1 (0.9%)\n\n\n    Sri Lanka\n1 (0.9%)\n\n\n    Sweden\n1 (0.9%)\n\n\n    Switzerland\n1 (0.9%)\n\n\n    Syria\n1 (0.9%)\n\n\n    Tanzania\n1 (0.9%)\n\n\n    Thailand\n1 (0.9%)\n\n\n    Togo\n1 (0.9%)\n\n\n    Trinidad & Tobago\n1 (0.9%)\n\n\n    Turkey\n1 (0.9%)\n\n\n    Uganda\n1 (0.9%)\n\n\n    United Kingdom\n1 (0.9%)\n\n\n    United States of America\n1 (0.9%)\n\n\n    Uruguay\n1 (0.9%)\n\n\n    Venezuela\n1 (0.9%)\n\n\n    Zambia\n1 (0.9%)\n\n\n    Zimbabwe\n1 (0.9%)\n\n\nreal gdp per capita 1960\n2,485 (1,153, 4,354)\n\n\nreal gdp per capita 1965\n2,884 (1,365, 5,873)\n\n\nreal gdp per capita 1970\n3,072 (1,488, 6,995)\n\n\nreal gdp per capita 1975\n3,742 (1,481, 8,356)\n\n\nreal gdp per capita 1980\n4,306 (1,709, 9,969)\n\n\nreal gdp per capita 1985\n4,201 (1,599, 10,037)\n\n\nreal gdp per capita 1990\n4,034 (1,829, 11,716)\n\n\nreal gdp per capita 1995\n4,468 (1,674, 13,628)\n\n\n=1 if in Africa\n40 (37%)\n\n\n=1 if in Asia\n14 (13%)\n\n\n=1 if in Western Europe\n15 (14%)\n\n\ngrowth\n0.66 (0.25, 1.05)\n\n\n\n1 n (%); Median (IQR)\n\n\n\n\n\n\n\n\n# check the assignments of countries to continents\ndata |&gt;\n  select(country, africa, asia, weurope) |&gt;\n  view()\n\ndata &lt;- mutate(data, x_1 = africa + asia + weurope)\n\ndata |&gt;\n  filter(x_1 == 0) |&gt;\n  select(africa, asia, weurope, country) |&gt;\n  view()\n\n# correct the assignment manually\ndata$weurope[data$country == \"Austria\"] &lt;- 1\ndata$weurope[data$country == \"Greece\"] &lt;- 1\ndata$weurope[data$country == \"Cyprus\"] &lt;- 1\n\nfilter(data, data$weurope == 1) # check changes\n\n# A tibble: 18 × 14\n   country       gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90 gdppc95\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Austria         7842.   9387.  11946.  14198.  16869.  17919.  21178.  22474.\n 2 Belgium         8314.  10454.  12980.  15024.  17451.  18109.  21246.  22356.\n 3 Cyprus          3178.   4261.   5638.   4827.   8302.  10228.  13798.  17169.\n 4 Denmark        11745.  14749.  17143.  17750.  19558.  21596.  23308.  25293.\n 5 Finland         8007.   9851.  12198.  14884.  16621.  18585.  21667.  20084.\n 6 France          8364.  10497.  13186.  14951.  17335.  18429.  21403.  21502.\n 7 Greece          4454.   6549.   9022.  11121.  12672.  12287.  12794.  13332.\n 8 Iceland         8786.  11403.  11678.  15235.  19440.  20414.  22502.  21901.\n 9 Ireland         5490.   6413.   7760.   9064.  10649.  11641.  15133.  18456.\n10 Italy           7364.   9097.  12072.  13386.  16286.  17518.  20638.  21691.\n11 Luxembourg     12510.  14019.  16163.  17384.  19089.  21414.  28744.  36741.\n12 Netherlands     9883.  11702.  14237.  15803.  17339.  17974.  20823.  22320.\n13 Norway          8808.  10478.  11959.  14873.  17977.  20630.  21855.  25538.\n14 Portugal        3665.   4866.   6730.   7951.   9667.   9847.  13155.  13924.\n15 Spain           4956.   7459.   9701.  11970.  12294.  12583.  15475.  17434.\n16 Sweden         10870.  13552.  15850.  17588.  18348.  20001.  22219.  22122.\n17 Switzerland    16010.  18929.  22031.  21809.  23860.  24844.  27931.  26227.\n18 United Kingd…  10341.  11633.  12917.  14072.  15302.  16878.  19585.  20963.\n# ℹ 5 more variables: africa &lt;dbl&gt;, asia &lt;dbl&gt;, weurope &lt;dbl&gt;, growth &lt;dbl&gt;,\n#   x_1 &lt;dbl&gt;\n\n# In the following, I do the same with a loop\n# c_europe &lt;- c(\"Austria\",\"Greece\",\"Cyprus\")\n# sum(data$weurope)                       # check changes\n# for (i in c_europe){\n#   print(i)\n#   data$weurope[data$country == i] &lt;- 1\n#   }\n# sum(data$weurope)                       # check changes\n# data$weurope[data$country == \"Austria\"] # check changes\n\n# create a category for the remaining countries\n# use ifelse -- ifelse(condition, result if TRUE, result if FALSE)\ndata$rest &lt;- ifelse(data$africa == 0 & data$asia == 0 & data$weurope == 0, 1, 0)\ndata$rest &lt;- set_label(data$rest, label = \"=1 if not in Africa, W.Europe, or Asia\")\n\n# create table with means across country groups\ntable_gdp &lt;- data |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  summarise_at(vars(gdppc60:gdppc95), list(name = mean))\n\ndata |&gt;\n  group_by(africa, asia, weurope) |&gt;\n  select(gdppc60:gdppc95) |&gt;\n  summarise_all(mean)\n\nAdding missing grouping variables: `africa`, `asia`, `weurope`\n\n\n# A tibble: 4 × 11\n# Groups:   africa, asia [3]\n  africa  asia weurope gdppc60 gdppc65 gdppc70 gdppc75 gdppc80 gdppc85 gdppc90\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1      0     0       0   4288.   5034.   5727.   6411.   7042.   7185.   7457.\n2      0     0       1   8366.  10294.  12401.  13994.  16059.  17272.  20192.\n3      0     1       0   1739.   2247.   3090.   3760.   4905.   5761.   7501.\n4      1     0       0   1596.   1860.   2046.   2182.   2426.   2382.   2562.\n# ℹ 1 more variable: gdppc95 &lt;dbl&gt;\n\n# create growth rate\ndata$gr1 &lt;- (data$gdppc95 - data$gdppc60) / data$gdppc60\ndata$gr2 &lt;- log(data$gdppc95) - log(data$gdppc60)\ncor(data$gr1, data$gr2)\n\n[1] 0.9008887\n\nggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0)\n\n\n\n\n\n\n\np1 &lt;- ggplot(data, aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"World\")\n\np2 &lt;- data |&gt;\n  filter(weurope == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Western Europe\")\n\np3 &lt;- data |&gt;\n  filter(asia == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  # geom_text(hjust=0, vjust=0) +\n  ggtitle(\"Asia\")\n\np4 &lt;- data |&gt;\n  filter(africa == 1) |&gt;\n  ggplot(aes(x = gdppc60, y = growth, label = country)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1) +\n  #  geom_text( hjust=0, vjust=0) +\n  ggtitle(\"Africa\")\n\nggarrange(p1, p2, p3, p4,\n  labels = c(\"A\", \"B\", \"C\", \"D\"),\n  ncol = 2, nrow = 2\n)\n\nWarning: The following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n# Regression analysis\nm1 &lt;- lm(growth ~ gdppc60, data = data)\nm2 &lt;- lm(growth ~ gdppc60, data = subset(data, weurope == 1))\nm3 &lt;- lm(growth ~ gdppc60, data = subset(data, asia == 1))\nm4 &lt;- lm(growth ~ gdppc60, data = subset(data, africa == 1))\n\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE,\n  show.aic = TRUE,\n  dv.labels = c(\"World\", \"W.Europe\", \"Asia\", \"Africa\")\n)\n\n\n\n\n\n \nWorld\nW.Europe\nAsia\nAfrica\n\n\nPredictors\nEstimates\nEstimates\nEstimates\nEstimates\n\n\n(Intercept)\n0.54 ***\n1.59 ***\n0.91 ***\n0.20 \n\n\nreal gdp per capita 1960\n0.00 *\n-0.00 ***\n0.00 *\n0.00 \n\n\nObservations\n107\n18\n14\n40\n\n\nR2 / R2 adjusted\n0.021 / 0.012\n0.727 / 0.710\n0.158 / 0.088\n0.002 / -0.024\n\n\nAIC\n204.917\n-14.237\n31.220\n76.318\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n# reshape data (see: https://stackoverflow.com/questions/2185252/reshaping-data-frame-from-wide-to-long-format)\ndata_long &lt;- gather(data, condition, measurement, gdppc60:gdppc95, factor_key = TRUE)\n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\ndata_long$year &lt;- as.numeric(substr(data_long$condition, 6, 7))\n\ndata_long$gr_long &lt;- data_long |&gt;\n  select(country, measurement) |&gt;\n  group_by(country) |&gt;\n  mutate(gr = c(NA, diff(measurement)) / lag(measurement, 1))\n\n# erase all helping variables\ndata &lt;- select(data, -starts_with(\"h_\"))\n\n# generate and remove variables in a dataframe\ndata &lt;- mutate(data, Land = country)\ndata &lt;- select(data, -country)\n\ndata |&gt;\n  summarise(\n    y65 = mean(gdppc65, na.rm = TRUE),\n    y70 = mean(gdppc70, na.rm = TRUE),\n    y75 = mean(gdppc75, na.rm = TRUE),\n    y80 = mean(gdppc80, na.rm = TRUE),\n    y85 = mean(gdppc85, na.rm = TRUE),\n    y90 = mean(gdppc90, na.rm = TRUE),\n    y95 = mean(gdppc95, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 7\n    y65   y70   y75   y80   y85   y90   y95\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 4367. 5128. 5759. 6554. 6900. 7775. 8468.\n\nsuppressMessages(pacman::p_unload(\n  haven, tidyverse, vtable, gtsummary, pastecs, Hmisc,\n  sjlabelled, tis, ggpubr, sjPlot\n))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#unemployment-and-gdp-in-germany-and-france",
    "href": "80_exercises.html#unemployment-and-gdp-in-germany-and-france",
    "title": "9  Collection of exercises",
    "section": "9.9 Unemployment and GDP in Germany and France",
    "text": "9.9 Unemployment and GDP in Germany and France\nThe following exercise was a former exam.\nPlease answer all (!) questions in an R script. Normal text should be written as comments, using the ‘#’ to comment out text. Make sure the script runs without errors before submitting it. Each task (starting with 1) is worth five points. You have a total of 120 minutes of editing time. Please do not forget to number your answers.\nWhen you are done with your work, save the R script, export the script to pdf format and upload the pdf file.\nSuppose you aim to empirically examine unemployment and GDP for Germany and France. The data set that we use in the following is ‘forest.Rdata’.\n\nWrite down your name, matriculation number, and date.\nSet your working directory.\n\n\nClear your global environment.\n\n\nInstall and load the following packages: ‘tidyverse’, ‘sjPlot’, and ‘ggpubr’\n\n\nDownload and load the data, respectively, with the following code:\n\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nIf that is not working, you can also download the data from ILIAS, save it in your working directory and load it from there with:\n\n# load(\"forest.Rdata\")\n\n\nShow the first eight observations of the dataset df.\nShow the last observation of the dataset df.\nWhich type of data do we have here (Panel, cross-section,time series, …)? Name the variable(s) that are necessary to identify the observations in the dataset.\nExplain what the assignment operator in R is and what it is good for.\nWrite down the R code to store the number of observations and the number of variables that are in the dataset df. Name the object in which you store these numbers ‘observations_df’.\nIn the dataset df, rename the variable ‘country.x’ to ‘nation’ and the variable ‘date’ to ‘year’.\nExplain what the pipe operator in R is and what it is good for.\nFor the upcoming analysis you are only interested the following variables that are part of the dataframe df: nation, year, gdp, pop, gdppc, and unemployment. Drop all other variables from the dataframe df.\nCreate a variable that indicates the GDP per capita (‘gdp’ divided by ‘pop’). Name the variable ‘gdp_pc’. (Hint: If you fail here, use the variable ‘gdppc’ which is already in the dataset as a replacement for ‘gdp_pc’ in the following tasks.)\nFor the upcoming analysis you are only interested the following countries that are part of the dataframe df: Germany and France. Drop all other countries from the dataframe df.\nCreate a table showing the average unemployment rate and GDP per capita for Germany and France in the given years. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\n\n\nCreate a table showing the unemployment rate and GDP per capita for Germany and France in the year 2020. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\n\n\nCreate a table showing the highest unemployment rate and the highest GDP per capita for Germany and France during the given period. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\n\n\nCalculate the standard deviation of the unemployment rate and GDP per capita for Germany and France in the given years. (Hint: See below for how your result should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\n\n\nIn statistics, the coefficient of variation (COV) is a standardized measure of dispersion. It is defined as the ratio of the standard deviation (\\(\\sigma\\)) to the mean (\\(\\mu\\)): \\(COV={\\frac {\\sigma }{\\mu }}\\). Write down the R code to calculate the coefficient of variation (COV) for the unemployment rate in Germany and France. (Hint: See below for what your result should should look like.)\n\n\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\n\n\nWrite down the R code to calculate the coefficient of variation (COV) for the GDP per capita in Germany and France. (Hint: See below for what your result should look like.)\n\n\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\n\n\nCreate a chart (bar chart, line chart, or scatter plot) that shows the unemployment rate of Germany over the available years. Label the chart ‘Germany’ with ‘ggtitle(“Germany”)’. Please note that you may choose any type of graphical representation. (Hint: Below you can see one of many |&gt; of what your result may look like).\n\n\n\n\n\n\n\n\n\n\n\nand 23. (This task is worth 10 points) The following chart shows the simultaneous development of the unemployment rate and GDP per capita over time for France.\n\n\n\n\n\n\n\n\n\n\nSuppose you want to visualize the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany as well.\nSuppose further that you have found the following lines of code that create the kind of chart you are looking for.\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\n\nUse these lines of code and customize them to create the co-movement visualization for Germany using the available df data. The result should look something like this:\n\n\n\n\n\n\n\n\n\n\nInterpret the two graphs above, which show the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany and France. What are your expectations regarding the correlation between the unemployment rate and GDP per capita variables? Can you see this expectation in the figures? Discuss.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, dim, filter, geom_line, ggplot, ggtitle, group_by, head, load, max, mean, mutate, plot, rename, sd, select, summarise, tail, text, title, url.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\ntail(df, 1)\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\ndf |&gt;\n  filter(nation == \"Germany\") |&gt;\n  ggplot(aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\n# rmarkdown::render(\"22-11_dsda_exam.Rmd\", \"all\")\n\n# knitr::purl(input = \"22-11_dsda_exam.Rmd\", output = \"22-11_dsda_solution.R\",documentation = 0)\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\n# A tibble: 8 × 11\n# Groups:   country.x [1]\n  country.x     date     gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 United Arab…  1992 1.26e11     -2.48          1.84 Middl… High …   3.63 2.05e6\n2 United Arab…  1993 1.27e11     -4.34          1.85 Middl… High …   3.72 2.17e6\n3 United Arab…  1994 1.36e11      1.25          1.81 Middl… High …   3.81 2.29e6\n4 United Arab…  1995 1.45e11      1.35          1.80 Middl… High …   3.90 2.42e6\n5 United Arab…  1996 1.54e11      0.631         1.90 Middl… High …   3.99 2.54e6\n6 United Arab…  1997 1.66e11      2.83          1.98 Middl… High …   4.08 2.67e6\n7 United Arab…  1998 1.67e11     -4.77          2.14 Middl… High …   4.18 2.81e6\n8 United Arab…  1999 1.72e11     -2.40          2.22 Middl… High …   4.27 2.97e6\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\ntail(df, 1)\n\n# A tibble: 1 × 11\n# Groups:   country.x [1]\n  country.x  date        gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Zimbabwe   2020    1.94e10      -7.62         5.35 Sub-S… Lower…   45.1 1.49e7\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\ndf |&gt;\n  filter(nation == \"Germany\") |&gt;\n  ggplot(aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\n\n\n\n\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n\n\n\n\n\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\n\n\n\n\n\n\n# rmarkdown::render(\"22-11_dsda_exam.Rmd\", \"all\")\n\n# knitr::purl(input = \"22-11_dsda_exam.Rmd\", output = \"22-11_dsda_solution.R\",documentation = 0)\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#import-data-and-write-a-report",
    "href": "80_exercises.html#import-data-and-write-a-report",
    "title": "9  Collection of exercises",
    "section": "9.10 Import data and write a report",
    "text": "9.10 Import data and write a report\nReproduce Figure 3 of Hortaçsu & Syverson (2015, p. 99) using R. Write a clear report about your work, i.e., document everything with a R script or a R Markdown file.\nHere are the required steps:\n\nGo to https://www.aeaweb.org/articles?id=10.1257/jep.29.4.89 and download the replication package from the OPENICPSR page. Please note, that you can download the replication package after you have registered for the platform.\nUnzip the replication package.\nIn the file diffusion_curves_figure.xlsx you find the required data. Import them to R.\nReproduce the plot using ggplot().\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, download.file, geom_line, ggplot, pivot_longer, read_excel, unzip.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# setwd(\"~/Dropbox/hsf/courses/Rlang/hortacsu\")\n\nrm(list = ls())\n\n\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, readxl)\n\n\n# Define the URL of the ZIP file\nzipF &lt;- \"https://github.com/hubchev/courses/raw/main/dta/113962-V1.zip\"\n\n# Download the ZIP file\ndownload.file(zipF, destfile = \"113962-V1.zip\")\n\n# Unzip the contents\nunzip(\"113962-V1.zip\")\n\ndf_curves &lt;- read_excel(\"Hortacsu_Syverson_JEP_Retail/diffusion_curves_figure.xlsx\",\n  sheet = \"Data and Predictions\", range = \"N3:Y60\"\n)\n\ndf &lt;- df_curves |&gt;\n  pivot_longer(\n    cols = \"Music and Video\":\"Food and Beverages\",\n    names_to = \"industry\",\n    values_to = \"value\"\n  )\n\n# Plot\ndf |&gt;\n  ggplot(aes(x = Year, y = value, group = industry, color = industry)) +\n  geom_line()\n\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, readxl))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"~/Dropbox/hsf/courses/Rlang/hortacsu\")\n\nrm(list = ls())\n\n\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, readxl)\n\n\n# Define the URL of the ZIP file\nzipF &lt;- \"https://github.com/hubchev/courses/raw/main/dta/113962-V1.zip\"\n\n# Download the ZIP file\ndownload.file(zipF, destfile = \"113962-V1.zip\")\n\n# Unzip the contents\nunzip(\"113962-V1.zip\")\n\ndf_curves &lt;- read_excel(\"Hortacsu_Syverson_JEP_Retail/diffusion_curves_figure.xlsx\",\n  sheet = \"Data and Predictions\", range = \"N3:Y60\"\n)\n\ndf &lt;- df_curves |&gt;\n  pivot_longer(\n    cols = \"Music and Video\":\"Food and Beverages\",\n    names_to = \"industry\",\n    values_to = \"value\"\n  )\n\n# Plot\ndf |&gt;\n  ggplot(aes(x = Year, y = value, group = industry, color = industry)) +\n  geom_line()\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, readxl))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#explain-the-weight-of-students",
    "href": "80_exercises.html#explain-the-weight-of-students",
    "title": "9  Collection of exercises",
    "section": "9.11 Explain the weight of students",
    "text": "9.11 Explain the weight of students\nIn the statistic course of WS 2020, I asked 23 students about their weight, height, sex, and number of siblings. I wonder how good the height can explain the weight of students. Examine with corelations and a regression analysis the association. Load the data as follows:\n\nlibrary(\"haven\")\nclassdata &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/classdata.csv\")\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, coef, fitted, geom_abline, geom_point, ggplot, head, library, lm, plot, read.csv, residuals, show, stat_smooth, subset, summary, tab_model.\n\n\n\n\n\n\nR script\n\n\n\n\n\n## ---- echo = TRUE--------------------------------------------------\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\nclassdata &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/classdata.csv\")\n\nhead(classdata)\n\n## ---- echo = TRUE--------------------------------------------------\n\nsummary(classdata)\n\n## ----pressure, echo=TRUE-------------------------------------------\nlibrary(\"ggplot2\")\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point()\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1)\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline regression  model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\nshow(model)\ninterm &lt;- model$coefficients[1]\nslope &lt;- model$coefficients[2]\ninterw &lt;- model$coefficients[1] + model$coefficients[3]\n\n## ---- echo=TRUE----------------------------------------------------\nsummary(model)\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point() +\n  geom_abline(slope = slope, intercept = interw, linetype = 2, size = 1.5) +\n  geom_abline(slope = slope, intercept = interm, linetype = 2, size = 1.5) +\n  geom_abline(slope = coef(model)[[2]], intercept = coef(model)[[1]])\n\n\n## ---- echo=TRUE----------------------------------------------------\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x, method = \"lm\",\n    se = FALSE, colour = \"red\", linetype = 1\n  )\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = siblings))\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x,\n    method = \"lm\",\n    se = T,\n    colour = \"red\",\n    linetype = 1\n  )\n\n## ---- echo=TRUE, results='hide'------------------------------------\n\nm1 &lt;- lm(weight ~ height, data = classdata)\nm2 &lt;- lm(weight ~ height + sex, data = classdata)\nm3 &lt;- lm(weight ~ height + sex + height * sex, data = classdata)\nm4 &lt;- lm(weight ~ height + sex + height * sex + siblings, data = classdata)\nm5 &lt;- lm(weight ~ height + sex + height * sex, data = subset(classdata, siblings &lt; 4))\n\nlibrary(sjPlot)\ntab_model(m1, m2, m3, m4, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m3, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n## ---- echo=T-------------------------------------------------------\nplot(residuals(m3), fitted(m3))\nplot(residuals(m3), classdata$siblings)\n\n## ----eval=FALSE----------------------------------------------------\n#  rmarkdown::render(\"regress_lecture.Rmd\", \"all\")\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n## ---- echo = TRUE--------------------------------------------------\n# install and load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\nclassdata &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/classdata.csv\")\n\nhead(classdata)\n\n  id sex weight height siblings row\n1  1   w     53    156        1   g\n2  2   w     73    170        1   g\n3  3   m     68    169        1   g\n4  4   w     67    166        1   g\n5  5   w     65    175        1   g\n6  6   w     48    161        0   g\n\n## ---- echo = TRUE--------------------------------------------------\n\nsummary(classdata)\n\n       id           sex                weight          height     \n Min.   : 1.0   Length:23          Min.   :48.00   Min.   :156.0  \n 1st Qu.: 6.5   Class :character   1st Qu.:64.50   1st Qu.:168.0  \n Median :12.0   Mode  :character   Median :70.00   Median :175.0  \n Mean   :12.0                      Mean   :70.61   Mean   :173.7  \n 3rd Qu.:17.5                      3rd Qu.:81.00   3rd Qu.:180.0  \n Max.   :23.0                      Max.   :90.00   Max.   :194.0  \n    siblings         row           \n Min.   :0.000   Length:23         \n 1st Qu.:1.000   Class :character  \n Median :1.000   Mode  :character  \n Mean   :1.391                     \n 3rd Qu.:2.000                     \n Max.   :4.000                     \n\n## ----pressure, echo=TRUE-------------------------------------------\nlibrary(\"ggplot2\")\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point()\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight)) +\n  geom_point() +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE, colour = \"red\", linetype = 1)\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline regression  model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\nshow(model)\n\n\nCall:\nlm(formula = weight ~ height + sex, data = classdata)\n\nCoefficients:\n(Intercept)       height         sexw  \n   -29.5297       0.5923      -5.7894  \n\ninterm &lt;- model$coefficients[1]\nslope &lt;- model$coefficients[2]\ninterw &lt;- model$coefficients[1] + model$coefficients[3]\n\n## ---- echo=TRUE----------------------------------------------------\nsummary(model)\n\n\nCall:\nlm(formula = weight ~ height + sex, data = classdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.086  -3.730   2.850   7.245  12.914 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -29.5297    47.6606  -0.620   0.5425  \nheight        0.5923     0.2671   2.217   0.0383 *\nsexw         -5.7894     4.4773  -1.293   0.2107  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.942 on 20 degrees of freedom\nMultiple R-squared:  0.4124,    Adjusted R-squared:  0.3537 \nF-statistic: 7.019 on 2 and 20 DF,  p-value: 0.004904\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point() +\n  geom_abline(slope = slope, intercept = interw, linetype = 2, size = 1.5) +\n  geom_abline(slope = slope, intercept = interm, linetype = 2, size = 1.5) +\n  geom_abline(slope = coef(model)[[2]], intercept = coef(model)[[1]])\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x, method = \"lm\",\n    se = FALSE, colour = \"red\", linetype = 1\n  )\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = siblings))\n\n\n\n\n\n\n\n## ---- echo=TRUE----------------------------------------------------\n## baseline model\nmodel &lt;- lm(weight ~ height + sex, data = classdata)\n\nggplot(classdata, aes(x = height, y = weight, shape = sex)) +\n  geom_point(aes(size = 2)) +\n  stat_smooth(\n    formula = y ~ x,\n    method = \"lm\",\n    se = T,\n    colour = \"red\",\n    linetype = 1\n  )\n\n\n\n\n\n\n\n## ---- echo=TRUE, results='hide'------------------------------------\n\nm1 &lt;- lm(weight ~ height, data = classdata)\nm2 &lt;- lm(weight ~ height + sex, data = classdata)\nm3 &lt;- lm(weight ~ height + sex + height * sex, data = classdata)\nm4 &lt;- lm(weight ~ height + sex + height * sex + siblings, data = classdata)\nm5 &lt;- lm(weight ~ height + sex + height * sex, data = subset(classdata, siblings &lt; 4))\n\nlibrary(sjPlot)\n\n#refugeeswelcome\n\ntab_model(m1, m2, m3, m4, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n\n\n\n\n \nweight\nweight\nweight\nweight\nweight\n\n\nPredictors\nEstimates\nEstimates\nEstimates\nEstimates\nEstimates\n\n\n(Intercept)\n-65.44 *\n-29.53 \n47.14 \n50.27 \n27.69 \n\n\nheight\n0.78 ***\n0.59 ***\n0.16 \n0.16 \n0.28 \n\n\nsex [w]\n\n-5.79 \n-153.96 **\n-161.92 **\n-134.51 *\n\n\nheight × sex [w]\n\n\n0.85 *\n0.89 *\n0.74 *\n\n\nsiblings\n\n\n\n-1.16 \n\n\n\nObservations\n23\n23\n23\n23\n21\n\n\nR2 / R2 adjusted\n0.363 / 0.333\n0.412 / 0.354\n0.487 / 0.407\n0.496 / 0.385\n0.572 / 0.497\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m1, m2, m3, m4,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n\n\n\n\n \nweight\nweight\nweight\nweight\n\n\nPredictors\nEstimates\nEstimates\nEstimates\nEstimates\n\n\n(Intercept)\n-65.44 *\n-29.53 \n47.14 \n50.27 \n\n\nheight\n0.78 ***\n0.59 ***\n0.16 \n0.16 \n\n\nsex [w]\n\n-5.79 \n-153.96 **\n-161.92 **\n\n\nheight × sex [w]\n\n\n0.85 *\n0.89 *\n\n\nsiblings\n\n\n\n-1.16 \n\n\nObservations\n23\n23\n23\n23\n\n\nR2 / R2 adjusted\n0.363 / 0.333\n0.412 / 0.354\n0.487 / 0.407\n0.496 / 0.385\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n## ---- echo=FALSE---------------------------------------------------\ntab_model(m3, m5,\n  p.style = \"stars\",\n  p.threshold = c(0.2, 0.1, 0.05),\n  show.ci = FALSE,\n  show.se = FALSE\n)\n\n\n\n\n\n \nweight\nweight\n\n\nPredictors\nEstimates\nEstimates\n\n\n(Intercept)\n47.14 \n27.69 \n\n\nheight\n0.16 \n0.28 \n\n\nsex [w]\n-153.96 **\n-134.51 *\n\n\nheight × sex [w]\n0.85 *\n0.74 *\n\n\nObservations\n23\n21\n\n\nR2 / R2 adjusted\n0.487 / 0.407\n0.572 / 0.497\n\n\n* p&lt;0.2   ** p&lt;0.1   *** p&lt;0.05\n\n\n\n\n\n\n\n## ---- echo=T-------------------------------------------------------\nplot(residuals(m3), fitted(m3))\n\n\n\n\n\n\n\nplot(residuals(m3), classdata$siblings)\n\n\n\n\n\n\n\n## ----eval=FALSE----------------------------------------------------\n#  rmarkdown::render(\"regress_lecture.Rmd\", \"all\")\n\n#  unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#calories-and-weight",
    "href": "80_exercises.html#calories-and-weight",
    "title": "9  Collection of exercises",
    "section": "9.12 Calories and weight",
    "text": "9.12 Calories and weight\n\nWrite down your name, your matriculation number, and the date.\nSet your working directory.\nClear your global environment.\nLoad the following package: tidyverse\n\nThe following table stems from a survey carried out at the Campus of the German Sport University of Cologne at Opening Day (first day of the new semester) between 8:00am and 8:20am. The survey consists of 6 individuals with the following information:\n\n\n\nid\nsex\nage\nweight\ncalories\nsport\n\n\n\n\n1\nf\n21\n48\n1700\n60\n\n\n2\nf\n19\n55\n1800\n120\n\n\n3\nf\n23\n50\n2300\n180\n\n\n4\nm\n18\n71\n2000\n60\n\n\n5\nm\n20\n77\n2800\n240\n\n\n6\nm\n61\n85\n2500\n30\n\n\n\nData Description:\n\nid: Variable with an anonymized identifier for each participant.\nsex: Gender, i.e., the participants replied to be either male (m) or female (f).\nage: The age in years of the participants at the time of the survey.\nweight: Number of kg the participants pretended to weight.\ncalories: Estimate of the participants on their average daily consumption of calories.\nsport: Estimate of the participants on their average daily time that they spend on doing sports (measured in minutes).\n\n\nWhich type of data do we have here? (Panel data, repeated cross-sectional data, cross-sectional data, time Series data)\nStore each of the five variables in a vector and put all five variables into a dataframe with the title df. If you fail here, read in the data using this line of code:\n\n\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/df-calories.csv\")\n\nRows: 6 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (4): age, weight, calories, sport\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nShow for all numerical variables the summary statistics including the mean, median, minimum, and the maximum.\nShow for all numerical variables the summary statistics including the mean and the standard deviation, separated by male and female. Use therefore the pipe operator.\nSuppose you want to analyze the general impact of average calories consumption per day on the weight. Discuss if the sample design is appropriate to draw conclusions on the population. What may cause some bias in the data? Discuss possibilities to improve the sampling and the survey, respectively.\nThe following plot visualizes the two variables weight and calories. Discuss what can be improved in the graphical visualization.\n\n\n\nWeight vs. Calories\n\n\n\n\nMake a scatterplot matrix containing all numerical variables.\nCalculate the Pearson Correlation Coefficient of the two variables\n\ncalories and sport\nweight and calories\n\nMake a scatterplot with weight in the y-axis and calories on the x-axis. Additionally, the plot should contain a linear fit and the points should be labeled with the sex just like in the figure shown above.\nEstimate the following regression specification using the OLS method: [weight_i=_0+_1 calories_i+ _i]\n\nShow a summary of the estimates that look like the following:\n\n\n\nCall:\nlm(formula = weight ~ calories, data = df)\n\nResiduals:\n     1      2      3      4      5      6 \n-5.490 -1.182 -6.640  9.435 -6.099  9.976 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  7.730275  20.197867   0.383   0.7214  \ncalories     0.026917   0.009107   2.956   0.0417 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.68 on 4 degrees of freedom\nMultiple R-squared:  0.6859,    Adjusted R-squared:  0.6074 \nF-statistic: 8.735 on 1 and 4 DF,  p-value: 0.04174\n\n\n\nInterpret the results. In particular, interpret how many kg the estimated weight increases—on average and ceteris paribus—if calories increase by 100 calories. Additionally, discuss the statistical properties of the estimated coefficient \\(\\hat{\\beta_1}\\) and the meaning of the Adjusted R-squared.\nOLS estimates can suffer from omitted variable bias. State the two conditions that need to be fulfilled for omitted bias to occur.\nDiscuss potential confounding variables that may cause omitted variable bias. Given the dataset above how can some of the confounding variables be controlled for?\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, cor, data.frame, geom_point, geom_text, ggplot, group_by, lm, mean, plot, read_csv, sd, stat_smooth, summarise, summary.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# 1\n# Stephan Huber, 000, 2020-May-30\n\n# 2\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsb_bac/work/\")\n\n# 3\nrm(list = ls())\n\n# 4\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\n# 5\n# cross-section\n\n# 6\nsex &lt;- c(\"f\", \"f\", \"f\", \"m\", \"m\", \"m\")\nage &lt;- c(21, 19, 23, 18, 20, 61)\nweight &lt;- c(48, 55, 63, 71, 77, 85)\ncalories &lt;- c(1700, 1800, 2300, 2000, 2800, 2500)\nsport &lt;- c(60, 120, 180, 60, 240, 30)\ndf &lt;- data.frame(sex, age, weight, calories, sport)\n\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/exams/21-04/stuff/df.csv\")\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/github/courses/dta/df-calories.csv\")\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/df-calories.csv\")\n\n# 7\nsummary(df)\n\n# 8\ndf |&gt;\n  group_by(sex) |&gt;\n  summarise(\n    mcal = mean(calories),\n    sdcal = sd(calories),\n    mweight = mean(weight),\n    sdweight = sd(weight)\n  )\n\n# 9\n# discussed in class\n\n# 10\n# Many things can be mentioned here such as the use of colors\n# (red/blue is not a good choice for color blind people),\n# the legend makes no sense as red and green both refer to \\textit{sport},\n# the label of `f' and `m' is not explained in the legend,\n# rotating the labels of the y-axis would increase readability, and\n# both axes do not start at zero which is hard to see.\n# Also, it is a common to draw the variable you want to explain\n# (here: calories) on the y-axis.\n\n# 11\nplot(df)\n\n# 12\ncor(df$calories, df$sport, method = c(\"pearson\"))\ncor(df$weight, df$calories, method = c(\"pearson\"))\n\n# 13\nggplot(df, aes(x = calories, y = weight, label = sex)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE)\n\n# 14\nreg_base &lt;- lm(weight ~ calories, data = df)\nsummary(reg_base)\n\n# 15\n# 1) An increase of 100 calories (taken on average on a daily basis) is associated\n# - on average and ceteris paribus - with 2.69 more of kg the participants are\n# pretended to weight.\n# 2) The estimated coefficient $beta_1$ is statistically significantly different to zero\n# on a significance level of 5%.\n# 3) About 60 % of the variation of the weight is explained by the\n# estimated coefficients of the empirical model.\n\n# 16\n# For omitted variable bias to occur, the omitted variable `Z` must satisfy\n# two conditions:\n#   1) The omitted variable is correlated with the included regressor\n#   2) The omitted variable is a determinant of the dependent variable\n\n# 17\n# discussed in class\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# 1\n# Stephan Huber, 000, 2020-May-30\n\n# 2\n# setwd(\"/home/sthu/Dropbox/hsf/22-ss/dsb_bac/work/\")\n\n# 3\nrm(list = ls())\n\n# 4\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, haven)\n\n# 5\n# cross-section\n\n# 6\nsex &lt;- c(\"f\", \"f\", \"f\", \"m\", \"m\", \"m\")\nage &lt;- c(21, 19, 23, 18, 20, 61)\nweight &lt;- c(48, 55, 63, 71, 77, 85)\ncalories &lt;- c(1700, 1800, 2300, 2000, 2800, 2500)\nsport &lt;- c(60, 120, 180, 60, 240, 30)\ndf &lt;- data.frame(sex, age, weight, calories, sport)\n\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/exams/21-04/stuff/df.csv\")\n# write_csv(df, file = \"/home/sthu/Dropbox/hsf/github/courses/dta/df-calories.csv\")\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/df-calories.csv\")\n\nRows: 6 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (4): age, weight, calories, sport\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# 7\nsummary(df)\n\n     sex                 age            weight        calories        sport    \n Length:6           Min.   :18.00   Min.   :48.0   Min.   :1700   Min.   : 30  \n Class :character   1st Qu.:19.25   1st Qu.:57.0   1st Qu.:1850   1st Qu.: 60  \n Mode  :character   Median :20.50   Median :67.0   Median :2150   Median : 90  \n                    Mean   :27.00   Mean   :66.5   Mean   :2183   Mean   :115  \n                    3rd Qu.:22.50   3rd Qu.:75.5   3rd Qu.:2450   3rd Qu.:165  \n                    Max.   :61.00   Max.   :85.0   Max.   :2800   Max.   :240  \n\n# 8\ndf |&gt;\n  group_by(sex) |&gt;\n  summarise(\n    mcal = mean(calories),\n    sdcal = sd(calories),\n    mweight = mean(weight),\n    sdweight = sd(weight)\n  )\n\n# A tibble: 2 × 5\n  sex    mcal sdcal mweight sdweight\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 f     1933.  321.    55.3     7.51\n2 m     2433.  404.    77.7     7.02\n\n# 9\n# discussed in class\n\n# 10\n# Many things can be mentioned here such as the use of colors\n# (red/blue is not a good choice for color blind people),\n# the legend makes no sense as red and green both refer to \\textit{sport},\n# the label of `f' and `m' is not explained in the legend,\n# rotating the labels of the y-axis would increase readability, and\n# both axes do not start at zero which is hard to see.\n# Also, it is a common to draw the variable you want to explain\n# (here: calories) on the y-axis.\n\n# 11\nplot(df)\n\n\n\n\n\n\n\n# 12\ncor(df$calories, df$sport, method = c(\"pearson\"))\n\n[1] 0.5330615\n\ncor(df$weight, df$calories, method = c(\"pearson\"))\n\n[1] 0.8281972\n\n# 13\nggplot(df, aes(x = calories, y = weight, label = sex)) +\n  geom_point() +\n  geom_text(hjust = 0, vjust = 0) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE)\n\nWarning: The following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n# 14\nreg_base &lt;- lm(weight ~ calories, data = df)\nsummary(reg_base)\n\n\nCall:\nlm(formula = weight ~ calories, data = df)\n\nResiduals:\n     1      2      3      4      5      6 \n-5.490 -1.182 -6.640  9.435 -6.099  9.976 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  7.730275  20.197867   0.383   0.7214  \ncalories     0.026917   0.009107   2.956   0.0417 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.68 on 4 degrees of freedom\nMultiple R-squared:  0.6859,    Adjusted R-squared:  0.6074 \nF-statistic: 8.735 on 1 and 4 DF,  p-value: 0.04174\n\n# 15\n# 1) An increase of 100 calories (taken on average on a daily basis) is associated\n# - on average and ceteris paribus - with 2.69 more of kg the participants are\n# pretended to weight.\n# 2) The estimated coefficient $beta_1$ is statistically significantly different to zero\n# on a significance level of 5%.\n# 3) About 60 % of the variation of the weight is explained by the\n# estimated coefficients of the empirical model.\n\n# 16\n# For omitted variable bias to occur, the omitted variable `Z` must satisfy\n# two conditions:\n#   1) The omitted variable is correlated with the included regressor\n#   2) The omitted variable is a determinant of the dependent variable\n\n# 17\n# discussed in class\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, haven))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#bundesliga",
    "href": "80_exercises.html#bundesliga",
    "title": "9  Collection of exercises",
    "section": "9.13 Bundesliga",
    "text": "9.13 Bundesliga\nOpen the script that you find here and work on the following tasks:\n\nSet your working directory.\nClear th environment.\nInstall and load the bundesligR and tidyverse.\nRead in the data bundesligR as a tibble.\nReplace “Bor. Moenchengladbach” with “Borussia Moenchengladbach.”\nCheck for the data class.\nView the data.\nGlimpse on the data.\nShow the first and last observations.\nShow summary statistics to all variables.\nHow many teams have played in the league over the years?\nWhich teams have played Bundesliga so far?\nHow many teams have played Bundesliga?\nHow often has each team played in the Bundesliga?\nShow summary statistics of variable Season only.\nShow summary statistics of all numeric variables (Team is a character).\nWhat is the highest number of points ever received by a team? Show only the name of the club with the highest number of points ever received.\nCreate a new tibble using liga removing the variable Pts_pre_95 from the data.\nCreate a new tibble using liga renaming W, D, and L to Win, Draw, and Loss. Additionally rename GF, GA, GD to Goals_shot, Goals_received, Goal_difference.\nCreate a new tibble using liga without the variable Pts_pre_95 and only observations before the year 1996.\nRemove the three tibbles just created from the environment.\nRename all variables of liga to lowercase and store it as dfb.\nShow the winner and the runner up after the year 2010. Additionally show the points received.\nCreate a variable that counts how often a team was ranked first.\nHow often has each team played in the Bundesliga?\nMake a ranking that shows which team has played the Bundesliga most often.\nAdd a variable to dfb that contains the number of appearances of a team in the league.\nCreate a number that indicates how often a team has played Bundesliga in a given year.\nMake a ranking with the number of titles of all teams that ever won the league.\nCreate a numeric identifying variable for each team.\nWhen a team is in the league, what is the probability that it wins the league?\nMake a scatterplot with points on the y-axis and position on the x-axis.\nMake a scatterplot with points on the y-axis and position on the x-axis. Additionally, only consider seasons with 18 teams and add lines that make clear how many points you needed to be placed in between rank 2 and 15.\nRemove all objects from the environment except dfb and liga.\nIn Figure Figure 9.2, the ranking history of 1. FC Kaiserslautern is shown. Replicate that plot.\n\n\n\n\nFigure 9.2: Ranking history: 1. FC Kaiserslautern\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Figure Figure 9.3, I made the graph a bit nicer. Can you spot all differences and can you guess what the dashed line and the triangles mean? How could the visualization be improved further? Replicate the plot.\n\n\n\n\nFigure 9.3: Ranking history: 1. FC Köln\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry to make the ranking history for each club ever played the league and export the graph as a png file.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, arrange, as_tibble, as.numeric, between, c, case_when, class, complete, desc, dir.create, dir.exists, element_blank, facet_wrap, factor, filter, geom_hline, geom_line, geom_point, geom_vline, ggplot, ggsave, glimpse, group_by, head, ifelse, is.na, labs, list, max, mutate, n_distinct, paste, print, rename, rename_all, row_number, scale_x_continuous, scale_y_continuous, scale_y_reverse, select, seq, setdiff, slice_head, subset, sum, summarise, summary, table, tail, theme, theme_classic, theme_minimal, unique, unlink, view, xlim.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# In dfb.R I analyze German soccer results\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/23-ws/dsda/scripts\")\n\n# clear environment\nrm(list = ls())\n\n# (Install and) load packagages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  bundesligR,\n  tidyverse\n)\n\n# Read in the data as tibble\nliga &lt;- as_tibble(bundesligR)\n\n# --------------------------------------\n# !!! ERRORS / ISSUES:\n# \"Borussia Moenchengladbach\" is also entitled \"Bor. Moenchengladbach\"!\n# Leverkusen is falsly entitled \"SV Bayer 04 Leverkusen\"\n# Uerdingen has changed its name several times\n# Stuttgarter Kickers are named differently\n\n# How often is \"Bor. Moenchengladbach\" in the data?\nsum(liga$Team == \"Bor. Moenchengladbach\")\n\n# show the entries\nliga |&gt;\n  filter(Team == \"Bor. Moenchengladbach\")\n\n# Replace \"Bor. Moenchengladbach\" with \"Borussia Moenchengladbach\"\nliga &lt;- liga |&gt;\n  mutate(Team = ifelse(Team == \"Bor. Moenchengladbach\",\n    \"Borussia Moenchengladbach\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Bayer 04 Leverkusen\",\n    \"TSV Bayer 04 Leverkusen\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"FC Bayer 05 Uerdingen\" |\n    Team == \"Bayer 05 Uerdingen\",\n  \"KFC Uerdingen 05\",\n  Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Stuttgarter Kickers\",\n    \"Stuttgarter Kickers\",\n    Team\n  ))\n\n# ------------------------------------\n\n# Check for the data class\nclass(liga)\n\n# view data\nview(liga)\n\n# Glimpse on the data\nglimpse(liga)\n\n# first and last observations\nhead(liga)\ntail(liga)\n\n# summary statistics\nsummary(liga)\n\n# How many teams have played in the league over the years?\ntable(liga$Season)\n\n# Which teams have played Bundesliga\nunique(liga$Team)\n\n# How many teams have played Bundesliga\nn_distinct(liga$Team)\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n# summary of variable Season only\nsummary(liga$Season)\n\n# summary of numeric of variables (Team is a character)\nliga |&gt;\n  select(Season, Position, Played, W, D, L, GF, GA, GD, Points, Pts_pre_95) |&gt;\n  summary()\n\n# shorter alternative\nliga |&gt;\n  select(Season, Position, Played:Pts_pre_95) |&gt;\n  summary()\n\n# shortest alternative\nliga |&gt;\n  select(-Team) |&gt;\n  filter(Season == 1999 | Season == 2010) |&gt;\n  summary()\n\n# Most points ever received by a team\nliga |&gt;\n  filter(Points == max(Points))\n\n# Show only the team name\nliga |&gt;\n  filter(Points == max(Points)) |&gt;\n  select(Team) |&gt;\n  print()\n\n# remove the variable `Pts_pre_95` from the data\nliga_post95 &lt;- liga |&gt;\n  select(-Pts_pre_95)\n\n# rename W, D, and L to Win, Draw, and Loss\n# additionally rename GF, GA, GD to Goals_shot, Goals_received, Goal_difference\nliga_longnames &lt;- liga |&gt;\n  rename(Win = W, Draw = D, Loss = L) |&gt;\n  rename(Goals_shot = GF, Goals_received = GA, Goal_difference = GD)\n\n# Remove the variable `Pts_pre_95` from `liga`\n# additionally remove all observations before the year 1996\nliga_no3point &lt;- liga |&gt;\n  select(-Pts_pre_95) |&gt;\n  filter(Season &gt;= 1996)\n\n# Remove the objects liga_post95, liga_longnames, and liga_no3point from the environment\nrm(liga_post95, liga_longnames, liga_no3point)\n\n# Rename all variables of `liga`to lower cases and store it as `dfb`\ndfb &lt;- liga |&gt;\n  rename_all(tolower)\n\n# Show the winner and the runner up after 2010\n# additionally show the points\ndfb |&gt;\n  filter(season &gt; 2010) |&gt;\n  group_by(season) |&gt;\n  arrange(desc(points)) |&gt;\n  slice_head(n = 2) |&gt;\n  select(team, points, position)\n\n# Create a variable that counts how often a team was ranked first\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(meister_count = sum(position == 1))\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n# Make a ranking\ndfb |&gt;\n  group_by(team) |&gt;\n  summarise(appearances = n_distinct(season)) |&gt;\n  arrange(desc(appearances)) |&gt;\n  print(n = Inf)\n\n# Add a variable to `dfb` that contains the number of appearances of a team in the league\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(appearances = n_distinct(season))\n\n# create a number that indicates how often a team has played Bundesliga in a given year\ndfb &lt;- dfb |&gt;\n  arrange(team, season) |&gt;\n  group_by(team) |&gt;\n  mutate(team_in_liga_count = row_number())\n\n# Make a ranking with the number of titles of all teams that ever won the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  filter(meister_count != 0) |&gt;\n  arrange(desc(meister_count)) |&gt;\n  select(meister_count, team)\n\n# Create a numeric identifying variable for each team\ndfb_teamid &lt;- dfb |&gt;\n  mutate(team_id = as.numeric(factor(team)))\n\n# When a team is in the league, what is the probability that it wins the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  mutate(prob_win = meister_count / appearances) |&gt;\n  filter(prob_win &gt; 0) |&gt;\n  arrange(desc(prob_win)) |&gt;\n  select(meister_count, prob_win, team)\n\n\n# make a scatterplot with points on the y-axis and position on the x-axis\nggplot(dfb, aes(x = position, y = points)) +\n  geom_point()\n\n# Make a scatterplot with points on the y-axis and position on the x-axis.\n# Additionally, only consider seasons with 18 teams and\n# add lines that make clear how many points you needed to be placed\n# in between rank 2 and 15.\ndfb_18 &lt;- dfb |&gt;\n  group_by(season) |&gt;\n  mutate(teams_in_league = n_distinct(team)) |&gt;\n  filter(teams_in_league == 18)\n\nh_1 &lt;- dfb_18 |&gt;\n  filter(position == 16) |&gt;\n  mutate(ma = max(points))\n\nmax_points_rank_16 &lt;- max(h_1$ma) + 1\n\nh_2 &lt;- dfb_18 |&gt;\n  filter(position == 2) |&gt;\n  mutate(mb = max(points))\n\nmin_points_rank_2 &lt;- max(h_2$mb) + 1\n\ndfb_18 &lt;- dfb_18 |&gt;\n  mutate(season_category = case_when(\n    season &lt; 1970 ~ 1,\n    between(season, 1970, 1979) ~ 2,\n    between(season, 1980, 1989) ~ 3,\n    between(season, 1990, 1999) ~ 4,\n    between(season, 2000, 2009) ~ 5,\n    between(season, 2010, 2019) ~ 6,\n    TRUE ~ 7 # Adjust this line based on the actual range of your data\n  ))\n\nggplot(dfb_18, aes(x = position, y = points)) +\n  geom_point() +\n  labs(\n    title = \"Scatterplot of Points and Position\",\n    x = \"Position\",\n    y = \"Points\"\n  ) +\n  geom_vline(xintercept = c(1.5, 15.5), linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = max_points_rank_16, linetype = \"dashed\", color = \"blue\") +\n  geom_hline(yintercept = min_points_rank_2, linetype = \"dashed\", color = \"blue\") +\n  scale_y_continuous(breaks = c(min_points_rank_2, max_points_rank_16, seq(0, max(dfb_18$points), by = 5))) +\n  scale_x_continuous(breaks = c(seq(0, max(dfb_18$points), by = 1))) +\n  theme_classic()\n\n\n# Remove all objects except liga and dfb\nrm(list = setdiff(ls(), c(\"liga\", \"dfb\")))\n\n# Rank \"1. FC Kaiserslautern\" over time\ndfb_bal &lt;- dfb |&gt;\n  select(season, team, position) |&gt;\n  as_tibble() |&gt;\n  complete(season, team)\n\ntable(dfb_bal$team)\n\ndfb_fck &lt;- dfb_bal |&gt;\n  filter(team == \"1. FC Kaiserslautern\")\n\nggplot(dfb_fck, aes(x = season, y = position)) +\n  geom_point() +\n  geom_line() +\n  scale_y_reverse(breaks = seq(1, 18, by = 1))\n\n\n\n\n# Make the plot nice\n\n# consider different rules for having to leave the league:\ndfb_fck &lt;- dfb_fck |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown))\n\n\nggplot(dfb_fck, aes(x = season)) +\n  geom_point(aes(y = position)) +\n  geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 18, by = 1)) +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"blue\")\n\n\n\ndfb_bal &lt;- dfb_bal |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown)) |&gt;\n  mutate(inliga = ifelse(is.na(position), 0, 1))\n\n\n\nrank_plot &lt;- ggplot(dfb_bal, aes(x = season)) +\n  geom_point(aes(y = position), shape = 1) +\n  # geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n  xlim(1963, 2015) +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n  geom_point(aes(y = position), shape = 1)\n\nrank_plot\n# !--&gt; in 1979 is a gap! Error?\n# No. Reason: two clubs shared the third place.\n\nrank_plot +\n  facet_wrap(~team)\n\n# Create \"test\" directory if it doesn't already exist\nif (!dir.exists(\"test\")) {\n  dir.create(\"test\")\n}\n\n\nplots &lt;- list()\nfor (club in unique(dfb_bal$team)) {\n  dfb_subset &lt;- subset(dfb_bal, team == club)\n\n  p &lt;- ggplot(dfb_subset, aes(x = season)) +\n    geom_point(aes(y = position), shape = 15) +\n    geom_line(aes(y = position)) +\n    geom_point(aes(y = godown), shape = 25) +\n    scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n    xlim(1963, 2015) +\n    theme(panel.grid.minor = element_blank()) +\n    geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n    geom_point(aes(y = position), shape = 1) +\n    labs(title = paste(\"Ranking History:\", club))\n  ggsave(filename = paste(\"test/r_\", club, \".png\", sep = \"\"))\n  plots[[club]] &lt;- p\n}\n\nprint(plots$`Meidericher SV`)\nprint(plots$`1. FC Koeln`)\n\n# unload packages\nsuppressMessages(pacman::p_unload(\n  bundesligR,\n  tidyverse\n))\n\n# Remove the \"test\" directory and its contents after saving all graphs\nunlink(\"test\", recursive = TRUE)\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# In dfb.R I analyze German soccer results\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/23-ws/dsda/scripts\")\n\n# clear environment\nrm(list = ls())\n\n# (Install and) load packagages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(\n  bundesligR,\n  tidyverse\n)\n\n# Read in the data as tibble\nliga &lt;- as_tibble(bundesligR)\n\n# --------------------------------------\n# !!! ERRORS / ISSUES:\n# \"Borussia Moenchengladbach\" is also entitled \"Bor. Moenchengladbach\"!\n# Leverkusen is falsly entitled \"SV Bayer 04 Leverkusen\"\n# Uerdingen has changed its name several times\n# Stuttgarter Kickers are named differently\n\n# How often is \"Bor. Moenchengladbach\" in the data?\nsum(liga$Team == \"Bor. Moenchengladbach\")\n\n[1] 2\n\n# show the entries\nliga |&gt;\n  filter(Team == \"Bor. Moenchengladbach\")\n\n# A tibble: 2 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   1989       15 Bor. Moench…     34    11     8    15    37    45    -8     41\n2   1976        1 Bor. Moench…     34    17    10     7    58    34    24     61\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\n# Replace \"Bor. Moenchengladbach\" with \"Borussia Moenchengladbach\"\nliga &lt;- liga |&gt;\n  mutate(Team = ifelse(Team == \"Bor. Moenchengladbach\",\n    \"Borussia Moenchengladbach\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Bayer 04 Leverkusen\",\n    \"TSV Bayer 04 Leverkusen\",\n    Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"FC Bayer 05 Uerdingen\" |\n    Team == \"Bayer 05 Uerdingen\",\n  \"KFC Uerdingen 05\",\n  Team\n  )) |&gt;\n  mutate(Team = ifelse(Team == \"SV Stuttgarter Kickers\",\n    \"Stuttgarter Kickers\",\n    Team\n  ))\n\n# ------------------------------------\n\n# Check for the data class\nclass(liga)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# view data\nview(liga)\n\n# Glimpse on the data\nglimpse(liga)\n\nRows: 952\nColumns: 12\n$ Season     &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,…\n$ Position   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ Team       &lt;chr&gt; \"FC Bayern Muenchen\", \"Borussia Dortmund\", \"Bayer 04 Leverk…\n$ Played     &lt;dbl&gt; 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,…\n$ W          &lt;dbl&gt; 28, 24, 18, 17, 15, 14, 14, 12, 10, 11, 10, 9, 10, 9, 9, 9,…\n$ D          &lt;dbl&gt; 4, 6, 6, 4, 7, 8, 8, 9, 13, 8, 10, 11, 8, 11, 10, 9, 6, 4, …\n$ L          &lt;dbl&gt; 2, 4, 10, 13, 12, 12, 12, 13, 11, 15, 14, 14, 16, 14, 15, 1…\n$ GF         &lt;dbl&gt; 80, 82, 56, 67, 51, 46, 42, 47, 38, 40, 33, 42, 50, 38, 39,…\n$ GA         &lt;dbl&gt; 17, 34, 40, 50, 49, 42, 42, 49, 42, 46, 42, 52, 65, 53, 54,…\n$ GD         &lt;dbl&gt; 63, 48, 16, 17, 2, 4, 0, -2, -4, -6, -9, -10, -15, -15, -15…\n$ Points     &lt;dbl&gt; 88, 78, 60, 55, 52, 50, 50, 45, 43, 41, 40, 38, 38, 38, 37,…\n$ Pts_pre_95 &lt;dbl&gt; 60, 54, 42, 38, 37, 36, 36, 33, 33, 30, 30, 29, 28, 29, 28,…\n\n# first and last observations\nhead(liga)\n\n# A tibble: 6 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   2015        1 FC Bayern M…     34    28     4     2    80    17    63     88\n2   2015        2 Borussia Do…     34    24     6     4    82    34    48     78\n3   2015        3 Bayer 04 Le…     34    18     6    10    56    40    16     60\n4   2015        4 Borussia Mo…     34    17     4    13    67    50    17     55\n5   2015        5 FC Schalke …     34    15     7    12    51    49     2     52\n6   2015        6 1. FSV Main…     34    14     8    12    46    42     4     50\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\ntail(liga)\n\n# A tibble: 6 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   1963       11 Eintracht B…     30    11     6    13    36    49   -13     39\n2   1963       12 1. FC Kaise…     30    10     6    14    48    69   -21     36\n3   1963       13 Karlsruher …     30     8     8    14    42    55   -13     32\n4   1963       14 Hertha BSC       30     9     6    15    45    65   -20     33\n5   1963       15 Preussen Mu…     30     7     9    14    34    52   -18     30\n6   1963       16 1. FC Saarb…     30     6     5    19    44    72   -28     23\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\n# summary statistics\nsummary(liga)\n\n     Season        Position          Team               Played     \n Min.   :1963   Min.   : 1.000   Length:952         Min.   :30.00  \n 1st Qu.:1976   1st Qu.: 5.000   Class :character   1st Qu.:34.00  \n Median :1989   Median : 9.000   Mode  :character   Median :34.00  \n Mean   :1989   Mean   : 9.486                      Mean   :33.95  \n 3rd Qu.:2002   3rd Qu.:14.000                      3rd Qu.:34.00  \n Max.   :2015   Max.   :20.000                      Max.   :38.00  \n       W               D                L               GF        \n Min.   : 2.00   Min.   : 2.000   Min.   : 1.00   Min.   : 15.00  \n 1st Qu.: 9.75   1st Qu.: 7.000   1st Qu.:10.00   1st Qu.: 42.00  \n Median :12.00   Median : 9.000   Median :13.00   Median : 50.00  \n Mean   :12.61   Mean   : 8.733   Mean   :12.61   Mean   : 52.01  \n 3rd Qu.:15.00   3rd Qu.:11.000   3rd Qu.:15.00   3rd Qu.: 61.00  \n Max.   :29.00   Max.   :18.000   Max.   :28.00   Max.   :101.00  \n       GA             GD               Points        Pts_pre_95   \n Min.   :10.0   Min.   :-60.0000   Min.   :10.00   Min.   : 8.00  \n 1st Qu.:43.0   1st Qu.:-13.0000   1st Qu.:38.00   1st Qu.:29.00  \n Median :51.0   Median : -2.0000   Median :44.00   Median :33.00  \n Mean   :51.7   Mean   :  0.3015   Mean   :46.56   Mean   :33.95  \n 3rd Qu.:60.0   3rd Qu.: 13.0000   3rd Qu.:55.00   3rd Qu.:39.00  \n Max.   :93.0   Max.   : 80.0000   Max.   :91.00   Max.   :62.00  \n\n# How many teams have played in the league over the years?\ntable(liga$Season)\n\n\n1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 \n  16   16   18   18   18   18   18   18   18   18   18   18   18   18   18   18 \n1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 \n  18   18   18   18   18   18   18   18   18   18   18   18   20   18   18   18 \n1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 \n  18   18   18   18   18   18   18   18   18   18   18   18   18   18   18   18 \n2011 2012 2013 2014 2015 \n  18   18   18   18   18 \n\n# Which teams have played Bundesliga\nunique(liga$Team)\n\n [1] \"FC Bayern Muenchen\"        \"Borussia Dortmund\"        \n [3] \"Bayer 04 Leverkusen\"       \"Borussia Moenchengladbach\"\n [5] \"FC Schalke 04\"             \"1. FSV Mainz 05\"          \n [7] \"Hertha BSC\"                \"VfL Wolfsburg\"            \n [9] \"1. FC Koeln\"               \"Hamburger SV\"             \n[11] \"FC Ingolstadt 04\"          \"FC Augsburg\"              \n[13] \"Werder Bremen\"             \"SV Darmstadt 98\"          \n[15] \"TSG 1899 Hoffenheim\"       \"Eintracht Frankfurt\"      \n[17] \"VfB Stuttgart\"             \"Hannover 96\"              \n[19] \"SC Freiburg\"               \"SC Paderborn 07\"          \n[21] \"1. FC Nuernberg\"           \"Eintracht Braunschweig\"   \n[23] \"Fortuna Duesseldorf\"       \"SpVgg Greuther Fuerth\"    \n[25] \"1. FC Kaiserslautern\"      \"FC St. Pauli\"             \n[27] \"VfL Bochum\"                \"Energie Cottbus\"          \n[29] \"Karlsruher SC\"             \"Arminia Bielefeld\"        \n[31] \"Hansa Rostock\"             \"MSV Duisburg\"             \n[33] \"Alemannia Aachen\"          \"TSV 1860 Muenchen\"        \n[35] \"SpVgg Unterhaching\"        \"SSV Ulm 1846\"             \n[37] \"KFC Uerdingen 05\"          \"Dynamo Dresden\"           \n[39] \"SG Wattenscheid 09\"        \"VfB Leipzig\"              \n[41] \"1. FC Saarbruecken\"        \"TSV Bayer 04 Leverkusen\"  \n[43] \"SV Werder Bremen\"          \"1. FC Dynamo Dresden\"     \n[45] \"Stuttgarter Kickers\"       \"FC Hansa Rostock\"         \n[47] \"SV Waldhof Mannheim\"       \"FC 08 Homburg\"            \n[49] \"FC Homburg\"                \"Blau-Weiss 90 Berlin\"     \n[51] \"Kickers Offenbach\"         \"Tennis Borussia Berlin\"   \n[53] \"Rot-Weiss Essen\"           \"Wuppertaler SV\"           \n[55] \"SC Fortuna Koeln\"          \"Rot-Weiss Oberhausen\"     \n[57] \"SC Rot-Weiss Oberhausen\"   \"Borussia Neunkirchen\"     \n[59] \"Meidericher SV\"            \"SC Tasmania 1900 Berlin\"  \n[61] \"Preussen Muenster\"        \n\n# How many teams have played Bundesliga\nn_distinct(liga$Team)\n\n[1] 61\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n\n     1. FC Dynamo Dresden      1. FC Kaiserslautern               1. FC Koeln \n                        1                        44                        45 \n          1. FC Nuernberg        1. FC Saarbruecken           1. FSV Mainz 05 \n                       32                         5                        10 \n         Alemannia Aachen         Arminia Bielefeld       Bayer 04 Leverkusen \n                        4                        17                        30 \n     Blau-Weiss 90 Berlin         Borussia Dortmund Borussia Moenchengladbach \n                        1                        49                        48 \n     Borussia Neunkirchen            Dynamo Dresden    Eintracht Braunschweig \n                        3                         3                        21 \n      Eintracht Frankfurt           Energie Cottbus             FC 08 Homburg \n                       47                         6                         2 \n              FC Augsburg        FC Bayern Muenchen          FC Hansa Rostock \n                        5                        51                         1 \n               FC Homburg          FC Ingolstadt 04             FC Schalke 04 \n                        1                         1                        48 \n             FC St. Pauli       Fortuna Duesseldorf              Hamburger SV \n                        8                        23                        53 \n              Hannover 96             Hansa Rostock                Hertha BSC \n                       28                        11                        33 \n            Karlsruher SC          KFC Uerdingen 05         Kickers Offenbach \n                       24                        14                         7 \n           Meidericher SV              MSV Duisburg         Preussen Muenster \n                        3                        25                         1 \n          Rot-Weiss Essen      Rot-Weiss Oberhausen          SC Fortuna Koeln \n                        7                         3                         1 \n              SC Freiburg           SC Paderborn 07   SC Rot-Weiss Oberhausen \n                       16                         1                         1 \n  SC Tasmania 1900 Berlin        SG Wattenscheid 09     SpVgg Greuther Fuerth \n                        1                         4                         1 \n       SpVgg Unterhaching              SSV Ulm 1846       Stuttgarter Kickers \n                        2                         1                         2 \n          SV Darmstadt 98       SV Waldhof Mannheim          SV Werder Bremen \n                        3                         7                         1 \n   Tennis Borussia Berlin       TSG 1899 Hoffenheim         TSV 1860 Muenchen \n                        2                         8                        20 \n  TSV Bayer 04 Leverkusen               VfB Leipzig             VfB Stuttgart \n                        7                         1                        51 \n               VfL Bochum             VfL Wolfsburg             Werder Bremen \n                       34                        19                        51 \n           Wuppertaler SV \n                        3 \n\n# summary of variable Season only\nsummary(liga$Season)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1963    1976    1989    1989    2002    2015 \n\n# summary of numeric of variables (Team is a character)\nliga |&gt;\n  select(Season, Position, Played, W, D, L, GF, GA, GD, Points, Pts_pre_95) |&gt;\n  summary()\n\n     Season        Position          Played            W        \n Min.   :1963   Min.   : 1.000   Min.   :30.00   Min.   : 2.00  \n 1st Qu.:1976   1st Qu.: 5.000   1st Qu.:34.00   1st Qu.: 9.75  \n Median :1989   Median : 9.000   Median :34.00   Median :12.00  \n Mean   :1989   Mean   : 9.486   Mean   :33.95   Mean   :12.61  \n 3rd Qu.:2002   3rd Qu.:14.000   3rd Qu.:34.00   3rd Qu.:15.00  \n Max.   :2015   Max.   :20.000   Max.   :38.00   Max.   :29.00  \n       D                L               GF               GA      \n Min.   : 2.000   Min.   : 1.00   Min.   : 15.00   Min.   :10.0  \n 1st Qu.: 7.000   1st Qu.:10.00   1st Qu.: 42.00   1st Qu.:43.0  \n Median : 9.000   Median :13.00   Median : 50.00   Median :51.0  \n Mean   : 8.733   Mean   :12.61   Mean   : 52.01   Mean   :51.7  \n 3rd Qu.:11.000   3rd Qu.:15.00   3rd Qu.: 61.00   3rd Qu.:60.0  \n Max.   :18.000   Max.   :28.00   Max.   :101.00   Max.   :93.0  \n       GD               Points        Pts_pre_95   \n Min.   :-60.0000   Min.   :10.00   Min.   : 8.00  \n 1st Qu.:-13.0000   1st Qu.:38.00   1st Qu.:29.00  \n Median : -2.0000   Median :44.00   Median :33.00  \n Mean   :  0.3015   Mean   :46.56   Mean   :33.95  \n 3rd Qu.: 13.0000   3rd Qu.:55.00   3rd Qu.:39.00  \n Max.   : 80.0000   Max.   :91.00   Max.   :62.00  \n\n# shorter alternative\nliga |&gt;\n  select(Season, Position, Played:Pts_pre_95) |&gt;\n  summary()\n\n     Season        Position          Played            W        \n Min.   :1963   Min.   : 1.000   Min.   :30.00   Min.   : 2.00  \n 1st Qu.:1976   1st Qu.: 5.000   1st Qu.:34.00   1st Qu.: 9.75  \n Median :1989   Median : 9.000   Median :34.00   Median :12.00  \n Mean   :1989   Mean   : 9.486   Mean   :33.95   Mean   :12.61  \n 3rd Qu.:2002   3rd Qu.:14.000   3rd Qu.:34.00   3rd Qu.:15.00  \n Max.   :2015   Max.   :20.000   Max.   :38.00   Max.   :29.00  \n       D                L               GF               GA      \n Min.   : 2.000   Min.   : 1.00   Min.   : 15.00   Min.   :10.0  \n 1st Qu.: 7.000   1st Qu.:10.00   1st Qu.: 42.00   1st Qu.:43.0  \n Median : 9.000   Median :13.00   Median : 50.00   Median :51.0  \n Mean   : 8.733   Mean   :12.61   Mean   : 52.01   Mean   :51.7  \n 3rd Qu.:11.000   3rd Qu.:15.00   3rd Qu.: 61.00   3rd Qu.:60.0  \n Max.   :18.000   Max.   :28.00   Max.   :101.00   Max.   :93.0  \n       GD               Points        Pts_pre_95   \n Min.   :-60.0000   Min.   :10.00   Min.   : 8.00  \n 1st Qu.:-13.0000   1st Qu.:38.00   1st Qu.:29.00  \n Median : -2.0000   Median :44.00   Median :33.00  \n Mean   :  0.3015   Mean   :46.56   Mean   :33.95  \n 3rd Qu.: 13.0000   3rd Qu.:55.00   3rd Qu.:39.00  \n Max.   : 80.0000   Max.   :91.00   Max.   :62.00  \n\n# shortest alternative\nliga |&gt;\n  select(-Team) |&gt;\n  filter(Season == 1999 | Season == 2010) |&gt;\n  summary()\n\n     Season        Position        Played         W               D         \n Min.   :1999   Min.   : 1.0   Min.   :34   Min.   : 4.00   Min.   : 3.000  \n 1st Qu.:1999   1st Qu.: 5.0   1st Qu.:34   1st Qu.: 9.75   1st Qu.: 6.000  \n Median :2004   Median : 9.5   Median :34   Median :12.00   Median : 8.000  \n Mean   :2004   Mean   : 9.5   Mean   :34   Mean   :12.83   Mean   : 8.333  \n 3rd Qu.:2010   3rd Qu.:14.0   3rd Qu.:34   3rd Qu.:14.25   3rd Qu.:10.250  \n Max.   :2010   Max.   :18.0   Max.   :34   Max.   :23.00   Max.   :15.000  \n       L               GF              GA              GD        \n Min.   : 3.00   Min.   :31.00   Min.   :22.00   Min.   :-34.00  \n 1st Qu.:10.75   1st Qu.:41.00   1st Qu.:44.00   1st Qu.:-10.25  \n Median :13.00   Median :47.00   Median :48.50   Median : -3.00  \n Mean   :12.83   Mean   :49.42   Mean   :49.42   Mean   :  0.00  \n 3rd Qu.:16.00   3rd Qu.:54.25   3rd Qu.:59.00   3rd Qu.:  4.75  \n Max.   :21.00   Max.   :81.00   Max.   :71.00   Max.   : 45.00  \n     Points        Pts_pre_95   \n Min.   :22.00   Min.   :18.00  \n 1st Qu.:39.75   1st Qu.:29.75  \n Median :44.00   Median :32.00  \n Mean   :46.83   Mean   :34.00  \n 3rd Qu.:50.75   3rd Qu.:37.50  \n Max.   :75.00   Max.   :52.00  \n\n# Most points ever received by a team\nliga |&gt;\n  filter(Points == max(Points))\n\n# A tibble: 1 × 12\n  Season Position Team         Played     W     D     L    GF    GA    GD Points\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   2012        1 FC Bayern M…     34    29     4     1    98    18    80     91\n# ℹ 1 more variable: Pts_pre_95 &lt;dbl&gt;\n\n# Show only the team name\nliga |&gt;\n  filter(Points == max(Points)) |&gt;\n  select(Team) |&gt;\n  print()\n\n# A tibble: 1 × 1\n  Team              \n  &lt;chr&gt;             \n1 FC Bayern Muenchen\n\n# remove the variable `Pts_pre_95` from the data\nliga_post95 &lt;- liga |&gt;\n  select(-Pts_pre_95)\n\n# rename W, D, and L to Win, Draw, and Loss\n# additionally rename GF, GA, GD to Goals_shot, Goals_received, Goal_difference\nliga_longnames &lt;- liga |&gt;\n  rename(Win = W, Draw = D, Loss = L) |&gt;\n  rename(Goals_shot = GF, Goals_received = GA, Goal_difference = GD)\n\n# Remove the variable `Pts_pre_95` from `liga`\n# additionally remove all observations before the year 1996\nliga_no3point &lt;- liga |&gt;\n  select(-Pts_pre_95) |&gt;\n  filter(Season &gt;= 1996)\n\n# Remove the objects liga_post95, liga_longnames, and liga_no3point from the environment\nrm(liga_post95, liga_longnames, liga_no3point)\n\n# Rename all variables of `liga`to lower cases and store it as `dfb`\ndfb &lt;- liga |&gt;\n  rename_all(tolower)\n\n# Show the winner and the runner up after 2010\n# additionally show the points\ndfb |&gt;\n  filter(season &gt; 2010) |&gt;\n  group_by(season) |&gt;\n  arrange(desc(points)) |&gt;\n  slice_head(n = 2) |&gt;\n  select(team, points, position)\n\n# A tibble: 10 × 4\n# Groups:   season [5]\n   season team               points position\n    &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n 1   2011 Borussia Dortmund      81        1\n 2   2011 FC Bayern Muenchen     73        2\n 3   2012 FC Bayern Muenchen     91        1\n 4   2012 Borussia Dortmund      66        2\n 5   2013 FC Bayern Muenchen     90        1\n 6   2013 Borussia Dortmund      71        2\n 7   2014 FC Bayern Muenchen     79        1\n 8   2014 VfL Wolfsburg          69        2\n 9   2015 FC Bayern Muenchen     88        1\n10   2015 Borussia Dortmund      78        2\n\n# Create a variable that counts how often a team was ranked first\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(meister_count = sum(position == 1))\n\n# How often has each team played in the Bundesliga\ntable(liga$Team)\n\n\n     1. FC Dynamo Dresden      1. FC Kaiserslautern               1. FC Koeln \n                        1                        44                        45 \n          1. FC Nuernberg        1. FC Saarbruecken           1. FSV Mainz 05 \n                       32                         5                        10 \n         Alemannia Aachen         Arminia Bielefeld       Bayer 04 Leverkusen \n                        4                        17                        30 \n     Blau-Weiss 90 Berlin         Borussia Dortmund Borussia Moenchengladbach \n                        1                        49                        48 \n     Borussia Neunkirchen            Dynamo Dresden    Eintracht Braunschweig \n                        3                         3                        21 \n      Eintracht Frankfurt           Energie Cottbus             FC 08 Homburg \n                       47                         6                         2 \n              FC Augsburg        FC Bayern Muenchen          FC Hansa Rostock \n                        5                        51                         1 \n               FC Homburg          FC Ingolstadt 04             FC Schalke 04 \n                        1                         1                        48 \n             FC St. Pauli       Fortuna Duesseldorf              Hamburger SV \n                        8                        23                        53 \n              Hannover 96             Hansa Rostock                Hertha BSC \n                       28                        11                        33 \n            Karlsruher SC          KFC Uerdingen 05         Kickers Offenbach \n                       24                        14                         7 \n           Meidericher SV              MSV Duisburg         Preussen Muenster \n                        3                        25                         1 \n          Rot-Weiss Essen      Rot-Weiss Oberhausen          SC Fortuna Koeln \n                        7                         3                         1 \n              SC Freiburg           SC Paderborn 07   SC Rot-Weiss Oberhausen \n                       16                         1                         1 \n  SC Tasmania 1900 Berlin        SG Wattenscheid 09     SpVgg Greuther Fuerth \n                        1                         4                         1 \n       SpVgg Unterhaching              SSV Ulm 1846       Stuttgarter Kickers \n                        2                         1                         2 \n          SV Darmstadt 98       SV Waldhof Mannheim          SV Werder Bremen \n                        3                         7                         1 \n   Tennis Borussia Berlin       TSG 1899 Hoffenheim         TSV 1860 Muenchen \n                        2                         8                        20 \n  TSV Bayer 04 Leverkusen               VfB Leipzig             VfB Stuttgart \n                        7                         1                        51 \n               VfL Bochum             VfL Wolfsburg             Werder Bremen \n                       34                        19                        51 \n           Wuppertaler SV \n                        3 \n\n# Make a ranking\ndfb |&gt;\n  group_by(team) |&gt;\n  summarise(appearances = n_distinct(season)) |&gt;\n  arrange(desc(appearances)) |&gt;\n  print(n = Inf)\n\n# A tibble: 61 × 2\n   team                      appearances\n   &lt;chr&gt;                           &lt;int&gt;\n 1 Hamburger SV                       53\n 2 FC Bayern Muenchen                 51\n 3 VfB Stuttgart                      51\n 4 Werder Bremen                      51\n 5 Borussia Dortmund                  49\n 6 Borussia Moenchengladbach          48\n 7 FC Schalke 04                      48\n 8 Eintracht Frankfurt                47\n 9 1. FC Koeln                        45\n10 1. FC Kaiserslautern               44\n11 VfL Bochum                         34\n12 Hertha BSC                         33\n13 1. FC Nuernberg                    32\n14 Bayer 04 Leverkusen                30\n15 Hannover 96                        28\n16 MSV Duisburg                       25\n17 Karlsruher SC                      24\n18 Fortuna Duesseldorf                23\n19 Eintracht Braunschweig             21\n20 TSV 1860 Muenchen                  20\n21 VfL Wolfsburg                      19\n22 Arminia Bielefeld                  17\n23 SC Freiburg                        16\n24 KFC Uerdingen 05                   14\n25 Hansa Rostock                      11\n26 1. FSV Mainz 05                    10\n27 FC St. Pauli                        8\n28 TSG 1899 Hoffenheim                 8\n29 Kickers Offenbach                   7\n30 Rot-Weiss Essen                     7\n31 SV Waldhof Mannheim                 7\n32 TSV Bayer 04 Leverkusen             7\n33 Energie Cottbus                     6\n34 1. FC Saarbruecken                  5\n35 FC Augsburg                         5\n36 Alemannia Aachen                    4\n37 SG Wattenscheid 09                  4\n38 Borussia Neunkirchen                3\n39 Dynamo Dresden                      3\n40 Meidericher SV                      3\n41 Rot-Weiss Oberhausen                3\n42 SV Darmstadt 98                     3\n43 Wuppertaler SV                      3\n44 FC 08 Homburg                       2\n45 SpVgg Unterhaching                  2\n46 Stuttgarter Kickers                 2\n47 Tennis Borussia Berlin              2\n48 1. FC Dynamo Dresden                1\n49 Blau-Weiss 90 Berlin                1\n50 FC Hansa Rostock                    1\n51 FC Homburg                          1\n52 FC Ingolstadt 04                    1\n53 Preussen Muenster                   1\n54 SC Fortuna Koeln                    1\n55 SC Paderborn 07                     1\n56 SC Rot-Weiss Oberhausen             1\n57 SC Tasmania 1900 Berlin             1\n58 SSV Ulm 1846                        1\n59 SV Werder Bremen                    1\n60 SpVgg Greuther Fuerth               1\n61 VfB Leipzig                         1\n\n# Add a variable to `dfb` that contains the number of appearances of a team in the league\ndfb &lt;- dfb |&gt;\n  group_by(team) |&gt;\n  mutate(appearances = n_distinct(season))\n\n# create a number that indicates how often a team has played Bundesliga in a given year\ndfb &lt;- dfb |&gt;\n  arrange(team, season) |&gt;\n  group_by(team) |&gt;\n  mutate(team_in_liga_count = row_number())\n\n# Make a ranking with the number of titles of all teams that ever won the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  filter(meister_count != 0) |&gt;\n  arrange(desc(meister_count)) |&gt;\n  select(meister_count, team)\n\n# A tibble: 12 × 2\n# Groups:   team [12]\n   meister_count team                     \n           &lt;int&gt; &lt;chr&gt;                    \n 1            25 FC Bayern Muenchen       \n 2             5 Borussia Dortmund        \n 3             5 Borussia Moenchengladbach\n 4             4 Werder Bremen            \n 5             3 Hamburger SV             \n 6             3 VfB Stuttgart            \n 7             2 1. FC Kaiserslautern     \n 8             2 1. FC Koeln              \n 9             1 1. FC Nuernberg          \n10             1 Eintracht Braunschweig   \n11             1 TSV 1860 Muenchen        \n12             1 VfL Wolfsburg            \n\n# Create a numeric identifying variable for each team\ndfb_teamid &lt;- dfb |&gt;\n  mutate(team_id = as.numeric(factor(team)))\n\n# When a team is in the league, what is the probability that it wins the league\ndfb |&gt;\n  filter(team_in_liga_count == 1) |&gt;\n  mutate(prob_win = meister_count / appearances) |&gt;\n  filter(prob_win &gt; 0) |&gt;\n  arrange(desc(prob_win)) |&gt;\n  select(meister_count, prob_win, team)\n\n# A tibble: 12 × 3\n# Groups:   team [12]\n   meister_count prob_win team                     \n           &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                    \n 1            25   0.490  FC Bayern Muenchen       \n 2             5   0.104  Borussia Moenchengladbach\n 3             5   0.102  Borussia Dortmund        \n 4             4   0.0784 Werder Bremen            \n 5             3   0.0588 VfB Stuttgart            \n 6             3   0.0566 Hamburger SV             \n 7             1   0.0526 VfL Wolfsburg            \n 8             1   0.05   TSV 1860 Muenchen        \n 9             1   0.0476 Eintracht Braunschweig   \n10             2   0.0455 1. FC Kaiserslautern     \n11             2   0.0444 1. FC Koeln              \n12             1   0.0312 1. FC Nuernberg          \n\n# make a scatterplot with points on the y-axis and position on the x-axis\nggplot(dfb, aes(x = position, y = points)) +\n  geom_point()\n\n\n\n\n\n\n\n# Make a scatterplot with points on the y-axis and position on the x-axis.\n# Additionally, only consider seasons with 18 teams and\n# add lines that make clear how many points you needed to be placed\n# in between rank 2 and 15.\ndfb_18 &lt;- dfb |&gt;\n  group_by(season) |&gt;\n  mutate(teams_in_league = n_distinct(team)) |&gt;\n  filter(teams_in_league == 18)\n\nh_1 &lt;- dfb_18 |&gt;\n  filter(position == 16) |&gt;\n  mutate(ma = max(points))\n\nmax_points_rank_16 &lt;- max(h_1$ma) + 1\n\nh_2 &lt;- dfb_18 |&gt;\n  filter(position == 2) |&gt;\n  mutate(mb = max(points))\n\nmin_points_rank_2 &lt;- max(h_2$mb) + 1\n\ndfb_18 &lt;- dfb_18 |&gt;\n  mutate(season_category = case_when(\n    season &lt; 1970 ~ 1,\n    between(season, 1970, 1979) ~ 2,\n    between(season, 1980, 1989) ~ 3,\n    between(season, 1990, 1999) ~ 4,\n    between(season, 2000, 2009) ~ 5,\n    between(season, 2010, 2019) ~ 6,\n    TRUE ~ 7 # Adjust this line based on the actual range of your data\n  ))\n\nggplot(dfb_18, aes(x = position, y = points)) +\n  geom_point() +\n  labs(\n    title = \"Scatterplot of Points and Position\",\n    x = \"Position\",\n    y = \"Points\"\n  ) +\n  geom_vline(xintercept = c(1.5, 15.5), linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = max_points_rank_16, linetype = \"dashed\", color = \"blue\") +\n  geom_hline(yintercept = min_points_rank_2, linetype = \"dashed\", color = \"blue\") +\n  scale_y_continuous(breaks = c(min_points_rank_2, max_points_rank_16, seq(0, max(dfb_18$points), by = 5))) +\n  scale_x_continuous(breaks = c(seq(0, max(dfb_18$points), by = 1))) +\n  theme_classic()\n\n\n\n\n\n\n\n# Remove all objects except liga and dfb\nrm(list = setdiff(ls(), c(\"liga\", \"dfb\")))\n\n# Rank \"1. FC Kaiserslautern\" over time\ndfb_bal &lt;- dfb |&gt;\n  select(season, team, position) |&gt;\n  as_tibble() |&gt;\n  complete(season, team)\n\ntable(dfb_bal$team)\n\n\n     1. FC Dynamo Dresden      1. FC Kaiserslautern               1. FC Koeln \n                       53                        53                        53 \n          1. FC Nuernberg        1. FC Saarbruecken           1. FSV Mainz 05 \n                       53                        53                        53 \n         Alemannia Aachen         Arminia Bielefeld       Bayer 04 Leverkusen \n                       53                        53                        53 \n     Blau-Weiss 90 Berlin         Borussia Dortmund Borussia Moenchengladbach \n                       53                        53                        53 \n     Borussia Neunkirchen            Dynamo Dresden    Eintracht Braunschweig \n                       53                        53                        53 \n      Eintracht Frankfurt           Energie Cottbus             FC 08 Homburg \n                       53                        53                        53 \n              FC Augsburg        FC Bayern Muenchen          FC Hansa Rostock \n                       53                        53                        53 \n               FC Homburg          FC Ingolstadt 04             FC Schalke 04 \n                       53                        53                        53 \n             FC St. Pauli       Fortuna Duesseldorf              Hamburger SV \n                       53                        53                        53 \n              Hannover 96             Hansa Rostock                Hertha BSC \n                       53                        53                        53 \n            Karlsruher SC          KFC Uerdingen 05         Kickers Offenbach \n                       53                        53                        53 \n           Meidericher SV              MSV Duisburg         Preussen Muenster \n                       53                        53                        53 \n          Rot-Weiss Essen      Rot-Weiss Oberhausen          SC Fortuna Koeln \n                       53                        53                        53 \n              SC Freiburg           SC Paderborn 07   SC Rot-Weiss Oberhausen \n                       53                        53                        53 \n  SC Tasmania 1900 Berlin        SG Wattenscheid 09     SpVgg Greuther Fuerth \n                       53                        53                        53 \n       SpVgg Unterhaching              SSV Ulm 1846       Stuttgarter Kickers \n                       53                        53                        53 \n          SV Darmstadt 98       SV Waldhof Mannheim          SV Werder Bremen \n                       53                        53                        53 \n   Tennis Borussia Berlin       TSG 1899 Hoffenheim         TSV 1860 Muenchen \n                       53                        53                        53 \n  TSV Bayer 04 Leverkusen               VfB Leipzig             VfB Stuttgart \n                       53                        53                        53 \n               VfL Bochum             VfL Wolfsburg             Werder Bremen \n                       53                        53                        53 \n           Wuppertaler SV \n                       53 \n\ndfb_fck &lt;- dfb_bal |&gt;\n  filter(team == \"1. FC Kaiserslautern\")\n\nggplot(dfb_fck, aes(x = season, y = position)) +\n  geom_point() +\n  geom_line() +\n  scale_y_reverse(breaks = seq(1, 18, by = 1))\n\n\n\n\n\n\n\n# Make the plot nice\n\n# consider different rules for having to leave the league:\ndfb_fck &lt;- dfb_fck |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown))\n\n\nggplot(dfb_fck, aes(x = season)) +\n  geom_point(aes(y = position)) +\n  geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 18, by = 1)) +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"blue\")\n\n\n\n\n\n\n\ndfb_bal &lt;- dfb_bal |&gt;\n  mutate(godown = ifelse(season &lt;= 1964, 14.5, NA)) |&gt;\n  mutate(godown = ifelse(season &gt; 1964 & season &lt;= 1973, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1973 & season &lt;= 1980, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1980 & season &lt;= 1990, 16, godown)) |&gt;\n  mutate(godown = ifelse(season == 1991, 16.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 1991 & season &lt;= 2008, 15.5, godown)) |&gt;\n  mutate(godown = ifelse(season &gt; 2008, 16, godown)) |&gt;\n  mutate(inliga = ifelse(is.na(position), 0, 1))\n\n\n\nrank_plot &lt;- ggplot(dfb_bal, aes(x = season)) +\n  geom_point(aes(y = position), shape = 1) +\n  # geom_line(aes(y = position)) +\n  geom_point(aes(y = godown), shape = 25) +\n  scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n  xlim(1963, 2015) +\n  theme(panel.grid.minor = element_blank()) +\n  geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n  geom_point(aes(y = position), shape = 1)\n\nrank_plot\n\n\n\n\n\n\n\n# !--&gt; in 1979 is a gap! Error?\n# No. Reason: two clubs shared the third place.\n\nrank_plot +\n  facet_wrap(~team)\n\n\n\n\n\n\n\n# Create \"test\" directory if it doesn't already exist\nif (!dir.exists(\"test\")) {\n  dir.create(\"test\")\n}\n\n\nplots &lt;- list()\nfor (club in unique(dfb_bal$team)) {\n  dfb_subset &lt;- subset(dfb_bal, team == club)\n\n  p &lt;- ggplot(dfb_subset, aes(x = season)) +\n    geom_point(aes(y = position), shape = 15) +\n    geom_line(aes(y = position)) +\n    geom_point(aes(y = godown), shape = 25) +\n    scale_y_reverse(breaks = seq(1, 20, by = 1), limits = c(20, 1)) +\n    xlim(1963, 2015) +\n    theme(panel.grid.minor = element_blank()) +\n    geom_hline(yintercept = 1.5, linetype = \"dashed\", color = \"gray\") +\n    geom_point(aes(y = position), shape = 1) +\n    labs(title = paste(\"Ranking History:\", club))\n  ggsave(filename = paste(\"test/r_\", club, \".png\", sep = \"\"))\n  plots[[club]] &lt;- p\n}\n\nprint(plots$`Meidericher SV`)\n\n\n\n\n\n\n\nprint(plots$`1. FC Koeln`)\n\n\n\n\n\n\n\n# unload packages\nsuppressMessages(pacman::p_unload(\n  bundesligR,\n  tidyverse\n))\n\n# Remove the \"test\" directory and its contents after saving all graphs\nunlink(\"test\", recursive = TRUE)",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#okuns-law",
    "href": "80_exercises.html#okuns-law",
    "title": "9  Collection of exercises",
    "section": "9.14 Okun’s Law",
    "text": "9.14 Okun’s Law\nSuppose you aim to empirically examine unemployment and GDP for Germany and France. The data set that we use in the following is ‘forest.Rdata’ and should already been known to you from the lecture.\n\nWrite down your name, matriculation number, and date.\nSet your working directory.\n\n\nClear your global environment.\n\n\nInstall and load the following packages: ‘tidyverse’, ‘sjPlot’, and ‘ggpubr’\n\n\nDownload and load the data, respectively, with the following code:\n\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nIf that is not working, you can also download the data from ILIAS, save it in your working directory and load it from there with:\nload(\"forest.Rdata\")\n\nShow the first eight observations of the dataset df.\nShow the last observation of the dataset df.\nWhich type of data do we have here (Panel, cross-section,time series, …)? Name the variable(s) that are necessary to identify the observations in the dataset.\nExplain what the assignment operator in R is and what it is good for.\nWrite down the R code to store the number of observations and the number of variables that are in the dataset df. Name the object in which you store these numbers observations_df.\nIn the dataset df, rename the variable ‘country.x’ to ‘nation’ and the variable ‘date’ to ‘year’.\nExplain what the pipe operator in R is and what it is good for.\nFor the upcoming analysis you are only interested the following variables that are part of the dataframe df: nation, year, gdp, pop, gdppc, and unemployment. Drop all other variables from the dataframe df.\nCreate a variable that indicates the GDP per capita (‘gdp’ divided by ‘pop’). Name the variable ‘gdp_pc’. (Hint: If you fail here, use the variable ‘gdppc’ which is already in the dataset as a replacement for ‘gdp_pc’ in the following tasks.)\nFor the upcoming analysis you are only interested the following countries that are part of the dataframe df: Germany and France. Drop all other countries from the dataframe df.\nCreate a table showing the average unemployment rate and GDP per capita for Germany and France in the given years. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\n\n\nCreate a table showing the unemployment rate and GDP per capita for Germany and France in the year 2020. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\n\n\nCreate a table showing the highest unemployment rate and the highest GDP per capita for Germany and France during the given period. Use the pipe operator. (Hint: See below for how your results should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\n\n\nCalculate the standard deviation of the unemployment rate and GDP per capita for Germany and France in the given years. (Hint: See below for how your result should look like.)\n\n\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\n\n\nIn statistics, the coefficient of variation (COV) is a standardized measure of dispersion. It is defined as the ratio of the standard deviation (\\(\\sigma\\)) to the mean (\\(\\mu\\)): \\(COV={\\frac {\\sigma }{\\mu }}\\). Write down the R code to calculate the coefficient of variation (COV) for the unemployment rate in Germany and France. (Hint: See below for what your result should should look like.)\n\n\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\n\n\nWrite down the R code to calculate the coefficient of variation (COV) for the GDP per capita in Germany and France. (Hint: See below for what your result should should look like.)\n\nlook like.)\n\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\n\n\nCreate a chart (bar chart, line chart, or scatter plot) that shows the unemployment rate of Germany over the available years. Label the chart ‘Germany’ with ggtitle(\"Germany\"). Please note that you may choose any type of graphical representation. (Hint: Below you can see one of many possible examples of what your result may look like).\n\n\n\n\n\n\n\n\n\n\n\nand 23. (This task is worth 10 points) The following chart shows the simultaneous development of the unemployment rate and GDP per capita over time for France.\n\n\n\n\n\n\n\n\n\n\nSuppose you want to visualize the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany as well.\nSuppose further that you have found the following lines of code that create the kind of chart you are looking for.\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\n\nUse these lines of code and customize them to create the co-movement visualization for Germany using the available df data. The result should look something like this:\n\n\n\n\n\n\n\n\n\n\nInterpret the two graphs above, which show the simultaneous evolution of the unemployment rate and GDP per capita over time for Germany and France. What are your expectations regarding the correlation between the unemployment rate and GDP per capita variables? Can you see this expectation in the figures? Discuss.\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, c, dim, filter, geom_line, ggplot, ggtitle, group_by, head, load, max, mean, mutate, plot, rename, sd, select, summarise, tail, text, title, url.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\ntail(df, 1)\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\ndf_pger &lt;- df |&gt;\n  filter(nation == \"Germany\")\n\npger &lt;- ggplot(df_pger, aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\nplot(pger)\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# setwd(\"/home/sthu/Dropbox/hsf/exams/22-11/scr/\")\n\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, ggpubr, sjPlot)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/forest.Rdata\"))\n\nhead(df, 8)\n\n# A tibble: 8 × 11\n# Groups:   country.x [1]\n  country.x     date     gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 United Arab…  1992 1.26e11     -2.48          1.84 Middl… High …   3.63 2.05e6\n2 United Arab…  1993 1.27e11     -4.34          1.85 Middl… High …   3.72 2.17e6\n3 United Arab…  1994 1.36e11      1.25          1.81 Middl… High …   3.81 2.29e6\n4 United Arab…  1995 1.45e11      1.35          1.80 Middl… High …   3.90 2.42e6\n5 United Arab…  1996 1.54e11      0.631         1.90 Middl… High …   3.99 2.54e6\n6 United Arab…  1997 1.66e11      2.83          1.98 Middl… High …   4.08 2.67e6\n7 United Arab…  1998 1.67e11     -4.77          2.14 Middl… High …   4.18 2.81e6\n8 United Arab…  1999 1.72e11     -2.40          2.22 Middl… High …   4.27 2.97e6\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\ntail(df, 1)\n\n# A tibble: 1 × 11\n# Groups:   country.x [1]\n  country.x  date        gdp gdp_growth unemployment region income forest    pop\n  &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Zimbabwe   2020    1.94e10      -7.62         5.35 Sub-S… Lower…   45.1 1.49e7\n# ℹ 2 more variables: unemployment_dif &lt;dbl&gt;, gdppc &lt;dbl&gt;\n\n# panel data set\n# date and country.x\n\nobservations_df &lt;- dim(df)\n\ndf &lt;- rename(df, nation = country.x)\ndf &lt;- rename(df, year = date)\n\ndf &lt;- df |&gt;\n  select(nation, year, gdp, pop, gdppc, unemployment)\n\ndf &lt;- df |&gt;\n  mutate(gdp_pc = gdp / pop)\n\ndf &lt;- df |&gt; filter(nation == \"Germany\" | nation == \"France\")\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  9.75        34356.\n2 Germany                 7.22        36739.\n\ndf |&gt;\n  filter(year == 2020) |&gt;\n  group_by(nation) |&gt;\n  summarise(mean(unemployment), mean(gdppc))\n\n# A tibble: 2 × 3\n  nation  `mean(unemployment)` `mean(gdppc)`\n  &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 France                  8.01        35786.\n2 Germany                 3.81        41315.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(max(unemployment), max(gdppc))\n\n# A tibble: 2 × 3\n  nation  `max(unemployment)` `max(gdppc)`\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n1 France                 12.6       38912.\n2 Germany                11.2       43329.\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), sd(unemployment))\n\n# A tibble: 2 × 3\n  nation  `sd(gdppc)` `sd(unemployment)`\n  &lt;chr&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n1 France        2940.               1.58\n2 Germany       4015.               2.37\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(unemployment), mean(unemployment), cov = sd(unemployment) / mean(unemployment))\n\n# A tibble: 2 × 4\n  nation  `sd(unemployment)` `mean(unemployment)`   cov\n  &lt;chr&gt;                &lt;dbl&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 France                1.58                 9.75 0.162\n2 Germany               2.37                 7.22 0.328\n\ndf |&gt;\n  group_by(nation) |&gt;\n  summarise(sd(gdppc), mean(gdppc), cov = sd(gdppc) / mean(gdppc))\n\n# A tibble: 2 × 4\n  nation  `sd(gdppc)` `mean(gdppc)`    cov\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 France        2940.        34356. 0.0856\n2 Germany       4015.        36739. 0.109 \n\ndf_pger &lt;- df |&gt;\n  filter(nation == \"Germany\")\n\npger &lt;- ggplot(df_pger, aes(x = year, y = unemployment)) +\n  geom_line() +\n  ggtitle(\"Germany\")\n\nplot(pger)\n\n\n\n\n\n\n\nlabels &lt;- 1992:2020\ndfra &lt;- df |&gt; filter(nation == \"France\")\nplot(dfra$gdppc, dfra$unemployment,\n  type = \"b\",\n  xlab = \"GDP per capita\", ylab = \"Unemployment rate\"\n)\ntext(dfra$gdppc + 0.1, dfra$unemployment + 0.1, labels)\ntitle(\"France\")\n\n\n\n\n\n\n\n# Data\nx &lt;- c(1, 2, 3, 4, 5, 4, 7, 8, 9)\ny &lt;- c(12, 16, 14, 18, 16, 13, 15, 20, 22)\nlabels &lt;- 1970:1978\n\n# Connected scatter plot with text\nplot(x, y, type = \"b\", xlab = \"Var 1\", ylab = \"Var 2\")\ntext(x + 0.4, y + 0.1, labels)\n\n\n\n\n\n\n\ndfger &lt;- df |&gt; filter(nation == \"Germany\")\nlabels &lt;- 1992:2020\nplot(dfger$gdppc, dfger$unemployment,\n  type = \"b\",\n  xlab = \"Var 1\", ylab = \"Var 2\"\n)\ntext(dfger$gdppc + 0.7, dfger$unemployment + 0.4, labels)\ntitle(\"Germany\")\n\n\n\n\n\n\n\nsuppressMessages(pacman::p_unload(tidyverse, ggpubr, sjPlot))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#sec-exe_duplicates",
    "href": "80_exercises.html#sec-exe_duplicates",
    "title": "9  Collection of exercises",
    "section": "9.15 Names and duplicates",
    "text": "9.15 Names and duplicates\n\nLoad the required packages (pacman, tidyverse, janitor, babynames, stringr).\nLoad the dataset from the URL: https://github.com/hubchev/courses/raw/main/dta/df_names.RData. Make yourself familiar with the data.\nAfter loading the dataset, remove all objects except df_2022 and df_2022_error.\nReorder the data using the relocate function so that surname, name, and age appear first. Save the changed data in a tibble called df.\nSort the data according to surname, name, and age.\nMake a variable named born that contains the year of birth. How is the born variable calculated?\nCreate a new variable named id that identifies each person by surname, name, and their birth year (born). Why is this identifier useful?\nInvestigate how the data is identified. Are there any duplicates? If so, can you think of strategies to identify and how to deal with these duplicates.\nUnload the packages used in the script. Why is unloading packages considered good practice?\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: anti_join, arrange, c, cur_group_id, desc, dim, distinct, filter, get_dupes, glimpse, group_by, head, load, max, mutate, n, paste, relocate, row_number, setdiff, summary, tail, ungroup, url.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# Find duplicates\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/test/initial_script\")\n\n# clear environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, babynames, stringr)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/df_names.RData\"))\n\n# Remove all objects except df_2022 and df_2022_error\nrm(list = setdiff(ls(), c(\"df_2022_error\", \"df_2022\")))\n\n# Re-order the data so that surname, name, and age appears first.\n# Save the changed data in a tibble called `df`.\ndf &lt;- df_2022 |&gt;\n  relocate(surname, name, age)\n\n# Sort the data according to surname, name, and age.\ndf &lt;- df |&gt;\n  arrange(surname, name, age)\n\n# Inspect df_2022 and df_2022_error\ndf\ndim(df)\nhead(df)\ntail(df)\nglimpse(df)\nsummary(df)\n\ndf_2022_error\n\n# Make a variable that contains the year of birth. Name the variable `born`\n# and new dataframe `df`.\ndf &lt;- df_2022 |&gt;\n  mutate(born = time - age)\n\n# Make a new variable that identifies each person by surname, name,\n# and their birth born. Name the variable `id`.\ndf &lt;- df |&gt;\n  mutate(id = paste(surname, name, born, sep = \"_\"))\n\n# How many different groups do exist?\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(id_num = cur_group_id()) |&gt;\n  ungroup()\n\nmax(df$id_num)\n\n# Show groups that exist more than once.\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(\n    dup_count = row_number(),\n    dup_sum   = n()\n  ) |&gt;\n  ungroup() |&gt;\n  arrange(id)\n\ndf |&gt; filter(dup_sum &gt; 1)\ndf |&gt; get_dupes(name, surname)\n\n# Make yourself familiar with the function `get_dupes()` from `janitor` package.\ndf |&gt; get_dupes()\ndf |&gt; get_dupes(surname, name)\ndf |&gt; get_dupes(id)\n\ndf_uni &lt;- df |&gt;\n  arrange() |&gt;\n  distinct(id, .keep_all = TRUE)\n\ndf_uni_b &lt;- df |&gt;\n  arrange(desc(dup_count)) |&gt;\n  distinct(id, .keep_all = TRUE)\n\nanti_join(df, df_uni)\nanti_join(df, df_uni_b)\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, janitor, babynames, stringr))\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# Find duplicates\n\n# set working directory\n# setwd(\"~/Dropbox/hsf/test/initial_script\")\n\n# clear environment\nrm(list = ls())\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, babynames, stringr)\n\nload(url(\"https://github.com/hubchev/courses/raw/main/dta/df_names.RData\"))\n\n# Remove all objects except df_2022 and df_2022_error\nrm(list = setdiff(ls(), c(\"df_2022_error\", \"df_2022\")))\n\n# Re-order the data so that surname, name, and age appears first.\n# Save the changed data in a tibble called `df`.\ndf &lt;- df_2022 |&gt;\n  relocate(surname, name, age)\n\n# Sort the data according to surname, name, and age.\ndf &lt;- df |&gt;\n  arrange(surname, name, age)\n\n# Inspect df_2022 and df_2022_error\ndf\n\n# A tibble: 1,018 × 8\n   surname name       age sex      cm  time error error_desc\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n 1 Adams   Adonnis     30 M      192   2022     0 &lt;NA&gt;      \n 2 Adams   Adonnis     30 M      192   2022     1 duplicate \n 3 Adams   Aila        79 F      157   2022     0 &lt;NA&gt;      \n 4 Adams   Avenelle    69 F      157   2022     0 &lt;NA&gt;      \n 5 Adams   Brysan      39 M      192   2022     0 &lt;NA&gt;      \n 6 Adams   Eona        84 F      157   2022     0 &lt;NA&gt;      \n 7 Adams   Eveline     42 F      157   2022     0 &lt;NA&gt;      \n 8 Adams   Faithe      17 F      172.  2022     0 &lt;NA&gt;      \n 9 Adams   Ineisha     47 F      157   2022     0 &lt;NA&gt;      \n10 Adams   Kloeigh     31 F      157   2022     0 &lt;NA&gt;      \n# ℹ 1,008 more rows\n\ndim(df)\n\n[1] 1018    8\n\nhead(df)\n\n# A tibble: 6 × 8\n  surname name       age sex      cm  time error error_desc\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Adams   Adonnis     30 M       192  2022     0 &lt;NA&gt;      \n2 Adams   Adonnis     30 M       192  2022     1 duplicate \n3 Adams   Aila        79 F       157  2022     0 &lt;NA&gt;      \n4 Adams   Avenelle    69 F       157  2022     0 &lt;NA&gt;      \n5 Adams   Brysan      39 M       192  2022     0 &lt;NA&gt;      \n6 Adams   Eona        84 F       157  2022     0 &lt;NA&gt;      \n\ntail(df)\n\n# A tibble: 6 × 8\n  surname name       age sex      cm  time error error_desc                     \n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                          \n1 Young   Leiliana    54 F     157    2022     0 &lt;NA&gt;                           \n2 Young   Shamar      23 M     192    2022     0 &lt;NA&gt;                           \n3 Young   Tajanay      1 F      81.5  2022     0 &lt;NA&gt;                           \n4 huber   Stephan    186 M      41    2022     1 age/cm false, not capitalized …\n5 huber   Stephan     NA &lt;NA&gt;   NA    2022     1 wrong name                     \n6 &lt;NA&gt;    Zita         6 &lt;NA&gt;  110    2022     2 surname missing, sex unspecifi…\n\nglimpse(df)\n\nRows: 1,018\nColumns: 8\n$ surname    &lt;chr&gt; \"Adams\", \"Adams\", \"Adams\", \"Adams\", \"Adams\", \"Adams\", \"Adam…\n$ name       &lt;chr&gt; \"Adonnis\", \"Adonnis\", \"Aila\", \"Avenelle\", \"Brysan\", \"Eona\",…\n$ age        &lt;dbl&gt; 30, 30, 79, 69, 39, 84, 42, 17, 47, 31, 65, 80, 6, 5, 5, 20…\n$ sex        &lt;chr&gt; \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"F\",…\n$ cm         &lt;dbl&gt; 192.00000, 192.00000, 157.00000, 157.00000, 192.00000, 157.…\n$ time       &lt;dbl&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022,…\n$ error      &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ error_desc &lt;chr&gt; NA, \"duplicate\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\nsummary(df)\n\n   surname              name                age             sex           \n Length:1018        Length:1018        Min.   :  1.00   Length:1018       \n Class :character   Class :character   1st Qu.: 21.00   Class :character  \n Mode  :character   Mode  :character   Median : 43.00   Mode  :character  \n                                       Mean   : 45.75                     \n                                       3rd Qu.: 69.00                     \n                                       Max.   :399.00                     \n                                       NA's   :2                          \n       cm             time          error          error_desc       \n Min.   : 41.0   Min.   :2022   Min.   :0.00000   Length:1018       \n 1st Qu.:157.0   1st Qu.:2022   1st Qu.:0.00000   Class :character  \n Median :157.0   Median :2022   Median :0.00000   Mode  :character  \n Mean   :163.2   Mean   :2022   Mean   :0.02456                     \n 3rd Qu.:192.0   3rd Qu.:2022   3rd Qu.:0.00000                     \n Max.   :295.0   Max.   :2022   Max.   :3.00000                     \n NA's   :4                                                          \n\ndf_2022_error\n\n# A tibble: 18 × 8\n   sex   name    surname    age    cm  time error error_desc                    \n   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                         \n 1 M     Savier  Campbell    72 192    2022     1 duplicate                     \n 2 F     Tina    Adams        5  98.0  2022     1 duplicate                     \n 3 F     Abery   Allen       79 157    2022     1 duplicate                     \n 4 M     Adonnis Adams       30 192    2022     1 duplicate                     \n 5 M     Stephan Maier       41 186    2022     1 wrong surname                 \n 6 &lt;NA&gt;  Stephan huber       NA  NA    2022     1 wrong name                    \n 7 M     stephan Huber      186  41    2022     1 age/cm false, not capitalized…\n 8 M     Stephan huber      186  41    2022     1 age/cm false, not capitalized…\n 9 M     Stephan Huber       41 186    2022     1 duplicate                     \n10 M     Stephan Huber       41  NA    2022     1 duplicate, cm NA              \n11 F     Rosa    Huber        9  NA    2022     3 only age and sex given        \n12 &lt;NA&gt;  Rosa    Huber       NA 130    2022     3 age missing, sex unspecified  \n13 &lt;NA&gt;  Ignaz   Huber        7  NA    2022     2 cm missing, sex unspecified   \n14 &lt;NA&gt;  Zita    &lt;NA&gt;         6 110    2022     2 surname missing, sex unspecif…\n15 &lt;NA&gt;  Alois   Huber        3 295    2022     2 cm not possible, sex unspecif…\n16 F     Martina Huber      399 169    2022     2 age not possible              \n17 M     Stephan Huber       41 186    2022     0 no error                      \n18 M     Stephan Huber       41 186    2022     1 duplicate                     \n\n# Make a variable that contains the year of birth. Name the variable `born`\n# and new dataframe `df`.\ndf &lt;- df_2022 |&gt;\n  mutate(born = time - age)\n\n# Make a new variable that identifies each person by surname, name,\n# and their birth born. Name the variable `id`.\ndf &lt;- df |&gt;\n  mutate(id = paste(surname, name, born, sep = \"_\"))\n\n# How many different groups do exist?\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(id_num = cur_group_id()) |&gt;\n  ungroup()\n\nmax(df$id_num)\n\n[1] 1011\n\n# Show groups that exist more than once.\ndf &lt;- df |&gt;\n  group_by(id) |&gt;\n  mutate(\n    dup_count = row_number(),\n    dup_sum   = n()\n  ) |&gt;\n  ungroup() |&gt;\n  arrange(id)\n\ndf |&gt; filter(dup_sum &gt; 1)\n\n# A tibble: 12 × 13\n   sex   name    surname    age    cm  time error error_desc   born id    id_num\n   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n 1 M     Adonnis Adams       30 192    2022     0 &lt;NA&gt;         1992 Adam…      1\n 2 M     Adonnis Adams       30 192    2022     1 duplicate    1992 Adam…      1\n 3 F     Tina    Adams        5  98.0  2022     1 duplicate    2017 Adam…     13\n 4 F     Tina    Adams        5  98.0  2022     0 &lt;NA&gt;         2017 Adam…     13\n 5 F     Abery   Allen       79 157    2022     0 &lt;NA&gt;         1943 Alle…     15\n 6 F     Abery   Allen       79 157    2022     1 duplicate    1943 Alle…     15\n 7 M     Savier  Campbell    72 192    2022     0 &lt;NA&gt;         1950 Camp…    100\n 8 M     Savier  Campbell    72 192    2022     1 duplicate    1950 Camp…    100\n 9 M     Stephan Huber       41 186    2022     1 duplicate    1981 Hube…    383\n10 M     Stephan Huber       41 186    2022     0 no error     1981 Hube…    383\n11 M     Stephan Huber       41 186    2022     1 duplicate    1981 Hube…    383\n12 M     Stephan Huber       41  NA    2022     1 duplicate,…  1981 Hube…    383\n# ℹ 2 more variables: dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\ndf |&gt; get_dupes(name, surname)\n\n# A tibble: 18 × 14\n   name  surname dupe_count sex     age    cm  time error error_desc  born id   \n   &lt;chr&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1 Step… Huber            4 M        41 186    2022     1 duplicate   1981 Hube…\n 2 Step… Huber            4 M        41 186    2022     0 no error    1981 Hube…\n 3 Step… Huber            4 M        41 186    2022     1 duplicate   1981 Hube…\n 4 Step… Huber            4 M        41  NA    2022     1 duplicate…  1981 Hube…\n 5 Abery Allen            2 F        79 157    2022     0 &lt;NA&gt;        1943 Alle…\n 6 Abery Allen            2 F        79 157    2022     1 duplicate   1943 Alle…\n 7 Adon… Adams            2 M        30 192    2022     0 &lt;NA&gt;        1992 Adam…\n 8 Adon… Adams            2 M        30 192    2022     1 duplicate   1992 Adam…\n 9 Merl… Miller           2 F        12 153.   2022     0 &lt;NA&gt;        2010 Mill…\n10 Merl… Miller           2 F         2  99.9  2022     0 &lt;NA&gt;        2020 Mill…\n11 Rosa  Huber            2 F         9  NA    2022     3 only age …  2013 Hube…\n12 Rosa  Huber            2 &lt;NA&gt;     NA 130    2022     3 age missi…    NA Hube…\n13 Savi… Campbe…          2 M        72 192    2022     0 &lt;NA&gt;        1950 Camp…\n14 Savi… Campbe…          2 M        72 192    2022     1 duplicate   1950 Camp…\n15 Step… huber            2 M       186  41    2022     1 age/cm fa…  1836 hube…\n16 Step… huber            2 &lt;NA&gt;     NA  NA    2022     1 wrong name    NA hube…\n17 Tina  Adams            2 F         5  98.0  2022     1 duplicate   2017 Adam…\n18 Tina  Adams            2 F         5  98.0  2022     0 &lt;NA&gt;        2017 Adam…\n# ℹ 3 more variables: id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\n# Make yourself familiar with the function `get_dupes()` from `janitor` package.\ndf |&gt; get_dupes()\n\nNo variable names specified - using all columns.\n\n\nNo duplicate combinations found of: sex, name, surname, age, cm, time, error, error_desc, born, ... and 4 other variables\n\n\n# A tibble: 0 × 14\n# ℹ 14 variables: sex &lt;chr&gt;, name &lt;chr&gt;, surname &lt;chr&gt;, age &lt;dbl&gt;, cm &lt;dbl&gt;,\n#   time &lt;dbl&gt;, error &lt;dbl&gt;, error_desc &lt;chr&gt;, born &lt;dbl&gt;, id &lt;chr&gt;,\n#   id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;, dupe_count &lt;int&gt;\n\ndf |&gt; get_dupes(surname, name)\n\n# A tibble: 18 × 14\n   surname name  dupe_count sex     age    cm  time error error_desc  born id   \n   &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1 Huber   Step…          4 M        41 186    2022     1 duplicate   1981 Hube…\n 2 Huber   Step…          4 M        41 186    2022     0 no error    1981 Hube…\n 3 Huber   Step…          4 M        41 186    2022     1 duplicate   1981 Hube…\n 4 Huber   Step…          4 M        41  NA    2022     1 duplicate…  1981 Hube…\n 5 Adams   Adon…          2 M        30 192    2022     0 &lt;NA&gt;        1992 Adam…\n 6 Adams   Adon…          2 M        30 192    2022     1 duplicate   1992 Adam…\n 7 Adams   Tina           2 F         5  98.0  2022     1 duplicate   2017 Adam…\n 8 Adams   Tina           2 F         5  98.0  2022     0 &lt;NA&gt;        2017 Adam…\n 9 Allen   Abery          2 F        79 157    2022     0 &lt;NA&gt;        1943 Alle…\n10 Allen   Abery          2 F        79 157    2022     1 duplicate   1943 Alle…\n11 Campbe… Savi…          2 M        72 192    2022     0 &lt;NA&gt;        1950 Camp…\n12 Campbe… Savi…          2 M        72 192    2022     1 duplicate   1950 Camp…\n13 Huber   Rosa           2 F         9  NA    2022     3 only age …  2013 Hube…\n14 Huber   Rosa           2 &lt;NA&gt;     NA 130    2022     3 age missi…    NA Hube…\n15 Miller  Merl…          2 F        12 153.   2022     0 &lt;NA&gt;        2010 Mill…\n16 Miller  Merl…          2 F         2  99.9  2022     0 &lt;NA&gt;        2020 Mill…\n17 huber   Step…          2 M       186  41    2022     1 age/cm fa…  1836 hube…\n18 huber   Step…          2 &lt;NA&gt;     NA  NA    2022     1 wrong name    NA hube…\n# ℹ 3 more variables: id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\ndf |&gt; get_dupes(id)\n\n# A tibble: 12 × 14\n   id    dupe_count sex   name  surname   age    cm  time error error_desc  born\n   &lt;chr&gt;      &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Hube…          4 M     Step… Huber      41 186    2022     1 duplicate   1981\n 2 Hube…          4 M     Step… Huber      41 186    2022     0 no error    1981\n 3 Hube…          4 M     Step… Huber      41 186    2022     1 duplicate   1981\n 4 Hube…          4 M     Step… Huber      41  NA    2022     1 duplicate…  1981\n 5 Adam…          2 M     Adon… Adams      30 192    2022     0 &lt;NA&gt;        1992\n 6 Adam…          2 M     Adon… Adams      30 192    2022     1 duplicate   1992\n 7 Adam…          2 F     Tina  Adams       5  98.0  2022     1 duplicate   2017\n 8 Adam…          2 F     Tina  Adams       5  98.0  2022     0 &lt;NA&gt;        2017\n 9 Alle…          2 F     Abery Allen      79 157    2022     0 &lt;NA&gt;        1943\n10 Alle…          2 F     Abery Allen      79 157    2022     1 duplicate   1943\n11 Camp…          2 M     Savi… Campbe…    72 192    2022     0 &lt;NA&gt;        1950\n12 Camp…          2 M     Savi… Campbe…    72 192    2022     1 duplicate   1950\n# ℹ 3 more variables: id_num &lt;int&gt;, dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\ndf_uni &lt;- df |&gt;\n  arrange() |&gt;\n  distinct(id, .keep_all = TRUE)\n\ndf_uni_b &lt;- df |&gt;\n  arrange(desc(dup_count)) |&gt;\n  distinct(id, .keep_all = TRUE)\n\nanti_join(df, df_uni)\n\nJoining with `by = join_by(sex, name, surname, age, cm, time, error,\nerror_desc, born, id, id_num, dup_count, dup_sum)`\n\n\n# A tibble: 7 × 13\n  sex   name    surname    age    cm  time error error_desc    born id    id_num\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1 M     Adonnis Adams       30 192    2022     1 duplicate     1992 Adam…      1\n2 F     Tina    Adams        5  98.0  2022     0 &lt;NA&gt;          2017 Adam…     13\n3 F     Abery   Allen       79 157    2022     1 duplicate     1943 Alle…     15\n4 M     Savier  Campbell    72 192    2022     1 duplicate     1950 Camp…    100\n5 M     Stephan Huber       41 186    2022     0 no error      1981 Hube…    383\n6 M     Stephan Huber       41 186    2022     1 duplicate     1981 Hube…    383\n7 M     Stephan Huber       41  NA    2022     1 duplicate, …  1981 Hube…    383\n# ℹ 2 more variables: dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\nanti_join(df, df_uni_b)\n\nJoining with `by = join_by(sex, name, surname, age, cm, time, error,\nerror_desc, born, id, id_num, dup_count, dup_sum)`\n\n\n# A tibble: 7 × 13\n  sex   name    surname    age    cm  time error error_desc  born id      id_num\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;\n1 M     Adonnis Adams       30 192    2022     0 &lt;NA&gt;        1992 Adams_…      1\n2 F     Tina    Adams        5  98.0  2022     1 duplicate   2017 Adams_…     13\n3 F     Abery   Allen       79 157    2022     0 &lt;NA&gt;        1943 Allen_…     15\n4 M     Savier  Campbell    72 192    2022     0 &lt;NA&gt;        1950 Campbe…    100\n5 M     Stephan Huber       41 186    2022     1 duplicate   1981 Huber_…    383\n6 M     Stephan Huber       41 186    2022     0 no error    1981 Huber_…    383\n7 M     Stephan Huber       41 186    2022     1 duplicate   1981 Huber_…    383\n# ℹ 2 more variables: dup_count &lt;int&gt;, dup_sum &lt;int&gt;\n\n# unload packages\nsuppressMessages(pacman::p_unload(tidyverse, janitor, babynames, stringr))",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "80_exercises.html#zipfs-law",
    "href": "80_exercises.html#zipfs-law",
    "title": "9  Collection of exercises",
    "section": "9.16 Zipf’s law",
    "text": "9.16 Zipf’s law\nThe data under investigation includes population information for various German cities, identified by the variable stadt, spanning the years 1970, 1987, and 2010. The variable status provides details about the legislative status of the cities, and the variable state (Bundesland) indicates the state in which each respective city is situated.\nPreamble\n\nSet your working directory.\n\n\nClear your global environment.\n\n\nInstall and load the following packages: ‘tidyverse’, ‘haven’, and ‘janitor’.\n\nRead in, inspect, and clean the data\n\nDownload and load the data, respectively, with the following code:\n\n\ndf &lt;- read_dta(\n  \"https://github.com/hubchev/courses/raw/main/dta/city.dta\",\n  encoding = \"latin1\"\n) |&gt;\n  as_tibble()\n\nIf that is not working, you can also download the data from ILIAS, save it in your working directory and load it from there with:\nload(\"city.RData\")\n\nShow the first six and the last six observations of the dataset df.\nHow many observations (rows) and variables (columns) are in the dataset?\nShow for all numerical variables the summary statistics including the mean, median, minimum, and the maximum.\nRename the variable stadt to city.\nRemove the variables pop1970 and pop1987.\nReplicate the following table which contains some summary statistics.\n\n\n\n# A tibble: 17 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Wrttemberg                 7580            7580\n 2 Baden-Württemberg               23680.        7837917\n 3 Bayern                          23996.        7558677\n 4 Berlin                        3292365         3292365\n 5 Brandenburg                     18472.        1865632\n 6 Bremen                         325432.         650863\n 7 Hamburg                       1706696         1706696\n 8 Hessen                          22996.        5036121\n 9 Mecklenburg-Vorpommern          27034.         811005\n10 Niedersachsen                   24107.        6219515\n11 Nordrhein-Westfalen             47465.       18036727\n12 Rheinland-Pfalz                 25644.        1871995\n13 Saarland                           NA              NA\n14 Sachsen                         27788.        2973351\n15 Sachsen-Anhalt                  21212.        1993915\n16 Schleswig-Holstein              24157.        1739269\n17 Th_ringen                       29192.        1167692\n\n\n\nThe states “Baden-Wrttemberg” and “Th_ringen” are falsely pronounced. Correct the names and regenerate the summary statistics table presented above. Your result should look like this:\n\n\n\n# A tibble: 16 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Württemberg               23631.        7845497\n 2 Bayern                          23996.        7558677\n 3 Berlin                        3292365         3292365\n 4 Brandenburg                     18472.        1865632\n 5 Bremen                         325432.         650863\n 6 Hamburg                       1706696         1706696\n 7 Hessen                          22996.        5036121\n 8 Mecklenburg-Vorpommern          27034.         811005\n 9 Niedersachsen                   24107.        6219515\n10 Nordrhein-Westfalen             47465.       18036727\n11 Rheinland-Pfalz                 25644.        1871995\n12 Saarland                           NA              NA\n13 Sachsen                         27788.        2973351\n14 Sachsen-Anhalt                  21212.        1993915\n15 Schleswig-Holstein              24157.        1739269\n16 Thüringen                       29192.        1167692\n\n\n\nTo investigate the reason for observing only NAs for Saarland, examine all cities within Saarland. Therefore, please display all observations for cities in Saarland in the Console, as illustrated below.\n\n\n\n# A tibble: 47 × 5\n   city                status  state    pop2011 rankX\n   &lt;chr&gt;               &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 Perl                Commune Saarland    7775  2003\n 2 Freisen             Commune Saarland    8270  1894\n 3 Großrosseln         Commune Saarland    8403  1868\n 4 Nonnweiler          Commune Saarland    8844  1775\n 5 Nalbach             Commune Saarland    9302  1678\n 6 Wallerfangen        Commune Saarland    9542  1642\n 7 Kirkel              Commune Saarland   10058  1541\n 8 Merchweiler         Commune Saarland   10219  1515\n 9 Nohfelden           Commune Saarland   10247  1511\n10 Friedrichsthal      City    Saarland   10409  1489\n11 Marpingen           Commune Saarland   10590  1461\n12 Mandelbachtal       Commune Saarland   11107  1390\n13 Kleinblittersdorf   Commune Saarland   11396  1354\n14 Überherrn           Commune Saarland   11655  1317\n15 Mettlach            Commune Saarland   12180  1241\n16 Tholey              Commune Saarland   12385  1217\n17 Saarwellingen       Commune Saarland   13348  1104\n18 Quierschied         Commune Saarland   13506  1088\n19 Spiesen-Elversberg  Commune Saarland   13509  1086\n20 Rehlingen-Siersburg Commune Saarland   14526   996\n21 Riegelsberg         Commune Saarland   14763   982\n22 Ottweiler           City    Saarland   14934   969\n23 Beckingen           Commune Saarland   15355   931\n24 Losheim am See      Commune Saarland   15906   887\n25 Schiffweiler        Commune Saarland   15993   882\n26 Wadern              City    Saarland   16181   874\n27 Schmelz             Commune Saarland   16435   857\n28 Sulzbach/Saar       City    Saarland   16591   849\n29 Illingen            Commune Saarland   16978   827\n30 Schwalbach          Commune Saarland   17320   812\n31 Eppelborn           Commune Saarland   17726   793\n32 Wadgassen           Commune Saarland   17885   785\n33 Bexbach             City    Saarland   18038   777\n34 Heusweiler          Commune Saarland   18201   762\n35 Püttlingen          City    Saarland   19134   718\n36 Lebach              City    Saarland   19484   701\n37 Dillingen/Saar      City    Saarland   20253   654\n38 Blieskastel         City    Saarland   21255   601\n39 St. Wendel          City    Saarland   26220   460\n40 Merzig              City    Saarland   29727   392\n41 Saarlouis           City    Saarland   34479   323\n42 St. Ingbert         City    Saarland   36645   299\n43 Völklingen          City    Saarland   38809   279\n44 Homburg             City    Saarland   41502   247\n45 Neunkirchen         City    Saarland   46172   206\n46 Saarbrücken         City    Saarland  175853    43\n47 Perl                Commune Saarland      NA    NA\n\n\n\nWith reference to the table above, we have identified an entry for the city of Perl that solely consists of NAs. This city is duplicated in the dataset, appearing at positions 1 and 47. The latter duplicate contains only NAs and can be safely removed without the loss of valuable information. Please eliminate this duplification and regenerate the list of all cities in the Saarland.\nCalculate the total population and average size of cities in Saarland.\nCheck if any other city is recorded more than once in the dataset. To do so, reproduce the table below.\n\n\n\n# A tibble: 23 × 5\n# Groups:   city [11]\n   city        status                  state               pop2011 unique_count\n   &lt;chr&gt;       &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt;        &lt;int&gt;\n 1 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 2 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 3 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 4 Brühl       Commune                 Baden-Württemberg     13805            2\n 5 Brühl       City                    Nordrhein-Westfalen   43568            2\n 6 Erbach      City                    Baden-Württemberg     13024            2\n 7 Erbach      City                    Hessen                13245            2\n 8 Fürth       City with County Rights Bayern               115613            2\n 9 Fürth       Commune                 Hessen                10481            2\n10 Lichtenau   City                    Nordrhein-Westfalen   10473            2\n11 Lichtenau   Commune                 Sachsen                7544            2\n12 Münster     Commune                 Hessen                14071            2\n13 Münster     City with County Rights Nordrhein-Westfalen  289576            2\n14 Neunkirchen Commune                 Nordrhein-Westfalen   13930            2\n15 Neunkirchen City                    Saarland              46172            2\n16 Neuried     Commune                 Baden-Württemberg      9383            2\n17 Neuried     Commune                 Bayern                 8277            2\n18 Petersberg  Commune                 Hessen                14766            2\n19 Petersberg  Commune                 Sachsen-Anhalt        10097            2\n20 Senden      City                    Bayern                21560            2\n21 Senden      Commune                 Nordrhein-Westfalen   19976            2\n22 Staufenberg City                    Hessen                 8114            2\n23 Staufenberg Commune                 Niedersachsen          7983            2\n\n\n\nThe table indicates that the city of Bonn appears three times in the dataset, and all three observations contain identical information. Thus, remove two of these observations to ensure that Bonn is uniquely represented in the dataset. All other cities that occur more than once in the data are situated in different states. That means, these are distinct cities that coincidentally share the same name.\n\nData analysis (Zipf’s Law)\n*Note: If you have failed to solve the data cleaning tasks above, you can download the cleaned data from ILIAS, save it in your working directory and load it from there with: load(\"city_clean.RData\")\nIn the following, you aim to examine the validity of Zipf’s Law for Germany. Zipf’s Law postulates how the size of cities is distributed. The “law” states that there is a special relationship between the size of a city and the rank it occupies in a series sorted by city size. In the estimation equation \\[\n\\log(M_j) = c - q \\log(R_j),\n\\] the law postulates a coefficient of \\(( q=1 )\\). \\(c\\) is a constant; \\(M_j\\) is the size of city \\(j\\); \\(R_j\\) is the rank that city \\(j\\) occupies in a series sorted by city size.\n\n\n\nCreate a variable named rank that includes a ranking of cities based on the population size in the year 2011. Therefore, Berlin should have a rank of 1, Hamburg a rank of 2, Munich a rank of 3, and so on.\nNote: If you cannot solve this task, use the variable rankX as a substitute for the variable rank that was not generated.\n\n\n# A tibble: 6 × 3\n  city                    pop2011  rank\n  &lt;chr&gt;                     &lt;dbl&gt; &lt;int&gt;\n1 Berlin                  3292365     1\n2 Hamburg                 1706696     2\n3 München [Munich]        1348335     3\n4 Köln [Cologne]          1005775     4\n5 Frankfurt am Main        667925     5\n6 Düsseldorf [Dusseldorf]  586291     6\n\n\n\nCalculate the Pearson Correlation Coefficient of the two variables pop2011 and rank. The result should be:\n\n\n\n[1] -0.2948903\n\n\n\nCreate a scatter plot. On the x-axis, plot the variable rank, and on the y-axis, plot pop2011. Add a regression line representing the observed relationship to the same scatter plot.\n\n\n\n\n\n\n\n\n\n\n\nLogarithmize the variables rank and pop2011. Title the new variables as lnrank and lnpop2011, respectively. Here is a snapshot of the resulting variables:\n\n\n\n# A tibble: 6 × 5\n  city                     rank lnrank pop2011 lnpop2011\n  &lt;chr&gt;                   &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1 Berlin                      1  0     3292365      15.0\n2 Hamburg                     2  0.693 1706696      14.4\n3 München [Munich]            3  1.10  1348335      14.1\n4 Köln [Cologne]              4  1.39  1005775      13.8\n5 Frankfurt am Main           5  1.61   667925      13.4\n6 Düsseldorf [Dusseldorf]     6  1.79   586291      13.3\n\n\n\nCalculate the Pearson Correlation Coefficient of the two variables lnpop2011 and lnrank. The result should be:\n\n\n\n[1] -0.9990053\n\n\n\nCreate a scatter plot. On the x-axis, plot the variable lnrank, and on the y-axis, plot lnpop2011. Add a regression line representing the observed relationship to the same scatter plot. Additionally, add a title and label the axes like is shown here:\n\n\n\n\n\n\n\n\n\n\n\nNow, test the relationship postulated in Zipf’s Law. Regress the logarithmic city size in the year 2011 on the logarithmic rank of a city in a series sorted by city size. Briefly interpret the results, addressing the coefficient of determination. Show the regression results. Here is one way to present the results of the regression (Note: The way how you present your regression results do not matter):\n\n\n\n\nCall:\nlm(formula = lnpop2011 ~ lnrank, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.28015 -0.01879  0.01083  0.02005  0.25973 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14.947859   0.005141    2908   &lt;2e-16 ***\nlnrank      -0.780259   0.000766   -1019   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03454 on 2067 degrees of freedom\nMultiple R-squared:  0.998, Adjusted R-squared:  0.998 \nF-statistic: 1.038e+06 on 1 and 2067 DF,  p-value: &lt; 2.2e-16\n\n\n\nExplain the following lines of code.\n\n\ndf &lt;- df |&gt;\n  mutate(prediction = predict(zipf, newdata = df)) |&gt;\n  mutate(pred_pop = exp(prediction))\ndf |&gt;\n  select(city, pop2011, pred_pop) |&gt;\n  filter(city == \"Regensburg\")\n\n# A tibble: 1 × 3\n  city       pop2011 pred_pop\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Regensburg  135403  134194.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe script uses the following functions: aes, arrange, as_tibble, c, case_when, cor, desc, dim, exp, filter, geom_point, geom_smooth, ggplot, group_by, head, is.na, labs, lm, log, mean, mutate, n, predict, print, read_dta, rename, row_number, save, select, starts_with, sum, summarise, summary, tail, ungroup.\n\n\n\n\n\n\nR script\n\n\n\n\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\nsuppressMessages(pacman::p_unload(all))\n# setwd(\"~/Dropbox/hsf/exams/24-01/Rmd\")\n\nrm(list = ls())\n\npacman::p_load(tidyverse, haven, janitor, jtools)\n\ndf &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/city.dta\",\n  encoding = \"latin1\"\n) |&gt;\n  as_tibble()\n\nhead(df)\ntail(df)\n\ndim(df)\n\nsummary(df)\n\ndf &lt;- df |&gt;\n  rename(city = stadt)\n\ndf &lt;- df |&gt;\n  select(-pop1970, -pop1987)\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\ndf &lt;- df |&gt;\n  mutate(state = case_when(\n    state == \"Baden-Wrttemberg\" ~ \"Baden-Württemberg\",\n    state == \"Th_ringen\" ~ \"Thüringen\",\n    TRUE ~ state\n  ))\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\ndf &lt;- df |&gt;\n  filter(!(city == \"Perl\" & is.na(pop2011)))\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\ndf |&gt;\n  group_by(city) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n\ndf &lt;- df |&gt;\n  group_by(city, state) |&gt;\n  mutate(n_row = row_number()) |&gt;\n  filter(n_row == 1) |&gt;\n  select(-n_row)\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\nsave(df, file = \"city_clean.RData\")\n\ndf &lt;- df |&gt;\n  ungroup() |&gt;\n  arrange(desc(pop2011)) |&gt;\n  mutate(rank = row_number())\n\ndf |&gt;\n  select(-rankX, -status, -state) |&gt;\n  head()\n\n\ncor(df$pop2011, df$rank, method = c(\"pearson\"))\n\nggplot(df, aes(x = rank, y = pop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\")\n\ndf &lt;- df |&gt;\n  mutate(lnrank = log(rank)) |&gt;\n  mutate(lnpop2011 = log(pop2011))\n\ndf |&gt;\n  select(city, rank, lnrank, pop2011, lnpop2011) |&gt;\n  head()\n\n\ncor(df$lnpop2011, df$lnrank, method = c(\"pearson\"))\n\nggplot(df, aes(x = lnrank, y = lnpop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Scatterplot with Regression Line\",\n    x = \"lnrank (Logarithmized Rank)\",\n    y = \"lnpop2011 (Logarithmized Population 2011)\"\n  )\n\nzipf &lt;- lm(lnpop2011 ~ lnrank, data = df)\nsummary(zipf)\n\ndf &lt;- df |&gt;\n  mutate(prediction = predict(zipf, newdata = df)) |&gt;\n  mutate(pred_pop = exp(prediction))\ndf |&gt;\n  select(city, pop2011, pred_pop) |&gt;\n  filter(city == \"Regensburg\")\n\nsuppressMessages(pacman::p_unload(tidyverse, haven, janitor, jtools))\n\n# rmarkdown::render(\"24-01_dsda.Rmd\", \"all\")\n\n# knitr::purl(input = \"24-01_dsda.Rmd\", output = \"24-01_dsda_solution.R\",documentation = 0)\n\n\n\n\n\n\n\n\n\nOutput of the R script\n\n\n\n\n\n\n# load packages\nif (!require(pacman)) install.packages(\"pacman\")\nsuppressMessages(pacman::p_unload(all))\n# setwd(\"~/Dropbox/hsf/exams/24-01/Rmd\")\n\nrm(list = ls())\n\npacman::p_load(tidyverse, haven, janitor, jtools)\n\ndf &lt;- read_dta(\"https://github.com/hubchev/courses/raw/main/dta/city.dta\",\n  encoding = \"latin1\"\n) |&gt;\n  as_tibble()\n\nhead(df)\n\n# A tibble: 6 × 7\n  stadt              status  state              pop1970 pop1987 pop2011 rankX\n  &lt;chr&gt;              &lt;chr&gt;   &lt;chr&gt;                &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Vohenstrauß        City    Bayern                7349    7059    7500  2069\n2 Stockstadt a. Main Commune Bayern                6416    6615    7504  2068\n3 Jesteburg          Commune Niedersachsen         4141    5818    7510  2067\n4 Bordesholm         Commune Schleswig-Holstein    6011    6726    7513  2066\n5 Herrieden          City    Bayern                5631    6250    7516  2065\n6 Weida              City    Th_ringen               NA      NA    7522  2064\n\ntail(df)\n\n# A tibble: 6 × 7\n  stadt             status                  state  pop1970 pop1987 pop2011 rankX\n  &lt;chr&gt;             &lt;chr&gt;                   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Frankfurt am Main City with County Rights Hessen  699297  618266  667925     5\n2 Köln [Cologne]    City with County Rights Nordr…  994705  928309 1005775     4\n3 München [Munich]  City with County Rights Bayern 1293599 1185421 1348335     3\n4 Hamburg           City with County Rights Hambu… 1793823 1592770 1706696     2\n5 Berlin            City with County Rights Berlin 3210000 3260000 3292365     1\n6 Perl              Commune                 Saarl…      NA      NA      NA    NA\n\ndim(df)\n\n[1] 2072    7\n\nsummary(df)\n\n    stadt              status             state              pop1970       \n Length:2072        Length:2072        Length:2072        Min.   :   1604  \n Class :character   Class :character   Class :character   1st Qu.:   8149  \n Mode  :character   Mode  :character   Mode  :character   Median :  11912  \n                                                          Mean   :  30504  \n                                                          3rd Qu.:  21318  \n                                                          Max.   :3210000  \n                                                          NA's   :355      \n    pop1987           pop2011            rankX       \n Min.   :   4003   Min.   :   7500   Min.   :   1.0  \n 1st Qu.:   9194   1st Qu.:   9998   1st Qu.: 516.5  \n Median :  13118   Median :  13937   Median :1034.0  \n Mean   :  30854   Mean   :  30772   Mean   :1034.0  \n 3rd Qu.:  23074   3rd Qu.:  24096   3rd Qu.:1551.5  \n Max.   :3260000   Max.   :3292365   Max.   :2069.0  \n NA's   :248       NA's   :1         NA's   :1       \n\ndf &lt;- df |&gt;\n  rename(city = stadt)\n\ndf &lt;- df |&gt;\n  select(-pop1970, -pop1987)\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\n# A tibble: 17 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Wrttemberg                 7580            7580\n 2 Baden-Württemberg               23680.        7837917\n 3 Bayern                          23996.        7558677\n 4 Berlin                        3292365         3292365\n 5 Brandenburg                     18472.        1865632\n 6 Bremen                         325432.         650863\n 7 Hamburg                       1706696         1706696\n 8 Hessen                          22996.        5036121\n 9 Mecklenburg-Vorpommern          27034.         811005\n10 Niedersachsen                   24107.        6219515\n11 Nordrhein-Westfalen             47465.       18036727\n12 Rheinland-Pfalz                 25644.        1871995\n13 Saarland                           NA              NA\n14 Sachsen                         27788.        2973351\n15 Sachsen-Anhalt                  21212.        1993915\n16 Schleswig-Holstein              24157.        1739269\n17 Th_ringen                       29192.        1167692\n\ndf &lt;- df |&gt;\n  mutate(state = case_when(\n    state == \"Baden-Wrttemberg\" ~ \"Baden-Württemberg\",\n    state == \"Th_ringen\" ~ \"Thüringen\",\n    TRUE ~ state\n  ))\n\ndf |&gt;\n  group_by(state) |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\n# A tibble: 16 × 3\n   state                  `mean(pop2011)` `sum(pop2011)`\n   &lt;chr&gt;                            &lt;dbl&gt;          &lt;dbl&gt;\n 1 Baden-Württemberg               23631.        7845497\n 2 Bayern                          23996.        7558677\n 3 Berlin                        3292365         3292365\n 4 Brandenburg                     18472.        1865632\n 5 Bremen                         325432.         650863\n 6 Hamburg                       1706696         1706696\n 7 Hessen                          22996.        5036121\n 8 Mecklenburg-Vorpommern          27034.         811005\n 9 Niedersachsen                   24107.        6219515\n10 Nordrhein-Westfalen             47465.       18036727\n11 Rheinland-Pfalz                 25644.        1871995\n12 Saarland                           NA              NA\n13 Sachsen                         27788.        2973351\n14 Sachsen-Anhalt                  21212.        1993915\n15 Schleswig-Holstein              24157.        1739269\n16 Thüringen                       29192.        1167692\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\n# A tibble: 47 × 5\n   city                status  state    pop2011 rankX\n   &lt;chr&gt;               &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 Perl                Commune Saarland    7775  2003\n 2 Freisen             Commune Saarland    8270  1894\n 3 Großrosseln         Commune Saarland    8403  1868\n 4 Nonnweiler          Commune Saarland    8844  1775\n 5 Nalbach             Commune Saarland    9302  1678\n 6 Wallerfangen        Commune Saarland    9542  1642\n 7 Kirkel              Commune Saarland   10058  1541\n 8 Merchweiler         Commune Saarland   10219  1515\n 9 Nohfelden           Commune Saarland   10247  1511\n10 Friedrichsthal      City    Saarland   10409  1489\n11 Marpingen           Commune Saarland   10590  1461\n12 Mandelbachtal       Commune Saarland   11107  1390\n13 Kleinblittersdorf   Commune Saarland   11396  1354\n14 Überherrn           Commune Saarland   11655  1317\n15 Mettlach            Commune Saarland   12180  1241\n16 Tholey              Commune Saarland   12385  1217\n17 Saarwellingen       Commune Saarland   13348  1104\n18 Quierschied         Commune Saarland   13506  1088\n19 Spiesen-Elversberg  Commune Saarland   13509  1086\n20 Rehlingen-Siersburg Commune Saarland   14526   996\n21 Riegelsberg         Commune Saarland   14763   982\n22 Ottweiler           City    Saarland   14934   969\n23 Beckingen           Commune Saarland   15355   931\n24 Losheim am See      Commune Saarland   15906   887\n25 Schiffweiler        Commune Saarland   15993   882\n26 Wadern              City    Saarland   16181   874\n27 Schmelz             Commune Saarland   16435   857\n28 Sulzbach/Saar       City    Saarland   16591   849\n29 Illingen            Commune Saarland   16978   827\n30 Schwalbach          Commune Saarland   17320   812\n31 Eppelborn           Commune Saarland   17726   793\n32 Wadgassen           Commune Saarland   17885   785\n33 Bexbach             City    Saarland   18038   777\n34 Heusweiler          Commune Saarland   18201   762\n35 Püttlingen          City    Saarland   19134   718\n36 Lebach              City    Saarland   19484   701\n37 Dillingen/Saar      City    Saarland   20253   654\n38 Blieskastel         City    Saarland   21255   601\n39 St. Wendel          City    Saarland   26220   460\n40 Merzig              City    Saarland   29727   392\n41 Saarlouis           City    Saarland   34479   323\n42 St. Ingbert         City    Saarland   36645   299\n43 Völklingen          City    Saarland   38809   279\n44 Homburg             City    Saarland   41502   247\n45 Neunkirchen         City    Saarland   46172   206\n46 Saarbrücken         City    Saarland  175853    43\n47 Perl                Commune Saarland      NA    NA\n\ndf &lt;- df |&gt;\n  filter(!(city == \"Perl\" & is.na(pop2011)))\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  print(n = 100)\n\n# A tibble: 46 × 5\n   city                status  state    pop2011 rankX\n   &lt;chr&gt;               &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 Perl                Commune Saarland    7775  2003\n 2 Freisen             Commune Saarland    8270  1894\n 3 Großrosseln         Commune Saarland    8403  1868\n 4 Nonnweiler          Commune Saarland    8844  1775\n 5 Nalbach             Commune Saarland    9302  1678\n 6 Wallerfangen        Commune Saarland    9542  1642\n 7 Kirkel              Commune Saarland   10058  1541\n 8 Merchweiler         Commune Saarland   10219  1515\n 9 Nohfelden           Commune Saarland   10247  1511\n10 Friedrichsthal      City    Saarland   10409  1489\n11 Marpingen           Commune Saarland   10590  1461\n12 Mandelbachtal       Commune Saarland   11107  1390\n13 Kleinblittersdorf   Commune Saarland   11396  1354\n14 Überherrn           Commune Saarland   11655  1317\n15 Mettlach            Commune Saarland   12180  1241\n16 Tholey              Commune Saarland   12385  1217\n17 Saarwellingen       Commune Saarland   13348  1104\n18 Quierschied         Commune Saarland   13506  1088\n19 Spiesen-Elversberg  Commune Saarland   13509  1086\n20 Rehlingen-Siersburg Commune Saarland   14526   996\n21 Riegelsberg         Commune Saarland   14763   982\n22 Ottweiler           City    Saarland   14934   969\n23 Beckingen           Commune Saarland   15355   931\n24 Losheim am See      Commune Saarland   15906   887\n25 Schiffweiler        Commune Saarland   15993   882\n26 Wadern              City    Saarland   16181   874\n27 Schmelz             Commune Saarland   16435   857\n28 Sulzbach/Saar       City    Saarland   16591   849\n29 Illingen            Commune Saarland   16978   827\n30 Schwalbach          Commune Saarland   17320   812\n31 Eppelborn           Commune Saarland   17726   793\n32 Wadgassen           Commune Saarland   17885   785\n33 Bexbach             City    Saarland   18038   777\n34 Heusweiler          Commune Saarland   18201   762\n35 Püttlingen          City    Saarland   19134   718\n36 Lebach              City    Saarland   19484   701\n37 Dillingen/Saar      City    Saarland   20253   654\n38 Blieskastel         City    Saarland   21255   601\n39 St. Wendel          City    Saarland   26220   460\n40 Merzig              City    Saarland   29727   392\n41 Saarlouis           City    Saarland   34479   323\n42 St. Ingbert         City    Saarland   36645   299\n43 Völklingen          City    Saarland   38809   279\n44 Homburg             City    Saarland   41502   247\n45 Neunkirchen         City    Saarland   46172   206\n46 Saarbrücken         City    Saarland  175853    43\n\ndf |&gt;\n  filter(state == \"Saarland\") |&gt;\n  summarise(\n    mean(pop2011),\n    sum(pop2011)\n  )\n\n# A tibble: 1 × 2\n  `mean(pop2011)` `sum(pop2011)`\n            &lt;dbl&gt;          &lt;dbl&gt;\n1          20850.         959110\n\ndf |&gt;\n  group_by(city) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n# A tibble: 23 × 5\n# Groups:   city [11]\n   city        status                  state               pop2011 unique_count\n   &lt;chr&gt;       &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt;        &lt;int&gt;\n 1 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 2 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 3 Bonn        City with County Rights Nordrhein-Westfalen  305765            3\n 4 Brühl       Commune                 Baden-Württemberg     13805            2\n 5 Brühl       City                    Nordrhein-Westfalen   43568            2\n 6 Erbach      City                    Baden-Württemberg     13024            2\n 7 Erbach      City                    Hessen                13245            2\n 8 Fürth       City with County Rights Bayern               115613            2\n 9 Fürth       Commune                 Hessen                10481            2\n10 Lichtenau   City                    Nordrhein-Westfalen   10473            2\n11 Lichtenau   Commune                 Sachsen                7544            2\n12 Münster     Commune                 Hessen                14071            2\n13 Münster     City with County Rights Nordrhein-Westfalen  289576            2\n14 Neunkirchen Commune                 Nordrhein-Westfalen   13930            2\n15 Neunkirchen City                    Saarland              46172            2\n16 Neuried     Commune                 Baden-Württemberg      9383            2\n17 Neuried     Commune                 Bayern                 8277            2\n18 Petersberg  Commune                 Hessen                14766            2\n19 Petersberg  Commune                 Sachsen-Anhalt        10097            2\n20 Senden      City                    Bayern                21560            2\n21 Senden      Commune                 Nordrhein-Westfalen   19976            2\n22 Staufenberg City                    Hessen                 8114            2\n23 Staufenberg Commune                 Niedersachsen          7983            2\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n# A tibble: 3 × 5\n# Groups:   city, state [1]\n  city  status                  state               pop2011 unique_count\n  &lt;chr&gt; &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt;        &lt;int&gt;\n1 Bonn  City with County Rights Nordrhein-Westfalen  305765            3\n2 Bonn  City with County Rights Nordrhein-Westfalen  305765            3\n3 Bonn  City with County Rights Nordrhein-Westfalen  305765            3\n\ndf &lt;- df |&gt;\n  group_by(city, state) |&gt;\n  mutate(n_row = row_number()) |&gt;\n  filter(n_row == 1) |&gt;\n  select(-n_row)\n\ndf |&gt;\n  group_by(city, state) |&gt;\n  mutate(unique_count = n()) |&gt;\n  arrange(city, state) |&gt;\n  filter(unique_count &gt; 1) |&gt;\n  select(city, status, state, starts_with(\"pop\"), unique_count) |&gt;\n  print(n = 100)\n\n# A tibble: 0 × 5\n# Groups:   city, state [0]\n# ℹ 5 variables: city &lt;chr&gt;, status &lt;chr&gt;, state &lt;chr&gt;, pop2011 &lt;dbl&gt;,\n#   unique_count &lt;int&gt;\n\nsave(df, file = \"city_clean.RData\")\n\ndf &lt;- df |&gt;\n  ungroup() |&gt;\n  arrange(desc(pop2011)) |&gt;\n  mutate(rank = row_number())\n\ndf |&gt;\n  select(-rankX, -status, -state) |&gt;\n  head()\n\n# A tibble: 6 × 3\n  city                    pop2011  rank\n  &lt;chr&gt;                     &lt;dbl&gt; &lt;int&gt;\n1 Berlin                  3292365     1\n2 Hamburg                 1706696     2\n3 München [Munich]        1348335     3\n4 Köln [Cologne]          1005775     4\n5 Frankfurt am Main        667925     5\n6 Düsseldorf [Dusseldorf]  586291     6\n\ncor(df$pop2011, df$rank, method = c(\"pearson\"))\n\n[1] -0.2948903\n\nggplot(df, aes(x = rank, y = pop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\ndf &lt;- df |&gt;\n  mutate(lnrank = log(rank)) |&gt;\n  mutate(lnpop2011 = log(pop2011))\n\ndf |&gt;\n  select(city, rank, lnrank, pop2011, lnpop2011) |&gt;\n  head()\n\n# A tibble: 6 × 5\n  city                     rank lnrank pop2011 lnpop2011\n  &lt;chr&gt;                   &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1 Berlin                      1  0     3292365      15.0\n2 Hamburg                     2  0.693 1706696      14.4\n3 München [Munich]            3  1.10  1348335      14.1\n4 Köln [Cologne]              4  1.39  1005775      13.8\n5 Frankfurt am Main           5  1.61   667925      13.4\n6 Düsseldorf [Dusseldorf]     6  1.79   586291      13.3\n\ncor(df$lnpop2011, df$lnrank, method = c(\"pearson\"))\n\n[1] -0.9990053\n\nggplot(df, aes(x = lnrank, y = lnpop2011)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Scatterplot with Regression Line\",\n    x = \"lnrank (Logarithmized Rank)\",\n    y = \"lnpop2011 (Logarithmized Population 2011)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nzipf &lt;- lm(lnpop2011 ~ lnrank, data = df)\nsummary(zipf)\n\n\nCall:\nlm(formula = lnpop2011 ~ lnrank, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.28015 -0.01879  0.01083  0.02005  0.25973 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14.947859   0.005141    2908   &lt;2e-16 ***\nlnrank      -0.780259   0.000766   -1019   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03454 on 2067 degrees of freedom\nMultiple R-squared:  0.998, Adjusted R-squared:  0.998 \nF-statistic: 1.038e+06 on 1 and 2067 DF,  p-value: &lt; 2.2e-16\n\ndf &lt;- df |&gt;\n  mutate(prediction = predict(zipf, newdata = df)) |&gt;\n  mutate(pred_pop = exp(prediction))\ndf |&gt;\n  select(city, pop2011, pred_pop) |&gt;\n  filter(city == \"Regensburg\")\n\n# A tibble: 1 × 3\n  city       pop2011 pred_pop\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Regensburg  135403  134194.\n\nsuppressMessages(pacman::p_unload(tidyverse, haven, janitor, jtools))\n\n# rmarkdown::render(\"24-01_dsda.Rmd\", \"all\")\n\n# knitr::purl(input = \"24-01_dsda.Rmd\", output = \"24-01_dsda_solution.R\",documentation = 0)\n\n\n\n\n\n\n\n\n\nFigure 9.1: The logo of the DatasauRus package\nWeight vs. Calories\nFigure 9.2: Ranking history: 1. FC Kaiserslautern\nFigure 9.3: Ranking history: 1. FC Köln\n\n\n\nHortaçsu, A., & Syverson, C. (2015). The ongoing evolution of US retail: A format tug-of-war. Journal of Economic Perspectives, 29(4), 89–112.",
    "crumbs": [
      "Do stuff",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Collection of exercises</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chambers, J. M. (2017). Extending R. CRC Press.\n\n\nDavenport, T. H., & Patil, D. (2012). Data scientist: The sexiest\njob of the 21st century. Harvard Business Review,\n90(5), 70–76.\n\n\nHadley, W. (2014). Tidy data. Journal of Statistical Software,\n59(10), 1–23.\n\n\nHealy, K. (2018). Data visualization: A practical introduction.\nAccessed January 30, 2023; Princeton University Press. https://socviz.co/\n\n\nHortaçsu, A., & Syverson, C. (2015). The ongoing evolution of\nUS retail: A format tug-of-war. Journal of Economic\nPerspectives, 29(4), 89–112.\n\n\nIrizarry, R. A. (2022). Introduction to data science: Data analysis\nand prediction algorithms with R. Accessed January 30,\n2023; CRC Press. https://rafalab.github.io/dsbook/\n\n\nIsmay, C., & Kim, A. Y. (2022). Statistical inference via data\nscience: A ModernDive into R and the tidyverse. CRC\nPress. https://moderndive.com/\n\n\nKabacoff, R. (2024). Modern data visualization with\nR. Chapman; Hall/CRC. https://rkabacoff.github.io/datavis/\n\n\nKelleher, J. D., & Tierney, B. (2018). Data science. MIT\nPress.\n\n\nKirchkamp, O. (2018). Using graphs and visualising data.\n\n\nMuschelli, J., & Jaffe, A. (2022). Introduction to\nR for public health researchers. GitHub. https://github.com/muschellij2/intro_to_r\n\n\nNavarro, D. (2020). Learning statistics with r (Version 0.6).\nhttps://learningstatisticswithr.com\n\n\nNeth, H. (2023). ds4psy: Data science for psychologists. Social\nPsychology; Decision Sciences, University of Konstanz. https://doi.org/10.5281/zenodo.7229812\n\n\nStephenson, P. (2023). Data science practice. Accessed January\n30, 2023. https://datasciencepractice.study/\n\n\nThulin, M. (2021). Modern statistics with R: From\nwrangling and exploring data to inference and predictive modelling.\nEos Chasma Press. https://www.modernstatisticswithr.com/\n\n\nTufte, E. R. (2022). The visual display of quantitative\ninformation (2nd ed.). Graphics Press.\n\n\nVenables, W. N., Smith, D. M., & R Core Team. (2022). An\nintroduction to R: Notes on R: A programming\nenvironment for data analysis and graphics (Version 4.3.2\n(2023-10-31)). http://cran.r-project.org/doc/manuals/R-intro.pdf\n\n\nWickham, H. (2024). The tidyverse style guide. https://style.tidyverse.org/\n\n\nWickham, H., & Grolemund, G. (2023). R for data science\n(2e). https://r4ds.hadley.nz/\n\n\nWooldridge, J. M. (2002). Introductory econometrics: A modern approach.\nIn Delhi: Cengage Learnng (2nd ed.). South-Western.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "95_filesys.html",
    "href": "95_filesys.html",
    "title": "Appendix A — Navigating the file system",
    "section": "",
    "text": "A.1 The file system\nIn this section, I describe the basic idea behind file locations and file paths. Regardless of whether you are using Windows, macOS, or Linux, every file on the computer is assigned a human-readable address, and every address has the same basic structure: it describes a path that starts from a root location, through a series of folders (or directories), and finally ends up at the file.\nOn a Windows computer, the root is the storage device on which the file is stored, and for many home computers, the name of the storage device that stores all your files is C:. After that comes the folders, and on Windows, the folder names are separated by a backslash symbol \\. So, the complete path to this book on my Windows computer might be something like this:\nOn Linux, Unix, and macOS systems, the addresses look a little different, but they are more or less identical in spirit. Instead of using the backslash, folders are separated using a forward slash, and unlike Windows, they do not treat the storage device as being the root of the file system. So, the path on a Mac might be something like this:\n/Users/huber/Rbook/rcourse-book.pdf\nThat is what we mean by the path to a file. The next concept to grasp is the idea of a working directory and how to change it. For those of you who have used command-line interfaces previously, this should be obvious already. But if not, here is what I mean. The working directory is just whatever folder I am currently looking at. Suppose that I am currently looking for files in Explorer (if you are using Windows) or using Finder (on a Mac). The folder I currently have open is my user directory (i.e., C:\\Users\\huber or /Users/huber). That is my current working directory.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Navigating the file system</span>"
    ]
  },
  {
    "objectID": "95_filesys.html#sec-filesystem",
    "href": "95_filesys.html#sec-filesystem",
    "title": "Appendix A — Navigating the file system",
    "section": "",
    "text": "C:\\Users\\huber\\Rbook\\rcourse-book.pdf",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Navigating the file system</span>"
    ]
  },
  {
    "objectID": "95_filesys.html#working-directory",
    "href": "95_filesys.html#working-directory",
    "title": "Appendix A — Navigating the file system",
    "section": "A.2 Working directory",
    "text": "A.2 Working directory\nThe next concept to grasp is the idea of a working directory and how to change it. For those of you who have used command line interfaces previously, this should be obvious already. But if not, here’s what I mean. The working directory is just “whatever folder I’m currently looking at”. Suppose that I’m currently looking for files in Explorer (if you’re using Windows) or using Finder (on a Mac). The folder I currently have open is my user directory (i.e., C:\\Users\\huber or /Users/huber). That’s my current working directory.\nThe fact that we can imagine that the program is “in” a particular directory means that we can talk about moving from our current location to a new one. What that means is that we might want to specify a new location in relation to our current location. To do so, we need to introduce two new conventions. Regardless of what operating system you’re using, we use . to refer to the current working directory, and .. to refer to the directory above it. This allows us to specify a path to a new location in relation to our current location, as the following examples illustrate. Let’s assume that I’m using my Windows computer, and my working directory is C:\\Users\\huber\\Rbook. The table below shows several addresses in relation to my current one:\n\n\n\nAbsolute path\nRelative path\n\n\n\n\nC:\\Users\\huber\n..\n\n\nC:\\Users\n..\\..\n\n\nC:\\Users\\huber\\Rbook\\source\n.\\source\n\n\nC:\\Users\\huber\\nerdstuff\n..\\nerdstuff\n\n\n\nIt is quite common on computers that have multiple users to define ~ to be the user’s home directory. The home directory on a Mac for the `huber'' user is/Users/huber/. And so, not surprisingly, it is possible to define other directories in terms of their relationship to the home directory. For example, an alternative way to describe the location of thercourse-book.pdf` file on a Mac would be\n~\\Rbook\\rcourse-book.pdf\nYou can find out your home directory with the path.expand() function:\n\npath.expand(\"~\")\n\n[1] \"/home/sthu\"\n\n\nThus, on my machine ~ is an abbreviation for the path /home/sthu.\n\ngetwd()\n\n[1] \"/home/sthu/Dropbox/hsf/courses/dsr\"",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Navigating the file system</span>"
    ]
  },
  {
    "objectID": "95_filesys.html#sec-navigationR",
    "href": "95_filesys.html#sec-navigationR",
    "title": "Appendix A — Navigating the file system",
    "section": "A.3 Navigating the file system using the R console",
    "text": "A.3 Navigating the file system using the R console\nWhen you want to load or save a file in R it’s important to know what the working directory is. You can find out by using the getwd() command. For the moment, let’s assume that I’m using Mac OS or Linux, since things are different on Windows, see section Section A.5. Let’s check the current active working directory:\n\ngetwd()\n\n[1] \"/home/sthu/Dropbox/hsf/courses/dsr\"\n\n\nThe function setwd() allows to change the working directory:\n\nsetwd(\"/Users/huber/Rbook/data\")\nsetwd(\"./Rbook/data\")\n\nThe function list.files() lists all the files in that directory:\n\nlist.files()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Navigating the file system</span>"
    ]
  },
  {
    "objectID": "95_filesys.html#sec-rstudioprojects",
    "href": "95_filesys.html#sec-rstudioprojects",
    "title": "Appendix A — Navigating the file system",
    "section": "A.4 R Studio projects",
    "text": "A.4 R Studio projects\nSetting the working directory repeatedly can be a cumbersome task. Fortunately, R Studio projects can automate this process for you. When you open an R Studio project, the working directory is automatically set to the project directory.\nCreating a new project in R Studio is simple. Just click on File &gt; New Project…. This will create a directory on your computer with a *.Rproj_ file that can be used to open the saved project at a later date. The newly created directory contains your R code, data files, and other project-related files. By working within projects, all of your files and data are organized in one place, making it easier to share your work with others, reproduce your analyses, and keep track of changes over time.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Navigating the file system</span>"
    ]
  },
  {
    "objectID": "95_filesys.html#sec-winbackslash",
    "href": "95_filesys.html#sec-winbackslash",
    "title": "Appendix A — Navigating the file system",
    "section": "A.5 Why do the Windows paths use the back-slash?",
    "text": "A.5 Why do the Windows paths use the back-slash?\nLet’s suppose I’m using a computer with Windows. As before, I can find out what my current working directory is like this:\n\ngetwd()\n[1] \"C:/Users/huber/\n\nR is displaying a Windows path using the wrong type of slash, the back-slash. The answer has to do with the fact that R treats the \\ character as special. If you’re deeply wedded to the idea of specifying a path using the Windows style slashes, then what you need to use two back-slashes \\\\ whenever you mean \\. In other words, if you want to specify the working directory on a Windows computer, you need to use one of the following commands:\n\nsetwd( \"C:/Users/huber\" )\nsetwd( \"C:\\\\Users\\\\huber\" )",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Navigating the file system</span>"
    ]
  },
  {
    "objectID": "952_operators.html",
    "href": "952_operators.html",
    "title": "Appendix B — Operators",
    "section": "",
    "text": "B.1 Assignment:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Operators</span>"
    ]
  },
  {
    "objectID": "952_operators.html#assignment",
    "href": "952_operators.html#assignment",
    "title": "Appendix B — Operators",
    "section": "",
    "text": "&lt;- (assignment operator)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Operators</span>"
    ]
  },
  {
    "objectID": "952_operators.html#arithmetic",
    "href": "952_operators.html#arithmetic",
    "title": "Appendix B — Operators",
    "section": "B.2 Arithmetic:",
    "text": "B.2 Arithmetic:\n\n+ (addition)\n- (subtraction)\n* (multiplication)\n/ (division)\n^ or ** (exponentiation)\n%% (modulo, remainder)\n%/% (integer division)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Operators</span>"
    ]
  },
  {
    "objectID": "952_operators.html#relational",
    "href": "952_operators.html#relational",
    "title": "Appendix B — Operators",
    "section": "B.3 Relational:",
    "text": "B.3 Relational:\n\n&lt; (less than)\n&gt; (greater than)\n&lt;= (less than or equal to)\n&gt;= (greater than or equal to)\n== (equal to)\n!= or &lt;&gt; (not equal to)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Operators</span>"
    ]
  },
  {
    "objectID": "952_operators.html#logical",
    "href": "952_operators.html#logical",
    "title": "Appendix B — Operators",
    "section": "B.4 Logical:",
    "text": "B.4 Logical:\n\n& (element-wise AND)\n| (element-wise OR)\n! (logical NOT)\n&& (scalar AND)\n|| (scalar OR)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Operators</span>"
    ]
  },
  {
    "objectID": "952_operators.html#others",
    "href": "952_operators.html#others",
    "title": "Appendix B — Operators",
    "section": "B.5 Others:",
    "text": "B.5 Others:\n\n%*% (matrix multiplication)\n%in% (checks if an element is in a vector)\n%&gt;% or |&gt; (pipe operator from the magrittr package)\n[]: Extract content from vectors, lists, or data frames.\n[[ ]] and $: Extract a single item from an object.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Operators</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html",
    "href": "953_popfunctions.html",
    "title": "Appendix C — Popular functions",
    "section": "",
    "text": "C.1 Help",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#help",
    "href": "953_popfunctions.html#help",
    "title": "Appendix C — Popular functions",
    "section": "",
    "text": "?: Search R documentation for a specific term.\n?? Search R help files for a word or phrase.\nRSiteSearch: Search search.r-project.org \nhelp.start: Access to html manuals and documentations implemented in R  \nbrowseVignettes: view a list of all vignettes associated with your installed packages\nvignette: View a specified package vignette, that is, supporting material such as introductions.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#package-management",
    "href": "953_popfunctions.html#package-management",
    "title": "Appendix C — Popular functions",
    "section": "C.2 Package management",
    "text": "C.2 Package management\n\ninstall.packages: Installs packages from CRAN.\npacman::p_load: Installs and loads specified R packages.\nlibrary: (Install and) loads specified R packages.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#general",
    "href": "953_popfunctions.html#general",
    "title": "Appendix C — Popular functions",
    "section": "C.3 General",
    "text": "C.3 General\n\nsetwd: Sets the working directory to the specified path.\nrm: Removes objects (variables) from the workspace.\nsessionInfo: Information about the R environment.\nsource: Executes R code from a file.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#tools",
    "href": "953_popfunctions.html#tools",
    "title": "Appendix C — Popular functions",
    "section": "C.4 Tools",
    "text": "C.4 Tools\n\nelse: Execute a block of code if the preceding condition is false.\nelse if: Specify a new condition to test if the first condition is false.\nif: Execute a block of code if a specified condition is true.\nifelse: Check a condition for every element of a vector.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#data-import",
    "href": "953_popfunctions.html#data-import",
    "title": "Appendix C — Popular functions",
    "section": "C.5 Data import",
    "text": "C.5 Data import\n\nc: Combine values into a vector or list.\nread.csv: Reads a CSV file into a data frame.\nread_dta: Read Stata dataset.\nload: Loads an RData file.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#inspect-data",
    "href": "953_popfunctions.html#inspect-data",
    "title": "Appendix C — Popular functions",
    "section": "C.6 Inspect data",
    "text": "C.6 Inspect data\n\ndim: Returns the dimensions (number of rows and columns) of a data frame.\nglimpse: Provide a concise summary.\nhead: Returns the first elements.\nprint: Prints the specified object.\nnames: Returns the variable names in a data frame.\nn() or nrow(): Counts the number of observations in a data frame or group of observations.\nncol: Returns the number of columns in a data frame.\nsummary: Summary statistics.\ntable: Create a table of counts or cross-tabulation.\ntail: Returns the last n elements.\nunique: Extracts unique elements from a vector.\nview: Opens a viewer for data frames.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#graphics",
    "href": "953_popfunctions.html#graphics",
    "title": "Appendix C — Popular functions",
    "section": "C.7 Graphics",
    "text": "C.7 Graphics\n\nabline: Adds lines to a plot.\naes: Aesthetic mapping in ggplot.\nfacet_wrap: Creates a grid of facetted plots.\ngeom_hline: Adds horizontal lines to a ggplot.\ngeom_line: Adds lines to a ggplot.\ngeom_point: Adds points to a ggplot.\ngeom_smooth: Adds a smoothed line to a ggplot.\ngeom_text: Adds text to a ggplot.\ngeom_vline: Adds vertical lines to a ggplot.\nggsave: Saves a ggplot to a file.\nlabs: Adds or modifies plot labels.\nplot: Creates a scatter plot.\nscale_y_reverse: Reverses the y-axis in a ggplot.\nstat_smooth: Adds a smoothed line to a ggplot.\ntheme_classic: Applies a classic theme to a ggplot.\ntheme_minimal: Applies a minimal theme to a ggplot.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#data-management",
    "href": "953_popfunctions.html#data-management",
    "title": "Appendix C — Popular functions",
    "section": "C.8 Data management",
    "text": "C.8 Data management\n\narrange: Reorder the rows of a data frame.\nclean_names: Cleans names of an object (usually a data.frame).\ncomplete: Completes a data frame with all combinations of specified columns.\ndata.frame: Creates a data frame.\ndistinct: Removes duplicate rows from a data frame.\nidentical: Check if two objects are identical.\nis(na): Identify and flag a missing or undefined value (NA).\nis_tibble: Check if an object is a tibble.\nrm: Removes objects (variables) from the workspace.\nrelocate: Reorders columns in a dataframe.\nround: Rounds a numeric vector to the nearest integer.\nrownames: Get or set the row names of a matrix-like object.\ntibble: Creates a tibble, a modern and tidy data frame.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#dplyr-functions",
    "href": "953_popfunctions.html#dplyr-functions",
    "title": "Appendix C — Popular functions",
    "section": "C.9 dplyr functions",
    "text": "C.9 dplyr functions\n\narrange: Reorder the rows of a data frame.\ncomplete: Completes a data frame with all combinations of specified columns.\nends_with: matches to a specified suffix\nfilter: Pick observations by their values.\nfirst: Returns the first element.\ngroup_by: Group data by one or more variables.\nlast: Returns the last element.\nmutate: Add new variables or modify existing variables in a data frame.\nnth: Returns the nth element.\nn_distinct: Returns the number of distinct elements.\nrename: Rename variables in a data frame.\nrename_all: Renames all variables in a data frame.\nrow_number: Adds a column with row numbers.\nrowwise: Perform operations row by row.\nselect: Pick variables by their names.\nselect_all: Selects all columns in a data frame.\nslice_head: Selects the top N rows from each group.\nstarts_with: Select variables whose names start with a certain string.\nsummarise: Reduce data to a single summary value.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#data-analysis",
    "href": "953_popfunctions.html#data-analysis",
    "title": "Appendix C — Popular functions",
    "section": "C.10 Data analysis",
    "text": "C.10 Data analysis\n\naggregate: Apply a function to the data by levels of one or more factors.\nanti_join: Return rows from the first data frame that do not have a match in the second data frame.\ncor: Computes correlation coefficients.\ncov: Computes covariance.\ndiff: Calculates differences between consecutive elements.\nget_dupes: Identify duplicate rows in a data frame (from the janitor package).\npaste0: Concatenate vectors after converting to character.\npredict: Predict method for model fits.\nprop.table: Create a table of proportions.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "953_popfunctions.html#statistical-functions",
    "href": "953_popfunctions.html#statistical-functions",
    "title": "Appendix C — Popular functions",
    "section": "C.11 Statistical functions",
    "text": "C.11 Statistical functions\n\ncor(): Computes correlation coefficients.\ncov(): Computes the covariance.\nexp(): Exponential function.\nIQR(): Computes the interquartile range.\nkurtosis(): Computes the kurtosis.\nlog(): Natural logarithm.\nmad(): Computes the mean absolute deviation.\nmax(): Returns the maximum value.\nmean(): Calculates the mean.\nmedian(): Computes the median.\nmin(): Returns the minimum value.\nquantile(): Computes sample quantiles.\nsd(): Calculates the standard deviation.\nskewness(): Calculates the skewness.\nvar(): Calculates the variance.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Popular functions</span>"
    ]
  },
  {
    "objectID": "957_shortcuts.html",
    "href": "957_shortcuts.html",
    "title": "Appendix D — Helpful shortcuts",
    "section": "",
    "text": "Table 1: Different OS, different keys\n\n\nKey in Windows/Linux\nKey in Mac\n\n\n\n\nCTRL\nCommand Key\n\n\nAlt\nOption Key\n\n\n\n\nTable 2: Helpful shortcuts\n\n\n\n\n\n\n\nAction\nShortcut Keys\nDescription\n\n\n\n\nRun code\nCtrl + Enter\nRuns the current line and jumps to the next one, or runs the selected part without jumping further.\n\n\n\nAlt + Enter\nAllows running code without moving the cursor to the next line if you want to run one line of code multiple times without selecting it.\n\n\n\nCtrl + Alt + R\nRuns the entire script.\n\n\n\nCtrl + Alt + B/E\nRun the script from the Beginning to the current line and from the current line to the End.\n\n\nWrite code\nAlt + (-)\nInserts the assignment operator (&lt;-) with spaces surrounding it.\n\n\n\nCtrl + Shift + M\nInserts the magrittr/pipe operator (%&gt;%) with spaces surrounding it.\n\n\n\nCtrl + Shift + C\nComments out code by putting a # in front of each line of marked code of a script.\n\n\n\nCtrl + Shift + R\nCreates a foldable comment section in your code.\n\n\nNavigating in RStudio\nCtrl + 1\nMove focus to editor.\n\n\n\nCtrl + 2\nMove focus to console.\n\n\n\nCtrl+Tab and Ctrl+Shift+Tab\nto switch between tabs.\n\n\n\nCtrl + Shift + N\nOpen a new R script.\n\n\n\nCtrl + w\nClose a tab.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Helpful shortcuts</span>"
    ]
  }
]