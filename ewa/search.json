[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Empirisch-Wissenschaftliches Arbeiten",
    "section": "",
    "text": "Vorwort\n\n\n\n\n\n\nEine PDF-Version dieser Notizen ist hier verfügbar.\n\n\n\nBitte beachten Sie, dass der Inhalt der PDF-Version identisch ist, sie jedoch nicht für das PDF-Format optimiert wurde. Daher könnten einige Teile nicht wie beabsichtigt erscheinen.\n\n\n\nWikipedia sagt:\n\n“Die Psychologie […] ist eine empirische Wissenschaft”\n\n\n\nDiese Unterlagen helfen…\n\ndie Abfolge und die Inhalte der Übung zur computergestützen Datenanalyse zu überblicken,\ndie Übungsaufgaben zu verstehen und zu bearbeiten und\ndie Projektarbeit der Veranstaltung Empirisch-Wissenschaftliches Arbeiten erfolgreich zu gestalten.\n\n\n\nDie Übung vermittelt…\n\nKenntnisse der Programmiersprache R welche eine wissenschaftliche Datenbearbeitung und Datenanalyse ermöglichen.\nKenntnisse zum programmbasierten Verfassen von wissenschaftlichen Arbeiten (Aufsätze, Bücher, Arbeitspapiere, Hausarbeiten).\n\n\n\nStudierende lernen…\n\nDaten mit der Programmiersprache R und mit Hilfe der integrierten Entwicklungsumgebung RStudio einzulesen, zu bearbeiten und empirisch auszuwerten.\nEmpirische Ergebnisse in ein publikationswürdiges Format zu übertragen.\nEinen APA konformes Manuskript mit Quarto, bzw. (R)Markdown, zu erstellen und dies entsprechend zu publizieren.\nLiteratur entsprechend wählbaren Zitationsregeln unter Verwendung von Quarto und BibTeX in einen Aufsatz einzuarbeiten.\n\n\n\nStudierende sollen…\n\nDie angeführte Literatur studieren: Ohne eigenständige Vor- und Nachbereitung lassen sich die Programmierkenntnisse nicht erlernen.\nAktiv um Hilfe bitten: Wenn etwas unklar ist, kann ich individuell während des Kurses versuchen zu helfen. Für eine intensivere Betreuung, bitte ich mich zu kontaktieren, in die Sprechstunde zu kommen, oder eine außerordentliche Sprechstunde zu vereinbaren. Dies ist möglich und erwünscht.\n\nInhaltliche Fragen und Wünsche jederzeit kommunizieren. Es besteht die Möglichkeit diese in das Curriculum aufzunehmen.\n\n\n\nLiebe Studierende,\ndas Erlernen einer Programmiersprache in Verbindung mit empirischen Arbeiten ist eine Herausforderung die Vielen keinen Spaß macht. So ist es nur Verständlich, dass die Sinnhaftigkeit dieses Kurses teilweise von Studierenden angezweifelt wird. Tätigkeiten die keinen Spaß machen, sollten sinnstiftend sein oder zumindest ein monetäres Einkommen sichern. Da das Vorhandensein von empirischen Kenntnissen und einer Programmiersprache in einem Lebenslauf zweifelsfrei in der heutigen Zeit die Vermittlungsfähigkeit und die Verhandlungsposition am Arbeitsmarkt wesentlich verbessern, will ich mich hier kurz bemühen, die Sinnhaftigkeit zu thematisieren.\nIch verstehe die Abneigung gegenüber diesen Kurs: Viele haben sich nicht für ein Studium der Psychologie entschieden, um empirische Methoden und deren computergestützte Umsetzung zu erlernen. In der modernen Welt aber, insbesondere in der psychologischen Forschung, ist ein Verständnis von empirischen Methoden sowie deren computergestützten Umsetzung die praktische Voraussetzung zum Erkenntnisgewinns. Ohne dieses Verständnis verharrt man bei rein theoretische und philosophische Überlegungen ohne jede Evidenz. Eine professionell agierende Psychologin und Psychologe, sollte die Fähigkeit besitzen die Literatur in seinem Fach zu begreifen sowie in der Lage ein die Ergebnisse kritisch zu hinterfragen und/oder zu überprüfen.\nIch bemühe mich, die Veranstaltung so attraktiv wie möglich zu gestalten. Ich biete…\n\nein ausführliches Skript zur Programmiersprache R an, welches\n\neine Batterie an Übungsaufgaben mit Lösungskripten und\neine Vielzahl an interaktive Übungen zum eigenständigen bearbeiten enthält.\n\ndieses Skript, welches\n\nPsychologie-spezifische empirische Inhalte aufgreift und\nSoftware vorstellt, welche die Erstellung der Projektarbeit erleichtert.\n\nmündliche Erklärungen in der Veranstaltung.\ndie Möglichkeit spezifische Fragen zu stellen und Unklarheiten anzusprechen.\nindividuelle Betreuung während und außerhalb der Sprechstunde.\n\nWenn sie Vorschläge und Wünsche bezüglich der Inhalte oder der didaktischen Aufbereitung haben, bitte ich diese auszusprechen. Konstruktive Kritik ist sehr willkommen. Ich nehme diese an und ernst. Ob Sie diesen Kurs letztendlich als gelungen betrachten, ist ihrer Wahrnehmung überlassen. Bevor Sie den Kurs aber schlecht evaluieren, bitte ich sie um Folgendes: Fragen Sie sich, ob ihr Wille und ihr Wunsch ausgeprägt genug waren, um sich ernsthaft mit den Inhalten und den Angeboten auseinanderzusetzen und ob sie mir evtl. die Gelegenheit gegeben haben auf Ihre Wünsche einzugehen.\n\nAbschließend wünsche ich Ihnen viel Freude mit dem Kurs und den angebotenen Unterlagen. Ich freue mich, diesen Kurs halten zu dürfen. Es ist mir stets eine Freude, den anwesenden Studierenden R, Quarto, BibTeX und Co. zu erklären. Ich wünsche mir, möglichst Viele mit den dargebotenen Inhalten zu erreichen und hoffe, meine Arbeit bereichert ihr Studium und beschleunigt Ihr Vorankommen hinsichtlich Projektarbeit und kommenden Studienarbeiten.\nIhr\nStephan Huber\n\n\n\n\n\n\nLizenz\n\n\n\nDieses Skript wird unter der Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Lizenz veröffentlicht. Das bedeutet, dass die Inhalte wiederverwendet, remixt, behalten, überarbeitet und weiterverbreitet werden können, solange den Autoren angemessenes Credit gegeben wird. Wenn Sie die Originalversion dieses offenen Skirpts remixen oder modifizieren, müssen Sie alle Versionen dieses offenen Skripts unter derselben Lizenz weiterverbreiten.",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Die Programmiersprache R",
    "section": "",
    "text": "Ich bitte Sie, studieren sie das Skript How to use R for data science (Huber, 2024).\nIn den ersten Wochen werden wir uns ausschließlich damit beschäftigen, die Programmiersprache R zu erlernen. Das ist ähnlich mühsam wie das Erlernen einer wirklichen Sprache. Wer keine Lust darauf hat, wird es schwer haben. Ich beispielsweise hatte in der Schule überhaupt keine Lust auf Englisch und Latein. Dementsprechend schlecht waren meine Noten. Ich musste die siebte Klasse wiederholen und bis zum Abitur waren Sprachen für mich ein nötiges Übel. Erst als ich im Studium sah, dass praktisch alle relevanten und für mich interessanten Artikel und Bücher in englischer Sprache verfasst sind, machte das Erlernen der Sprache einen Sinn für mich. Jetzt lehre ich abseits dieses Kurses ausschließlich auf Englisch und publiziere in englischer Sprache. Interesse und Freude sind mächtige Katalysatoren für Erfolg.\nDas Schreiben von Code ist für die meisten Studierenden Neuland. Studierende im Jahr 2024 sind zumeist mit dem Smartphone aufgewachsen und demnach sind Sie es gewohnt, ihre Geräte (Smartphone, Tablet, Desktop-PC) ohne zur Hilfenahme einer Programmiersprache zu steuern. Das ist wunderbar: Die grafische Benutzeroberfläche heutzutage erlaubt eine effiziente und intuitive Art der Steuerung mit der Computermaus, durch Wischen, Tippen oder durch Spracheingabe. Leider hat diese Art der Steuerung massive Nachteile beim wissenschaftlich orientierten Arbeiten mit Daten. Insbesondere was die Reproduzierbarkeit der Ergebnisse und die Flexibilität des Arbeitsprozesses anbelangt, stößt man bei Applikationen ohne Code an Grenzen. Die Vor- und Nachteile von Script-basierten Arbeiten werden im Kapitel The limitations of no-code applications (Huber, 2024) ausführlich erläutert.\n\nHuber, S. (2024). How to Use R for Data Science: Lecture Notes. https://hubchev.github.io/ds/\nZusammenfassend sollten Studierende nach den ersten 5-6 Unterrichtseinheiten folgendes getan haben beziehungsweise erlernt haben:\n\nInstallation von\n\nR,\nRStudio und der\ngängisten Pakete.\n\nWissen über…\n\nden Aufbau von R Skripten.\ndie Verwendung von Funktionen, Objekten und Pakete in R.\ndie grundsätzlichen Eigenheiten der Programmiersprache R.\ndas Ausführen von Code (Ctrl+Enter, Klicken von Run, oder durch die Funktion source()).\ndie Verwendung von Pipes mit dem Pipe Operator (|&gt;).\ndie Verwendung von logischen und relativen Operatoren.\ndie Funktionen des Pakets dplyr (filter(), select(), mutate(), summarise(), etc.)",
    "crumbs": [
      "Einleitung",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Die Programmiersprache R</span>"
    ]
  },
  {
    "objectID": "paper.html",
    "href": "paper.html",
    "title": "2  Wissenschaftliche Texte schreiben",
    "section": "",
    "text": "2.1 WYSIWYG Anwendungen\nDie Nutzung klassischer Textverarbeitungsprogramme wie Microsoft Word oder Apple Pages zum Verfassen wissenschaftlicher Texte ist in der studentischen Welt weit verbreitet. Obwohl diese Programme für alltägliche Schreibprojekte benutzerfreundlich sind, erzeugen sie erheblichen Mehraufwand, um den Ansprüchen wissenschaftlicher Arbeit gerecht zu werden.\nEin erstes Problem ist die Einbindung von Literatur. Die korrekte Formatierung nach verschiedenen Zitierrichtlinien ist oft alles andere als intuitiv und Fehler treten leicht auf. Dies gilt insbesondere, wenn die von der Software bereitgestellten Zitat- und Bibliografiefunktionen nicht oder nicht richtig genutzt werden. Anstelle externer Zitationsmanager zu nutzen und sich in deren Gebrauch einzuarbeiten, verfassen viele Studierende Zitate und Literaturlisten manuell. Dies führt erfahrungsgemäß zu zahlreichen kleinen und manchmal größeren Fehlern, die vermeidbar wären.\nEin weiterer Schwachpunkt von studentischen Arbeiten ist die Einhaltung spezifischer Formatierungsvorgaben. Akademische Institutionen und Journale fordern oft eine strenge Beachtung von Formatierungsrichtlinien, inklusive der Gestaltung von Titelseiten, Kopf- und Fußzeilen, Seitenrändern und Überschriftenhierarchien. Zwar bieten Word und Pages Vorlagen und Stile an, diese müssen jedoch für jedes Dokument individuell angepasst und oft aufgrund geringfügiger Änderungen im Text modifiziert werden. Wenn eine Formatanpassung erforderlich wird, ist dies meistens nur mit großem Aufwand möglich.\nDas Einfügen empirischer Ergebnisse wie statistischer Daten und Grafiken stellt eine zusätzliche Hürde dar. In Word und Pages gestaltet sich der Vorgang häufig manuell: Forschungsdaten müssen aus Statistiksoftware exportiert, als Bilder abgespeichert und anschließend in das Dokument eingebunden werden. Ändert sich etwas an den Daten, so muss dieser mühsame Prozess wiederholt werden, was den Arbeitsaufwand signifikant erhöht und die Fehleranfälligkeit steigert.",
    "crumbs": [
      "Einleitung",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wissenschaftliche Texte schreiben</span>"
    ]
  },
  {
    "objectID": "paper.html#vorteile-von-codebasierten-anwendungen",
    "href": "paper.html#vorteile-von-codebasierten-anwendungen",
    "title": "2  Wissenschaftliche Texte schreiben",
    "section": "2.2 Vorteile von codebasierten Anwendungen",
    "text": "2.2 Vorteile von codebasierten Anwendungen\nDer traditionelle Ansatz zum Verfassen wissenschaftlicher Texte mittels MS Word oder Pages kann für Studierende zeitaufwendig und fehleranfällig sein. Im folgenden Abschnitt möchte ich Quarto (bzw. R Markdown) vorstellen, eine moderne Alternative, die folgende Vorteile bietet:\n\nMit Quarto lassen sich mühelos verschiedene Ausgabeformate generieren. So kann derselbe Text beispielsweise als Website (HTML), Manuskript (PDF, DOCX), Buch (EPUB, PDF) oder in Form von Präsentationsfolien (PDF). Diese Flexibilität erlaubt es, sich eher auf den Inhalt als auf das Format zu konzentrieren.\nDie Formatierung kann in Quarto einfach geändert werden indem bestimmte Vorlagen verwendet werden.\nLiteraturreferenzen lassen sich unkompliziert einbinden, während die Einhaltung von Zitierregeln von der Software übernommen wird. Quartos Integration mit Zitationsverwaltungssystemen ermöglicht es, Literaturverweise und Bibliografien effizienter und konsistenter zu handhaben als beispielsweise in Word.\nQuerverweise auf Abschnitte, Tabellen und Abbildungen lassen sich leicht erstellen.\nDie Datenanalyse und das Erstellen von Datenoutputs erfolgen direkt in Quarto. Dadurch sind dargestellte Grafiken und Tabellen stets aktuell und manuelles Nachbearbeiten entfällt, wodurch die Reproduzierbarkeit der Ergebnisse gewährleistet ist.\nForschende können ihre Datenvisualisierungen ohne manuelle Zwischenschritte direkt in den Text einbetten.\nVersionskontrollsysteme wie Git erleichtern die Zusammenarbeit an wissenschaftlichen Dokumenten, da Änderungen nachverfolgbar sind und integriert werden können, ohne auf komplexe und konfliktträchtige Vergleichstools angewiesen zu sein.\n\n\n\n\n\n\n\nLesetipp\n\n\n\nFür Interessierte empfehle ich den Onlinekurs Introduction to Reproducible Publications with RStudio, der explizit erläutert, wie man empirisch nachvollziehbar arbeitet. Eine etwas kompaktere Einführung bietet Bauer & Landesvatter (2023) und das Standardwerk zum Thema stammt von Gandrud (2020).\n\n\n\nGandrud, C. (2020). Reproducible research with R and R studio (3. Aufl.). Chapman; Hall/CRC.\n\nBauer, P. C., & Landesvatter, C. (2023). Writing a reproducible paper with RStudio and Quarto. https://doi.org/10.31219/osf.io/ur4xn",
    "crumbs": [
      "Einleitung",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wissenschaftliche Texte schreiben</span>"
    ]
  },
  {
    "objectID": "paper.html#einführung-in-quarto",
    "href": "paper.html#einführung-in-quarto",
    "title": "2  Wissenschaftliche Texte schreiben",
    "section": "2.3 Einführung in Quarto",
    "text": "2.3 Einführung in Quarto\nQuarto kann in RStudio genutzt werden, um APA-konforme Texte zu erstellen. Gehen Sie dazu bitte wie folgt vor:\n\nInstallieren Sie R und R Studio.\nInstallieren Sie Quarto folgendermaßen:\n\n\ninstall.packages(\"quarto\")\n\n\nInstallieren Sie das Paket tinytex, um PDF-Dateien zu generieren:\n\n\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n\n\nEs ist zudem ratsam, weitere Pakete zu installieren, die später benötigt werden könnten:\n\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(knitr, rmarkdown, papaja)\n\n\nEignen Sie sich Kenntnisse in Markdown an. Markdown ist eine leichtgewichtige Markup-Language zur Formatierung von Klartext. Sie ist eine essenzielle Fähigkeit für die effektive Nutzung von Quarto. Beginnen Sie damit, ausreichend Markdown für die Strukturierung Ihrer Arbeit zu erlernen, einschließlich Überschriften, Listen, Links und Codeblöcken. Markdown ist schnell zu erlernen; ich empfehle dazu den Besuch von www.markdowntutorial.com und das Durcharbeiten der interaktiven Lektionen sowie des Abschnitts Markdown Basics auf quarto.org.\nMachen Sie sich vertraut mit Quarto. Als Lektüre dient Telford (2023): Enough Markdown to Write a Thesis, welcher fast alles abdeckt, was für das akademische Schreiben hilfreich ist. Alternativ finden Sie umfassende Informationen zur Arbeit mit Quarto direkt auf der Webseite quarto.org/docs/guide.\n\n\nTelford, R. J. (2023). Enough Markdown to Write a Thesis. https://biostats-r.github.io/biostats/quarto/\n\n\n\n\n\n\nQuarto und R markdown\n\n\n\nQuarto ist ein relativ neues Werkzeug und kann als Nachfolger von R Markdown betrachtet werden. Die meisten R Markdown-Dokumente sind mit Quarto kompatibel. Allerdings bietet Quarto einige verbesserte Funktionen gegenüber R Markdown, die die Benutzerfreundlichkeit steigern. Einen detaillierten Überblick über die Unterschiede und Gemeinsamkeiten zwischen den beiden Plattformen finden Sie in [diesem Artikel] (https://quarto.org/docs/faq/rmarkdown.html).",
    "crumbs": [
      "Einleitung",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wissenschaftliche Texte schreiben</span>"
    ]
  },
  {
    "objectID": "paper.html#erste-schritte-mit-quarto",
    "href": "paper.html#erste-schritte-mit-quarto",
    "title": "2  Wissenschaftliche Texte schreiben",
    "section": "2.4 Erste Schritte mit Quarto",
    "text": "2.4 Erste Schritte mit Quarto\n\nÖffnen Sie RStudio.\nWählen Sie “File” -&gt; “New File” -&gt; “Quarto Document” und dann “Create”.\nSpeichern Sie die neue Datei in einem leeren Ordner und definieren Sie diesen Ordner als Ihr Arbeitsverzeichnis.\nKlicken Sie auf “Render”.\nBesuchen Sie die Webseite Markdown Basics, fügen Sie etwas Markdown in Ihr Dokument ein und klicken Sie erneut auf “Render”.\nKlicken Sie auf den Pfeil neben dem “Render”-Knopf. Hier können Sie andere Dateiformate auswählen und diese generieren. Probieren Sie es aus.\nKonsultieren Sie die Webseite PDF Basics und ergänzen Sie Ihren Header mit den dort gefundenen Informationen.\nVersuchen Sie das Paper von Huber & Rust (2016), das Sie hier finden, in Ihrem Dokument zu zitieren.\n\nKlicken Sie dazu auf “Visual”,\ngehen Sie an die Stelle im Text, an der Sie das Paper zitieren möchten, und wählen Sie “Insert” -&gt; “Citation”.\nSuchen Sie im Kontextmenü mithilfe der entsprechenden DOI (https://doi.org/10.1177/1536867X1601600209) nach dem Papier und fügen Sie es ein.\n\nUm mit dem APA Version 7-Stil zu zitieren, schreiben Sie folgendes in den YAML-Header:\n\n\nHuber, S., & Rust, C. (2016). Calculate travel time and distance with OpenStreetMap data using the Open Source Routing Machine (OSRM). The Stata Journal, 16(2), 416–423.\ncsl: \"https://www.zotero.org/styles/apa\"\n\nWählen Sie einen anderen Zitierstil von www.zotero.org/styles. Rendern Sie dann das Dokument erneut und beobachten Sie die Unterschiede.",
    "crumbs": [
      "Einleitung",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wissenschaftliche Texte schreiben</span>"
    ]
  },
  {
    "objectID": "paper.html#apa-konformes-manuscript-erstellen-mit-quarto-apaquarto",
    "href": "paper.html#apa-konformes-manuscript-erstellen-mit-quarto-apaquarto",
    "title": "2  Wissenschaftliche Texte schreiben",
    "section": "2.5 APA konformes Manuscript erstellen mit Quarto (apaquarto)",
    "text": "2.5 APA konformes Manuscript erstellen mit Quarto (apaquarto)\nUm ein APA konformes Manuscript zu erstellen, empfiehlt es sich, die Quarto Extension apaquarto zu benutzen. Wie das geht wird hier genau beschrieben. Durch die Verwendung der Vorlage werden alle APA Regeln automatisch berücksichtigt. Da auch APA viel Spielraum lässt und jeder Gutachter Sonderwünsche hat, erlaubt es apaquarto, eine Vielzahl von Einstellungen. Beispielsweise kann in der Preamble (YAML header) die Sprache geändert werden oder der allgemeine Stil des Dokumentes verändert werden.",
    "crumbs": [
      "Einleitung",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wissenschaftliche Texte schreiben</span>"
    ]
  },
  {
    "objectID": "paper.html#vorlage-zur-hausarbeit-mit-quarto",
    "href": "paper.html#vorlage-zur-hausarbeit-mit-quarto",
    "title": "2  Wissenschaftliche Texte schreiben",
    "section": "2.6 Vorlage zur Hausarbeit mit Quarto",
    "text": "2.6 Vorlage zur Hausarbeit mit Quarto\nIch habe eine Vorlage erstellt, die Sie zur Erstellung ihrer Hausarbeit verwenden können. Sollte bei Ihnen etwas nicht funktionieren oder sie Hinweise zur Verbesserung haben, freue ich mich über eine Nachricht. Um die Vorlage zu verwenden, folgen Sie bitte den anweisungen auf meinem GitHub Account im Repository temp_apa_de:\nhttps://github.com/hubchev/temp_apa_de",
    "crumbs": [
      "Einleitung",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wissenschaftliche Texte schreiben</span>"
    ]
  },
  {
    "objectID": "einlesen.html",
    "href": "einlesen.html",
    "title": "3  Daten einlesen und aufbereiten",
    "section": "",
    "text": "Dieses Dokument beschreibt exemplarisch die Datenaufbereitung der Datei ‘Dataset 71.txt’. Alle Schritte werden mit R durchgeführt. Der Code ist in die Quarto Datein eingebettet. Die Ergebniss sind vollständig replizierbar. Der verwendete Code kann wieder und anderweitig verwendet werden.\n\n\n\n\n\n\nTipp\n\n\n\nDie PDF Datei kann hier heruntergeladen werden: https://github.com/hubchev/ewa/raw/main/ss_24/read_in_71/doc_read_in_71.pdf.\nUm die komplette Arbeit zu replizieren und gegebenfalls auf einen anderen Datensatz anzuwenden, kann das Repository “ewa” von meinem GitHub Account heruntergeladen werden. Alle entsprechenden Dateien befinden sich im Verzeichnis “ewa/ss_24/read_in_71”. Hier ist der Link zu dem entsprechenden Repository: https://github.com/hubchev/ewa/\nWie das alles im Detail von statten geht, wurde in der Übung behandelt.\n\n\n\n\n\n\nHier finden sie den Ausschnitt des Codes der für die Datenbereinigung zuständig ist:\n\n\n\n\n\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, psych, tinytable, ggstats,\n               modelsummary, knitr, kableExtra, labelled)\nrm(list = ls())\n\nsetwd(\"~/Dropbox/hsf/github/ewa/ss_24/read_in_71\")\n\ndf_raw &lt;- read.delim(\"Dataset 71.txt\")\n\ndf_cosmetic &lt;- df_raw |&gt;\n  clean_names() |&gt;\n  as_tibble() |&gt;\n  mutate(across(everything(), ~ if_else(is.nan(.), NA, .))) |&gt;\n  rowwise() |&gt; \n  filter(!all(across(starts_with(\"item_\"), ~ is.na(.)))) |&gt; \n  ungroup()\n\ndf &lt;- df_cosmetic |&gt;\n  rowwise() |&gt;\n  mutate(outlier = max(abs(c_across(starts_with(\"item_\"))), na.rm = TRUE)) |&gt;\n  mutate(has_outlier = if_else(outlier &gt; 5 | outlier == 0, TRUE, FALSE)) |&gt;\n  mutate(count_larger_5 = \n           sum( c_across(starts_with(\"item_\")) &gt; 5 | \n                  c_across(starts_with(\"item_\")) == 0, na.rm = TRUE)) |&gt; \n  mutate(count_typos = sum(c_across(starts_with(\"item_\")) %in% \n                             c(11, 22, 33, 44, 55), na.rm = TRUE)) |&gt; \n  mutate(has_larger_5_notypos = (count_typos &lt; count_larger_5)) |&gt; \n  mutate(has_typos = count_typos &gt; 0 ) |&gt;\n  mutate(has_nas = if_else(anyNA(pick(starts_with(\"item_\"))), TRUE, FALSE)) |&gt;\n  mutate(complete = (has_outlier == FALSE & has_nas == FALSE)) |&gt; \n  ungroup()\n\nlikert_levels &lt;- c(\n  \"Stimme überhaupt nicht zu\",\n  \"Stimme nicht zu\",\n  \"Neutral\",\n  \"Stimme zu\",\n  \"Stimme voll und ganz zu\"\n)\n\ndf_chr &lt;- df |&gt; \n  mutate(across(starts_with(\"item_\"), \n                ~ case_when(\n                  . == 1 ~ \"Stimme überhaupt nicht zu\",\n                  . == 2 ~ \"Stimme nicht zu\",\n                  . == 3 ~ \"Neutral\",\n                  . == 4 ~ \"Stimme zu\",\n                  . == 5 ~ \"Stimme voll und ganz zu\",\n                  TRUE ~ as.character(.)\n                ))) |&gt; \n  mutate(across(starts_with(\"item_\"), ~ factor(.x, levels = likert_levels)))\n\ndf_complete &lt;- df_chr |&gt; \n  filter(complete == TRUE) \n\ndf_cleaned &lt;- df |&gt; \n  mutate(across(starts_with(\"item_\"), ~ case_when(\n    . == 11 ~ 1,\n    . == 22 ~ 2,\n    . == 33 ~ 3,\n    . == 44 ~ 4,\n    . == 55 ~ 5,\n    TRUE ~ .\n  ))) |&gt; \n  mutate(across(starts_with(\"item_\"), ~ if_else(. &gt; 5 | . == 0, NA, .))) |&gt; \n  mutate(across(starts_with(\"item_\"), \n                ~ case_when(\n                  . == 1 ~ \"Stimme überhaupt nicht zu\",\n                  . == 2 ~ \"Stimme nicht zu\",\n                  . == 3 ~ \"Neutral\",\n                  . == 4 ~ \"Stimme zu\",\n                  . == 5 ~ \"Stimme voll und ganz zu\",\n                  TRUE ~ as.character(.)\n                ))) |&gt; \n  mutate(across(starts_with(\"item_\"), ~ factor(.x, levels = likert_levels)))\n\nrm(list = setdiff(ls(), c(\"df_complete\", \"df_raw\", \"df_cleaned\", \"df\")))\nsave.image(\"data_71.RData\")",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen und aufbereiten</span>"
    ]
  },
  {
    "objectID": "festuca.html",
    "href": "festuca.html",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "",
    "text": "4.1 R-Sitzung einrichten\nrm(list = ls())\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, rstatix, ggpubr, agricolae, tinytable, rempsyc,\n               knitr, kableExtra, ggstatsplot, papaja, janitor, apa)",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#daten-einlesen",
    "href": "festuca.html#daten-einlesen",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.2 Daten einlesen",
    "text": "4.2 Daten einlesen\nPflanzen haben einen optimalen Boden-pH-Wert für ihr Wachstum, und dieser variiert zwischen den Arten. Folglich würden wir erwarten, dass wenn wir zwei Pflanzen im Wettbewerb zueinander unter verschiedenen pH-Werten anbauen, der Effekt des Wettbewerbs je nach Boden-pH-Wert unterschiedlich ausfallen könnte. In einer aktuellen Studie wurde das Wachstum des Grases Festuca ovina (Schaf-Schwingel) im Wettbewerb mit der Besenheide Calluna vulgaris (Heidekraut) in Böden mit unterschiedlichen pH-Werten untersucht. Calluna ist gut angepasst, auf sehr sauren Böden wie dem Millstone Grit und den Hochmoorflächen um Sheffield zu wachsen. Festuca wächst auf Böden mit einem viel breiteren pH-Bereich. Wir könnten die Hypothese aufstellen, dass Calluna in sehr sauren Böden ein besserer Konkurrent von Festuca sein wird als in mäßig sauren Böden. Hier sind die Daten: Die Spalten pH 3.5 und pH 5.5 enthalten das Gewicht, die Spalte Condition enthält die Anwesenheit oder Abwesenheit von Calluna.\nDies ist ein vollständig faktorielles Zwei-Wege-Design. Die Gesamtanzahl der unterschiedlichen Behandlungsgruppen beträgt \\(2 \\times 2 = 4\\). Für jede der Behandlungen gab es 5 Messwerte bzw. Pflanzen, was insgesamt \\(2 \\times 2 \\times 5 = 20\\) Beobachtungen ergibt. Hier sind die vorliegenden Daten:\n\ndata_present &lt;- data.frame(\n  Condition = rep(c(\"Calluna Present\"), each = 5),\n  `ph_3_5` = c(2.76, 2.39, 3.54, 3.71, 2.49),\n  `ph_5_5` = c(3.21, 4.10, 3.04, 4.13, 5.21),\n  check.names = FALSE\n)\ndata_present\n\n        Condition ph_3_5 ph_5_5\n1 Calluna Present   2.76   3.21\n2 Calluna Present   2.39   4.10\n3 Calluna Present   3.54   3.04\n4 Calluna Present   3.71   4.13\n5 Calluna Present   2.49   5.21\n\ndata_absent &lt;- data.frame(\n  Condition = rep(c(\"Calluna Absent\"), each = 5),\n  `ph_3_5`= c(4.10, 2.72, 2.28, 4.43, 3.31),\n  `ph_5_5` = c(5.92, 7.31, 6.10, 5.25, 7.45),\n  check.names = FALSE\n)\ndata_absent\n\n       Condition ph_3_5 ph_5_5\n1 Calluna Absent   4.10   5.92\n2 Calluna Absent   2.72   7.31\n3 Calluna Absent   2.28   6.10\n4 Calluna Absent   4.43   5.25\n5 Calluna Absent   3.31   7.45\n\n\nUm diese zwei Datensätze zu kombinieren, verwende ich die Funktion bind_rows (siehe R Dokumentation):\n\ndata &lt;- bind_rows(data_present, data_absent)\ndata\n\n         Condition ph_3_5 ph_5_5\n1  Calluna Present   2.76   3.21\n2  Calluna Present   2.39   4.10\n3  Calluna Present   3.54   3.04\n4  Calluna Present   3.71   4.13\n5  Calluna Present   2.49   5.21\n6   Calluna Absent   4.10   5.92\n7   Calluna Absent   2.72   7.31\n8   Calluna Absent   2.28   6.10\n9   Calluna Absent   4.43   5.25\n10  Calluna Absent   3.31   7.45\n\n\nUm diesen Datensatz nun im sogenannten Long-Format darzustellen, verwende ich die Funktion pivot_longer. Dieses Format hat bei der Verwendung einiger Befehle vorteile. Wie zwischen dem Long-Format und den Wide-Format gewechselt werden kann, bitte ich Wickham & Grolemund (2023): 5.3 Lengthening data zu entnehmen.\n\nWickham, H., & Grolemund, G. (2023). R for Data Science (2e). https://r4ds.hadley.nz/\n\nfestuca &lt;- data |&gt; \n  pivot_longer(cols = starts_with(\"pH\"), names_to = \"ph\", values_to = \"weight\") |&gt; \n  rename(calluna = Condition) |&gt; \n  mutate(across(c(calluna, ph), as.factor))\n\nfestuca\n\n# A tibble: 20 × 3\n   calluna         ph     weight\n   &lt;fct&gt;           &lt;fct&gt;   &lt;dbl&gt;\n 1 Calluna Present ph_3_5   2.76\n 2 Calluna Present ph_5_5   3.21\n 3 Calluna Present ph_3_5   2.39\n 4 Calluna Present ph_5_5   4.1 \n 5 Calluna Present ph_3_5   3.54\n 6 Calluna Present ph_5_5   3.04\n 7 Calluna Present ph_3_5   3.71\n 8 Calluna Present ph_5_5   4.13\n 9 Calluna Present ph_3_5   2.49\n10 Calluna Present ph_5_5   5.21\n11 Calluna Absent  ph_3_5   4.1 \n12 Calluna Absent  ph_5_5   5.92\n13 Calluna Absent  ph_3_5   2.72\n14 Calluna Absent  ph_5_5   7.31\n15 Calluna Absent  ph_3_5   2.28\n16 Calluna Absent  ph_5_5   6.1 \n17 Calluna Absent  ph_3_5   4.43\n18 Calluna Absent  ph_5_5   5.25\n19 Calluna Absent  ph_3_5   3.31\n20 Calluna Absent  ph_5_5   7.45",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#deskriptive-statistik",
    "href": "festuca.html#deskriptive-statistik",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.3 Deskriptive Statistik",
    "text": "4.3 Deskriptive Statistik\nUm Aussagen über die Beziehung des pH-Werts mit der Pflanzenart tätigen zu können, sollte zunächst ein deskriptiver Blick auf die Daten getätigt werden. Lassen Sie uns also auf den Mittelwert und die Standardabweichung der vier Gruppen blicken. Dies kann tabellarisch oder grafisch geschehen.\n\n4.3.1 Tabellarisch\nDies geht flexibel mit den Funktionen group_by in Kombination mit summarize:\n\nsummary_stats &lt;- festuca |&gt; \n  group_by(calluna, ph) |&gt; \n  summarize(\n    mean = mean(weight),\n    sd = sd(weight)\n  ) |&gt; \n  ungroup()\n\nsummary_stats\n\n# A tibble: 4 × 4\n  calluna         ph      mean    sd\n  &lt;fct&gt;           &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Calluna Absent  ph_3_5  3.37 0.904\n2 Calluna Absent  ph_5_5  6.41 0.945\n3 Calluna Present ph_3_5  2.98 0.609\n4 Calluna Present ph_5_5  3.94 0.869\n\n\nWenn wir schließlich eine publikationswürdige Tabelle haben wollen, geht das wie folgt:\n```{r  , echo=FALSE, warning=FALSE, message=FALSE}\n#| label: tbl-desc_calluna\n#| tbl-cap: Deskriptive Statistiken\n#| tbl.align: left\n\nsummary_stats |&gt; \n  kable() \n```\nDas Ergebnis, ist in Tabelle 4.1 zu sehen.\n\n\n\n\nTabelle 4.1: Deskriptive Statistiken\n\n\n\n\n\n\ncalluna\nph\nmean\nsd\n\n\n\n\nCalluna Absent\nph_3_5\n3.368\n0.9042511\n\n\nCalluna Absent\nph_5_5\n6.406\n0.9451614\n\n\nCalluna Present\nph_3_5\n2.978\n0.6089089\n\n\nCalluna Present\nph_5_5\n3.938\n0.8685448\n\n\n\n\n\n\n\n\n\n\n4.3.2 Grafisch\nBoxplots bieten einen guten Einblick in die Häufigkeitsverteilung, ohne die Grafik zu überfrachten. Bei wenigen Beobachtungen, wie in unserem Fall, können sie aber problematisch sein da die Datengrundlage (5 Beobachtungen pro Boxplot) nicht ersichtlich ist, siehe Abbildung 4.1.\n\nggplot(data = festuca, aes(x = calluna, y = weight, colour = ph)) + \n  geom_boxplot()\n\n\n\n\nAbbildung 4.1: Boxplots\n\n\n\n\n\n\n\n\nMit der Funktion ggbetweenstats aus dem Paket ggstatsplot können die einzelnen Beobachtungen und die statistischen Test zu den Mittelwertvergleichen angezeigt werden, siehe Abbildung 4.2.\n\nfestuca_group &lt;- festuca |&gt; \n  mutate(groups = paste(calluna, ph, sep = \", \"))\n  \nplt &lt;- ggbetweenstats(\n  data = festuca_group,\n  x = groups,\n  y = weight\n)\n\nplt\n\n\n\n\nAbbildung 4.2: Boxplots mit ggbetweenstats",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#t-test",
    "href": "festuca.html#t-test",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.4 t-Test",
    "text": "4.4 t-Test\n\n4.4.1 One Sample t-test\n\nt.test(festuca$weight, mu = 4)\n\n\n    One Sample t-test\n\ndata:  festuca$weight\nt = 0.49085, df = 19, p-value = 0.6292\nalternative hypothesis: true mean is not equal to 4\n95 percent confidence interval:\n 3.436939 4.908061\nsample estimates:\nmean of x \n   4.1725 \n\n\n\nt.test(festuca$weight, mu = 1)\n\n\n    One Sample t-test\n\ndata:  festuca$weight\nt = 9.0273, df = 19, p-value = 2.664e-08\nalternative hypothesis: true mean is not equal to 1\n95 percent confidence interval:\n 3.436939 4.908061\nsample estimates:\nmean of x \n   4.1725 \n\n\n\n\n4.4.2 Two sided t-test\n\nt.test(data$ph_3_5, data$ph_5_5, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  data$ph_3_5 and data$ph_5_5\nt = -3.6529, df = 13.013, p-value = 0.002917\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.1811156 -0.8168844\nsample estimates:\nmean of x mean of y \n    3.173     5.172 \n\nt.test(data_absent$ph_3_5, data_absent$ph_5_5, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  data_absent$ph_3_5 and data_absent$ph_5_5\nt = -5.1934, df = 7.9844, p-value = 0.0008343\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.387422 -1.688578\nsample estimates:\nmean of x mean of y \n    3.368     6.406 \n\nt.test(data_present$ph_3_5, data_present$ph_5_5, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  data_present$ph_3_5 and data_present$ph_5_5\nt = -2.0237, df = 7.1669, p-value = 0.08173\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.0764347  0.1564347\nsample estimates:\nmean of x mean of y \n    2.978     3.938 \n\nt.test(data_absent$ph_3_5, data_present$ph_5_5, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  data_absent$ph_3_5 and data_present$ph_5_5\nt = -1.0165, df = 7.9871, p-value = 0.3392\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.8633899  0.7233899\nsample estimates:\nmean of x mean of y \n    3.368     3.938 \n\nt.test(data_present$ph_3_5, data_absent$ph_5_5, paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  data_present$ph_3_5 and data_absent$ph_5_5\nt = -6.8177, df = 6.8324, p-value = 0.0002776\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.622899 -2.233101\nsample estimates:\nmean of x mean of y \n    2.978     6.406 \n\n\n\nt.test(weight ~ ph, data = festuca)\n\n\n    Welch Two Sample t-test\n\ndata:  weight by ph\nt = -3.6529, df = 13.013, p-value = 0.002917\nalternative hypothesis: true difference in means between group ph_3_5 and group ph_5_5 is not equal to 0\n95 percent confidence interval:\n -3.1811156 -0.8168844\nsample estimates:\nmean in group ph_3_5 mean in group ph_5_5 \n               3.173                5.172 \n\n\n\nt.test(weight ~ calluna, data = festuca)\n\n\n    Welch Two Sample t-test\n\ndata:  weight by calluna\nt = 2.2371, df = 12.893, p-value = 0.04359\nalternative hypothesis: true difference in means between group Calluna Absent and group Calluna Present is not equal to 0\n95 percent confidence interval:\n 0.04785705 2.81014295\nsample estimates:\n mean in group Calluna Absent mean in group Calluna Present \n                        4.887                         3.458",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#anova",
    "href": "festuca.html#anova",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.5 ANOVA",
    "text": "4.5 ANOVA\nVerwenden Sie dieses Modell, um die ANOVA zu berechnen: weight ~ ph + calluna + ph:calluna\n\nfestuca_model &lt;- aov(weight ~ ph + calluna + ph:calluna, data = festuca)\nanova(festuca_model)\n\nAnalysis of Variance Table\n\nResponse: weight\n           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nph          1 19.9800 19.9800 28.1792 7.065e-05 ***\ncalluna     1 10.2102 10.2102 14.4001   0.00159 ** \nph:calluna  1  5.3976  5.3976  7.6126   0.01397 *  \nResiduals  16 11.3446  0.7090                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDiese Ergebnis können publikationswürdig mit den Funktionen apa_print aus dem Paket papaja und kable dargestellt werden, siehe Tabelle 4.2:\n```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}\n#| label: tbl-festuca_model\n#| tbl-cap: \"ANOVA Ergebnisse\"\n\napa_anova &lt;- apa_print(festuca_model)\nknitr::kable( apa_anova$table, booktabs=T) \n```\n\n\n\nTabelle 4.2: ANOVA Ergebnisse\n\n\n\n       Effect                                              \n1 (Intercept) F(1, 16) = 491.08, p &lt; .001, petasq = .97 ***\n2          ph F(1, 16) =  28.18, p &lt; .001, petasq = .64 ***\n3     calluna F(1, 16) =  14.40, p = .002, petasq = .47 ** \n4  ph:calluna F(1, 16) =   7.61, p = .014, petasq = .32 *",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#diagnostics",
    "href": "festuca.html#diagnostics",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.6 Diagnostics",
    "text": "4.6 Diagnostics\nLesen Sie Childs et al. (2021): 27.5 Diagnostics. Außerdem ist diese Seite einen Blick wert. Dort finden Sie einige für die ANOVA-Diagnostik hilfreiche R-Funktionen.",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#interaktions-diagramm",
    "href": "festuca.html#interaktions-diagramm",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.7 Interaktions Diagramm",
    "text": "4.7 Interaktions Diagramm\nEin Interaktionsdiagramm illustriert, wie zwei oder mehr unabhängige Variablen gemeinsam die abhängige Variable beeinflussen. Es hilft dabei, Wechselwirkungen zwischen Faktoren visuell darzustellen und besser zu verstehen, ob der Effekt einer unabhängigen Variablen von der Ausprägung einer anderen abhängt. Dies ist besonders wichtig, um mögliche Interaktionen identifizieren und interpretieren zu können, die in einer ANOVA-Analyse auftreten.\nSo ein Diagramm kann mit der Funktion interaction.plot erstellt werden:\n\ninteraction.plot(festuca$ph, festuca$calluna, response = festuca$weight)\n\n\n\n\n\n\n\n\nHier ist eine viel ansprechendere und flexiblere Methode, um Interaktionsdiagramme mithilfe der tidyverse-Funktionen zu erstellen:\n\n# step 1. calculate means for each treatment combination\nfestuca_means &lt;- \n  festuca |&gt;  \n  group_by(calluna, ph) |&gt;  # &lt;- remember to group by *both* factors\n  summarise(Means = mean(weight))\n\n\n# step 2. plot these as an interaction plot\nggplot(festuca_means, \n       aes(x = ph, y = Means, colour = calluna, group = calluna)) +\n  geom_point(size = 4) + geom_line()\n\n\n\n\n\n\n\n\nBitte lesen Sie Childs et al. (2021): 27.6.1 und berücksichtigen Sie Abbildung 4.3.\n\nChilds, D. Z., Hindle, B. J., & Warren, P. H. (2021). APS 240: Data Analysis and Statistics with R. online. https://dzchilds.github.io/stats-for-bio\n\n\n\n\n\nAbbildung 4.3: Grafische Veranschaulichung des Models",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#multiple-vergleichs-test",
    "href": "festuca.html#multiple-vergleichs-test",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.8 Multiple-Vergleichs-Test",
    "text": "4.8 Multiple-Vergleichs-Test\nEin Multiple-Vergleichs-Test, wie der TukeyHSD-Test, wird verwendet, um nach einer ANOVA-Analyse die Unterschiede zwischen den Gruppenpaaren genauer zu untersuchen. Er hilft dabei, festzustellen, welche spezifischen Gruppen sich signifikant voneinander unterscheiden, indem er alle möglichen Paarvergleiche berücksichtigt. Dies ist besonders nützlich, um nach signifikanten Ergebnissen aus der ANOVA detailliertere Erkenntnisse zu gewinnen.\n\nTukeyHSD(festuca_model, which = 'ph:calluna')\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = weight ~ ph + calluna + ph:calluna, data = festuca)\n\n$`ph:calluna`\n                                                diff        lwr        upr\nph_5_5:Calluna Absent-ph_3_5:Calluna Absent    3.038  1.5143518  4.5616482\nph_3_5:Calluna Present-ph_3_5:Calluna Absent  -0.390 -1.9136482  1.1336482\nph_5_5:Calluna Present-ph_3_5:Calluna Absent   0.570 -0.9536482  2.0936482\nph_3_5:Calluna Present-ph_5_5:Calluna Absent  -3.428 -4.9516482 -1.9043518\nph_5_5:Calluna Present-ph_5_5:Calluna Absent  -2.468 -3.9916482 -0.9443518\nph_5_5:Calluna Present-ph_3_5:Calluna Present  0.960 -0.5636482  2.4836482\n                                                  p adj\nph_5_5:Calluna Absent-ph_3_5:Calluna Absent   0.0001731\nph_3_5:Calluna Present-ph_3_5:Calluna Absent  0.8826936\nph_5_5:Calluna Present-ph_3_5:Calluna Absent  0.7117913\nph_3_5:Calluna Present-ph_5_5:Calluna Absent  0.0000443\nph_5_5:Calluna Present-ph_5_5:Calluna Absent  0.0014155\nph_5_5:Calluna Present-ph_3_5:Calluna Present 0.3079685\n\n\n\nHSD.test(festuca_model, trt = c(\"ph\", \"calluna\"), console = TRUE)\n\n\nStudy: festuca_model ~ c(\"ph\", \"calluna\")\n\nHSD Test for weight \n\nMean Square Error:  0.709035 \n\nph:calluna,  means\n\n                       weight       std r        se  Min  Max  Q25  Q50  Q75\nph_3_5:Calluna Absent   3.368 0.9042511 5 0.3765727 2.28 4.43 2.72 3.31 4.10\nph_3_5:Calluna Present  2.978 0.6089089 5 0.3765727 2.39 3.71 2.49 2.76 3.54\nph_5_5:Calluna Absent   6.406 0.9451614 5 0.3765727 5.25 7.45 5.92 6.10 7.31\nph_5_5:Calluna Present  3.938 0.8685448 5 0.3765727 3.04 5.21 3.21 4.10 4.13\n\nAlpha: 0.05 ; DF Error: 16 \nCritical Value of Studentized Range: 4.046093 \n\nMinimun Significant Difference: 1.523648 \n\nTreatments with the same letter are not significantly different.\n\n                       weight groups\nph_5_5:Calluna Absent   6.406      a\nph_5_5:Calluna Present  3.938      b\nph_3_5:Calluna Absent   3.368      b\nph_3_5:Calluna Present  2.978      b",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "festuca.html#schlussfolgerungen-ziehen-und-ergebnisse-präsentieren",
    "href": "festuca.html#schlussfolgerungen-ziehen-und-ergebnisse-präsentieren",
    "title": "4  Zwei-Wege-ANOVA-Modellen",
    "section": "4.9 Schlussfolgerungen ziehen und Ergebnisse präsentieren",
    "text": "4.9 Schlussfolgerungen ziehen und Ergebnisse präsentieren\nHier sind einige Code-Beispiele, wie die oben gezeigten Diagramme viel schöner gestaltet werden könnten.\n\n# step 1. calculate means for each treatment combination\nfestuca_stats &lt;- \n  festuca |&gt; \n  group_by(calluna, ph) %&gt;% # &lt;- remember to group by the two factors\n  summarise(means = mean(weight), SEs = sd(weight)/sqrt(n()))\n\n`summarise()` has grouped output by 'calluna'. You can override using the\n`.groups` argument.\n\n\n\n# step 1. calculate means for each treatment combination\nfestuca_stats &lt;- \n  festuca |&gt; \n  group_by(calluna, ph) %&gt;% # &lt;- remember to group by the two factors\n  summarise(means = mean(weight), ses = sd(weight)/sqrt(n()))\n\n\n# step 2. plot these as an interaction plot\nggplot(festuca_stats, \n       aes(x = calluna, y = means, colour = ph,\n           ymin = means - ses, ymax = means + ses)) +\n  # this adds the mean\n  geom_point(size = 3) +\n  # this adds the error bars\n  geom_errorbar(width = 0.1) +\n  # controlling the appearance\n  scale_y_continuous(limits = c(2, 7)) + \n  xlab(\"Calluna\") + ylab(\"Festuca yield (g dry weight)\") + \n  # use a more professional theme\n  theme_bw()\n\n\n\n\n\n\n\n\n\n# define a position adjustment \npos &lt;- position_dodge(0.15)\n# make the plot\nggplot(festuca_stats, \n       aes(x = calluna, y = means, colour = ph,\n           ymin = means - ses, ymax = means + ses)) +\n  # this adds the mean (shift positions with 'position =')\n  geom_point(size = 3, position = pos) +\n  # this adds the error bars (shift positions with 'position =')\n  geom_errorbar(width = 0.1, position = pos) +\n  # controlling the appearance\n  scale_y_continuous(limits = c(2, 7)) + \n  xlab(\"Calluna\") + ylab(\"Festuca yield (g dry weight)\") + \n  # use a more professional theme\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggplot(festuca_stats, \n       aes(x = calluna, y = means, fill = ph,\n           ymin = means - ses, ymax = means + ses)) +\n  # this adds the mean\n  geom_col(position = position_dodge()) +\n  # this adds the error bars\n  geom_errorbar(position = position_dodge(0.9), width=.2) +\n  # controlling the appearance\n  xlab(\"Calluna\") + ylab(\"Festuca yield (g dry weight)\")\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 4.1: Boxplots\nAbbildung 4.2: Boxplots mit ggbetweenstats\nAbbildung 4.3: Grafische Veranschaulichung des Models",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zwei-Wege-ANOVA-Modellen</span>"
    ]
  },
  {
    "objectID": "calluna.html",
    "href": "calluna.html",
    "title": "5  ANOVA Ergebnisse und Quarto",
    "section": "",
    "text": "In den folgenden zwei Abschnitten präsentiere ich zwei Dokumente. Beide Dokumente zeigen exemplarisch auf, wie ANOVA Analysen mit R durchgeführt und mit Hilfe von Quarto veranschaulicht werden können.\nUm die dargestellten Ergebniss zu replizieren und den Code gegebenfalls auf einen anderen Datensatz anzuwenden, kann das Repository “ewa” von meinem GitHub Account heruntergeladen werden. Alle entsprechenden Dateien befinden sich im entsprechenden Unterverzeichnis “ewa/ss_24”. Hier ist der Link zu dem entsprechenden Repository: https://github.com/hubchev/ewa/\n\n\n\n\n\n\nTipp\n\n\n\nDie PDF Datei kann hier heruntergeladen werden: https://github.com/hubchev/ewa/raw/main/ss_24/desc_aov/desc_aov.pdf.\nDie dazu gehörende Quarto Datei sowie alle sonstigen Dateien, sind auf meinem GitHub Account zu finden (Huber, 2024): https://github.com/hubchev/ewa/\nWie das alles im Detail von statten geht, wurde in der Übung behandelt.\n\n\n\nHuber, S. (2024). Empirisch-wissenschaftlich Arbeiten (ewa). GitHub repository. https://github.com/hubchev/ewa",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ANOVA Ergebnisse und Quarto</span>"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "6  Regression",
    "section": "",
    "text": "6.1 Making regression tables using apa_table\nHere is an example how to use apa_table from the papaja package to make regression output tables.\nrm(list = ls())\n\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, stargazer, kableExtra, papaja, haven, tinytable)\n# Load the mtcars dataset\ndata(\"mtcars\")\n\n# Fit a linear regression model\nm1 &lt;- lm(mpg ~ wt + hp, data = mtcars)\nm2 &lt;- lm(mpg ~ wt , data = mtcars)\n\n# Summary of the model\nsummary(m1)\n\n\nCall:\nlm(formula = mpg ~ wt + hp, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.941 -1.600 -0.182  1.050  5.854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 37.22727    1.59879  23.285  &lt; 2e-16 ***\nwt          -3.87783    0.63273  -6.129 1.12e-06 ***\nhp          -0.03177    0.00903  -3.519  0.00145 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.593 on 29 degrees of freedom\nMultiple R-squared:  0.8268,    Adjusted R-squared:  0.8148 \nF-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12\n\napa_lm &lt;- apa_print(m1)\nTabelle 6.1: A full regression table.\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                term\n                estimate\n                conf.int\n                statistic\n                df\n                p.value\n              \n        \n        \n        \n                \n                  Intercept\n                  37.23\n                  [33.96, 40.50]\n                  23.28\n                  29\n                  &lt; .001\n                \n                \n                  Wt       \n                  -3.88\n                  [-5.17, -2.58]\n                  -6.13\n                  29\n                  &lt; .001\n                \n                \n                  Hp       \n                  -0.03\n                  [-0.05, -0.01]\n                  -3.52\n                  29\n                  .001",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#making-regression-tables-using-apa_table",
    "href": "regression.html#making-regression-tables-using-apa_table",
    "title": "6  Regression",
    "section": "",
    "text": "```{r  , echo=FALSE, warning=FALSE, message=FALSE}\n#| label: tbl-reg_class\n#| tbl-cap: Deskriptive Statistiken\n#| tbl.align: left\n\ntt(apa_lm$table)\n```",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#data",
    "href": "regression.html#data",
    "title": "6  Regression",
    "section": "6.2 Data",
    "text": "6.2 Data\nIn the statistic course of WS 2020, I asked 23 students about their weight, height, sex, and number of siblings:\n\nclassdata &lt;- read.csv(\"https://raw.githubusercontent.com/hubchev/courses/main/dta/classdata.csv\")\nhead(classdata)\n\n  id sex weight height siblings row\n1  1   w     53    156        1   g\n2  2   w     73    170        1   g\n3  3   m     68    169        1   g\n4  4   w     67    166        1   g\n5  5   w     65    175        1   g\n6  6   w     48    161        0   g",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#first-look-at-data",
    "href": "regression.html#first-look-at-data",
    "title": "6  Regression",
    "section": "6.3 First look at data",
    "text": "6.3 First look at data\n\nggplot(classdata, aes(x=height, y=weight)) + geom_point()",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#include-a-regression-line",
    "href": "regression.html#include-a-regression-line",
    "title": "6  Regression",
    "section": "6.4 Include a regression line:",
    "text": "6.4 Include a regression line:\n\nggplot(classdata, aes(x=height, y=weight)) +\n  geom_point() +\n  stat_smooth(formula=y~x, method=\"lm\", se=FALSE, colour=\"red\", linetype=1)",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#regression-distinguish-malefemale-by-including-a-seperate-constant",
    "href": "regression.html#regression-distinguish-malefemale-by-including-a-seperate-constant",
    "title": "6  Regression",
    "section": "6.5 Regression: Distinguish male/female by including a seperate constant:",
    "text": "6.5 Regression: Distinguish male/female by including a seperate constant:\n\n## baseline regression  model\nmodel  &lt;- lm(weight ~ height + sex , data = classdata )\nshow(model)\n\n\nCall:\nlm(formula = weight ~ height + sex, data = classdata)\n\nCoefficients:\n(Intercept)       height         sexw  \n   -29.5297       0.5923      -5.7894  \n\ninterm &lt;- model$coefficients[1] \nslope  &lt;- model$coefficients[2]\ninterw &lt;- model$coefficients[1]+model$coefficients[3] \n\n\nsummary(model)\n\n\nCall:\nlm(formula = weight ~ height + sex, data = classdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.086  -3.730   2.850   7.245  12.914 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -29.5297    47.6606  -0.620   0.5425  \nheight        0.5923     0.2671   2.217   0.0383 *\nsexw         -5.7894     4.4773  -1.293   0.2107  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.942 on 20 degrees of freedom\nMultiple R-squared:  0.4124,    Adjusted R-squared:  0.3537 \nF-statistic: 7.019 on 2 and 20 DF,  p-value: 0.004904\n\n\n\nggplot(classdata, aes(x=height, y=weight, shape = sex)) +\n  geom_point() +\n  geom_abline(slope = slope, intercept = interw, linetype = 2, size=1.5)+\n  geom_abline(slope = slope, intercept = interm, linetype = 2, size=1.5) +\n  geom_abline(slope = coef(model)[[2]], intercept = coef(model)[[1]]) \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nThat does not look good. Maybe we should introduce also different slopes for male and female.\n\nggplot(classdata, aes(x=height, y=weight, shape = sex)) +\n  geom_point( aes(size = 2)) +\n  stat_smooth(formula = y ~ x,  method = \"lm\", \n              se = FALSE, colour = \"red\", linetype = 1)",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#can-we-use-other-available-variables-such-as-siblings",
    "href": "regression.html#can-we-use-other-available-variables-such-as-siblings",
    "title": "6  Regression",
    "section": "6.6 Can we use other available variables such as siblings?",
    "text": "6.6 Can we use other available variables such as siblings?\n\nggplot(classdata, aes(x=height, y=weight, shape = sex)) +\n  geom_point( aes(size = siblings)) \n\n\n\n\n\n\n\n\n\nggplot(classdata, aes(x=height, y=weight, shape = sex)) +\n  geom_point( aes(size = 2)) +\n  stat_smooth(formula = y ~ x,  \n              method = \"lm\", \n              se = T, \n              colour = \"red\", \n              linetype = 1)",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#let-us-look-at-regression-output",
    "href": "regression.html#let-us-look-at-regression-output",
    "title": "6  Regression",
    "section": "6.7 Let us look at regression output:",
    "text": "6.7 Let us look at regression output:\n\nm1 &lt;- lm(weight ~ height , data = classdata )\nm2 &lt;- lm(weight ~ height + sex , data = classdata )\nm3 &lt;- lm(weight ~ height + sex + height * sex , data = classdata )\nm4 &lt;- lm(weight ~ height + sex + height * sex + siblings , data = classdata )\nm5 &lt;- lm(weight ~ height + sex + height * sex , data = subset(classdata, siblings &lt; 4 ))",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#interpretation-of-the-results",
    "href": "regression.html#interpretation-of-the-results",
    "title": "6  Regression",
    "section": "6.8 Interpretation of the results",
    "text": "6.8 Interpretation of the results\n\nWe can make predictions about the impact of height on male and female\nAs both, the intercept and the slope differs for male and female we should interpret the regressions seperately:\nOne centimeter more for MEN is on average and ceteris paribus related with 0.16 kg more weight.\nOne centimeter more for WOMEN is on average and ceteris paribus related with 1.01 kg more weight.",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#regression-diagnostics",
    "href": "regression.html#regression-diagnostics",
    "title": "6  Regression",
    "section": "6.9 Regression diagnostics",
    "text": "6.9 Regression diagnostics\nLinear Regression makes several assumptions about the data, the model assumes that:\n\nThe relationship between the predictor (x) and the dependent variable (y) has linear relationship.\nThe residuals are assumed to have a constant variance.\nThe residual errors are assumed to be normally distributed.\nError terms are independent and have zero mean.\n\nMore on regression Diagnostics can be found Applied Statistics with R: 13 Model Diagnostics\n\n6.9.1 Check assumptions\nWhen performing regression analysis, it is crucial to validate that the underlying assumptions of the model are met. These assumptions include linearity, independence, homoscedasticity (constant variance of residuals), absence of multicollinearity, and normality of residuals. Diagnosing these assumptions helps ensure the reliability and validity of the model.\nIn this section, we will explore how to perform regression diagnostics in R using the performance and see packages, which provide comprehensive tools for evaluating model assumptions and performance. Here is a sample code to illustrate these concepts:\n\n# Load the required packages using pacman\npacman::p_load(performance, see)\n\n# Check for heteroscedasticity (non-constant variance of residuals)\ncheck_heteroscedasticity(m4)\n\nOK: Error variance appears to be homoscedastic (p = 0.630).\n\n# Check for multicollinearity (correlations among predictors)\ncheck_collinearity(m4)\n\nModel has interaction terms. VIFs might be inflated.\n  You may check multicollinearity among predictors of a model without\n  interaction terms.\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n     Term  VIF        VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n   height 2.90 [  1.93,    4.90]         1.70      0.34     [0.20, 0.52]\n siblings 1.30 [  1.07,    2.37]         1.14      0.77     [0.42, 0.94]\n\nHigh Correlation\n\n       Term    VIF        VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n        sex 633.56 [359.01, 1118.64]        25.17  1.58e-03     [0.00, 0.00]\n height:sex 597.51 [338.60, 1054.98]        24.44  1.67e-03     [0.00, 0.00]\n\n# Check for normality of residuals\ncheck_normality(m4)\n\nOK: residuals appear as normally distributed (p = 0.086).\n\n# Check for outliers in the model\ncheck_outliers(m4)\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.816).\n- For variable: (Whole model)\n\n# Evaluate overall model performance\nmodel_performance(m4)\n\n# Indices of model performance\n\nAIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n---------------------------------------------------------------\n171.282 | 176.532 | 178.095 | 0.496 |     0.385 | 7.719 | 8.726\n\n# Compare performance of multiple models and rank them\ncompare_performance(m1, m2, m3, m4, rank = TRUE, verbose = FALSE)\n\n# Comparison of Model Performance Indices\n\nName | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights | BIC weights | Performance-Score\n---------------------------------------------------------------------------------------------------------------\nm3   |    lm | 0.487 |     0.407 | 7.788 | 8.568 |       0.381 |        0.240 |       0.241 |            82.70%\nm4   |    lm | 0.496 |     0.385 | 7.719 | 8.726 |       0.172 |        0.046 |       0.062 |            48.51%\nm2   |    lm | 0.412 |     0.354 | 8.338 | 8.942 |       0.215 |        0.260 |       0.240 |            35.23%\nm1   |    lm | 0.363 |     0.333 | 8.680 | 9.084 |       0.232 |        0.454 |       0.457 |            32.72%\n\n# Plot the performance comparison of multiple models\nplot(compare_performance(m1, m2, m3, m4, rank = TRUE, verbose = FALSE))\n\n\n\n\n\n\n\n# Perform statistical tests on the model performance\ntest_performance(m1, m2, m3, m4)\n\nName | Model |    BF | df | df_diff | Chi2 |     p\n--------------------------------------------------\nm1   |    lm |       |  3 |         |      |      \nm2   |    lm | 0.525 |  4 |    1.00 | 1.85 | 0.174\nm3   |    lm |  1.00 |  5 |    1.00 | 3.14 | 0.076\nm4   |    lm | 0.256 |  6 |    1.00 | 0.41 | 0.524\nModels were detected as nested (in terms of fixed parameters) and are compared in sequential order.\n\n# Comprehensive check of the model's assumptions\ncheck_model(m4)",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "desc_NRW.html",
    "href": "desc_NRW.html",
    "title": "7  Descriptive Statistics of the NRW80+ Dataset",
    "section": "",
    "text": "7.1 Technical Note\nIn the following, I load (and install) packages that I use later on and I show information about my R session with sessionInfo().\n# (Install and) load pacman package \nif (!require(pacman)) install.packages(\"pacman\")\n\n# load packages that are already installed and install packages that are not \n# installed yet and then load them:\npacman::p_load(tinylabels, \n               papaja,\n               haven, \n               labelled, \n               janitor,\n               skimr, \n               rstatix, \n               HH, \n               likert, \n               expss,\n               tidyr, \n               ggstats,\n               psych,\n               sjlabelled,\n               sjmisc,\n               tidyverse, \n               MASS,\n               dplyr,\n               magick,\n               tinytable)\n\n# sessionInfo()",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Descriptive Statistics of the NRW80+ Dataset</span>"
    ]
  },
  {
    "objectID": "desc_NRW.html#import-data",
    "href": "desc_NRW.html#import-data",
    "title": "7  Descriptive Statistics of the NRW80+ Dataset",
    "section": "7.2 Import Data",
    "text": "7.2 Import Data\nI host a R script on my GitHub account (see https://raw.githubusercontent.com/hubchev/courses/main/scr/readin_GESIS.R) that explains how to import the NRW80+ data. I have manually saved the data, gesis.RData, in a subfolder named data.",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Descriptive Statistics of the NRW80+ Dataset</span>"
    ]
  },
  {
    "objectID": "desc_NRW.html#how-to-use-the-nrw80-data",
    "href": "desc_NRW.html#how-to-use-the-nrw80-data",
    "title": "7  Descriptive Statistics of the NRW80+ Dataset",
    "section": "7.3 How to Use the NRW80+ Data",
    "text": "7.3 How to Use the NRW80+ Data\n\n7.3.1 Load and Subset Data\nI load the data and select some variables that are of particular interest to me.\n\ngetwd()\n\n[1] \"/home/sthu/Dropbox/hsf/courses/ewa\"\n\nload(\"/home/sthu/Dropbox/hsf/23-ws/ewa/data/gesis.RData\")\ndf &lt;- dfdta |&gt;\n  select(starts_with(\"alter\"), \n         ALT_agegroup, \n         ALT_sex, \n         famst1, famst7, \n         demtectcorr, \n         kogstat, \n         final, \n         geschlecht)\n\n# Remove the common prefix from all variables\ndf &lt;- df |&gt; \n  mutate_all(~ set_label(., gsub(\"^Alternserleben: \", \"\", get_label(.))))\n\nFor simplification, let us focus on the questions that refer to the “Experience of Ageing” and create a new dataset df_alterl that contains only those questions:\n\ndf_alterl &lt;- df |&gt; \n  select(alterl1, \n         alterl2, \n         alterl3, \n         alterl4, \n         alterl5, \n         alterl6, \n         alterl7, \n         alterl8, \n         alterl9, \n         alterl10) |&gt; \n  drop_unused_labels() \n\n# to remove unused labels you can use drop_unused_labels():\ndf_alterl_un &lt;- df_alterl |&gt;\n  drop_unused_labels()\n\nsummary(df_alterl)\n\n    alterl1          alterl2          alterl3          alterl4      \n Min.   :-2.000   Min.   :-2.000   Min.   :-2.000   Min.   :-2.000  \n 1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 2.000  \n Median : 3.000   Median : 4.000   Median : 2.000   Median : 3.000  \n Mean   : 2.656   Mean   : 3.282   Mean   : 2.349   Mean   : 2.763  \n 3rd Qu.: 4.000   3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.: 4.000  \n Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  \n    alterl5         alterl6          alterl7          alterl8      \n Min.   :-2.00   Min.   :-2.000   Min.   :-2.000   Min.   :-2.000  \n 1st Qu.: 2.00   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 1.000  \n Median : 3.00   Median : 4.000   Median : 3.000   Median : 3.000  \n Mean   : 2.99   Mean   : 3.405   Mean   : 3.237   Mean   : 2.712  \n 3rd Qu.: 4.00   3rd Qu.: 5.000   3rd Qu.: 4.000   3rd Qu.: 4.000  \n Max.   : 5.00   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  \n    alterl9          alterl10     \n Min.   :-2.000   Min.   :-2.000  \n 1st Qu.: 2.000   1st Qu.: 1.000  \n Median : 3.000   Median : 2.000  \n Mean   : 2.969   Mean   : 2.305  \n 3rd Qu.: 4.000   3rd Qu.: 3.000  \n Max.   : 5.000   Max.   : 5.000  \n\n\n\n\n7.3.2 Get an Overview by Counting\n\n7.3.2.1 table() of R base\nWith the table() function, you can count how many observations of each unique value a variable contains:\n\ntable(df_alterl$alterl1)\n\n\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        80          6        390        266        451        511        159 \n\n\nTo do that for each variable of a dataset is easy using ~, the pipe operator, and map() of the package purrr (Wickham & Henry, 2023):\n\nWickham, H., & Henry, L. (2023). purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr\n\ndf_alterl |&gt; \n  map(~ table(.))\n\n$alterl1\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        80          6        390        266        451        511        159 \n\n$alterl2\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        36          4        196        245        379        648        355 \n\n$alterl3\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        20          3        500        577        403        244        116 \n\n$alterl4\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n       122          8        222        260        527        543        181 \n\n$alterl5\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n       101          4        199        211        452        680        216 \n\n$alterl6\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        19          3        149        324        358        537        473 \n\n$alterl7\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        20          2        145        362        471        525        338 \n\n$alterl8\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        20          3        516        350        325        340        309 \n\n$alterl9\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        83         10        261        228        425        564        292 \n\n$alterl10\n.\nWeiß nicht Verweigert  Gar nicht  Ein wenig      Mäßig      Stark Sehr stark \n        44          7        537        433        486        251        105 \n\n\nUsing proportions() returns the conditional proportions:\n\ndf_alterl |&gt; \n  map(~ proportions(table(.)))\n\n$alterl1\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.042941492 0.003220612 0.209339775 0.142780462 0.242082662 0.274288782 \n Sehr stark \n0.085346216 \n\n$alterl2\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.019323671 0.002147075 0.105206656 0.131508320 0.203435319 0.347826087 \n Sehr stark \n0.190552872 \n\n$alterl3\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.010735373 0.001610306 0.268384326 0.309715513 0.216317767 0.130971551 \n Sehr stark \n0.062265164 \n\n$alterl4\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.065485776 0.004294149 0.119162641 0.139559850 0.282877080 0.291465378 \n Sehr stark \n0.097155126 \n\n$alterl5\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.054213634 0.002147075 0.106816962 0.113258186 0.242619431 0.365002684 \n Sehr stark \n0.115942029 \n\n$alterl6\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.010198604 0.001610306 0.079978529 0.173913043 0.192163178 0.288244767 \n Sehr stark \n0.253891573 \n\n$alterl7\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.010735373 0.001073537 0.077831455 0.194310252 0.252818035 0.281803543 \n Sehr stark \n0.181427805 \n\n$alterl8\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.010735373 0.001610306 0.276972625 0.187869028 0.174449812 0.182501342 \n Sehr stark \n0.165861514 \n\n$alterl9\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.044551798 0.005367687 0.140096618 0.122383253 0.228126677 0.302737520 \n Sehr stark \n0.156736447 \n\n$alterl10\n.\n Weiß nicht  Verweigert   Gar nicht   Ein wenig       Mäßig       Stark \n0.023617821 0.003757381 0.288244767 0.232420827 0.260869565 0.134728932 \n Sehr stark \n0.056360709 \n\n\n\n\n7.3.2.2 tabyl() of janitor\nWith tabyl() which is part of janitor (Firke, 2023), we can get both nicely:\n\nFirke, S. (2023). janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor\n\ndf_alterl |&gt; \n  tabyl(alterl1) \n\n alterl1   n     percent\n      -2  80 0.042941492\n      -1   6 0.003220612\n       1 390 0.209339775\n       2 266 0.142780462\n       3 451 0.242082662\n       4 511 0.274288782\n       5 159 0.085346216\n\ndf_alterl |&gt; \n  map(~ tabyl(.))\n\n$alterl1\n  .   n     percent\n -2  80 0.042941492\n -1   6 0.003220612\n  1 390 0.209339775\n  2 266 0.142780462\n  3 451 0.242082662\n  4 511 0.274288782\n  5 159 0.085346216\n\n$alterl2\n  .   n     percent\n -2  36 0.019323671\n -1   4 0.002147075\n  1 196 0.105206656\n  2 245 0.131508320\n  3 379 0.203435319\n  4 648 0.347826087\n  5 355 0.190552872\n\n$alterl3\n  .   n     percent\n -2  20 0.010735373\n -1   3 0.001610306\n  1 500 0.268384326\n  2 577 0.309715513\n  3 403 0.216317767\n  4 244 0.130971551\n  5 116 0.062265164\n\n$alterl4\n  .   n     percent\n -2 122 0.065485776\n -1   8 0.004294149\n  1 222 0.119162641\n  2 260 0.139559850\n  3 527 0.282877080\n  4 543 0.291465378\n  5 181 0.097155126\n\n$alterl5\n  .   n     percent\n -2 101 0.054213634\n -1   4 0.002147075\n  1 199 0.106816962\n  2 211 0.113258186\n  3 452 0.242619431\n  4 680 0.365002684\n  5 216 0.115942029\n\n$alterl6\n  .   n     percent\n -2  19 0.010198604\n -1   3 0.001610306\n  1 149 0.079978529\n  2 324 0.173913043\n  3 358 0.192163178\n  4 537 0.288244767\n  5 473 0.253891573\n\n$alterl7\n  .   n     percent\n -2  20 0.010735373\n -1   2 0.001073537\n  1 145 0.077831455\n  2 362 0.194310252\n  3 471 0.252818035\n  4 525 0.281803543\n  5 338 0.181427805\n\n$alterl8\n  .   n     percent\n -2  20 0.010735373\n -1   3 0.001610306\n  1 516 0.276972625\n  2 350 0.187869028\n  3 325 0.174449812\n  4 340 0.182501342\n  5 309 0.165861514\n\n$alterl9\n  .   n     percent\n -2  83 0.044551798\n -1  10 0.005367687\n  1 261 0.140096618\n  2 228 0.122383253\n  3 425 0.228126677\n  4 564 0.302737520\n  5 292 0.156736447\n\n$alterl10\n  .   n     percent\n -2  44 0.023617821\n -1   7 0.003757381\n  1 537 0.288244767\n  2 433 0.232420827\n  3 486 0.260869565\n  4 251 0.134728932\n  5 105 0.056360709\n\n\n\n\n7.3.2.3 frq() of sjmisc\nAs the variables df_alterl1 are factors. Thus, we can use the sjmisc package, see Lüdecke (2018) and the cheatsheet of sjmisc http://strengejacke.de/sjmisc-cheatsheet.pdf. Also worth a reading is browseVignettes(\"sjmisc\").\n\nLüdecke, D. (2018). sjmisc: Data and Variable Transformation Functions. Journal of Open Source Software, 3(26), 754. https://doi.org/10.21105/joss.00754\nFor example, we can use frq() for nice frequency tables:\n\ndf_alterl |&gt; \n  map(~ frq(. , show.na = T))\n\n$alterl1\nBeziehungen und andere Menschen mehr schätzen (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=2.66 sd=1.61\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  80 |  4.29 |    4.29 |   4.29\n    2 |  Ein wenig |   6 |  0.32 |    0.32 |   4.62\n    3 |      Mäßig | 390 | 20.93 |   20.93 |  25.55\n    4 |      Stark | 266 | 14.28 |   14.28 |  39.83\n    5 | Sehr stark | 451 | 24.21 |   24.21 |  64.04\n    6 |       &lt;NA&gt; | 511 | 27.43 |   27.43 |  91.47\n    7 |       &lt;NA&gt; | 159 |  8.53 |    8.53 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl2\nGesundheit mehr Aufmerksamkeit widmen (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=3.28 sd=1.45\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  36 |  1.93 |    1.93 |   1.93\n    2 |  Ein wenig |   4 |  0.21 |    0.21 |   2.15\n    3 |      Mäßig | 196 | 10.52 |   10.52 |  12.67\n    4 |      Stark | 245 | 13.15 |   13.15 |  25.82\n    5 | Sehr stark | 379 | 20.34 |   20.34 |  46.16\n    6 |       &lt;NA&gt; | 648 | 34.78 |   34.78 |  80.94\n    7 |       &lt;NA&gt; | 355 | 19.06 |   19.06 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl3\ngeistige Leistungsfähigkeit nimmt ab (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=2.35 sd=1.28\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  20 |  1.07 |    1.07 |   1.07\n    2 |  Ein wenig |   3 |  0.16 |    0.16 |   1.23\n    3 |      Mäßig | 500 | 26.84 |   26.84 |  28.07\n    4 |      Stark | 577 | 30.97 |   30.97 |  59.04\n    5 | Sehr stark | 403 | 21.63 |   21.63 |  80.68\n    6 |       &lt;NA&gt; | 244 | 13.10 |   13.10 |  93.77\n    7 |       &lt;NA&gt; | 116 |  6.23 |    6.23 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl4\nmehr Erfahrung, um Dinge und Menschen einzuschätzen (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=2.76 sd=1.72\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht | 122 |  6.55 |    6.55 |   6.55\n    2 |  Ein wenig |   8 |  0.43 |    0.43 |   6.98\n    3 |      Mäßig | 222 | 11.92 |   11.92 |  18.89\n    4 |      Stark | 260 | 13.96 |   13.96 |  32.85\n    5 | Sehr stark | 527 | 28.29 |   28.29 |  61.14\n    6 |       &lt;NA&gt; | 543 | 29.15 |   29.15 |  90.28\n    7 |       &lt;NA&gt; | 181 |  9.72 |    9.72 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl5\nbesseres Gespür, was wichtig ist (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=2.99 sd=1.66\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht | 101 |  5.42 |    5.42 |   5.42\n    2 |  Ein wenig |   4 |  0.21 |    0.21 |   5.64\n    3 |      Mäßig | 199 | 10.68 |   10.68 |  16.32\n    4 |      Stark | 211 | 11.33 |   11.33 |  27.64\n    5 | Sehr stark | 452 | 24.26 |   24.26 |  51.91\n    6 |       &lt;NA&gt; | 680 | 36.50 |   36.50 |  88.41\n    7 |       &lt;NA&gt; | 216 | 11.59 |   11.59 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl6\nEinschränkung der Aktivitäten (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=3.40 sd=1.38\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  19 |  1.02 |    1.02 |   1.02\n    2 |  Ein wenig |   3 |  0.16 |    0.16 |   1.18\n    3 |      Mäßig | 149 |  8.00 |    8.00 |   9.18\n    4 |      Stark | 324 | 17.39 |   17.39 |  26.57\n    5 | Sehr stark | 358 | 19.22 |   19.22 |  45.79\n    6 |       &lt;NA&gt; | 537 | 28.82 |   28.82 |  74.61\n    7 |       &lt;NA&gt; | 473 | 25.39 |   25.39 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl7\nweniger Energie (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=3.24 sd=1.32\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  20 |  1.07 |    1.07 |   1.07\n    2 |  Ein wenig |   2 |  0.11 |    0.11 |   1.18\n    3 |      Mäßig | 145 |  7.78 |    7.78 |   8.96\n    4 |      Stark | 362 | 19.43 |   19.43 |  28.40\n    5 | Sehr stark | 471 | 25.28 |   25.28 |  53.68\n    6 |       &lt;NA&gt; | 525 | 28.18 |   28.18 |  81.86\n    7 |       &lt;NA&gt; | 338 | 18.14 |   18.14 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl8\nAbhängigkeit von der Hilfe Anderer (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=2.71 sd=1.53\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  20 |  1.07 |    1.07 |   1.07\n    2 |  Ein wenig |   3 |  0.16 |    0.16 |   1.23\n    3 |      Mäßig | 516 | 27.70 |   27.70 |  28.93\n    4 |      Stark | 350 | 18.79 |   18.79 |  47.72\n    5 | Sehr stark | 325 | 17.44 |   17.44 |  65.16\n    6 |       &lt;NA&gt; | 340 | 18.25 |   18.25 |  83.41\n    7 |       &lt;NA&gt; | 309 | 16.59 |   16.59 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl9\nFreiheit, Tage nach eigenem Willen zu verleben (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=2.97 sd=1.68\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  83 |  4.46 |    4.46 |   4.46\n    2 |  Ein wenig |  10 |  0.54 |    0.54 |   4.99\n    3 |      Mäßig | 261 | 14.01 |   14.01 |  19.00\n    4 |      Stark | 228 | 12.24 |   12.24 |  31.24\n    5 | Sehr stark | 425 | 22.81 |   22.81 |  54.05\n    6 |       &lt;NA&gt; | 564 | 30.27 |   30.27 |  84.33\n    7 |       &lt;NA&gt; | 292 | 15.67 |   15.67 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n$alterl10\nMotivation fällt schwerer (x) &lt;numeric&gt; \n# total N=1863 valid N=1863 mean=2.31 sd=1.38\n\nValue |      Label |   N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n   -2 | Weiß nicht |   0 |  0.00 |    0.00 |   0.00\n   -1 | Verweigert |   0 |  0.00 |    0.00 |   0.00\n    1 |  Gar nicht |  44 |  2.36 |    2.36 |   2.36\n    2 |  Ein wenig |   7 |  0.38 |    0.38 |   2.74\n    3 |      Mäßig | 537 | 28.82 |   28.82 |  31.56\n    4 |      Stark | 433 | 23.24 |   23.24 |  54.80\n    5 | Sehr stark | 486 | 26.09 |   26.09 |  80.89\n    6 |       &lt;NA&gt; | 251 | 13.47 |   13.47 |  94.36\n    7 |       &lt;NA&gt; | 105 |  5.64 |    5.64 | 100.00\n &lt;NA&gt; |       &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n\n7.3.3 First Summary Statistics\n\n7.3.3.1 Using summary() and get_summary_stats()\nFirst, I am interested in the class of the data and some very basic summary statistics.\n\nsummary(df)\n\n    alterl1          alterl2          alterl3          alterl4      \n Min.   :-2.000   Min.   :-2.000   Min.   :-2.000   Min.   :-2.000  \n 1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 2.000  \n Median : 3.000   Median : 4.000   Median : 2.000   Median : 3.000  \n Mean   : 2.656   Mean   : 3.282   Mean   : 2.349   Mean   : 2.763  \n 3rd Qu.: 4.000   3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.: 4.000  \n Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  \n                                                                    \n    alterl5         alterl6          alterl7          alterl8      \n Min.   :-2.00   Min.   :-2.000   Min.   :-2.000   Min.   :-2.000  \n 1st Qu.: 2.00   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 1.000  \n Median : 3.00   Median : 4.000   Median : 3.000   Median : 3.000  \n Mean   : 2.99   Mean   : 3.405   Mean   : 3.237   Mean   : 2.712  \n 3rd Qu.: 4.00   3rd Qu.: 5.000   3rd Qu.: 4.000   3rd Qu.: 4.000  \n Max.   : 5.00   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  \n                                                                   \n    alterl9          alterl10        alter_int        alter_cont    \n Min.   :-2.000   Min.   :-2.000   Min.   : 80.00   Min.   : 80.11  \n 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 82.00   1st Qu.: 82.99  \n Median : 3.000   Median : 2.000   Median : 86.00   Median : 86.59  \n Mean   : 2.969   Mean   : 2.305   Mean   : 86.48   Mean   : 86.98  \n 3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.: 90.00   3rd Qu.: 90.56  \n Max.   : 5.000   Max.   : 5.000   Max.   :102.00   Max.   :102.92  \n                                   NA's   :6        NA's   :6       \n   alterl_m1       alterl_m2         alterp        ALT_agegroup  \n Min.   :1.000   Min.   :1.000   Min.   :-4.000   Min.   :1.000  \n 1st Qu.:2.600   1st Qu.:2.200   1st Qu.:-4.000   1st Qu.:1.000  \n Median :3.200   Median :2.800   Median :-4.000   Median :2.000  \n Mean   :3.168   Mean   :2.877   Mean   : 2.632   Mean   :1.883  \n 3rd Qu.:3.800   3rd Qu.:3.600   3rd Qu.:-4.000   3rd Qu.:3.000  \n Max.   :5.000   Max.   :5.000   Max.   :99.000   Max.   :3.000  \n NA's   :16      NA's   :14                                      \n    ALT_sex          famst1           famst7        demtectcorr     \n Min.   :1.000   Min.   :-1.000   Min.   :-3.000   Min.   :-11.000  \n 1st Qu.:1.000   1st Qu.: 1.000   1st Qu.:-3.000   1st Qu.: -1.000  \n Median :2.000   Median : 4.000   Median : 0.000   Median :  0.000  \n Mean   :1.502   Mean   : 2.765   Mean   :-1.179   Mean   : -1.742  \n 3rd Qu.:2.000   3rd Qu.: 4.000   3rd Qu.: 0.000   3rd Qu.:  0.000  \n Max.   :2.000   Max.   : 5.000   Max.   : 1.000   Max.   :  2.000  \n                                                                    \n    kogstat          final         geschlecht   \n Min.   :-4.00   Min.   :81.00   Min.   :1.000  \n 1st Qu.:-4.00   1st Qu.:81.00   1st Qu.:1.000  \n Median :-4.00   Median :81.00   Median :2.000  \n Mean   :-3.21   Mean   :81.09   Mean   :1.502  \n 3rd Qu.:-4.00   3rd Qu.:81.00   3rd Qu.:2.000  \n Max.   : 7.00   Max.   :82.00   Max.   :2.000  \n                                                \n\nsumstat_alter &lt;- df |&gt; \n  get_summary_stats(\n    alterl1, \n    alterl2, \n    alterl3, \n    alterl4, \n    alterl5, \n    alterl6, \n    alterl7, \n    alterl8, \n    alterl9, \n    alterl10,  \n    type = \"five_number\")  \n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\nsumstat_alter\n\n# A tibble: 10 × 7\n   variable     n   min   max    q1 median    q3\n   &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 alterl1   1863    -2     5     1      3     4\n 2 alterl2   1863    -2     5     2      4     4\n 3 alterl3   1863    -2     5     1      2     3\n 4 alterl4   1863    -2     5     2      3     4\n 5 alterl5   1863    -2     5     2      3     4\n 6 alterl6   1863    -2     5     2      4     5\n 7 alterl7   1863    -2     5     2      3     4\n 8 alterl8   1863    -2     5     1      3     4\n 9 alterl9   1863    -2     5     2      3     4\n10 alterl10  1863    -2     5     1      2     3\n\n\n\n\n7.3.3.2 Using psych::describe()\nA powerful alternative for descriptive summary statistics is provided by the function describe() of the psych package (William Revelle, 2023).\n\nsumstat_alter_psych &lt;- df |&gt;\n  select(starts_with(\"alterl\")) |&gt; \n  select(-ends_with(\"m1\"), -ends_with(\"m2\")) |&gt; \n  psych::describe() |&gt; \n  as_tibble(rownames=\"Question\")  |&gt; \n  select(-skew, -kurtosis, -range, -vars) \n\nsumstat_alter_psych\n\n# A tibble: 10 × 10\n   Question     n  mean    sd median trimmed   mad   min   max     se\n   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 alterl1   1863  2.66  1.61      3    2.76  1.48    -2     5 0.0374\n 2 alterl2   1863  3.28  1.45      4    3.43  1.48    -2     5 0.0336\n 3 alterl3   1863  2.35  1.28      2    2.28  1.48    -2     5 0.0296\n 4 alterl4   1863  2.76  1.72      3    2.96  1.48    -2     5 0.0398\n 5 alterl5   1863  2.99  1.66      3    3.20  1.48    -2     5 0.0385\n 6 alterl6   1863  3.40  1.38      4    3.54  1.48    -2     5 0.0321\n 7 alterl7   1863  3.24  1.32      3    3.33  1.48    -2     5 0.0306\n 8 alterl8   1863  2.71  1.53      3    2.68  1.48    -2     5 0.0355\n 9 alterl9   1863  2.97  1.68      3    3.14  1.48    -2     5 0.0389\n10 alterl10  1863  2.31  1.38      2    2.28  1.48    -2     5 0.0321\n\n\n\n\n7.3.3.3 Using summarize() and the tidyverse\nAs you may be aware, the tidyverse package provides powerful and flexible functions such as filter, select, group_by, and summarize. Here is an example demonstrating how these functions can be utilized to create descriptive statistic tables:\n\ndescriptives &lt;- dfdta |&gt;  \n  # filter(alterl1 &gt; 0) |&gt; \n  group_by(geschlecht)  |&gt; \n  summarize(\n    Mean = mean(alterl1)\n    , Count = n()\n    , SD = sd(alterl1)\n    , Min = min(alterl1)\n    , Max = max(alterl1)\n  )\n\ndescriptives\n\n# A tibble: 2 × 6\n  geschlecht    Mean Count    SD Min             Max           \n  &lt;dbl+lbl&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;       &lt;dbl+lbl&gt;     \n1 1 [Männlich]  2.71   927  1.50 -2 [Weiß nicht] 5 [Sehr stark]\n2 2 [Weiblich]  2.60   936  1.72 -2 [Weiß nicht] 5 [Sehr stark]\n\n\n\n\n\n7.3.4 Make Tables using tt()\n```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}\n#| label: tbl-tabrstatix\n#| tbl-cap: \"Summary Statistics: Experience of Ageing.\"\n\ntt(sumstat_alter,  output = \"markdown\", \n   note = \"Note: This table contains all variables of `alterl*`.\")\n```\n\n\n\n\nTabelle 7.1: Summary Statistics: Experience of Ageing.\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                variable\n                n\n                min\n                max\n                q1\n                median\n                q3\n              \n        \n        Note: This table contains all variables of `alterl*`.\n        \n                \n                  alterl1 \n                  1863\n                  -2\n                  5\n                  1\n                  3\n                  4\n                \n                \n                  alterl2 \n                  1863\n                  -2\n                  5\n                  2\n                  4\n                  4\n                \n                \n                  alterl3 \n                  1863\n                  -2\n                  5\n                  1\n                  2\n                  3\n                \n                \n                  alterl4 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl5 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl6 \n                  1863\n                  -2\n                  5\n                  2\n                  4\n                  5\n                \n                \n                  alterl7 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl8 \n                  1863\n                  -2\n                  5\n                  1\n                  3\n                  4\n                \n                \n                  alterl9 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl10\n                  1863\n                  -2\n                  5\n                  1\n                  2\n                  3\n                \n        \n      \n    \n\n\n\n\n\n\n```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}\n#| label: tbl-tabsumstatalterpsych\n#| tbl-cap: \"Summary Statistics: Experience of Ageing (psych)\"\n\ntt(sumstat_alter,  output = \"markdown\",\n   note = \"Note: This table contains all variables of `alterl*`.\")\n```\n\n\n\n\nTabelle 7.2: Summary Statistics: Experience of Ageing (psych)\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                variable\n                n\n                min\n                max\n                q1\n                median\n                q3\n              \n        \n        Note: This table contains all variables of `alterl*`.\n        \n                \n                  alterl1 \n                  1863\n                  -2\n                  5\n                  1\n                  3\n                  4\n                \n                \n                  alterl2 \n                  1863\n                  -2\n                  5\n                  2\n                  4\n                  4\n                \n                \n                  alterl3 \n                  1863\n                  -2\n                  5\n                  1\n                  2\n                  3\n                \n                \n                  alterl4 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl5 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl6 \n                  1863\n                  -2\n                  5\n                  2\n                  4\n                  5\n                \n                \n                  alterl7 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl8 \n                  1863\n                  -2\n                  5\n                  1\n                  3\n                  4\n                \n                \n                  alterl9 \n                  1863\n                  -2\n                  5\n                  2\n                  3\n                  4\n                \n                \n                  alterl10\n                  1863\n                  -2\n                  5\n                  1\n                  2\n                  3\n                \n        \n      \n    \n\n\n\n\n\n\n```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}\n#| label: tbl-tabsumstatalterpsychbal\n#| tbl-cap: \"Summary Statistics: Experience of Ageing (psych)\"\n\ntt(sumstat_alter_psych, output = \"markdown\",\n  note = \"This table contains all variables of `alterl*` and only observations where all questions had been answered.\")\n```\n\n\n\n\nTabelle 7.3: Summary Statistics: Experience of Ageing (psych)\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Question\n                n\n                mean\n                sd\n                median\n                trimmed\n                mad\n                min\n                max\n                se\n              \n        \n        \n        \n                \n                  alterl1 \n                  1863\n                  2.655931\n                  1.613659\n                  3\n                  2.757210\n                  1.4826\n                  -2\n                  5\n                  0.03738568\n                \n                \n                  alterl2 \n                  1863\n                  3.281804\n                  1.449666\n                  4\n                  3.429913\n                  1.4826\n                  -2\n                  5\n                  0.03358626\n                \n                \n                  alterl3 \n                  1863\n                  2.348900\n                  1.278429\n                  2\n                  2.277666\n                  1.4826\n                  -2\n                  5\n                  0.02961898\n                \n                \n                  alterl4 \n                  1863\n                  2.763285\n                  1.716885\n                  3\n                  2.963783\n                  1.4826\n                  -2\n                  5\n                  0.03977726\n                \n                \n                  alterl5 \n                  1863\n                  2.990338\n                  1.661439\n                  3\n                  3.196512\n                  1.4826\n                  -2\n                  5\n                  0.03849266\n                \n                \n                  alterl6 \n                  1863\n                  3.404724\n                  1.384050\n                  4\n                  3.537894\n                  1.4826\n                  -2\n                  5\n                  0.03206605\n                \n                \n                  alterl7 \n                  1863\n                  3.236715\n                  1.320460\n                  3\n                  3.325956\n                  1.4826\n                  -2\n                  5\n                  0.03059276\n                \n                \n                  alterl8 \n                  1863\n                  2.712292\n                  1.534387\n                  3\n                  2.684775\n                  1.4826\n                  -2\n                  5\n                  0.03554909\n                \n                \n                  alterl9 \n                  1863\n                  2.969404\n                  1.677112\n                  3\n                  3.142186\n                  1.4826\n                  -2\n                  5\n                  0.03885578\n                \n                \n                  alterl10\n                  1863\n                  2.305421\n                  1.383735\n                  2\n                  2.284373\n                  1.4826\n                  -2\n                  5\n                  0.03205875\n                \n        \n      \n    \n\n\n\n\n\n\n```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}\n#| label: tbl-tabdescriptives\n#| tbl-cap: \"Experience of Ageing: Valuing Relationships and Other People More (By Gender)\"\n\ntt(descriptives, output = \"markdown\")\n```\n\n\n\n\nTabelle 7.4: Experience of Ageing: Valuing Relationships and Other People More (By Gender)\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                geschlecht\n                Mean\n                Count\n                SD\n                Min\n                Max\n              \n        \n        \n        \n                \n                  1\n                  2.713053\n                  927\n                  1.500062\n                  -2\n                  5\n                \n                \n                  2\n                  2.599359\n                  936\n                  1.717715\n                  -2\n                  5\n                \n        \n      \n    \n\n\n\n\n\n\nTable Tabelle 7.1 was created with the function get_summary_stats() of the rstatix package (Kassambara, 2023), Tables Tabelle 7.2 and Tabelle 7.3 were created with the function describe() of the psych package (William Revelle, 2023), and Table Tabelle 7.4 was created with the function summarize() of the dplyr package (Wickham et al., 2023).\n\nKassambara, A. (2023). rstatix: Pipe-Friendly Framework for Basic Statistical Tests. https://CRAN.R-project.org/package=rstatix\n\nWilliam Revelle. (2023). psych: Procedures for Psychological, Psychometric, and Personality Research. Northwestern University. https://CRAN.R-project.org/package=psych\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr\n\n\n7.3.5 Use the Likert Scale using gglikert()\nWe have seen that the data contain not only the five different (Likert scaled) answers. Thus, let us remove all values that have, in one or multiple questions, no answer of the Likert scale. The cleaned dataset is named df_alterl_balance.\n\ndf_alterl_balance &lt;- df_alterl %&gt;%\n  rowwise() %&gt;%\n  mutate(has_negative = ifelse(any(c(across(alterl1:alterl10)) &lt; 0), 1, 0)) |&gt; \n  filter(has_negative == 0) |&gt; \n  select(starts_with(\"alter\")) |&gt; \n  as_tibble()\n\nUsing the gglikert() of the ggstats package (Larmarange, 2023) allows us to draw nice graphs. I highly recommend reading the vignette of the package in the R documentation which you get with vignette(\"gglikert\").\n\nLarmarange, J. (2023). ggstats: Extension to ’ggplot2’ for Plotting Stats. https://CRAN.R-project.org/package=ggstats\nFigures Abbildung 7.1 and Abbildung 7.3 shows the proportions of answers using df_alterl data and Figures Abbildung 7.2 and Abbildung 7.4 does so using the df_alterl_balance data whereby the latter to show the proportions stacked. Do you see any difference and can you explain the differences?\n\n\n\n\n\nAbbildung 7.1: Experience of Ageing: Proportions of Answers (df_alterl)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 7.2: Experience of Ageing: Proportions of Answers (df_alterl_balance)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 7.3: Experience of Ageing: Proportions of Answers - Stacked (df_alter)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 7.4: Experience of Ageing: Proportions of Answers - Stacked (df_alterl_balance)\n\n\n\n\n\n\n\n\nAs we are interested in the differences of the two samples, it makes sense to look as the summary statistics for the df_alter_balance sample. This is shown in Table Tabelle 7.3.",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Descriptive Statistics of the NRW80+ Dataset</span>"
    ]
  },
  {
    "objectID": "desc_NRW.html#cross-referencing-in-r-markdown",
    "href": "desc_NRW.html#cross-referencing-in-r-markdown",
    "title": "7  Descriptive Statistics of the NRW80+ Dataset",
    "section": "7.4 Cross-Referencing in R Markdown",
    "text": "7.4 Cross-Referencing in R Markdown\nIn adherence to the APA style guidelines (Association et al., 2022), it is imperative to reference all figures and tables by their respective numbers within the text. Avoid using generic phrases like “the table above” or “the figure below.” Additionally, refrain from hard-coding the numbers for a more dynamic and standardized approach. Xie et al. (2023) explains concisely how to do that with R Markdown, see: https://bookdown.org/yihui/rmarkdown-cookbook/cross-ref.html.\n\nAssociation, A. P. et al. (2022). Publication manual of the American psychological association. : American Psychological Association.\n\nXie, Y., Dervieux, C., & Riederer, E. (2023). R Markdown Cookbook. online. https://bookdown.org/yihui/rmarkdown-cookbook/\nFor example, I can refer to Table Tabelle 7.1 with @tbl-tabrstatix because I have specified the corresponding label in the R code-chunk, see:",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Descriptive Statistics of the NRW80+ Dataset</span>"
    ]
  },
  {
    "objectID": "desc_NRW.html#exercises",
    "href": "desc_NRW.html#exercises",
    "title": "7  Descriptive Statistics of the NRW80+ Dataset",
    "section": "7.5 Exercises",
    "text": "7.5 Exercises\n\nWith knitr::purl(\"desc_NRW80.Rmd\") you can extract the whole R code from the R Markdown file and write it into the R script desc_NRW80.R. Try it.\nThe dataset gesis.RData comes with two different tibbles: dfsav and dfdta. Is there a difference between these two when it comes to the statistics that are shown in this paper? To check that, rename the pdf file desc_NRW80.pdf, change the code in Section @ref(sec-load) so that you are using the other data (df &lt;- dfdta |&gt; ... vs. df &lt;- dfsav |&gt; ...), knit the Rmd again, and compare the stats.\nCheck possible differences in the gglikert plots when using df_alterl_un instead of df_alterl.\nThe stats above show that dealing with missing or non-standard answers is a crucial thing. Please read chapter Missing Values of Wickham & Grolemund (2023), see: https://r4ds.hadley.nz/missing-values.\nThe labels of the variables alterl1:alterl10 have “Alternserleben:” at the beginning. This is not necessary and overloads the graphs. Please change the labels for all graphs using the following code in the respective place in the rmd and then knit it again.\n\n\nWickham, H., & Grolemund, G. (2023). R for Data Science (2e). https://r4ds.hadley.nz/\n\n# Remove the common prefix from all variables\ndf &lt;- df |&gt; \n  mutate_all(~ set_label(., gsub(\"^Alternserleben: \", \"\", get_label(.))))\n\n\n\n\nAbbildung 7.1: Experience of Ageing: Proportions of Answers (df_alterl)\nAbbildung 7.2: Experience of Ageing: Proportions of Answers (df_alterl_balance)\nAbbildung 7.3: Experience of Ageing: Proportions of Answers - Stacked (df_alter)\nAbbildung 7.4: Experience of Ageing: Proportions of Answers - Stacked (df_alterl_balance)",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Descriptive Statistics of the NRW80+ Dataset</span>"
    ]
  },
  {
    "objectID": "ttest.html",
    "href": "ttest.html",
    "title": "8  Statistisch testen",
    "section": "",
    "text": "8.1 t-Test\nDer Begriff “t-Test” und “Student’s t-Test” werden oft synonym verwendet. Der t-Test ist aber nur einer von vielen Tests um zu bestimmen, ob es signifikante Unterschiede zwischen den Mittelwerten zweier Gruppen gibt.",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistisch testen</span>"
    ]
  },
  {
    "objectID": "ttest.html#t-test",
    "href": "ttest.html#t-test",
    "title": "8  Statistisch testen",
    "section": "",
    "text": "8.1.1 Unterschiedliche Arten\nEin t-Test kann auf verschiedene Arten durchgeführt werden, je nach Situation und Vorannahmen:\n\nEin-Stichproben-t-Test: Testet, ob der Mittelwert einer Stichprobe von einem bekannten Mittelwert abweicht.\nUnabhängiger t-Test / Zweistichproben-t-Test: Testet Unterschiede zwischen den Mittelwerten von zwei unabhängigen Gruppen.\nAbhängiger t-Test / Paarweiser t-Test: Testet Unterschiede zwischen den Mittelwerten von verbundenen oder gepaarten Stichproben (z.B. Vorher-Nachher-Messungen).\n\n\n\n8.1.2 Vorraussetzungen\nDer einfache t-Test setzt die folgenden Charakteristika der Daten voraus:\n\nUnabhängigkeit der Beobachtungen: Jede Versuchsperson sollte nur einer Gruppe angehören. Es sollte keine Beziehung zwischen den Beobachtungen in jeder Gruppe geben.\n\nSollte diese Annahme nicht erfüllt sein, muss ein paarweiser t-Test verwendet werden.\n\nKeine signifikanten Ausreißer in den beiden Gruppen: Ausreißer können das Testergebnis stark beeinflussen und sollten daher vermieden werden.\n\nSollte diese Annahme nicht erfüllt sein, sollte man sich Gedanken machen, ob ein statistischer Test mit den Aussreißern Sinn ergibt. Eventuell ist eine Datenbereinigung sinnvoll oder die Verwendung von Teststatistiken die empfindlich gegenüber Ausreißern sind (z.B.: Mann-Whitney-U-Test).\n\nVarianzgleichheit: Die Varianz der abhängigen Variable sollte in jeder Gruppe gleich sein. Zu beachten ist, dass der Welch-t-Test diese Annahme nicht voraussetzt.\n\nSollte diese Annahme nicht erfüllt sein, ist der Welch-t-Tests eine Alternative, die zwar eine niedrigere statistische Power hat, aber die Annahme der Varianzgleichheit nicht benötigt.\n\n\n\n\n\n\n\n\nTipp\n\n\n\nWenn Sie einen Test durchführen wollen, stellen Sie sicher, dass Ihre Daten die oben genannten Voraussetzungen erfüllen.\n\n\n\n\n8.1.3 Gepaarter t-Test\nEin gepaarter t-Test (paired t-test) wird durchgeführt, wenn man zwei Variablen verbundener Beobachtungen hat. Der gepaarte t-Test ist geeignet, wenn die Beobachtungen innerhalb jedes Paares korreliert (abhängig) sind und man überprüfen möchte, ob es einen statistisch signifikanten Unterschied in ihren Mittelwerten gibt. Typische Situationen sind:\n\nWiederholte Messungen: Die gleiche Gruppe von Subjekten oder Einheiten wird unter verschiedenen Bedingungen, Behandlungen oder Zeitpunkten gemessen. Beispiel: Vorher-Nachher-Messungen derselben Personen.\nGepaarte Paare: Beobachtungen sind auf irgendeine Weise natürlich gepaart, z.B. bei einem Cross-Over-Studien-Design, wo jedes Subjekt beide Behandlungen erhält und die Ergebnisse für jedes Subjekt verglichen werden.\nVorher-Nachher-Vergleiche: Messungen vor und nach einer Intervention oder einem Ereignis für dieselbe Gruppe von Subjekten.\nLinks-rechts-Vergleiche: Vergleich von Messungen von der linken und rechten Seite des Körpers oder von zwei eng verwandten Proben, wie Geschwistern oder Zwillingen.\n\n\n\n8.1.4 t-Testen mit R\nIn R bietet die Funktion t.test mehrere Argumente, die angepasst werden können. Um die voreingestellten Werte der Argumente zu sehen, ist ein Blick in die Dokumentation notwendig. Hierzu einfach ?t.test in die R-Konsole eingeben. Im Folgenden gebe ich eine Übersicht über die wichtigsten Argumente und deren Standardwerte:\n\nt.test(x, y = NULL,\n       alternative = c(\"two.sided\", \"less\", \"greater\"),\n       mu = 0,\n       paired = FALSE,\n       var.equal = FALSE,\n       conf.level = 0.95)\n\nBeschreibung der Argumente:\n\nx: Ein numerischer Vektor der Datenwerte.\ny: Ein optionaler numerischer Vektor der Datenwerte. Wenn y nicht NULL ist, wird ein Zweistichprobentest durchgeführt.\nalternative: Gibt die Form der Alternativhypothese an. Kann sein:\n\n\"two.sided\" (zweiseitig) (Standard)\n\"less\" (einseitig, Test auf kleiner)\n\"greater\" (einseitig, Test auf größer)\n\nmu: Der wahre Mittelwert oder die Differenz der Mittelwerte unter der Nullhypothese. Standard ist 0.\npaired: Ein logischer Wert, der angibt, ob ein gepaarter Test durchgeführt wird. Standard ist FALSE.\nvar.equal: Ein logischer Wert, der angibt, ob die beiden Populationen gleiche Varianzen haben. Standard ist FALSE.\nconf.level: Das Konfidenzniveau des Intervalls. Standard ist 0.95.\n\n\n\n\n\n\n\nTipp\n\n\n\nStellen Sie sicher, dass ihre Daten numerische Variablen sind. In dem Datensatz df_cleaned, den ich in Kapitel 3 beschreibe sind die Daten aber als Faktor Variablen kodiert. Dies kann einfach geändert werden:\n\nif (!require(pacman)) install.packages(\"pacman\")\n\nLoading required package: pacman\n\npacman::p_load(tidyverse, janitor, psych, tinytable, ggstats, car, ggstatsplot,\n               modelsummary, knitr, kableExtra, ggpubr, rstatix, rempsyc)\nrm(list = ls())\n\nload(\"~/Dropbox/hsf/github/ewa/ss_24/read_in_71/data_71.RData\")\n\ndf_test &lt;- df_cleaned |&gt; \n  mutate_at(vars(starts_with(\"item_\")), as.numeric)\n\nhead(df_test)\n\n# A tibble: 6 × 31\n     id group item_1 item_2 item_3 item_4 item_5 item_6 item_7 item_8 item_9\n  &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     1     1      4      3      4      5      2      3      2      2      3\n2     2     0      4      4      3      4      4      5      3      3      4\n3     3     1      1      3      4      3      3      4      4      3      4\n4     4     1      3      3      5      3      2      3      1      3      2\n5     5     1      3      3      2      5      4      4      4      3      4\n6     6     0      3      3      2      2      2      3      2      2      2\n# ℹ 20 more variables: item_10 &lt;dbl&gt;, item_11 &lt;dbl&gt;, item_12 &lt;dbl&gt;,\n#   item_13 &lt;dbl&gt;, item_14 &lt;dbl&gt;, item_15 &lt;dbl&gt;, item_16 &lt;dbl&gt;, item_17 &lt;dbl&gt;,\n#   item_18 &lt;dbl&gt;, item_19 &lt;dbl&gt;, item_20 &lt;dbl&gt;, item_21 &lt;dbl&gt;, outlier &lt;dbl&gt;,\n#   has_outlier &lt;lgl&gt;, count_larger_5 &lt;int&gt;, count_typos &lt;int&gt;,\n#   has_larger_5_notypos &lt;lgl&gt;, has_typos &lt;lgl&gt;, has_nas &lt;lgl&gt;, complete &lt;lgl&gt;\n\n\n\n\n\n\n\n\n\n\nLong und Wide Format\n\n\n\nOft ist es empfehlenswert den Datensatz in das sogenannte Long Format zu überführen. Wie zwischen dem Long-Format und den Wide-Format gewechselt werden kann, bitte ich Wickham & Grolemund (2023): 5.3 Lengthening data zu entnehmen. Hier ein Beispiel:\n\ndf_test_long &lt;- df_test |&gt; \n  pivot_longer(cols = starts_with(\"item_\"), # Zu pivotierende Spalten\n               names_to = \"item\",           # Neue Spalte für die Namen der Items\n               values_to = \"value\")  |&gt;     # Neue Spalte für die Werte der Items\n  select(id, group, complete, item, value)\nhead(df_test_long)\n\n\n\n\nWickham, H., & Grolemund, G. (2023). R for Data Science (2e). https://r4ds.hadley.nz/",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistisch testen</span>"
    ]
  },
  {
    "objectID": "ttest.html#beispiel",
    "href": "ttest.html#beispiel",
    "title": "8  Statistisch testen",
    "section": "8.2 Beispiel",
    "text": "8.2 Beispiel\n\n\n\n\n\n\nKopieren Sie dieses Skript und führen Sie es aus:\n\n\n\n\n\n\n## ----echo=TRUE, message=FALSE-----------------------------------------------\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, psych, tinytable, ggstats, car, ggstatsplot, \n               modelsummary, knitr, kableExtra, ggpubr, rstatix, rempsyc)\nrm(list = ls())\n\nload(\"~/Dropbox/hsf/github/ewa/ss_24/read_in_71/data_71.RData\")\n\n# Zuerst wandle ich die Daten etwas um, so dass ich keine Faktorvariable mehr habe:\ndf_test &lt;- df_cleaned |&gt; \n  mutate_at(vars(starts_with(\"item_\")), as.numeric)\n\n# ##########################\n# Ein-Stichproben t-Test\n# ##########################\n\nt.test(df_test$item_1, mu = 1)\nt.test(df_test$item_1, mu = 3)\n\n# Standardmäßig führt t.test einen zweiseitigen Test durch:\nt.test(df_test$item_1, mu = 3, alternative = \"two.sided\")\n\n# Sie können einen Test für einen Teil der Daten durchführen, indem Sie ein Argument der t.test-Funktion verwenden:\nt.test(df_test$item_1, \n       mu = 3, \n       alternative = \"two.sided\",\n       subset(df_test, group == 0))\n\nt.test(df_test$item_1, \n       mu = 3,\n       alternative = \"greater\")\n\nt.test(df_test$item_1, \n       mu = 3,\n       alternative = \"less\")\n\n# ##########################\n# Zweiseitiger t-Test in R\n# ##########################\n\n# ----------------------------\n# Für Daten im Breitformat:\n# ----------------------------\n\n# Welch-Test\nt.test(df_test$item_1, df_test$item_2, data = df_test)\n\n# Student's t-Test\nt.test(df_test$item_1, df_test$item_2, data = df_test, var.equal = TRUE)\n\n# Welch-Test\nt.test(df_test$item_1, df_test$item_2, data = df_test, \n       paired = TRUE, \n       var.equal = TRUE)\n\n## Die Antworten kommen von der selben Person, daher paired = TRUE\n\n# ----------------------------\n# Für Daten im Langformat:\n# ----------------------------\n\n# Test, ob das item_1 in beiden Gruppen gleich ist\n\n# Erstelle ein Boxplot von item_1 über Gruppen mit ggplot2\nggplot(df_test, aes(x = factor(group), y = item_1)) +\n  geom_boxplot() +\n  labs(x = \"Group\", y = \"Item 1\") +\n  ggtitle(\"Boxplot of Item 1 Across Groups\")\n\nggbetweenstats(\n  data = df_test,\n  x = group,\n  y = item_1\n)\n\n## Wenn Normalitäts- und Varianzannahmen erfüllt sind:\nt.test(item_1 ~ group, data = df_test, var.equal = FALSE)\n\n# OK, aber wie testet man nun,\n# ob die Antworten aller items in den jeweiligen Gruppen gleich sind? \n\n# Zuerst empfiehlt sich eine Umwandlung in das Langformat:\ndf_test_long &lt;- df_test |&gt; \n  pivot_longer(cols = starts_with(\"item_\"), # Zu pivotierende Spalten\n               names_to = \"item\",           # Neue Spalte für die Namen der Items\n               values_to = \"value\")  |&gt;     # Neue Spalte für die Werte der Items\n  select(id, group, complete, item, value)\n\n# Erstelle ein Boxplot von value über Gruppen mit ggplot2\nggplot(df_test_long, aes(x = factor(group), y = value)) +\n  geom_boxplot() +\n  labs(x = \"Group\", y = \"Item 1\") +\n  ggtitle(\"Boxplot of all items Across Groups\")\n\nggbetweenstats(\n  data = df_test_long,\n  x = group,\n  y = value\n)\n\n\n# ##########################\n# Prüfung der Normalitätsannahme\n# ##########################\n\n## Mit Shapiro\ndf_test |&gt; \n  group_by(group) |&gt; \n  shapiro_test(item_1)\n\n## Mit QQ-Plots\nggqqplot(df_test, x = \"item_1\", facet.by = \"group\")\n\n# Wenn der p-Wert klein ist, müssen wir einen Test verwenden, der keine Normalverteilung annimmt \n# --&gt; Mann-Whitney-U-Test (auch Wilcoxon-Rangsummentest genannt) vergleicht die Mediane \n# von zwei unabhängigen Gruppen und ist robust gegenüber \n# Nicht-Normalverteilung und unterschiedlichen Varianzen.\n\n# ##########################\n# Überprüfung der Varianzhomogenität\n# ##########################\n\n## Mit Levene\nleveneTest(item_1 ~ as.character(group), data = df_test)\n\n## Mit bartlett.test\nbartlett.test(item_1 ~ group, data = df_test)\n\n## Mit Fligner-Kelleen\nfligner.test(item_1 ~ group, data = df_test)\n\n# Wenn der p-Wert klein ist, ist die Varianz zwischen den Gruppen unterschiedlich und \n# wir müssen einen Test verwenden, der keine Normalverteilung annimmt \n# --&gt; Welch-t-Test (oder Mann-Whitney)\n\n# ##########################\n# Test \n# ##########################\n\n## Wenn Normalitäts- und Varianzannahmen erfüllt sind:\nt.test(item_1 ~ group, data = df_test, var.equal = TRUE)\n\n## Wenn Normalität erfüllt ist und Varianz nicht:\nt.test(item_1 ~ group, data = df_test, var.equal = FALSE)\n\n## Wenn Normalität nicht erfüllt ist:\nwilcox.test(item_1 ~ group, data = df_test)\n\n\n\n\nHier ist der Inhalt des Skriptes und der R-Output zu sehen:\n\n## ----echo=TRUE, message=FALSE-----------------------------------------------\nif (!require(pacman)) install.packages(\"pacman\")\npacman::p_load(tidyverse, janitor, psych, tinytable, ggstats, car, ggstatsplot, \n               modelsummary, knitr, kableExtra, ggpubr, rstatix, rempsyc)\nrm(list = ls())\n\nload(\"~/Dropbox/hsf/github/ewa/ss_24/read_in_71/data_71.RData\")\n\n# Zuerst wandle ich die Daten etwas um, so dass ich keine Faktorvariable mehr habe:\ndf_test &lt;- df_cleaned |&gt; \n  mutate_at(vars(starts_with(\"item_\")), as.numeric)\n\n# ##########################\n# Ein-Stichproben t-Test\n# ##########################\n\nt.test(df_test$item_1, mu = 1)\n\n\n    One Sample t-test\n\ndata:  df_test$item_1\nt = 15.448, df = 66, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 1\n95 percent confidence interval:\n 2.689525 3.191072\nsample estimates:\nmean of x \n 2.940299 \n\nt.test(df_test$item_1, mu = 3)\n\n\n    One Sample t-test\n\ndata:  df_test$item_1\nt = -0.47532, df = 66, p-value = 0.6361\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 2.689525 3.191072\nsample estimates:\nmean of x \n 2.940299 \n\n# Standardmäßig führt t.test einen zweiseitigen Test durch:\nt.test(df_test$item_1, mu = 3, alternative = \"two.sided\")\n\n\n    One Sample t-test\n\ndata:  df_test$item_1\nt = -0.47532, df = 66, p-value = 0.6361\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 2.689525 3.191072\nsample estimates:\nmean of x \n 2.940299 \n\n# Sie können einen Test für einen Teil der Daten durchführen, indem Sie ein Argument der t.test-Funktion verwenden:\nt.test(df_test$item_1, \n       mu = 3, \n       alternative = \"two.sided\",\n       subset(df_test, group == 0))\n\n\n    Welch Two Sample t-test\n\ndata:  df_test$item_1 and subset(df_test, group == 0)\nt = -14.256, df = 674.05, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 3\n95 percent confidence interval:\n -1.02438061 -0.05000914\nsample estimates:\nmean of x mean of y \n 2.940299  3.477493 \n\nt.test(df_test$item_1, \n       mu = 3,\n       alternative = \"greater\")\n\n\n    One Sample t-test\n\ndata:  df_test$item_1\nt = -0.47532, df = 66, p-value = 0.6819\nalternative hypothesis: true mean is greater than 3\n95 percent confidence interval:\n 2.73076     Inf\nsample estimates:\nmean of x \n 2.940299 \n\nt.test(df_test$item_1, \n       mu = 3,\n       alternative = \"less\")\n\n\n    One Sample t-test\n\ndata:  df_test$item_1\nt = -0.47532, df = 66, p-value = 0.3181\nalternative hypothesis: true mean is less than 3\n95 percent confidence interval:\n     -Inf 3.149837\nsample estimates:\nmean of x \n 2.940299 \n\n# ##########################\n# Zweiseitiger t-Test in R\n# ##########################\n\n# ----------------------------\n# Für Daten im Breitformat:\n# ----------------------------\n\n# Welch-Test\nt.test(df_test$item_1, df_test$item_2, data = df_test)\n\n\n    Welch Two Sample t-test\n\ndata:  df_test$item_1 and df_test$item_2\nt = 0.5873, df = 132.42, p-value = 0.558\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.2361367  0.4355743\nsample estimates:\nmean of x mean of y \n 2.940299  2.840580 \n\n# Student's t-Test\nt.test(df_test$item_1, df_test$item_2, data = df_test, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  df_test$item_1 and df_test$item_2\nt = 0.588, df = 134, p-value = 0.5575\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.2357030  0.4351406\nsample estimates:\nmean of x mean of y \n 2.940299  2.840580 \n\n# Welch-Test\nt.test(df_test$item_1, df_test$item_2, data = df_test, \n       paired = TRUE, \n       var.equal = TRUE)\n\n\n    Paired t-test\n\ndata:  df_test$item_1 and df_test$item_2\nt = 0.71556, df = 66, p-value = 0.4768\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.1870352  0.3959904\nsample estimates:\nmean difference \n      0.1044776 \n\n## Die Antworten kommen von der selben Person, daher paired = TRUE\n\n# ----------------------------\n# Für Daten im Langformat:\n# ----------------------------\n\n# Test, ob das item_1 in beiden Gruppen gleich ist\n\n# Erstelle ein Boxplot von item_1 über Gruppen mit ggplot2\nggplot(df_test, aes(x = factor(group), y = item_1)) +\n  geom_boxplot() +\n  labs(x = \"Group\", y = \"Item 1\") +\n  ggtitle(\"Boxplot of Item 1 Across Groups\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = df_test,\n  x = group,\n  y = item_1\n)\n\n\n\n\n\n\n\n## Wenn Normalitäts- und Varianzannahmen erfüllt sind:\nt.test(item_1 ~ group, data = df_test, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  item_1 by group\nt = 0.035326, df = 63.704, p-value = 0.9719\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.4978170  0.5157382\nsample estimates:\nmean in group 0 mean in group 1 \n       2.944444        2.935484 \n\n# OK, aber wie testet man nun,\n# ob die Antworten aller items in den jeweiligen Gruppen gleich sind? \n\n# Zuerst empfiehlt sich eine Umwandlung in das Langformat:\ndf_test_long &lt;- df_test |&gt; \n  pivot_longer(cols = starts_with(\"item_\"), # Zu pivotierende Spalten\n               names_to = \"item\",           # Neue Spalte für die Namen der Items\n               values_to = \"value\")  |&gt;     # Neue Spalte für die Werte der Items\n  select(id, group, complete, item, value)\n\n# Erstelle ein Boxplot von value über Gruppen mit ggplot2\nggplot(df_test_long, aes(x = factor(group), y = value)) +\n  geom_boxplot() +\n  labs(x = \"Group\", y = \"Item 1\") +\n  ggtitle(\"Boxplot of all items Across Groups\")\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = df_test_long,\n  x = group,\n  y = value\n)\n\n\n\n\n\n\n\n# ##########################\n# Prüfung der Normalitätsannahme\n# ##########################\n\n## Mit Shapiro\ndf_test |&gt; \n  group_by(group) |&gt; \n  shapiro_test(item_1)\n\n# A tibble: 2 × 4\n  group variable statistic       p\n  &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n1     0 item_1       0.903 0.00415\n2     1 item_1       0.909 0.0121 \n\n## Mit QQ-Plots\nggqqplot(df_test, x = \"item_1\", facet.by = \"group\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_qq()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_qq_line()`).\nRemoved 2 rows containing non-finite outside the scale range\n(`stat_qq_line()`).\n\n\n\n\n\n\n\n\n# Wenn der p-Wert klein ist, müssen wir einen Test verwenden, der keine Normalverteilung annimmt \n# --&gt; Mann-Whitney-U-Test (auch Wilcoxon-Rangsummentest genannt) vergleicht die Mediane \n# von zwei unabhängigen Gruppen und ist robust gegenüber \n# Nicht-Normalverteilung und unterschiedlichen Varianzen.\n\n# ##########################\n# Überprüfung der Varianzhomogenität\n# ##########################\n\n## Mit Levene\nleveneTest(item_1 ~ as.character(group), data = df_test)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  0.0048 0.9451\n      65               \n\n## Mit bartlett.test\nbartlett.test(item_1 ~ group, data = df_test)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  item_1 by group\nBartlett's K-squared = 0.0028132, df = 1, p-value = 0.9577\n\n## Mit Fligner-Kelleen\nfligner.test(item_1 ~ group, data = df_test)\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  item_1 by group\nFligner-Killeen:med chi-squared = 0.0049046, df = 1, p-value = 0.9442\n\n# Wenn der p-Wert klein ist, ist die Varianz zwischen den Gruppen unterschiedlich und \n# wir müssen einen Test verwenden, der keine Normalverteilung annimmt \n# --&gt; Welch-t-Test (oder Mann-Whitney)\n\n# ##########################\n# Test \n# ##########################\n\n## Wenn Normalitäts- und Varianzannahmen erfüllt sind:\nt.test(item_1 ~ group, data = df_test, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  item_1 by group\nt = 0.035301, df = 65, p-value = 0.9719\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.4979828  0.5159040\nsample estimates:\nmean in group 0 mean in group 1 \n       2.944444        2.935484 \n\n## Wenn Normalität erfüllt ist und Varianz nicht:\nt.test(item_1 ~ group, data = df_test, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  item_1 by group\nt = 0.035326, df = 63.704, p-value = 0.9719\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.4978170  0.5157382\nsample estimates:\nmean in group 0 mean in group 1 \n       2.944444        2.935484 \n\n## Wenn Normalität nicht erfüllt ist:\nwilcox.test(item_1 ~ group, data = df_test)\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  item_1 by group\nW = 566, p-value = 0.9206\nalternative hypothesis: true location shift is not equal to 0",
    "crumbs": [
      "Anwendungen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistisch testen</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Association, A. P. et al. (2022). Publication manual of the american\npsychological association. : American Psychological Association.\n\n\nAust, F., & Barth, M. (2023). papaja: Prepare reproducible\nAPA journal articles with R Markdown. https://github.com/crsh/papaja\n\n\nBauer, P. C., & Landesvatter, C. (2023). Writing a reproducible\npaper with RStudio and quarto. https://doi.org/10.31219/osf.io/ur4xn\n\n\nChilds, D. Z., Hindle, B. J., & Warren, P. H. (2021). APS 240:\nData analysis and statistics with r. online. https://dzchilds.github.io/stats-for-bio\n\n\nFirke, S. (2023). Janitor: Simple tools for examining and cleaning\ndirty data. https://CRAN.R-project.org/package=janitor\n\n\nGandrud, C. (2020). Reproducible research with r and r studio\n(3rd ed.). Chapman; Hall/CRC.\n\n\nHuber, S. (2024a). Empirisch-wissenschaftlich arbeiten (ewa).\nGitHub repository. https://github.com/hubchev/ewa\n\n\nHuber, S. (2024b). How to use R for data science:\nLecture notes. https://hubchev.github.io/ds/\n\n\nHuber, S. (2024c). Quantitative methods: Lecture notes. https://hubchev.github.io/qm/\n\n\nHuber, S., & Rust, C. (2016). Calculate travel time and distance\nwith OpenStreetMap data using the open source routing machine (OSRM).\nThe Stata Journal, 16(2), 416–423.\n\n\nKassambara, A. (2023). Rstatix: Pipe-friendly framework for basic\nstatistical tests. https://CRAN.R-project.org/package=rstatix\n\n\nLarmarange, J. (2023). Ggstats: Extension to ’ggplot2’ for plotting\nstats. https://CRAN.R-project.org/package=ggstats\n\n\nLüdecke, D. (2018). Sjmisc: Data and variable transformation functions.\nJournal of Open Source Software, 3(26), 754. https://doi.org/10.21105/joss.00754\n\n\nTelford, R. J. (2023). Enough markdown to write a thesis. https://biostats-r.github.io/biostats/quarto/\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D.\n(2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr\n\n\nWickham, H., & Grolemund, G. (2023). R for data science\n(2e). https://r4ds.hadley.nz/\n\n\nWickham, H., & Henry, L. (2023). Purrr: Functional programming\ntools. https://CRAN.R-project.org/package=purrr\n\n\nWilliam Revelle. (2023). Psych: Procedures for psychological,\npsychometric, and personality research. Northwestern University. https://CRAN.R-project.org/package=psych\n\n\nWysocki, A. C., Lawson, K. M., & Rhemtulla, M. (2022). Statistical\ncontrol requires causal justification. Advances in Methods and\nPractices in Psychological Science, 5(2). https://doi.org/10.1177/25152459221095823\n\n\nXie, Y., Dervieux, C., & Riederer, E. (2023). R markdown\ncookbook. online. https://bookdown.org/yihui/rmarkdown-cookbook/\n\n\nZank, S., Woopen, C., Wagner, M., Rietz, C., & Kaspar, R. (2022).\nQuality of life and well-being of very old people in NRW\n(representative survey NRW80+) - cross-section wave 1. GESIS,\nCologne. ZA7558 Data file Version 2.0.0. https://doi.org/10.4232/1.13978",
    "crumbs": [
      "Literatur"
    ]
  }
]